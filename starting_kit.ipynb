{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size,\n",
    "                embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "        # Implementation...\n",
    "        # Embedding 词向量的维数为：128\n",
    "        # input_x的输入的维度有两个，第一个代表句子的个数，None即代表不确定，第二个代表每个句子字词的长度: l * n\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name='input_x')\n",
    "        # num_classes 意味要分类的个数\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n",
    "        \n",
    "        # 为L2正则化系数设一个初始值\n",
    "        l2_loss = tf.constant(0.0)\n",
    "        \n",
    "        # Embedding layer 嵌入层，把每个word用128维向量来进行表示\n",
    "        with tf.device('/cpu:0'), tf.name_scope(embedding):\n",
    "            W = tf.Variable(\n",
    "                # random uniform代表从min到max的随机值\n",
    "                # vocab_size 行，128列的随机矩阵\n",
    "                # h * k\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name='W'\n",
    "            )\n",
    "            # embedding_lookup找W矩阵里的input_x的行数\n",
    "            # expand_dims在-1的地方增加一个维度\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "        \n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes): # [3, 4, 5]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'scope1/W:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'scopr2/W:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"scope1\", reuse=True):\n",
    "    W = tf.get_variable(name=\"W\", initializer=1.)\n",
    "    print(W)\n",
    "    \n",
    "with tf.variable_scope(\"scopr2\", reuse=True):\n",
    "    W = tf.get_variable(name=\"W\", initializer=2.)\n",
    "    print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN\t W\t attr\t data_helpers\t datetime\t learn\t max_document_length\t np\t os\t \n",
      "tf\t time\t value\t vocab_processor\t warnings\t x\t x_text\t y\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=64\n",
      "CHECKPOINT_EVERY=100\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=100\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NEGATIVE_DATA_FILE=./data/rt-polaritydata/rt-polarity.neg\n",
      "NUM_CHECKPOINTS=5\n",
      "NUM_EPOCHS=200\n",
      "NUM_FILTERS=128\n",
      "POSITIVE_DATA_FILE=./data/rt-polaritydata/rt-polarity.pos\n",
      "\n",
      "Loading data...\n",
      "len(x_text):  10662\n",
      "len(y):  10662\n",
      "Vocabulary Size: 18758\n",
      "Train/Dev split: 9596/1066\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n",
      "Writing to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\n",
      "\n",
      "2018-04-13T14:54:46.256372: step 1, loss 1.82538, acc 0.59375\n",
      "2018-04-13T14:54:46.547075: step 2, loss 2.37473, acc 0.421875\n",
      "2018-04-13T14:54:46.836780: step 3, loss 2.01898, acc 0.546875\n",
      "2018-04-13T14:54:47.151503: step 4, loss 1.52334, acc 0.546875\n",
      "2018-04-13T14:54:47.459721: step 5, loss 2.62774, acc 0.453125\n",
      "2018-04-13T14:54:47.754933: step 6, loss 2.22831, acc 0.484375\n",
      "2018-04-13T14:54:48.048136: step 7, loss 1.80262, acc 0.546875\n",
      "2018-04-13T14:54:48.361357: step 8, loss 1.86996, acc 0.609375\n",
      "2018-04-13T14:54:48.650562: step 9, loss 2.31217, acc 0.421875\n",
      "2018-04-13T14:54:48.964282: step 10, loss 1.58752, acc 0.546875\n",
      "2018-04-13T14:54:49.363565: step 11, loss 1.55005, acc 0.5\n",
      "2018-04-13T14:54:49.690797: step 12, loss 2.69318, acc 0.5\n",
      "2018-04-13T14:54:50.000515: step 13, loss 1.59295, acc 0.5625\n",
      "2018-04-13T14:54:50.308234: step 14, loss 2.18914, acc 0.46875\n",
      "2018-04-13T14:54:50.624963: step 15, loss 2.12168, acc 0.515625\n",
      "2018-04-13T14:54:50.916163: step 16, loss 1.75268, acc 0.453125\n",
      "2018-04-13T14:54:51.222380: step 17, loss 1.14082, acc 0.609375\n",
      "2018-04-13T14:54:51.520590: step 18, loss 0.968596, acc 0.578125\n",
      "2018-04-13T14:54:51.843817: step 19, loss 2.09693, acc 0.4375\n",
      "2018-04-13T14:54:52.145530: step 20, loss 1.91103, acc 0.53125\n",
      "2018-04-13T14:54:52.448748: step 21, loss 1.63179, acc 0.515625\n",
      "2018-04-13T14:54:52.773975: step 22, loss 1.47677, acc 0.53125\n",
      "2018-04-13T14:54:53.090704: step 23, loss 1.65029, acc 0.515625\n",
      "2018-04-13T14:54:53.397919: step 24, loss 2.30144, acc 0.5\n",
      "2018-04-13T14:54:53.711641: step 25, loss 1.55844, acc 0.578125\n",
      "2018-04-13T14:54:54.050876: step 26, loss 1.74489, acc 0.59375\n",
      "2018-04-13T14:54:54.361096: step 27, loss 1.7171, acc 0.546875\n",
      "2018-04-13T14:54:54.672817: step 28, loss 1.1727, acc 0.578125\n",
      "2018-04-13T14:54:55.011555: step 29, loss 2.31038, acc 0.375\n",
      "2018-04-13T14:54:55.384319: step 30, loss 1.81953, acc 0.546875\n",
      "2018-04-13T14:54:55.756578: step 31, loss 2.15649, acc 0.484375\n",
      "2018-04-13T14:54:56.067302: step 32, loss 1.4519, acc 0.578125\n",
      "2018-04-13T14:54:56.395031: step 33, loss 1.46362, acc 0.515625\n",
      "2018-04-13T14:54:56.693743: step 34, loss 1.94867, acc 0.453125\n",
      "2018-04-13T14:54:56.999958: step 35, loss 1.51955, acc 0.65625\n",
      "2018-04-13T14:54:57.321187: step 36, loss 1.8705, acc 0.53125\n",
      "2018-04-13T14:54:57.627901: step 37, loss 1.03611, acc 0.6875\n",
      "2018-04-13T14:54:57.951655: step 38, loss 1.73803, acc 0.59375\n",
      "2018-04-13T14:54:58.252403: step 39, loss 1.48063, acc 0.53125\n",
      "2018-04-13T14:54:58.582130: step 40, loss 1.95433, acc 0.46875\n",
      "2018-04-13T14:54:58.880844: step 41, loss 1.83947, acc 0.5\n",
      "2018-04-13T14:54:59.197063: step 42, loss 1.6753, acc 0.53125\n",
      "2018-04-13T14:54:59.519295: step 43, loss 1.68321, acc 0.5\n",
      "2018-04-13T14:54:59.833018: step 44, loss 2.02002, acc 0.46875\n",
      "2018-04-13T14:55:00.148239: step 45, loss 1.78907, acc 0.515625\n",
      "2018-04-13T14:55:00.477971: step 46, loss 1.61613, acc 0.578125\n",
      "2018-04-13T14:55:00.787689: step 47, loss 1.84324, acc 0.515625\n",
      "2018-04-13T14:55:01.108416: step 48, loss 2.26838, acc 0.484375\n",
      "2018-04-13T14:55:01.436646: step 49, loss 1.68114, acc 0.46875\n",
      "2018-04-13T14:55:01.745865: step 50, loss 1.416, acc 0.484375\n",
      "2018-04-13T14:55:02.096613: step 51, loss 2.29939, acc 0.359375\n",
      "2018-04-13T14:55:02.413335: step 52, loss 1.40124, acc 0.5\n",
      "2018-04-13T14:55:02.718052: step 53, loss 1.63206, acc 0.546875\n",
      "2018-04-13T14:55:03.058795: step 54, loss 1.87845, acc 0.546875\n",
      "2018-04-13T14:55:03.376017: step 55, loss 1.93947, acc 0.5\n",
      "2018-04-13T14:55:03.692740: step 56, loss 1.17835, acc 0.578125\n",
      "2018-04-13T14:55:04.033983: step 57, loss 1.22786, acc 0.671875\n",
      "2018-04-13T14:55:04.349204: step 58, loss 1.47618, acc 0.578125\n",
      "2018-04-13T14:55:04.675436: step 59, loss 1.49761, acc 0.5\n",
      "2018-04-13T14:55:04.997162: step 60, loss 1.55932, acc 0.546875\n",
      "2018-04-13T14:55:05.306381: step 61, loss 1.82896, acc 0.4375\n",
      "2018-04-13T14:55:05.653126: step 62, loss 1.79895, acc 0.546875\n",
      "2018-04-13T14:55:05.987872: step 63, loss 1.52075, acc 0.515625\n",
      "2018-04-13T14:55:06.323097: step 64, loss 1.27804, acc 0.5625\n",
      "2018-04-13T14:55:06.647826: step 65, loss 0.896377, acc 0.625\n",
      "2018-04-13T14:55:06.965049: step 66, loss 1.51625, acc 0.546875\n",
      "2018-04-13T14:55:07.314296: step 67, loss 1.49488, acc 0.5\n",
      "2018-04-13T14:55:07.654538: step 68, loss 1.48562, acc 0.546875\n",
      "2018-04-13T14:55:07.978765: step 69, loss 1.47765, acc 0.546875\n",
      "2018-04-13T14:55:08.274473: step 70, loss 1.38338, acc 0.484375\n",
      "2018-04-13T14:55:08.562677: step 71, loss 1.22867, acc 0.5625\n",
      "2018-04-13T14:55:08.854383: step 72, loss 1.70958, acc 0.390625\n",
      "2018-04-13T14:55:09.246159: step 73, loss 1.32791, acc 0.484375\n",
      "2018-04-13T14:55:09.594906: step 74, loss 1.59254, acc 0.5\n",
      "2018-04-13T14:55:09.899621: step 75, loss 1.62933, acc 0.484375\n",
      "2018-04-13T14:55:10.204837: step 76, loss 1.2961, acc 0.546875\n",
      "2018-04-13T14:55:10.506049: step 77, loss 1.21991, acc 0.640625\n",
      "2018-04-13T14:55:10.794253: step 78, loss 1.58442, acc 0.578125\n",
      "2018-04-13T14:55:11.095966: step 79, loss 1.57526, acc 0.515625\n",
      "2018-04-13T14:55:11.383174: step 80, loss 1.35353, acc 0.578125\n",
      "2018-04-13T14:55:11.664373: step 81, loss 1.09516, acc 0.609375\n",
      "2018-04-13T14:55:11.946072: step 82, loss 1.28858, acc 0.578125\n",
      "2018-04-13T14:55:12.232274: step 83, loss 1.34093, acc 0.59375\n",
      "2018-04-13T14:55:12.536489: step 84, loss 1.8747, acc 0.40625\n",
      "2018-04-13T14:55:12.821689: step 85, loss 1.49374, acc 0.515625\n",
      "2018-04-13T14:55:13.116899: step 86, loss 1.70328, acc 0.46875\n",
      "2018-04-13T14:55:13.400099: step 87, loss 0.946741, acc 0.578125\n",
      "2018-04-13T14:55:13.688302: step 88, loss 1.19485, acc 0.59375\n",
      "2018-04-13T14:55:13.991516: step 89, loss 1.37174, acc 0.546875\n",
      "2018-04-13T14:55:14.281221: step 90, loss 1.63773, acc 0.484375\n",
      "2018-04-13T14:55:14.567423: step 91, loss 1.26237, acc 0.53125\n",
      "2018-04-13T14:55:14.846623: step 92, loss 1.11244, acc 0.671875\n",
      "2018-04-13T14:55:15.137825: step 93, loss 1.30629, acc 0.515625\n",
      "2018-04-13T14:55:15.433535: step 94, loss 1.17201, acc 0.5625\n",
      "2018-04-13T14:55:15.717736: step 95, loss 1.17813, acc 0.609375\n",
      "2018-04-13T14:55:16.005438: step 96, loss 1.13711, acc 0.640625\n",
      "2018-04-13T14:55:16.296644: step 97, loss 1.19199, acc 0.578125\n",
      "2018-04-13T14:55:16.574340: step 98, loss 1.43019, acc 0.46875\n",
      "2018-04-13T14:55:16.864044: step 99, loss 1.27458, acc 0.53125\n",
      "2018-04-13T14:55:17.164757: step 100, loss 1.09258, acc 0.640625\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:55:18.147451: step 100, loss 0.763214, acc 0.571295\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-100\n",
      "\n",
      "2018-04-13T14:55:19.953879: step 101, loss 0.931488, acc 0.65625\n",
      "2018-04-13T14:55:20.250587: step 102, loss 1.4543, acc 0.59375\n",
      "2018-04-13T14:55:20.575349: step 103, loss 1.33549, acc 0.453125\n",
      "2018-04-13T14:55:20.893072: step 104, loss 1.32432, acc 0.5625\n",
      "2018-04-13T14:55:21.185278: step 105, loss 1.5485, acc 0.40625\n",
      "2018-04-13T14:55:21.477165: step 106, loss 1.21966, acc 0.546875\n",
      "2018-04-13T14:55:21.772380: step 107, loss 1.62489, acc 0.4375\n",
      "2018-04-13T14:55:22.079092: step 108, loss 1.27314, acc 0.515625\n",
      "2018-04-13T14:55:22.389308: step 109, loss 0.880491, acc 0.65625\n",
      "2018-04-13T14:55:22.699527: step 110, loss 1.11454, acc 0.546875\n",
      "2018-04-13T14:55:23.004243: step 111, loss 1.19845, acc 0.609375\n",
      "2018-04-13T14:55:23.312461: step 112, loss 1.28812, acc 0.515625\n",
      "2018-04-13T14:55:23.600163: step 113, loss 0.897273, acc 0.609375\n",
      "2018-04-13T14:55:23.893872: step 114, loss 0.892927, acc 0.625\n",
      "2018-04-13T14:55:24.180573: step 115, loss 0.911176, acc 0.640625\n",
      "2018-04-13T14:55:24.466275: step 116, loss 1.33699, acc 0.546875\n",
      "2018-04-13T14:55:24.794007: step 117, loss 1.37543, acc 0.546875\n",
      "2018-04-13T14:55:25.088215: step 118, loss 1.00582, acc 0.609375\n",
      "2018-04-13T14:55:25.374416: step 119, loss 1.40982, acc 0.5625\n",
      "2018-04-13T14:55:25.666623: step 120, loss 1.45612, acc 0.5\n",
      "2018-04-13T14:55:25.969837: step 121, loss 1.46771, acc 0.59375\n",
      "2018-04-13T14:55:26.278556: step 122, loss 1.61126, acc 0.578125\n",
      "2018-04-13T14:55:26.601283: step 123, loss 1.15029, acc 0.5625\n",
      "2018-04-13T14:55:26.893990: step 124, loss 0.911047, acc 0.640625\n",
      "2018-04-13T14:55:27.185195: step 125, loss 1.24528, acc 0.5625\n",
      "2018-04-13T14:55:27.479903: step 126, loss 1.17396, acc 0.53125\n",
      "2018-04-13T14:55:27.773110: step 127, loss 1.36982, acc 0.53125\n",
      "2018-04-13T14:55:28.070821: step 128, loss 1.50747, acc 0.5625\n",
      "2018-04-13T14:55:28.359024: step 129, loss 1.21818, acc 0.59375\n",
      "2018-04-13T14:55:28.658735: step 130, loss 1.54089, acc 0.5625\n",
      "2018-04-13T14:55:28.953445: step 131, loss 1.33291, acc 0.546875\n",
      "2018-04-13T14:55:29.260660: step 132, loss 1.32969, acc 0.5625\n",
      "2018-04-13T14:55:29.551369: step 133, loss 1.26261, acc 0.515625\n",
      "2018-04-13T14:55:29.841571: step 134, loss 1.69879, acc 0.40625\n",
      "2018-04-13T14:55:30.142283: step 135, loss 1.3572, acc 0.53125\n",
      "2018-04-13T14:55:30.423982: step 136, loss 1.47497, acc 0.515625\n",
      "2018-04-13T14:55:30.718190: step 137, loss 1.41765, acc 0.453125\n",
      "2018-04-13T14:55:31.009396: step 138, loss 1.26176, acc 0.578125\n",
      "2018-04-13T14:55:31.313884: step 139, loss 1.50661, acc 0.515625\n",
      "2018-04-13T14:55:31.626103: step 140, loss 1.2314, acc 0.5625\n",
      "2018-04-13T14:55:31.915308: step 141, loss 1.25061, acc 0.546875\n",
      "2018-04-13T14:55:32.212018: step 142, loss 1.30467, acc 0.484375\n",
      "2018-04-13T14:55:32.505725: step 143, loss 1.0144, acc 0.546875\n",
      "2018-04-13T14:55:32.805437: step 144, loss 1.13086, acc 0.59375\n",
      "2018-04-13T14:55:33.095642: step 145, loss 1.25973, acc 0.484375\n",
      "2018-04-13T14:55:33.381843: step 146, loss 1.2074, acc 0.484375\n",
      "2018-04-13T14:55:33.688060: step 147, loss 1.15588, acc 0.578125\n",
      "2018-04-13T14:55:33.979765: step 148, loss 1.13273, acc 0.5625\n",
      "2018-04-13T14:55:34.290985: step 149, loss 1.18897, acc 0.53125\n",
      "2018-04-13T14:55:34.579689: step 150, loss 1.34146, acc 0.583333\n",
      "2018-04-13T14:55:34.877902: step 151, loss 1.11768, acc 0.515625\n",
      "2018-04-13T14:55:35.180113: step 152, loss 0.871256, acc 0.625\n",
      "2018-04-13T14:55:35.462813: step 153, loss 0.994601, acc 0.578125\n",
      "2018-04-13T14:55:35.760527: step 154, loss 1.13352, acc 0.5\n",
      "2018-04-13T14:55:36.061740: step 155, loss 1.07513, acc 0.53125\n",
      "2018-04-13T14:55:36.347437: step 156, loss 0.962111, acc 0.515625\n",
      "2018-04-13T14:55:36.644647: step 157, loss 0.874316, acc 0.65625\n",
      "2018-04-13T14:55:36.944359: step 158, loss 0.796852, acc 0.609375\n",
      "2018-04-13T14:55:37.246572: step 159, loss 0.867099, acc 0.65625\n",
      "2018-04-13T14:55:37.581310: step 160, loss 0.95834, acc 0.59375\n",
      "2018-04-13T14:55:37.876518: step 161, loss 1.04909, acc 0.5\n",
      "2018-04-13T14:55:38.175228: step 162, loss 0.856841, acc 0.671875\n",
      "2018-04-13T14:55:38.460930: step 163, loss 0.864109, acc 0.65625\n",
      "2018-04-13T14:55:38.759140: step 164, loss 1.10209, acc 0.578125\n",
      "2018-04-13T14:55:39.045342: step 165, loss 0.91823, acc 0.640625\n",
      "2018-04-13T14:55:39.330543: step 166, loss 1.13756, acc 0.5\n",
      "2018-04-13T14:55:39.621252: step 167, loss 1.37198, acc 0.453125\n",
      "2018-04-13T14:55:39.947479: step 168, loss 0.710138, acc 0.59375\n",
      "2018-04-13T14:55:40.274210: step 169, loss 0.916096, acc 0.578125\n",
      "2018-04-13T14:55:40.551406: step 170, loss 1.16588, acc 0.515625\n",
      "2018-04-13T14:55:40.844112: step 171, loss 1.18217, acc 0.59375\n",
      "2018-04-13T14:55:41.166082: step 172, loss 0.736453, acc 0.59375\n",
      "2018-04-13T14:55:41.455286: step 173, loss 1.0792, acc 0.5625\n",
      "2018-04-13T14:55:41.743489: step 174, loss 1.143, acc 0.546875\n",
      "2018-04-13T14:55:42.028200: step 175, loss 0.865073, acc 0.640625\n",
      "2018-04-13T14:55:42.313902: step 176, loss 0.754834, acc 0.65625\n",
      "2018-04-13T14:55:42.597603: step 177, loss 0.810105, acc 0.578125\n",
      "2018-04-13T14:55:42.886811: step 178, loss 0.896884, acc 0.578125\n",
      "2018-04-13T14:55:43.180014: step 179, loss 0.947575, acc 0.578125\n",
      "2018-04-13T14:55:43.458210: step 180, loss 0.981313, acc 0.625\n",
      "2018-04-13T14:55:43.744412: step 181, loss 0.887237, acc 0.59375\n",
      "2018-04-13T14:55:44.038119: step 182, loss 0.846127, acc 0.640625\n",
      "2018-04-13T14:55:44.319318: step 183, loss 0.722986, acc 0.671875\n",
      "2018-04-13T14:55:44.607022: step 184, loss 0.753527, acc 0.65625\n",
      "2018-04-13T14:55:44.887719: step 185, loss 1.21408, acc 0.5625\n",
      "2018-04-13T14:55:45.185435: step 186, loss 1.04762, acc 0.53125\n",
      "2018-04-13T14:55:45.461624: step 187, loss 0.893217, acc 0.5625\n",
      "2018-04-13T14:55:45.755332: step 188, loss 0.876373, acc 0.59375\n",
      "2018-04-13T14:55:46.039033: step 189, loss 0.883613, acc 0.59375\n",
      "2018-04-13T14:55:46.328237: step 190, loss 0.898625, acc 0.609375\n",
      "2018-04-13T14:55:46.616444: step 191, loss 0.951312, acc 0.6875\n",
      "2018-04-13T14:55:46.926379: step 192, loss 0.876957, acc 0.609375\n",
      "2018-04-13T14:55:47.215586: step 193, loss 0.931316, acc 0.546875\n",
      "2018-04-13T14:55:47.500785: step 194, loss 0.804929, acc 0.6875\n",
      "2018-04-13T14:55:47.784485: step 195, loss 0.979171, acc 0.609375\n",
      "2018-04-13T14:55:48.071688: step 196, loss 0.840644, acc 0.578125\n",
      "2018-04-13T14:55:48.353886: step 197, loss 0.900981, acc 0.578125\n",
      "2018-04-13T14:55:48.634085: step 198, loss 0.82652, acc 0.59375\n",
      "2018-04-13T14:55:48.943321: step 199, loss 0.74638, acc 0.671875\n",
      "2018-04-13T14:55:49.234525: step 200, loss 0.799293, acc 0.609375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:55:50.217220: step 200, loss 0.660981, acc 0.613508\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-200\n",
      "\n",
      "2018-04-13T14:55:51.990213: step 201, loss 0.990183, acc 0.640625\n",
      "2018-04-13T14:55:52.316943: step 202, loss 0.712794, acc 0.671875\n",
      "2018-04-13T14:55:52.610150: step 203, loss 0.726647, acc 0.625\n",
      "2018-04-13T14:55:52.900355: step 204, loss 1.07766, acc 0.609375\n",
      "2018-04-13T14:55:53.223583: step 205, loss 0.950272, acc 0.5625\n",
      "2018-04-13T14:55:53.508290: step 206, loss 0.996794, acc 0.5625\n",
      "2018-04-13T14:55:53.791984: step 207, loss 0.970057, acc 0.59375\n",
      "2018-04-13T14:55:54.093697: step 208, loss 1.01945, acc 0.546875\n",
      "2018-04-13T14:55:54.393409: step 209, loss 0.781367, acc 0.59375\n",
      "2018-04-13T14:55:54.702633: step 210, loss 0.892909, acc 0.671875\n",
      "2018-04-13T14:55:55.082896: step 211, loss 1.02252, acc 0.59375\n",
      "2018-04-13T14:55:55.471104: step 212, loss 0.828712, acc 0.515625\n",
      "2018-04-13T14:55:55.777920: step 213, loss 0.948453, acc 0.5625\n",
      "2018-04-13T14:55:56.084137: step 214, loss 0.709511, acc 0.6875\n",
      "2018-04-13T14:55:56.382847: step 215, loss 0.639673, acc 0.703125\n",
      "2018-04-13T14:55:56.698072: step 216, loss 0.656694, acc 0.671875\n",
      "2018-04-13T14:55:57.090851: step 217, loss 0.626894, acc 0.71875\n",
      "2018-04-13T14:55:57.446098: step 218, loss 0.776675, acc 0.609375\n",
      "2018-04-13T14:55:57.748813: step 219, loss 0.884252, acc 0.578125\n",
      "2018-04-13T14:55:58.066036: step 220, loss 0.636355, acc 0.703125\n",
      "2018-04-13T14:55:58.363247: step 221, loss 1.01685, acc 0.578125\n",
      "2018-04-13T14:55:58.694480: step 222, loss 1.08619, acc 0.5\n",
      "2018-04-13T14:55:59.004699: step 223, loss 0.903271, acc 0.59375\n",
      "2018-04-13T14:55:59.307414: step 224, loss 0.8481, acc 0.609375\n",
      "2018-04-13T14:55:59.606124: step 225, loss 0.799773, acc 0.640625\n",
      "2018-04-13T14:55:59.902333: step 226, loss 0.713282, acc 0.671875\n",
      "2018-04-13T14:56:00.212552: step 227, loss 0.731261, acc 0.578125\n",
      "2018-04-13T14:56:00.517280: step 228, loss 0.750611, acc 0.625\n",
      "2018-04-13T14:56:00.820014: step 229, loss 0.802356, acc 0.671875\n",
      "2018-04-13T14:56:01.117226: step 230, loss 0.79596, acc 0.609375\n",
      "2018-04-13T14:56:01.401929: step 231, loss 1.00804, acc 0.625\n",
      "2018-04-13T14:56:01.719152: step 232, loss 0.678334, acc 0.625\n",
      "2018-04-13T14:56:02.032872: step 233, loss 0.893925, acc 0.578125\n",
      "2018-04-13T14:56:02.349096: step 234, loss 0.685706, acc 0.625\n",
      "2018-04-13T14:56:02.639800: step 235, loss 0.795385, acc 0.6875\n",
      "2018-04-13T14:56:02.920499: step 236, loss 0.929618, acc 0.5625\n",
      "2018-04-13T14:56:03.243232: step 237, loss 0.968761, acc 0.5625\n",
      "2018-04-13T14:56:03.558449: step 238, loss 0.818207, acc 0.546875\n",
      "2018-04-13T14:56:03.846660: step 239, loss 0.969522, acc 0.53125\n",
      "2018-04-13T14:56:04.137357: step 240, loss 1.07996, acc 0.5625\n",
      "2018-04-13T14:56:04.426061: step 241, loss 0.837407, acc 0.578125\n",
      "2018-04-13T14:56:04.749790: step 242, loss 0.96043, acc 0.515625\n",
      "2018-04-13T14:56:05.048502: step 243, loss 0.802676, acc 0.671875\n",
      "2018-04-13T14:56:05.342709: step 244, loss 0.9402, acc 0.671875\n",
      "2018-04-13T14:56:05.664438: step 245, loss 0.744506, acc 0.703125\n",
      "2018-04-13T14:56:05.998220: step 246, loss 0.886839, acc 0.609375\n",
      "2018-04-13T14:56:06.313443: step 247, loss 0.808625, acc 0.625\n",
      "2018-04-13T14:56:06.618657: step 248, loss 0.85626, acc 0.625\n",
      "2018-04-13T14:56:06.927878: step 249, loss 0.815178, acc 0.515625\n",
      "2018-04-13T14:56:07.230100: step 250, loss 0.764746, acc 0.671875\n",
      "2018-04-13T14:56:07.519805: step 251, loss 0.730901, acc 0.65625\n",
      "2018-04-13T14:56:07.824519: step 252, loss 0.808165, acc 0.578125\n",
      "2018-04-13T14:56:08.141743: step 253, loss 0.744907, acc 0.625\n",
      "2018-04-13T14:56:08.482483: step 254, loss 0.767263, acc 0.578125\n",
      "2018-04-13T14:56:08.843337: step 255, loss 0.75208, acc 0.640625\n",
      "2018-04-13T14:56:09.321674: step 256, loss 0.814314, acc 0.625\n",
      "2018-04-13T14:56:09.704444: step 257, loss 1.1079, acc 0.546875\n",
      "2018-04-13T14:56:10.141753: step 258, loss 0.736932, acc 0.59375\n",
      "2018-04-13T14:56:10.537533: step 259, loss 0.713347, acc 0.703125\n",
      "2018-04-13T14:56:10.899788: step 260, loss 1.00569, acc 0.453125\n",
      "2018-04-13T14:56:11.227520: step 261, loss 0.890723, acc 0.5625\n",
      "2018-04-13T14:56:11.600299: step 262, loss 0.642236, acc 0.65625\n",
      "2018-04-13T14:56:11.902513: step 263, loss 0.782896, acc 0.625\n",
      "2018-04-13T14:56:12.237249: step 264, loss 0.71693, acc 0.65625\n",
      "2018-04-13T14:56:12.568483: step 265, loss 0.689016, acc 0.65625\n",
      "2018-04-13T14:56:12.860189: step 266, loss 0.745275, acc 0.65625\n",
      "2018-04-13T14:56:13.276983: step 267, loss 0.883327, acc 0.59375\n",
      "2018-04-13T14:56:13.624729: step 268, loss 0.785457, acc 0.6875\n",
      "2018-04-13T14:56:14.078550: step 269, loss 0.765747, acc 0.65625\n",
      "2018-04-13T14:56:14.447310: step 270, loss 1.02896, acc 0.578125\n",
      "2018-04-13T14:56:14.846591: step 271, loss 0.692433, acc 0.671875\n",
      "2018-04-13T14:56:15.172876: step 272, loss 0.85692, acc 0.59375\n",
      "2018-04-13T14:56:15.512616: step 273, loss 0.847529, acc 0.578125\n",
      "2018-04-13T14:56:15.806824: step 274, loss 0.984698, acc 0.546875\n",
      "2018-04-13T14:56:16.108037: step 275, loss 0.716114, acc 0.671875\n",
      "2018-04-13T14:56:16.395739: step 276, loss 0.739691, acc 0.625\n",
      "2018-04-13T14:56:16.787016: step 277, loss 0.851156, acc 0.609375\n",
      "2018-04-13T14:56:17.108241: step 278, loss 0.774404, acc 0.640625\n",
      "2018-04-13T14:56:17.432973: step 279, loss 0.661467, acc 0.671875\n",
      "2018-04-13T14:56:17.806235: step 280, loss 0.596709, acc 0.71875\n",
      "2018-04-13T14:56:18.098442: step 281, loss 0.581344, acc 0.703125\n",
      "2018-04-13T14:56:18.395655: step 282, loss 0.830793, acc 0.59375\n",
      "2018-04-13T14:56:18.687858: step 283, loss 0.796666, acc 0.5625\n",
      "2018-04-13T14:56:18.990581: step 284, loss 0.750803, acc 0.609375\n",
      "2018-04-13T14:56:19.288798: step 285, loss 0.604315, acc 0.671875\n",
      "2018-04-13T14:56:19.612021: step 286, loss 0.844007, acc 0.546875\n",
      "2018-04-13T14:56:19.940752: step 287, loss 0.624015, acc 0.640625\n",
      "2018-04-13T14:56:20.224453: step 288, loss 0.804293, acc 0.65625\n",
      "2018-04-13T14:56:20.547681: step 289, loss 0.857207, acc 0.5625\n",
      "2018-04-13T14:56:20.874414: step 290, loss 0.595149, acc 0.71875\n",
      "2018-04-13T14:56:21.170624: step 291, loss 0.723762, acc 0.671875\n",
      "2018-04-13T14:56:21.466331: step 292, loss 0.703916, acc 0.703125\n",
      "2018-04-13T14:56:21.776549: step 293, loss 0.708812, acc 0.671875\n",
      "2018-04-13T14:56:22.082808: step 294, loss 0.937805, acc 0.484375\n",
      "2018-04-13T14:56:22.388522: step 295, loss 0.634459, acc 0.671875\n",
      "2018-04-13T14:56:22.687733: step 296, loss 0.841292, acc 0.578125\n",
      "2018-04-13T14:56:22.997954: step 297, loss 0.777335, acc 0.625\n",
      "2018-04-13T14:56:23.281653: step 298, loss 0.7516, acc 0.65625\n",
      "2018-04-13T14:56:23.572862: step 299, loss 0.934482, acc 0.625\n",
      "2018-04-13T14:56:23.873070: step 300, loss 0.763035, acc 0.633333\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:56:24.894293: step 300, loss 0.650402, acc 0.615385\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-300\n",
      "\n",
      "2018-04-13T14:56:26.626812: step 301, loss 0.898884, acc 0.484375\n",
      "2018-04-13T14:56:26.935533: step 302, loss 0.815706, acc 0.546875\n",
      "2018-04-13T14:56:27.232242: step 303, loss 0.828251, acc 0.609375\n",
      "2018-04-13T14:56:27.514938: step 304, loss 0.552856, acc 0.703125\n",
      "2018-04-13T14:56:27.823657: step 305, loss 0.848448, acc 0.59375\n",
      "2018-04-13T14:56:28.119872: step 306, loss 0.604217, acc 0.734375\n",
      "2018-04-13T14:56:28.419080: step 307, loss 0.742519, acc 0.6875\n",
      "2018-04-13T14:56:28.722293: step 308, loss 0.629306, acc 0.65625\n",
      "2018-04-13T14:56:29.025507: step 309, loss 0.565065, acc 0.703125\n",
      "2018-04-13T14:56:29.324217: step 310, loss 0.810907, acc 0.5625\n",
      "2018-04-13T14:56:29.605416: step 311, loss 0.683338, acc 0.6875\n",
      "2018-04-13T14:56:29.906128: step 312, loss 0.632202, acc 0.65625\n",
      "2018-04-13T14:56:30.199835: step 313, loss 0.798954, acc 0.59375\n",
      "2018-04-13T14:56:30.513056: step 314, loss 0.667852, acc 0.65625\n",
      "2018-04-13T14:56:30.831781: step 315, loss 0.715115, acc 0.609375\n",
      "2018-04-13T14:56:31.152007: step 316, loss 0.684765, acc 0.65625\n",
      "2018-04-13T14:56:31.466729: step 317, loss 0.64853, acc 0.703125\n",
      "2018-04-13T14:56:31.778450: step 318, loss 0.632788, acc 0.703125\n",
      "2018-04-13T14:56:32.091170: step 319, loss 0.730767, acc 0.703125\n",
      "2018-04-13T14:56:32.386379: step 320, loss 0.658032, acc 0.65625\n",
      "2018-04-13T14:56:32.686090: step 321, loss 0.643796, acc 0.65625\n",
      "2018-04-13T14:56:32.991807: step 322, loss 0.601108, acc 0.734375\n",
      "2018-04-13T14:56:33.280010: step 323, loss 0.55398, acc 0.734375\n",
      "2018-04-13T14:56:33.583227: step 324, loss 0.62929, acc 0.65625\n",
      "2018-04-13T14:56:33.892944: step 325, loss 0.779774, acc 0.53125\n",
      "2018-04-13T14:56:34.186651: step 326, loss 0.496668, acc 0.75\n",
      "2018-04-13T14:56:34.473853: step 327, loss 0.599419, acc 0.71875\n",
      "2018-04-13T14:56:34.772064: step 328, loss 0.551134, acc 0.71875\n",
      "2018-04-13T14:56:35.082783: step 329, loss 0.783463, acc 0.640625\n",
      "2018-04-13T14:56:35.379492: step 330, loss 0.597873, acc 0.703125\n",
      "2018-04-13T14:56:35.671699: step 331, loss 0.706924, acc 0.671875\n",
      "2018-04-13T14:56:35.991925: step 332, loss 0.799124, acc 0.59375\n",
      "2018-04-13T14:56:36.463761: step 333, loss 0.846067, acc 0.5625\n",
      "2018-04-13T14:56:36.843026: step 334, loss 0.639901, acc 0.609375\n",
      "2018-04-13T14:56:37.229798: step 335, loss 0.696314, acc 0.640625\n",
      "2018-04-13T14:56:37.671110: step 336, loss 0.667407, acc 0.609375\n",
      "2018-04-13T14:56:38.118426: step 337, loss 0.702658, acc 0.65625\n",
      "2018-04-13T14:56:38.660809: step 338, loss 0.636742, acc 0.671875\n",
      "2018-04-13T14:56:39.087110: step 339, loss 0.588, acc 0.6875\n",
      "2018-04-13T14:56:39.441861: step 340, loss 0.596018, acc 0.671875\n",
      "2018-04-13T14:56:39.744076: step 341, loss 0.593398, acc 0.6875\n",
      "2018-04-13T14:56:40.081315: step 342, loss 0.687376, acc 0.6875\n",
      "2018-04-13T14:56:40.388029: step 343, loss 0.516137, acc 0.765625\n",
      "2018-04-13T14:56:40.688241: step 344, loss 0.610195, acc 0.734375\n",
      "2018-04-13T14:56:41.018474: step 345, loss 0.587806, acc 0.6875\n",
      "2018-04-13T14:56:41.321689: step 346, loss 0.590158, acc 0.65625\n",
      "2018-04-13T14:56:41.630907: step 347, loss 0.676157, acc 0.6875\n",
      "2018-04-13T14:56:41.958137: step 348, loss 0.712077, acc 0.671875\n",
      "2018-04-13T14:56:42.247842: step 349, loss 0.634834, acc 0.703125\n",
      "2018-04-13T14:56:42.611102: step 350, loss 0.534394, acc 0.75\n",
      "2018-04-13T14:56:42.986363: step 351, loss 0.605257, acc 0.6875\n",
      "2018-04-13T14:56:43.284576: step 352, loss 0.840559, acc 0.625\n",
      "2018-04-13T14:56:43.610304: step 353, loss 0.540576, acc 0.71875\n",
      "2018-04-13T14:56:43.945040: step 354, loss 0.570038, acc 0.6875\n",
      "2018-04-13T14:56:44.363836: step 355, loss 0.422112, acc 0.84375\n",
      "2018-04-13T14:56:44.662548: step 356, loss 0.478688, acc 0.65625\n",
      "2018-04-13T14:56:44.963761: step 357, loss 0.770873, acc 0.625\n",
      "2018-04-13T14:56:45.257468: step 358, loss 0.695034, acc 0.671875\n",
      "2018-04-13T14:56:45.588203: step 359, loss 0.737366, acc 0.640625\n",
      "2018-04-13T14:56:45.916433: step 360, loss 0.708061, acc 0.625\n",
      "2018-04-13T14:56:46.219652: step 361, loss 0.605605, acc 0.75\n",
      "2018-04-13T14:56:46.554886: step 362, loss 0.737185, acc 0.640625\n",
      "2018-04-13T14:56:46.873318: step 363, loss 0.741446, acc 0.625\n",
      "2018-04-13T14:56:47.197551: step 364, loss 0.651708, acc 0.671875\n",
      "2018-04-13T14:56:47.515772: step 365, loss 0.674904, acc 0.65625\n",
      "2018-04-13T14:56:47.839000: step 366, loss 0.600214, acc 0.71875\n",
      "2018-04-13T14:56:48.156724: step 367, loss 0.535543, acc 0.71875\n",
      "2018-04-13T14:56:48.454457: step 368, loss 0.619465, acc 0.71875\n",
      "2018-04-13T14:56:48.756692: step 369, loss 0.862048, acc 0.546875\n",
      "2018-04-13T14:56:49.105940: step 370, loss 0.560359, acc 0.75\n",
      "2018-04-13T14:56:49.438677: step 371, loss 0.584929, acc 0.671875\n",
      "2018-04-13T14:56:49.717872: step 372, loss 0.55945, acc 0.71875\n",
      "2018-04-13T14:56:50.028591: step 373, loss 0.464466, acc 0.859375\n",
      "2018-04-13T14:56:50.376335: step 374, loss 0.620412, acc 0.640625\n",
      "2018-04-13T14:56:50.666541: step 375, loss 0.632437, acc 0.703125\n",
      "2018-04-13T14:56:50.990270: step 376, loss 0.570152, acc 0.703125\n",
      "2018-04-13T14:56:51.349029: step 377, loss 0.486448, acc 0.734375\n",
      "2018-04-13T14:56:51.654739: step 378, loss 0.618459, acc 0.6875\n",
      "2018-04-13T14:56:51.964459: step 379, loss 0.617672, acc 0.640625\n",
      "2018-04-13T14:56:52.285684: step 380, loss 0.657931, acc 0.640625\n",
      "2018-04-13T14:56:52.607411: step 381, loss 0.567519, acc 0.78125\n",
      "2018-04-13T14:56:52.938647: step 382, loss 0.535617, acc 0.734375\n",
      "2018-04-13T14:56:53.262374: step 383, loss 0.628784, acc 0.671875\n",
      "2018-04-13T14:56:53.572593: step 384, loss 0.785357, acc 0.59375\n",
      "2018-04-13T14:56:53.888818: step 385, loss 0.688964, acc 0.6875\n",
      "2018-04-13T14:56:54.224556: step 386, loss 0.594761, acc 0.703125\n",
      "2018-04-13T14:56:54.517260: step 387, loss 0.698687, acc 0.625\n",
      "2018-04-13T14:56:54.878015: step 388, loss 0.569984, acc 0.703125\n",
      "2018-04-13T14:56:55.171723: step 389, loss 0.662042, acc 0.703125\n",
      "2018-04-13T14:56:55.488446: step 390, loss 0.564115, acc 0.71875\n",
      "2018-04-13T14:56:55.793662: step 391, loss 0.634897, acc 0.671875\n",
      "2018-04-13T14:56:56.095375: step 392, loss 0.487755, acc 0.71875\n",
      "2018-04-13T14:56:56.389584: step 393, loss 0.622236, acc 0.640625\n",
      "2018-04-13T14:56:56.688793: step 394, loss 0.616836, acc 0.671875\n",
      "2018-04-13T14:56:56.994009: step 395, loss 0.901715, acc 0.546875\n",
      "2018-04-13T14:56:57.276717: step 396, loss 0.793892, acc 0.5625\n",
      "2018-04-13T14:56:57.573418: step 397, loss 0.699288, acc 0.578125\n",
      "2018-04-13T14:56:57.868127: step 398, loss 0.602699, acc 0.6875\n",
      "2018-04-13T14:56:58.166836: step 399, loss 0.641797, acc 0.65625\n",
      "2018-04-13T14:56:58.464547: step 400, loss 0.721451, acc 0.59375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:56:59.453144: step 400, loss 0.639792, acc 0.621951\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-400\n",
      "\n",
      "2018-04-13T14:57:01.082804: step 401, loss 0.580459, acc 0.75\n",
      "2018-04-13T14:57:01.402030: step 402, loss 0.637917, acc 0.65625\n",
      "2018-04-13T14:57:01.739768: step 403, loss 0.642011, acc 0.671875\n",
      "2018-04-13T14:57:02.065499: step 404, loss 0.482891, acc 0.78125\n",
      "2018-04-13T14:57:02.346196: step 405, loss 0.613449, acc 0.65625\n",
      "2018-04-13T14:57:02.675429: step 406, loss 0.542206, acc 0.703125\n",
      "2018-04-13T14:57:03.088730: step 407, loss 0.715222, acc 0.625\n",
      "2018-04-13T14:57:03.472993: step 408, loss 0.659422, acc 0.65625\n",
      "2018-04-13T14:57:03.784713: step 409, loss 0.653895, acc 0.640625\n",
      "2018-04-13T14:57:04.082923: step 410, loss 0.558695, acc 0.703125\n",
      "2018-04-13T14:57:04.373128: step 411, loss 0.74137, acc 0.5625\n",
      "2018-04-13T14:57:04.661832: step 412, loss 0.631221, acc 0.671875\n",
      "2018-04-13T14:57:04.982558: step 413, loss 0.604501, acc 0.65625\n",
      "2018-04-13T14:57:05.270262: step 414, loss 0.767646, acc 0.59375\n",
      "2018-04-13T14:57:05.584984: step 415, loss 0.632739, acc 0.640625\n",
      "2018-04-13T14:57:05.881193: step 416, loss 0.624436, acc 0.671875\n",
      "2018-04-13T14:57:06.182912: step 417, loss 0.628009, acc 0.609375\n",
      "2018-04-13T14:57:06.465105: step 418, loss 0.610154, acc 0.671875\n",
      "2018-04-13T14:57:06.811350: step 419, loss 0.482338, acc 0.78125\n",
      "2018-04-13T14:57:07.370745: step 420, loss 0.634896, acc 0.703125\n",
      "2018-04-13T14:57:07.790041: step 421, loss 0.621029, acc 0.6875\n",
      "2018-04-13T14:57:08.192826: step 422, loss 0.588978, acc 0.765625\n",
      "2018-04-13T14:57:08.573594: step 423, loss 0.526893, acc 0.734375\n",
      "2018-04-13T14:57:08.936851: step 424, loss 0.678568, acc 0.640625\n",
      "2018-04-13T14:57:09.250573: step 425, loss 0.601615, acc 0.6875\n",
      "2018-04-13T14:57:09.591813: step 426, loss 0.685773, acc 0.65625\n",
      "2018-04-13T14:57:09.983591: step 427, loss 0.704491, acc 0.59375\n",
      "2018-04-13T14:57:10.423401: step 428, loss 0.533417, acc 0.71875\n",
      "2018-04-13T14:57:10.972789: step 429, loss 0.793803, acc 0.546875\n",
      "2018-04-13T14:57:11.432113: step 430, loss 0.620174, acc 0.625\n",
      "2018-04-13T14:57:11.865419: step 431, loss 0.594098, acc 0.6875\n",
      "2018-04-13T14:57:12.283214: step 432, loss 0.589925, acc 0.703125\n",
      "2018-04-13T14:57:12.691001: step 433, loss 0.665554, acc 0.703125\n",
      "2018-04-13T14:57:13.062764: step 434, loss 0.637841, acc 0.6875\n",
      "2018-04-13T14:57:13.384991: step 435, loss 0.59816, acc 0.65625\n",
      "2018-04-13T14:57:13.731236: step 436, loss 0.624509, acc 0.671875\n",
      "2018-04-13T14:57:14.066973: step 437, loss 0.702682, acc 0.546875\n",
      "2018-04-13T14:57:14.370187: step 438, loss 0.577562, acc 0.71875\n",
      "2018-04-13T14:57:14.677404: step 439, loss 0.53061, acc 0.78125\n",
      "2018-04-13T14:57:15.030654: step 440, loss 0.650129, acc 0.65625\n",
      "2018-04-13T14:57:15.363388: step 441, loss 0.605411, acc 0.640625\n",
      "2018-04-13T14:57:15.705630: step 442, loss 0.632763, acc 0.625\n",
      "2018-04-13T14:57:16.063382: step 443, loss 0.763765, acc 0.59375\n",
      "2018-04-13T14:57:16.395117: step 444, loss 0.645671, acc 0.578125\n",
      "2018-04-13T14:57:16.719847: step 445, loss 0.597557, acc 0.6875\n",
      "2018-04-13T14:57:17.081101: step 446, loss 0.720888, acc 0.546875\n",
      "2018-04-13T14:57:17.409833: step 447, loss 0.53642, acc 0.703125\n",
      "2018-04-13T14:57:17.729059: step 448, loss 0.688378, acc 0.625\n",
      "2018-04-13T14:57:18.042280: step 449, loss 0.597456, acc 0.6875\n",
      "2018-04-13T14:57:18.387524: step 450, loss 0.689353, acc 0.6\n",
      "2018-04-13T14:57:18.706749: step 451, loss 0.524615, acc 0.765625\n",
      "2018-04-13T14:57:19.059499: step 452, loss 0.559556, acc 0.765625\n",
      "2018-04-13T14:57:19.405743: step 453, loss 0.708429, acc 0.609375\n",
      "2018-04-13T14:57:19.728471: step 454, loss 0.524037, acc 0.75\n",
      "2018-04-13T14:57:20.105744: step 455, loss 0.562908, acc 0.765625\n",
      "2018-04-13T14:57:20.409459: step 456, loss 0.646037, acc 0.671875\n",
      "2018-04-13T14:57:20.702665: step 457, loss 0.516868, acc 0.671875\n",
      "2018-04-13T14:57:21.009382: step 458, loss 0.683509, acc 0.671875\n",
      "2018-04-13T14:57:21.299586: step 459, loss 0.536013, acc 0.734375\n",
      "2018-04-13T14:57:21.611807: step 460, loss 0.543545, acc 0.734375\n",
      "2018-04-13T14:57:21.948545: step 461, loss 0.626158, acc 0.65625\n",
      "2018-04-13T14:57:22.309300: step 462, loss 0.680914, acc 0.578125\n",
      "2018-04-13T14:57:22.658046: step 463, loss 0.519619, acc 0.734375\n",
      "2018-04-13T14:57:22.988779: step 464, loss 0.622084, acc 0.671875\n",
      "2018-04-13T14:57:23.336025: step 465, loss 0.498496, acc 0.734375\n",
      "2018-04-13T14:57:23.667759: step 466, loss 0.519113, acc 0.796875\n",
      "2018-04-13T14:57:23.993489: step 467, loss 0.586468, acc 0.703125\n",
      "2018-04-13T14:57:24.338733: step 468, loss 0.580757, acc 0.71875\n",
      "2018-04-13T14:57:24.660460: step 469, loss 0.675414, acc 0.671875\n",
      "2018-04-13T14:57:25.039734: step 470, loss 0.504917, acc 0.734375\n",
      "2018-04-13T14:57:25.390476: step 471, loss 0.552363, acc 0.71875\n",
      "2018-04-13T14:57:25.712202: step 472, loss 0.555129, acc 0.703125\n",
      "2018-04-13T14:57:26.065453: step 473, loss 0.592114, acc 0.625\n",
      "2018-04-13T14:57:26.408193: step 474, loss 0.55259, acc 0.734375\n",
      "2018-04-13T14:57:26.734425: step 475, loss 0.45397, acc 0.765625\n",
      "2018-04-13T14:57:27.043142: step 476, loss 0.617752, acc 0.703125\n",
      "2018-04-13T14:57:27.399393: step 477, loss 0.605365, acc 0.65625\n",
      "2018-04-13T14:57:27.759648: step 478, loss 0.473263, acc 0.78125\n",
      "2018-04-13T14:57:28.089882: step 479, loss 0.586025, acc 0.609375\n",
      "2018-04-13T14:57:28.415611: step 480, loss 0.550892, acc 0.71875\n",
      "2018-04-13T14:57:28.727831: step 481, loss 0.605529, acc 0.75\n",
      "2018-04-13T14:57:29.038551: step 482, loss 0.506641, acc 0.75\n",
      "2018-04-13T14:57:29.376290: step 483, loss 0.576988, acc 0.71875\n",
      "2018-04-13T14:57:29.669997: step 484, loss 0.554135, acc 0.609375\n",
      "2018-04-13T14:57:30.031753: step 485, loss 0.579909, acc 0.65625\n",
      "2018-04-13T14:57:30.502084: step 486, loss 0.672146, acc 0.6875\n",
      "2018-04-13T14:57:30.882854: step 487, loss 0.469345, acc 0.734375\n",
      "2018-04-13T14:57:31.469769: step 488, loss 0.576256, acc 0.6875\n",
      "2018-04-13T14:57:31.804004: step 489, loss 0.626774, acc 0.640625\n",
      "2018-04-13T14:57:32.124230: step 490, loss 0.456759, acc 0.796875\n",
      "2018-04-13T14:57:32.466977: step 491, loss 0.568026, acc 0.65625\n",
      "2018-04-13T14:57:32.811715: step 492, loss 0.64725, acc 0.671875\n",
      "2018-04-13T14:57:33.121935: step 493, loss 0.604837, acc 0.65625\n",
      "2018-04-13T14:57:33.431653: step 494, loss 0.461551, acc 0.78125\n",
      "2018-04-13T14:57:33.748376: step 495, loss 0.484851, acc 0.734375\n",
      "2018-04-13T14:57:34.039583: step 496, loss 0.562577, acc 0.71875\n",
      "2018-04-13T14:57:34.352303: step 497, loss 0.846185, acc 0.5625\n",
      "2018-04-13T14:57:34.664524: step 498, loss 0.51947, acc 0.71875\n",
      "2018-04-13T14:57:34.982248: step 499, loss 0.478483, acc 0.734375\n",
      "2018-04-13T14:57:35.280959: step 500, loss 0.476822, acc 0.765625\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:57:36.481307: step 500, loss 0.610542, acc 0.654784\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-500\n",
      "\n",
      "2018-04-13T14:57:38.216766: step 501, loss 0.614601, acc 0.671875\n",
      "2018-04-13T14:57:38.505969: step 502, loss 0.608594, acc 0.65625\n",
      "2018-04-13T14:57:38.806682: step 503, loss 0.637621, acc 0.671875\n",
      "2018-04-13T14:57:39.105393: step 504, loss 0.640683, acc 0.703125\n",
      "2018-04-13T14:57:39.399100: step 505, loss 0.444496, acc 0.8125\n",
      "2018-04-13T14:57:39.730835: step 506, loss 0.743858, acc 0.59375\n",
      "2018-04-13T14:57:40.097593: step 507, loss 0.499755, acc 0.765625\n",
      "2018-04-13T14:57:40.385296: step 508, loss 0.661478, acc 0.625\n",
      "2018-04-13T14:57:40.739547: step 509, loss 0.477284, acc 0.828125\n",
      "2018-04-13T14:57:41.078787: step 510, loss 0.594402, acc 0.703125\n",
      "2018-04-13T14:57:41.386503: step 511, loss 0.682493, acc 0.625\n",
      "2018-04-13T14:57:41.731747: step 512, loss 0.603036, acc 0.6875\n",
      "2018-04-13T14:57:42.065984: step 513, loss 0.566125, acc 0.734375\n",
      "2018-04-13T14:57:42.419238: step 514, loss 0.690746, acc 0.640625\n",
      "2018-04-13T14:57:42.752968: step 515, loss 0.620981, acc 0.71875\n",
      "2018-04-13T14:57:43.063188: step 516, loss 0.536511, acc 0.6875\n",
      "2018-04-13T14:57:43.359897: step 517, loss 0.493121, acc 0.78125\n",
      "2018-04-13T14:57:43.647600: step 518, loss 0.444519, acc 0.765625\n",
      "2018-04-13T14:57:43.955317: step 519, loss 0.54494, acc 0.703125\n",
      "2018-04-13T14:57:44.244522: step 520, loss 0.481687, acc 0.796875\n",
      "2018-04-13T14:57:44.551238: step 521, loss 0.635601, acc 0.609375\n",
      "2018-04-13T14:57:44.856453: step 522, loss 0.57776, acc 0.6875\n",
      "2018-04-13T14:57:45.151162: step 523, loss 0.449841, acc 0.734375\n",
      "2018-04-13T14:57:45.444869: step 524, loss 0.549918, acc 0.75\n",
      "2018-04-13T14:57:45.740077: step 525, loss 0.527364, acc 0.765625\n",
      "2018-04-13T14:57:46.037288: step 526, loss 0.421672, acc 0.859375\n",
      "2018-04-13T14:57:46.331496: step 527, loss 0.442469, acc 0.765625\n",
      "2018-04-13T14:57:46.624202: step 528, loss 0.548565, acc 0.75\n",
      "2018-04-13T14:57:46.933920: step 529, loss 0.548566, acc 0.71875\n",
      "2018-04-13T14:57:47.230630: step 530, loss 0.583166, acc 0.734375\n",
      "2018-04-13T14:57:47.526839: step 531, loss 0.535014, acc 0.75\n",
      "2018-04-13T14:57:47.836058: step 532, loss 0.563195, acc 0.640625\n",
      "2018-04-13T14:57:48.121759: step 533, loss 0.549596, acc 0.765625\n",
      "2018-04-13T14:57:48.418969: step 534, loss 0.424335, acc 0.796875\n",
      "2018-04-13T14:57:48.729689: step 535, loss 0.407584, acc 0.84375\n",
      "2018-04-13T14:57:49.027899: step 536, loss 0.553586, acc 0.65625\n",
      "2018-04-13T14:57:49.331613: step 537, loss 0.500652, acc 0.75\n",
      "2018-04-13T14:57:49.625321: step 538, loss 0.649277, acc 0.671875\n",
      "2018-04-13T14:57:49.946047: step 539, loss 0.664141, acc 0.625\n",
      "2018-04-13T14:57:50.236252: step 540, loss 0.576282, acc 0.703125\n",
      "2018-04-13T14:57:50.529459: step 541, loss 0.529127, acc 0.71875\n",
      "2018-04-13T14:57:50.842181: step 542, loss 0.523861, acc 0.765625\n",
      "2018-04-13T14:57:51.140891: step 543, loss 0.576595, acc 0.703125\n",
      "2018-04-13T14:57:51.446107: step 544, loss 0.620401, acc 0.6875\n",
      "2018-04-13T14:57:51.742816: step 545, loss 0.575602, acc 0.671875\n",
      "2018-04-13T14:57:52.044530: step 546, loss 0.552971, acc 0.71875\n",
      "2018-04-13T14:57:52.346743: step 547, loss 0.569739, acc 0.71875\n",
      "2018-04-13T14:57:52.631443: step 548, loss 0.572556, acc 0.703125\n",
      "2018-04-13T14:57:52.944164: step 549, loss 0.582109, acc 0.765625\n",
      "2018-04-13T14:57:53.239873: step 550, loss 0.533431, acc 0.75\n",
      "2018-04-13T14:57:53.541086: step 551, loss 0.393155, acc 0.84375\n",
      "2018-04-13T14:57:53.848803: step 552, loss 0.650805, acc 0.65625\n",
      "2018-04-13T14:57:54.142510: step 553, loss 0.65461, acc 0.65625\n",
      "2018-04-13T14:57:54.435217: step 554, loss 0.450415, acc 0.796875\n",
      "2018-04-13T14:57:54.748939: step 555, loss 0.58, acc 0.6875\n",
      "2018-04-13T14:57:55.047149: step 556, loss 0.636561, acc 0.65625\n",
      "2018-04-13T14:57:55.336854: step 557, loss 0.500894, acc 0.765625\n",
      "2018-04-13T14:57:55.630061: step 558, loss 0.46048, acc 0.734375\n",
      "2018-04-13T14:57:55.932275: step 559, loss 0.571574, acc 0.75\n",
      "2018-04-13T14:57:56.226482: step 560, loss 0.776596, acc 0.609375\n",
      "2018-04-13T14:57:56.518188: step 561, loss 0.526404, acc 0.75\n",
      "2018-04-13T14:57:56.825906: step 562, loss 0.495376, acc 0.765625\n",
      "2018-04-13T14:57:57.128119: step 563, loss 0.536134, acc 0.703125\n",
      "2018-04-13T14:57:57.423829: step 564, loss 0.554829, acc 0.703125\n",
      "2018-04-13T14:57:57.734048: step 565, loss 0.515809, acc 0.703125\n",
      "2018-04-13T14:57:58.043765: step 566, loss 0.586742, acc 0.65625\n",
      "2018-04-13T14:57:58.337973: step 567, loss 0.590954, acc 0.75\n",
      "2018-04-13T14:57:58.639686: step 568, loss 0.551471, acc 0.71875\n",
      "2018-04-13T14:57:58.947403: step 569, loss 0.5646, acc 0.734375\n",
      "2018-04-13T14:57:59.250618: step 570, loss 0.627716, acc 0.703125\n",
      "2018-04-13T14:57:59.555333: step 571, loss 0.57294, acc 0.703125\n",
      "2018-04-13T14:57:59.871056: step 572, loss 0.517269, acc 0.75\n",
      "2018-04-13T14:58:00.180775: step 573, loss 0.539978, acc 0.734375\n",
      "2018-04-13T14:58:00.475983: step 574, loss 0.507321, acc 0.703125\n",
      "2018-04-13T14:58:00.776195: step 575, loss 0.499106, acc 0.703125\n",
      "2018-04-13T14:58:01.078909: step 576, loss 0.544389, acc 0.703125\n",
      "2018-04-13T14:58:01.373617: step 577, loss 0.554992, acc 0.703125\n",
      "2018-04-13T14:58:01.670826: step 578, loss 0.653921, acc 0.609375\n",
      "2018-04-13T14:58:01.972540: step 579, loss 0.501039, acc 0.71875\n",
      "2018-04-13T14:58:02.272751: step 580, loss 0.650504, acc 0.671875\n",
      "2018-04-13T14:58:02.577967: step 581, loss 0.496528, acc 0.75\n",
      "2018-04-13T14:58:02.889186: step 582, loss 0.55868, acc 0.65625\n",
      "2018-04-13T14:58:03.211415: step 583, loss 0.565734, acc 0.703125\n",
      "2018-04-13T14:58:03.515139: step 584, loss 0.608272, acc 0.703125\n",
      "2018-04-13T14:58:03.819855: step 585, loss 0.475089, acc 0.75\n",
      "2018-04-13T14:58:04.127071: step 586, loss 0.467019, acc 0.734375\n",
      "2018-04-13T14:58:04.419778: step 587, loss 0.595953, acc 0.71875\n",
      "2018-04-13T14:58:04.719990: step 588, loss 0.509818, acc 0.78125\n",
      "2018-04-13T14:58:05.023204: step 589, loss 0.578407, acc 0.765625\n",
      "2018-04-13T14:58:05.319913: step 590, loss 0.688162, acc 0.625\n",
      "2018-04-13T14:58:05.616623: step 591, loss 0.62943, acc 0.6875\n",
      "2018-04-13T14:58:05.937850: step 592, loss 0.592616, acc 0.640625\n",
      "2018-04-13T14:58:06.233059: step 593, loss 0.561763, acc 0.71875\n",
      "2018-04-13T14:58:06.531269: step 594, loss 0.519288, acc 0.75\n",
      "2018-04-13T14:58:06.853496: step 595, loss 0.554655, acc 0.703125\n",
      "2018-04-13T14:58:07.159713: step 596, loss 0.712412, acc 0.671875\n",
      "2018-04-13T14:58:07.450918: step 597, loss 0.529048, acc 0.75\n",
      "2018-04-13T14:58:07.773146: step 598, loss 0.604644, acc 0.671875\n",
      "2018-04-13T14:58:08.079863: step 599, loss 0.608468, acc 0.671875\n",
      "2018-04-13T14:58:08.377072: step 600, loss 0.58871, acc 0.7\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:58:09.376278: step 600, loss 0.653935, acc 0.622889\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-600\n",
      "\n",
      "2018-04-13T14:58:10.953830: step 601, loss 0.549536, acc 0.765625\n",
      "2018-04-13T14:58:11.273055: step 602, loss 0.624709, acc 0.671875\n",
      "2018-04-13T14:58:11.567763: step 603, loss 0.615195, acc 0.671875\n",
      "2018-04-13T14:58:11.885988: step 604, loss 0.56466, acc 0.671875\n",
      "2018-04-13T14:58:12.193706: step 605, loss 0.507772, acc 0.765625\n",
      "2018-04-13T14:58:12.502423: step 606, loss 0.469441, acc 0.75\n",
      "2018-04-13T14:58:12.818716: step 607, loss 0.388626, acc 0.875\n",
      "2018-04-13T14:58:13.135440: step 608, loss 0.693766, acc 0.609375\n",
      "2018-04-13T14:58:13.445158: step 609, loss 0.683608, acc 0.640625\n",
      "2018-04-13T14:58:13.746871: step 610, loss 0.438973, acc 0.8125\n",
      "2018-04-13T14:58:14.060594: step 611, loss 0.619356, acc 0.671875\n",
      "2018-04-13T14:58:14.359304: step 612, loss 0.376811, acc 0.84375\n",
      "2018-04-13T14:58:14.668022: step 613, loss 0.606271, acc 0.734375\n",
      "2018-04-13T14:58:14.978241: step 614, loss 0.546943, acc 0.734375\n",
      "2018-04-13T14:58:15.283959: step 615, loss 0.539963, acc 0.734375\n",
      "2018-04-13T14:58:15.610688: step 616, loss 0.450287, acc 0.75\n",
      "2018-04-13T14:58:15.918905: step 617, loss 0.665204, acc 0.59375\n",
      "2018-04-13T14:58:16.229130: step 618, loss 0.421819, acc 0.828125\n",
      "2018-04-13T14:58:16.524333: step 619, loss 0.540913, acc 0.703125\n",
      "2018-04-13T14:58:16.839056: step 620, loss 0.50879, acc 0.71875\n",
      "2018-04-13T14:58:17.147273: step 621, loss 0.484473, acc 0.75\n",
      "2018-04-13T14:58:17.480008: step 622, loss 0.440325, acc 0.8125\n",
      "2018-04-13T14:58:17.782221: step 623, loss 0.44518, acc 0.75\n",
      "2018-04-13T14:58:18.090439: step 624, loss 0.5473, acc 0.71875\n",
      "2018-04-13T14:58:18.389149: step 625, loss 0.406904, acc 0.75\n",
      "2018-04-13T14:58:18.688861: step 626, loss 0.474683, acc 0.765625\n",
      "2018-04-13T14:58:19.007086: step 627, loss 0.492866, acc 0.8125\n",
      "2018-04-13T14:58:19.292288: step 628, loss 0.538354, acc 0.734375\n",
      "2018-04-13T14:58:19.587996: step 629, loss 0.523208, acc 0.734375\n",
      "2018-04-13T14:58:19.898716: step 630, loss 0.635536, acc 0.6875\n",
      "2018-04-13T14:58:20.196926: step 631, loss 0.525537, acc 0.765625\n",
      "2018-04-13T14:58:20.507145: step 632, loss 0.434288, acc 0.828125\n",
      "2018-04-13T14:58:20.818366: step 633, loss 0.516328, acc 0.765625\n",
      "2018-04-13T14:58:21.122079: step 634, loss 0.529898, acc 0.71875\n",
      "2018-04-13T14:58:21.416288: step 635, loss 0.563641, acc 0.75\n",
      "2018-04-13T14:58:21.719501: step 636, loss 0.5745, acc 0.671875\n",
      "2018-04-13T14:58:22.015710: step 637, loss 0.565247, acc 0.71875\n",
      "2018-04-13T14:58:22.310466: step 638, loss 0.355203, acc 0.890625\n",
      "2018-04-13T14:58:22.615681: step 639, loss 0.656377, acc 0.75\n",
      "2018-04-13T14:58:22.925400: step 640, loss 0.44469, acc 0.796875\n",
      "2018-04-13T14:58:23.226612: step 641, loss 0.512676, acc 0.75\n",
      "2018-04-13T14:58:23.524823: step 642, loss 0.5317, acc 0.734375\n",
      "2018-04-13T14:58:23.832040: step 643, loss 0.574955, acc 0.734375\n",
      "2018-04-13T14:58:24.138256: step 644, loss 0.529209, acc 0.703125\n",
      "2018-04-13T14:58:24.439969: step 645, loss 0.62442, acc 0.609375\n",
      "2018-04-13T14:58:24.749188: step 646, loss 0.471693, acc 0.828125\n",
      "2018-04-13T14:58:25.066925: step 647, loss 0.568845, acc 0.6875\n",
      "2018-04-13T14:58:25.379145: step 648, loss 0.490408, acc 0.78125\n",
      "2018-04-13T14:58:25.726390: step 649, loss 0.51701, acc 0.671875\n",
      "2018-04-13T14:58:26.034607: step 650, loss 0.466522, acc 0.734375\n",
      "2018-04-13T14:58:26.328816: step 651, loss 0.440771, acc 0.796875\n",
      "2018-04-13T14:58:26.625025: step 652, loss 0.522202, acc 0.75\n",
      "2018-04-13T14:58:26.929239: step 653, loss 0.458551, acc 0.734375\n",
      "2018-04-13T14:58:27.244962: step 654, loss 0.439335, acc 0.828125\n",
      "2018-04-13T14:58:27.548677: step 655, loss 0.507594, acc 0.75\n",
      "2018-04-13T14:58:27.861398: step 656, loss 0.429792, acc 0.828125\n",
      "2018-04-13T14:58:28.169115: step 657, loss 0.539847, acc 0.71875\n",
      "2018-04-13T14:58:28.463322: step 658, loss 0.488574, acc 0.6875\n",
      "2018-04-13T14:58:28.767537: step 659, loss 0.469578, acc 0.765625\n",
      "2018-04-13T14:58:29.074754: step 660, loss 0.418522, acc 0.78125\n",
      "2018-04-13T14:58:29.390477: step 661, loss 0.58491, acc 0.734375\n",
      "2018-04-13T14:58:29.687187: step 662, loss 0.357217, acc 0.828125\n",
      "2018-04-13T14:58:30.000907: step 663, loss 0.466789, acc 0.78125\n",
      "2018-04-13T14:58:30.298619: step 664, loss 0.472336, acc 0.796875\n",
      "2018-04-13T14:58:30.596829: step 665, loss 0.504823, acc 0.796875\n",
      "2018-04-13T14:58:30.905547: step 666, loss 0.55163, acc 0.6875\n",
      "2018-04-13T14:58:31.213265: step 667, loss 0.628261, acc 0.71875\n",
      "2018-04-13T14:58:31.519981: step 668, loss 0.398844, acc 0.875\n",
      "2018-04-13T14:58:31.831701: step 669, loss 0.540454, acc 0.734375\n",
      "2018-04-13T14:58:32.136916: step 670, loss 0.468145, acc 0.734375\n",
      "2018-04-13T14:58:32.430123: step 671, loss 0.409901, acc 0.796875\n",
      "2018-04-13T14:58:32.740843: step 672, loss 0.492183, acc 0.75\n",
      "2018-04-13T14:58:33.043056: step 673, loss 0.420264, acc 0.859375\n",
      "2018-04-13T14:58:33.341767: step 674, loss 0.376792, acc 0.828125\n",
      "2018-04-13T14:58:33.633973: step 675, loss 0.544231, acc 0.796875\n",
      "2018-04-13T14:58:33.946694: step 676, loss 0.669431, acc 0.625\n",
      "2018-04-13T14:58:34.244405: step 677, loss 0.465788, acc 0.78125\n",
      "2018-04-13T14:58:34.551621: step 678, loss 0.549643, acc 0.703125\n",
      "2018-04-13T14:58:34.856837: step 679, loss 0.473589, acc 0.734375\n",
      "2018-04-13T14:58:35.168057: step 680, loss 0.472073, acc 0.75\n",
      "2018-04-13T14:58:35.469270: step 681, loss 0.452475, acc 0.78125\n",
      "2018-04-13T14:58:35.776487: step 682, loss 0.534549, acc 0.703125\n",
      "2018-04-13T14:58:36.076699: step 683, loss 0.498627, acc 0.796875\n",
      "2018-04-13T14:58:36.375410: step 684, loss 0.545794, acc 0.796875\n",
      "2018-04-13T14:58:36.671118: step 685, loss 0.51707, acc 0.71875\n",
      "2018-04-13T14:58:36.984340: step 686, loss 0.421125, acc 0.78125\n",
      "2018-04-13T14:58:37.284551: step 687, loss 0.64441, acc 0.640625\n",
      "2018-04-13T14:58:37.588766: step 688, loss 0.571063, acc 0.703125\n",
      "2018-04-13T14:58:37.912496: step 689, loss 0.485968, acc 0.765625\n",
      "2018-04-13T14:58:38.206703: step 690, loss 0.479998, acc 0.734375\n",
      "2018-04-13T14:58:38.517422: step 691, loss 0.469171, acc 0.796875\n",
      "2018-04-13T14:58:38.831144: step 692, loss 0.434877, acc 0.78125\n",
      "2018-04-13T14:58:39.137360: step 693, loss 0.403022, acc 0.84375\n",
      "2018-04-13T14:58:39.440574: step 694, loss 0.517246, acc 0.734375\n",
      "2018-04-13T14:58:39.753294: step 695, loss 0.405143, acc 0.828125\n",
      "2018-04-13T14:58:40.080527: step 696, loss 0.452172, acc 0.8125\n",
      "2018-04-13T14:58:40.375734: step 697, loss 0.516694, acc 0.703125\n",
      "2018-04-13T14:58:40.686453: step 698, loss 0.491739, acc 0.765625\n",
      "2018-04-13T14:58:40.997173: step 699, loss 0.514881, acc 0.78125\n",
      "2018-04-13T14:58:41.303889: step 700, loss 0.442199, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:58:42.288085: step 700, loss 0.58963, acc 0.666979\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-700\n",
      "\n",
      "2018-04-13T14:58:43.820634: step 701, loss 0.602659, acc 0.703125\n",
      "2018-04-13T14:58:44.143863: step 702, loss 0.454697, acc 0.765625\n",
      "2018-04-13T14:58:44.494311: step 703, loss 0.476004, acc 0.78125\n",
      "2018-04-13T14:58:44.797524: step 704, loss 0.496563, acc 0.796875\n",
      "2018-04-13T14:58:45.108745: step 705, loss 0.495847, acc 0.75\n",
      "2018-04-13T14:58:45.408456: step 706, loss 0.39702, acc 0.84375\n",
      "2018-04-13T14:58:45.715172: step 707, loss 0.490065, acc 0.796875\n",
      "2018-04-13T14:58:46.014383: step 708, loss 0.457977, acc 0.75\n",
      "2018-04-13T14:58:46.321601: step 709, loss 0.58977, acc 0.71875\n",
      "2018-04-13T14:58:46.626316: step 710, loss 0.433425, acc 0.75\n",
      "2018-04-13T14:58:46.939537: step 711, loss 0.389991, acc 0.8125\n",
      "2018-04-13T14:58:47.244752: step 712, loss 0.372988, acc 0.8125\n",
      "2018-04-13T14:58:47.544965: step 713, loss 0.477199, acc 0.71875\n",
      "2018-04-13T14:58:47.852182: step 714, loss 0.446884, acc 0.75\n",
      "2018-04-13T14:58:48.161900: step 715, loss 0.486065, acc 0.78125\n",
      "2018-04-13T14:58:48.466115: step 716, loss 0.500978, acc 0.71875\n",
      "2018-04-13T14:58:48.774332: step 717, loss 0.472777, acc 0.796875\n",
      "2018-04-13T14:58:49.078547: step 718, loss 0.565448, acc 0.734375\n",
      "2018-04-13T14:58:49.387265: step 719, loss 0.441344, acc 0.8125\n",
      "2018-04-13T14:58:49.690980: step 720, loss 0.42823, acc 0.796875\n",
      "2018-04-13T14:58:49.997697: step 721, loss 0.504169, acc 0.796875\n",
      "2018-04-13T14:58:50.304413: step 722, loss 0.5056, acc 0.78125\n",
      "2018-04-13T14:58:50.611630: step 723, loss 0.482404, acc 0.78125\n",
      "2018-04-13T14:58:50.925352: step 724, loss 0.474121, acc 0.71875\n",
      "2018-04-13T14:58:51.234569: step 725, loss 0.519255, acc 0.75\n",
      "2018-04-13T14:58:51.547791: step 726, loss 0.538235, acc 0.734375\n",
      "2018-04-13T14:58:51.861012: step 727, loss 0.456864, acc 0.765625\n",
      "2018-04-13T14:58:52.173733: step 728, loss 0.489993, acc 0.734375\n",
      "2018-04-13T14:58:52.476947: step 729, loss 0.499116, acc 0.796875\n",
      "2018-04-13T14:58:52.787166: step 730, loss 0.611952, acc 0.703125\n",
      "2018-04-13T14:58:53.091381: step 731, loss 0.414623, acc 0.859375\n",
      "2018-04-13T14:58:53.407605: step 732, loss 0.494251, acc 0.734375\n",
      "2018-04-13T14:58:53.712319: step 733, loss 0.512508, acc 0.734375\n",
      "2018-04-13T14:58:54.016033: step 734, loss 0.403315, acc 0.859375\n",
      "2018-04-13T14:58:54.319748: step 735, loss 0.48399, acc 0.828125\n",
      "2018-04-13T14:58:54.619460: step 736, loss 0.456621, acc 0.78125\n",
      "2018-04-13T14:58:54.947191: step 737, loss 0.563953, acc 0.6875\n",
      "2018-04-13T14:58:55.246902: step 738, loss 0.463382, acc 0.8125\n",
      "2018-04-13T14:58:55.551118: step 739, loss 0.549873, acc 0.71875\n",
      "2018-04-13T14:58:55.857835: step 740, loss 0.476044, acc 0.8125\n",
      "2018-04-13T14:58:56.164050: step 741, loss 0.606771, acc 0.6875\n",
      "2018-04-13T14:58:56.469767: step 742, loss 0.36996, acc 0.828125\n",
      "2018-04-13T14:58:56.792995: step 743, loss 0.454623, acc 0.78125\n",
      "2018-04-13T14:58:57.099211: step 744, loss 0.622521, acc 0.734375\n",
      "2018-04-13T14:58:57.405427: step 745, loss 0.570442, acc 0.703125\n",
      "2018-04-13T14:58:57.716147: step 746, loss 0.551651, acc 0.765625\n",
      "2018-04-13T14:58:58.025365: step 747, loss 0.536535, acc 0.75\n",
      "2018-04-13T14:58:58.334083: step 748, loss 0.539517, acc 0.6875\n",
      "2018-04-13T14:58:58.650806: step 749, loss 0.508329, acc 0.71875\n",
      "2018-04-13T14:58:58.963528: step 750, loss 0.409375, acc 0.816667\n",
      "2018-04-13T14:58:59.259736: step 751, loss 0.429318, acc 0.8125\n",
      "2018-04-13T14:58:59.571957: step 752, loss 0.560281, acc 0.6875\n",
      "2018-04-13T14:58:59.890682: step 753, loss 0.588684, acc 0.703125\n",
      "2018-04-13T14:59:00.199400: step 754, loss 0.436047, acc 0.796875\n",
      "2018-04-13T14:59:00.537639: step 755, loss 0.435243, acc 0.8125\n",
      "2018-04-13T14:59:00.855363: step 756, loss 0.408925, acc 0.8125\n",
      "2018-04-13T14:59:01.177090: step 757, loss 0.492725, acc 0.765625\n",
      "2018-04-13T14:59:01.483807: step 758, loss 0.463184, acc 0.734375\n",
      "2018-04-13T14:59:01.796028: step 759, loss 0.50779, acc 0.703125\n",
      "2018-04-13T14:59:02.096240: step 760, loss 0.439919, acc 0.796875\n",
      "2018-04-13T14:59:02.400964: step 761, loss 0.491169, acc 0.765625\n",
      "2018-04-13T14:59:02.718188: step 762, loss 0.338019, acc 0.859375\n",
      "2018-04-13T14:59:03.021401: step 763, loss 0.41627, acc 0.8125\n",
      "2018-04-13T14:59:03.330119: step 764, loss 0.456183, acc 0.765625\n",
      "2018-04-13T14:59:03.646844: step 765, loss 0.431716, acc 0.78125\n",
      "2018-04-13T14:59:03.965068: step 766, loss 0.406404, acc 0.796875\n",
      "2018-04-13T14:59:04.261278: step 767, loss 0.440114, acc 0.78125\n",
      "2018-04-13T14:59:04.570495: step 768, loss 0.467745, acc 0.796875\n",
      "2018-04-13T14:59:04.871708: step 769, loss 0.343173, acc 0.828125\n",
      "2018-04-13T14:59:05.177924: step 770, loss 0.485349, acc 0.734375\n",
      "2018-04-13T14:59:05.483641: step 771, loss 0.297739, acc 0.875\n",
      "2018-04-13T14:59:05.803867: step 772, loss 0.403989, acc 0.84375\n",
      "2018-04-13T14:59:06.111584: step 773, loss 0.427124, acc 0.8125\n",
      "2018-04-13T14:59:06.422302: step 774, loss 0.354899, acc 0.90625\n",
      "2018-04-13T14:59:06.797067: step 775, loss 0.381558, acc 0.84375\n",
      "2018-04-13T14:59:07.094788: step 776, loss 0.340325, acc 0.859375\n",
      "2018-04-13T14:59:07.407499: step 777, loss 0.437692, acc 0.8125\n",
      "2018-04-13T14:59:07.720219: step 778, loss 0.516406, acc 0.703125\n",
      "2018-04-13T14:59:08.037443: step 779, loss 0.464647, acc 0.8125\n",
      "2018-04-13T14:59:08.341158: step 780, loss 0.370608, acc 0.859375\n",
      "2018-04-13T14:59:08.647374: step 781, loss 0.420903, acc 0.859375\n",
      "2018-04-13T14:59:08.960595: step 782, loss 0.330756, acc 0.90625\n",
      "2018-04-13T14:59:09.281322: step 783, loss 0.408239, acc 0.8125\n",
      "2018-04-13T14:59:09.593543: step 784, loss 0.346285, acc 0.90625\n",
      "2018-04-13T14:59:09.911767: step 785, loss 0.470613, acc 0.796875\n",
      "2018-04-13T14:59:10.210978: step 786, loss 0.483774, acc 0.734375\n",
      "2018-04-13T14:59:10.511690: step 787, loss 0.481414, acc 0.84375\n",
      "2018-04-13T14:59:10.824911: step 788, loss 0.377034, acc 0.828125\n",
      "2018-04-13T14:59:11.126625: step 789, loss 0.401329, acc 0.765625\n",
      "2018-04-13T14:59:11.430340: step 790, loss 0.371601, acc 0.84375\n",
      "2018-04-13T14:59:11.745061: step 791, loss 0.340873, acc 0.84375\n",
      "2018-04-13T14:59:12.053279: step 792, loss 0.515626, acc 0.8125\n",
      "2018-04-13T14:59:12.359995: step 793, loss 0.40624, acc 0.84375\n",
      "2018-04-13T14:59:12.683224: step 794, loss 0.429911, acc 0.828125\n",
      "2018-04-13T14:59:13.003450: step 795, loss 0.314127, acc 0.859375\n",
      "2018-04-13T14:59:13.308665: step 796, loss 0.549797, acc 0.671875\n",
      "2018-04-13T14:59:13.621387: step 797, loss 0.398793, acc 0.796875\n",
      "2018-04-13T14:59:13.947116: step 798, loss 0.608968, acc 0.71875\n",
      "2018-04-13T14:59:14.269844: step 799, loss 0.521551, acc 0.765625\n",
      "2018-04-13T14:59:14.595074: step 800, loss 0.318496, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:59:15.595780: step 800, loss 0.586456, acc 0.677298\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-800\n",
      "\n",
      "2018-04-13T14:59:17.170133: step 801, loss 0.328785, acc 0.859375\n",
      "2018-04-13T14:59:17.495863: step 802, loss 0.403757, acc 0.828125\n",
      "2018-04-13T14:59:17.808083: step 803, loss 0.331306, acc 0.90625\n",
      "2018-04-13T14:59:18.135815: step 804, loss 0.542784, acc 0.71875\n",
      "2018-04-13T14:59:18.444032: step 805, loss 0.530112, acc 0.78125\n",
      "2018-04-13T14:59:18.776267: step 806, loss 0.42847, acc 0.859375\n",
      "2018-04-13T14:59:19.087988: step 807, loss 0.372403, acc 0.84375\n",
      "2018-04-13T14:59:19.401708: step 808, loss 0.427778, acc 0.8125\n",
      "2018-04-13T14:59:19.748954: step 809, loss 0.388828, acc 0.859375\n",
      "2018-04-13T14:59:20.080688: step 810, loss 0.474327, acc 0.78125\n",
      "2018-04-13T14:59:20.380400: step 811, loss 0.363352, acc 0.875\n",
      "2018-04-13T14:59:20.698126: step 812, loss 0.540535, acc 0.6875\n",
      "2018-04-13T14:59:21.015853: step 813, loss 0.394665, acc 0.84375\n",
      "2018-04-13T14:59:21.327068: step 814, loss 0.551518, acc 0.765625\n",
      "2018-04-13T14:59:21.640290: step 815, loss 0.63713, acc 0.6875\n",
      "2018-04-13T14:59:21.967520: step 816, loss 0.557389, acc 0.71875\n",
      "2018-04-13T14:59:22.268733: step 817, loss 0.476787, acc 0.796875\n",
      "2018-04-13T14:59:22.574449: step 818, loss 0.40539, acc 0.78125\n",
      "2018-04-13T14:59:22.907685: step 819, loss 0.472744, acc 0.78125\n",
      "2018-04-13T14:59:23.209898: step 820, loss 0.468033, acc 0.796875\n",
      "2018-04-13T14:59:23.527632: step 821, loss 0.526659, acc 0.734375\n",
      "2018-04-13T14:59:23.849859: step 822, loss 0.395911, acc 0.8125\n",
      "2018-04-13T14:59:24.163081: step 823, loss 0.3681, acc 0.859375\n",
      "2018-04-13T14:59:24.470798: step 824, loss 0.3809, acc 0.84375\n",
      "2018-04-13T14:59:24.780517: step 825, loss 0.372233, acc 0.8125\n",
      "2018-04-13T14:59:25.084731: step 826, loss 0.41149, acc 0.78125\n",
      "2018-04-13T14:59:25.389947: step 827, loss 0.469376, acc 0.8125\n",
      "2018-04-13T14:59:25.703168: step 828, loss 0.388485, acc 0.828125\n",
      "2018-04-13T14:59:26.017890: step 829, loss 0.439505, acc 0.8125\n",
      "2018-04-13T14:59:26.325109: step 830, loss 0.413562, acc 0.765625\n",
      "2018-04-13T14:59:26.638828: step 831, loss 0.43126, acc 0.8125\n",
      "2018-04-13T14:59:26.957054: step 832, loss 0.311843, acc 0.828125\n",
      "2018-04-13T14:59:27.266772: step 833, loss 0.362815, acc 0.84375\n",
      "2018-04-13T14:59:27.578492: step 834, loss 0.392164, acc 0.84375\n",
      "2018-04-13T14:59:27.908225: step 835, loss 0.481613, acc 0.75\n",
      "2018-04-13T14:59:28.231954: step 836, loss 0.380212, acc 0.8125\n",
      "2018-04-13T14:59:28.552180: step 837, loss 0.292172, acc 0.921875\n",
      "2018-04-13T14:59:28.896923: step 838, loss 0.500159, acc 0.703125\n",
      "2018-04-13T14:59:29.223155: step 839, loss 0.411479, acc 0.859375\n",
      "2018-04-13T14:59:29.552386: step 840, loss 0.497304, acc 0.75\n",
      "2018-04-13T14:59:29.890624: step 841, loss 0.476842, acc 0.75\n",
      "2018-04-13T14:59:30.208350: step 842, loss 0.57538, acc 0.734375\n",
      "2018-04-13T14:59:30.568103: step 843, loss 0.375284, acc 0.8125\n",
      "2018-04-13T14:59:30.901339: step 844, loss 0.365391, acc 0.859375\n",
      "2018-04-13T14:59:31.252587: step 845, loss 0.35689, acc 0.8125\n",
      "2018-04-13T14:59:31.575815: step 846, loss 0.395962, acc 0.796875\n",
      "2018-04-13T14:59:31.919058: step 847, loss 0.362099, acc 0.8125\n",
      "2018-04-13T14:59:32.218268: step 848, loss 0.487928, acc 0.765625\n",
      "2018-04-13T14:59:32.531990: step 849, loss 0.422243, acc 0.75\n",
      "2018-04-13T14:59:32.870229: step 850, loss 0.561375, acc 0.71875\n",
      "2018-04-13T14:59:33.177946: step 851, loss 0.468994, acc 0.796875\n",
      "2018-04-13T14:59:33.488665: step 852, loss 0.363496, acc 0.828125\n",
      "2018-04-13T14:59:33.807390: step 853, loss 0.515967, acc 0.75\n",
      "2018-04-13T14:59:34.114607: step 854, loss 0.480735, acc 0.765625\n",
      "2018-04-13T14:59:34.415820: step 855, loss 0.361936, acc 0.859375\n",
      "2018-04-13T14:59:34.726039: step 856, loss 0.515931, acc 0.734375\n",
      "2018-04-13T14:59:35.040761: step 857, loss 0.388944, acc 0.84375\n",
      "2018-04-13T14:59:35.340974: step 858, loss 0.38449, acc 0.828125\n",
      "2018-04-13T14:59:35.645688: step 859, loss 0.420822, acc 0.828125\n",
      "2018-04-13T14:59:35.966415: step 860, loss 0.402139, acc 0.8125\n",
      "2018-04-13T14:59:36.273633: step 861, loss 0.49463, acc 0.796875\n",
      "2018-04-13T14:59:36.587354: step 862, loss 0.352466, acc 0.890625\n",
      "2018-04-13T14:59:36.913083: step 863, loss 0.48471, acc 0.734375\n",
      "2018-04-13T14:59:37.220801: step 864, loss 0.44297, acc 0.75\n",
      "2018-04-13T14:59:37.532021: step 865, loss 0.551817, acc 0.71875\n",
      "2018-04-13T14:59:37.850745: step 866, loss 0.506858, acc 0.734375\n",
      "2018-04-13T14:59:38.164968: step 867, loss 0.451536, acc 0.78125\n",
      "2018-04-13T14:59:38.476688: step 868, loss 0.567972, acc 0.703125\n",
      "2018-04-13T14:59:38.787407: step 869, loss 0.503662, acc 0.6875\n",
      "2018-04-13T14:59:39.090121: step 870, loss 0.463074, acc 0.78125\n",
      "2018-04-13T14:59:39.387331: step 871, loss 0.385995, acc 0.84375\n",
      "2018-04-13T14:59:39.749589: step 872, loss 0.330387, acc 0.875\n",
      "2018-04-13T14:59:40.155341: step 873, loss 0.478648, acc 0.8125\n",
      "2018-04-13T14:59:40.457053: step 874, loss 0.470311, acc 0.75\n",
      "2018-04-13T14:59:40.772776: step 875, loss 0.441147, acc 0.8125\n",
      "2018-04-13T14:59:41.084997: step 876, loss 0.451457, acc 0.828125\n",
      "2018-04-13T14:59:41.400917: step 877, loss 0.457473, acc 0.8125\n",
      "2018-04-13T14:59:41.723145: step 878, loss 0.289901, acc 0.859375\n",
      "2018-04-13T14:59:42.054879: step 879, loss 0.721716, acc 0.65625\n",
      "2018-04-13T14:59:42.367099: step 880, loss 0.581914, acc 0.6875\n",
      "2018-04-13T14:59:42.668812: step 881, loss 0.51442, acc 0.765625\n",
      "2018-04-13T14:59:42.984535: step 882, loss 0.489714, acc 0.765625\n",
      "2018-04-13T14:59:43.310766: step 883, loss 0.438458, acc 0.8125\n",
      "2018-04-13T14:59:43.621985: step 884, loss 0.413598, acc 0.765625\n",
      "2018-04-13T14:59:43.946715: step 885, loss 0.455666, acc 0.71875\n",
      "2018-04-13T14:59:44.243924: step 886, loss 0.436181, acc 0.828125\n",
      "2018-04-13T14:59:44.562149: step 887, loss 0.465847, acc 0.78125\n",
      "2018-04-13T14:59:44.879374: step 888, loss 0.636772, acc 0.734375\n",
      "2018-04-13T14:59:45.183588: step 889, loss 0.387631, acc 0.8125\n",
      "2018-04-13T14:59:45.496309: step 890, loss 0.464161, acc 0.765625\n",
      "2018-04-13T14:59:45.813533: step 891, loss 0.476403, acc 0.84375\n",
      "2018-04-13T14:59:46.128255: step 892, loss 0.411841, acc 0.859375\n",
      "2018-04-13T14:59:46.437474: step 893, loss 0.352845, acc 0.84375\n",
      "2018-04-13T14:59:46.745691: step 894, loss 0.555282, acc 0.75\n",
      "2018-04-13T14:59:47.061414: step 895, loss 0.408898, acc 0.84375\n",
      "2018-04-13T14:59:47.370133: step 896, loss 0.231203, acc 0.921875\n",
      "2018-04-13T14:59:47.697363: step 897, loss 0.527368, acc 0.765625\n",
      "2018-04-13T14:59:48.006581: step 898, loss 0.319372, acc 0.859375\n",
      "2018-04-13T14:59:48.313298: step 899, loss 0.40677, acc 0.828125\n",
      "2018-04-13T14:59:48.603006: step 900, loss 0.401798, acc 0.816667\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T14:59:49.621221: step 900, loss 0.568129, acc 0.699812\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-900\n",
      "\n",
      "2018-04-13T14:59:52.298427: step 901, loss 0.385255, acc 0.859375\n",
      "2018-04-13T14:59:52.615651: step 902, loss 0.260356, acc 0.890625\n",
      "2018-04-13T14:59:52.931374: step 903, loss 0.294567, acc 0.90625\n",
      "2018-04-13T14:59:53.242092: step 904, loss 0.288813, acc 0.828125\n",
      "2018-04-13T14:59:53.567323: step 905, loss 0.334755, acc 0.859375\n",
      "2018-04-13T14:59:53.885047: step 906, loss 0.274558, acc 0.875\n",
      "2018-04-13T14:59:54.197768: step 907, loss 0.350273, acc 0.859375\n",
      "2018-04-13T14:59:54.515992: step 908, loss 0.347617, acc 0.875\n",
      "2018-04-13T14:59:54.849228: step 909, loss 0.318457, acc 0.890625\n",
      "2018-04-13T14:59:55.158446: step 910, loss 0.358942, acc 0.84375\n",
      "2018-04-13T14:59:55.485177: step 911, loss 0.255553, acc 0.90625\n",
      "2018-04-13T14:59:55.811907: step 912, loss 0.427072, acc 0.796875\n",
      "2018-04-13T14:59:56.131132: step 913, loss 0.27929, acc 0.9375\n",
      "2018-04-13T14:59:56.440351: step 914, loss 0.329132, acc 0.875\n",
      "2018-04-13T14:59:56.762078: step 915, loss 0.33411, acc 0.859375\n",
      "2018-04-13T14:59:57.073297: step 916, loss 0.269855, acc 0.890625\n",
      "2018-04-13T14:59:57.397526: step 917, loss 0.260564, acc 0.875\n",
      "2018-04-13T14:59:57.710247: step 918, loss 0.418263, acc 0.8125\n",
      "2018-04-13T14:59:58.033976: step 919, loss 0.290221, acc 0.921875\n",
      "2018-04-13T14:59:58.352201: step 920, loss 0.311061, acc 0.90625\n",
      "2018-04-13T14:59:58.696945: step 921, loss 0.427759, acc 0.828125\n",
      "2018-04-13T14:59:59.006663: step 922, loss 0.375488, acc 0.796875\n",
      "2018-04-13T14:59:59.335895: step 923, loss 0.289381, acc 0.859375\n",
      "2018-04-13T14:59:59.650618: step 924, loss 0.340173, acc 0.84375\n",
      "2018-04-13T14:59:59.976349: step 925, loss 0.296884, acc 0.859375\n",
      "2018-04-13T15:00:00.303079: step 926, loss 0.36054, acc 0.84375\n",
      "2018-04-13T15:00:00.642328: step 927, loss 0.388791, acc 0.84375\n",
      "2018-04-13T15:00:00.968549: step 928, loss 0.229956, acc 0.9375\n",
      "2018-04-13T15:00:01.299782: step 929, loss 0.31641, acc 0.84375\n",
      "2018-04-13T15:00:01.613004: step 930, loss 0.355766, acc 0.859375\n",
      "2018-04-13T15:00:01.949741: step 931, loss 0.354395, acc 0.859375\n",
      "2018-04-13T15:00:02.292984: step 932, loss 0.391672, acc 0.78125\n",
      "2018-04-13T15:00:02.631723: step 933, loss 0.260393, acc 0.875\n",
      "2018-04-13T15:00:02.977967: step 934, loss 0.382391, acc 0.84375\n",
      "2018-04-13T15:00:03.312704: step 935, loss 0.346814, acc 0.8125\n",
      "2018-04-13T15:00:03.624423: step 936, loss 0.265446, acc 0.890625\n",
      "2018-04-13T15:00:03.943649: step 937, loss 0.249809, acc 0.875\n",
      "2018-04-13T15:00:04.270880: step 938, loss 0.300692, acc 0.90625\n",
      "2018-04-13T15:00:04.599112: step 939, loss 0.316376, acc 0.859375\n",
      "2018-04-13T15:00:04.925343: step 940, loss 0.499736, acc 0.765625\n",
      "2018-04-13T15:00:05.261079: step 941, loss 0.341308, acc 0.875\n",
      "2018-04-13T15:00:05.583307: step 942, loss 0.327678, acc 0.859375\n",
      "2018-04-13T15:00:05.923548: step 943, loss 0.36934, acc 0.84375\n",
      "2018-04-13T15:00:06.249777: step 944, loss 0.414703, acc 0.859375\n",
      "2018-04-13T15:00:06.559997: step 945, loss 0.338469, acc 0.796875\n",
      "2018-04-13T15:00:06.887728: step 946, loss 0.45471, acc 0.8125\n",
      "2018-04-13T15:00:07.212457: step 947, loss 0.425415, acc 0.78125\n",
      "2018-04-13T15:00:07.539688: step 948, loss 0.427349, acc 0.828125\n",
      "2018-04-13T15:00:07.865418: step 949, loss 0.389596, acc 0.84375\n",
      "2018-04-13T15:00:08.194651: step 950, loss 0.315272, acc 0.875\n",
      "2018-04-13T15:00:08.505870: step 951, loss 0.349381, acc 0.875\n",
      "2018-04-13T15:00:08.840106: step 952, loss 0.337054, acc 0.859375\n",
      "2018-04-13T15:00:09.163335: step 953, loss 0.514536, acc 0.78125\n",
      "2018-04-13T15:00:09.491066: step 954, loss 0.568038, acc 0.765625\n",
      "2018-04-13T15:00:09.819298: step 955, loss 0.516523, acc 0.765625\n",
      "2018-04-13T15:00:10.140025: step 956, loss 0.406852, acc 0.78125\n",
      "2018-04-13T15:00:10.460251: step 957, loss 0.44554, acc 0.84375\n",
      "2018-04-13T15:00:10.800991: step 958, loss 0.301181, acc 0.859375\n",
      "2018-04-13T15:00:11.124720: step 959, loss 0.483771, acc 0.75\n",
      "2018-04-13T15:00:11.437441: step 960, loss 0.372797, acc 0.796875\n",
      "2018-04-13T15:00:11.766172: step 961, loss 0.394859, acc 0.828125\n",
      "2018-04-13T15:00:12.143439: step 962, loss 0.477201, acc 0.765625\n",
      "2018-04-13T15:00:12.529212: step 963, loss 0.437761, acc 0.84375\n",
      "2018-04-13T15:00:12.935999: step 964, loss 0.3828, acc 0.859375\n",
      "2018-04-13T15:00:13.328776: step 965, loss 0.380595, acc 0.828125\n",
      "2018-04-13T15:00:13.750583: step 966, loss 0.439422, acc 0.84375\n",
      "2018-04-13T15:00:14.082317: step 967, loss 0.377309, acc 0.8125\n",
      "2018-04-13T15:00:14.413551: step 968, loss 0.495468, acc 0.75\n",
      "2018-04-13T15:00:14.749789: step 969, loss 0.48244, acc 0.796875\n",
      "2018-04-13T15:00:15.077521: step 970, loss 0.387512, acc 0.8125\n",
      "2018-04-13T15:00:15.382235: step 971, loss 0.333842, acc 0.8125\n",
      "2018-04-13T15:00:15.674942: step 972, loss 0.320877, acc 0.8125\n",
      "2018-04-13T15:00:15.994167: step 973, loss 0.40995, acc 0.859375\n",
      "2018-04-13T15:00:16.308890: step 974, loss 0.412156, acc 0.8125\n",
      "2018-04-13T15:00:16.631118: step 975, loss 0.418376, acc 0.8125\n",
      "2018-04-13T15:00:17.002379: step 976, loss 0.299888, acc 0.84375\n",
      "2018-04-13T15:00:17.369138: step 977, loss 0.368005, acc 0.859375\n",
      "2018-04-13T15:00:17.718886: step 978, loss 0.268267, acc 0.90625\n",
      "2018-04-13T15:00:18.060626: step 979, loss 0.325872, acc 0.859375\n",
      "2018-04-13T15:00:18.496935: step 980, loss 0.282711, acc 0.859375\n",
      "2018-04-13T15:00:18.859691: step 981, loss 0.387408, acc 0.84375\n",
      "2018-04-13T15:00:19.199430: step 982, loss 0.388976, acc 0.859375\n",
      "2018-04-13T15:00:19.535168: step 983, loss 0.390516, acc 0.828125\n",
      "2018-04-13T15:00:19.870905: step 984, loss 0.266699, acc 0.890625\n",
      "2018-04-13T15:00:20.275191: step 985, loss 0.310359, acc 0.890625\n",
      "2018-04-13T15:00:20.649454: step 986, loss 0.31776, acc 0.828125\n",
      "2018-04-13T15:00:20.997200: step 987, loss 0.454155, acc 0.859375\n",
      "2018-04-13T15:00:21.328443: step 988, loss 0.466253, acc 0.796875\n",
      "2018-04-13T15:00:21.656175: step 989, loss 0.314324, acc 0.84375\n",
      "2018-04-13T15:00:21.983407: step 990, loss 0.370119, acc 0.875\n",
      "2018-04-13T15:00:22.313139: step 991, loss 0.469427, acc 0.796875\n",
      "2018-04-13T15:00:22.627361: step 992, loss 0.284949, acc 0.859375\n",
      "2018-04-13T15:00:22.953091: step 993, loss 0.356003, acc 0.8125\n",
      "2018-04-13T15:00:23.282824: step 994, loss 0.431434, acc 0.8125\n",
      "2018-04-13T15:00:23.602048: step 995, loss 0.32638, acc 0.875\n",
      "2018-04-13T15:00:23.938787: step 996, loss 0.43447, acc 0.828125\n",
      "2018-04-13T15:00:24.285032: step 997, loss 0.412081, acc 0.796875\n",
      "2018-04-13T15:00:24.603756: step 998, loss 0.362979, acc 0.78125\n",
      "2018-04-13T15:00:24.927985: step 999, loss 0.356395, acc 0.796875\n",
      "2018-04-13T15:00:25.246210: step 1000, loss 0.330823, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:00:26.275937: step 1000, loss 0.593438, acc 0.699812\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1000\n",
      "\n",
      "2018-04-13T15:00:27.759156: step 1001, loss 0.223525, acc 0.890625\n",
      "2018-04-13T15:00:28.092391: step 1002, loss 0.301651, acc 0.875\n",
      "2018-04-13T15:00:28.416620: step 1003, loss 0.465437, acc 0.796875\n",
      "2018-04-13T15:00:28.738847: step 1004, loss 0.321441, acc 0.84375\n",
      "2018-04-13T15:00:29.064578: step 1005, loss 0.326484, acc 0.84375\n",
      "2018-04-13T15:00:29.384804: step 1006, loss 0.358446, acc 0.875\n",
      "2018-04-13T15:00:29.704029: step 1007, loss 0.510199, acc 0.765625\n",
      "2018-04-13T15:00:30.025757: step 1008, loss 0.566584, acc 0.734375\n",
      "2018-04-13T15:00:30.363995: step 1009, loss 0.274372, acc 0.90625\n",
      "2018-04-13T15:00:30.684722: step 1010, loss 0.405664, acc 0.78125\n",
      "2018-04-13T15:00:31.019959: step 1011, loss 0.238631, acc 0.953125\n",
      "2018-04-13T15:00:31.351192: step 1012, loss 0.253435, acc 0.875\n",
      "2018-04-13T15:00:31.687937: step 1013, loss 0.274299, acc 0.890625\n",
      "2018-04-13T15:00:32.011665: step 1014, loss 0.256426, acc 0.921875\n",
      "2018-04-13T15:00:32.333892: step 1015, loss 0.396329, acc 0.859375\n",
      "2018-04-13T15:00:32.652117: step 1016, loss 0.375796, acc 0.78125\n",
      "2018-04-13T15:00:32.981361: step 1017, loss 0.409027, acc 0.875\n",
      "2018-04-13T15:00:33.299585: step 1018, loss 0.321726, acc 0.859375\n",
      "2018-04-13T15:00:33.626327: step 1019, loss 0.377163, acc 0.796875\n",
      "2018-04-13T15:00:33.961063: step 1020, loss 0.340601, acc 0.84375\n",
      "2018-04-13T15:00:34.288293: step 1021, loss 0.40386, acc 0.828125\n",
      "2018-04-13T15:00:34.609020: step 1022, loss 0.450234, acc 0.734375\n",
      "2018-04-13T15:00:34.928746: step 1023, loss 0.352954, acc 0.875\n",
      "2018-04-13T15:00:35.241968: step 1024, loss 0.451274, acc 0.796875\n",
      "2018-04-13T15:00:35.567197: step 1025, loss 0.561312, acc 0.703125\n",
      "2018-04-13T15:00:35.893927: step 1026, loss 0.433941, acc 0.8125\n",
      "2018-04-13T15:00:36.211652: step 1027, loss 0.447904, acc 0.734375\n",
      "2018-04-13T15:00:36.535381: step 1028, loss 0.312104, acc 0.859375\n",
      "2018-04-13T15:00:36.859110: step 1029, loss 0.344522, acc 0.84375\n",
      "2018-04-13T15:00:37.185840: step 1030, loss 0.504652, acc 0.828125\n",
      "2018-04-13T15:00:37.514071: step 1031, loss 0.419406, acc 0.796875\n",
      "2018-04-13T15:00:37.837300: step 1032, loss 0.475334, acc 0.796875\n",
      "2018-04-13T15:00:38.154524: step 1033, loss 0.271159, acc 0.890625\n",
      "2018-04-13T15:00:38.470247: step 1034, loss 0.450265, acc 0.796875\n",
      "2018-04-13T15:00:38.799979: step 1035, loss 0.484429, acc 0.78125\n",
      "2018-04-13T15:00:39.119210: step 1036, loss 0.367866, acc 0.828125\n",
      "2018-04-13T15:00:39.437430: step 1037, loss 0.502007, acc 0.796875\n",
      "2018-04-13T15:00:39.767163: step 1038, loss 0.447614, acc 0.796875\n",
      "2018-04-13T15:00:40.110405: step 1039, loss 0.4315, acc 0.796875\n",
      "2018-04-13T15:00:40.426628: step 1040, loss 0.326498, acc 0.875\n",
      "2018-04-13T15:00:40.762866: step 1041, loss 0.545322, acc 0.796875\n",
      "2018-04-13T15:00:41.084092: step 1042, loss 0.252712, acc 0.90625\n",
      "2018-04-13T15:00:41.403818: step 1043, loss 0.250031, acc 0.90625\n",
      "2018-04-13T15:00:41.727548: step 1044, loss 0.432845, acc 0.75\n",
      "2018-04-13T15:00:42.042769: step 1045, loss 0.293603, acc 0.828125\n",
      "2018-04-13T15:00:42.367999: step 1046, loss 0.470834, acc 0.734375\n",
      "2018-04-13T15:00:42.692729: step 1047, loss 0.430478, acc 0.796875\n",
      "2018-04-13T15:00:43.008452: step 1048, loss 0.259256, acc 0.90625\n",
      "2018-04-13T15:00:43.338684: step 1049, loss 0.251305, acc 0.9375\n",
      "2018-04-13T15:00:43.644400: step 1050, loss 0.320236, acc 0.866667\n",
      "2018-04-13T15:00:43.974633: step 1051, loss 0.276146, acc 0.890625\n",
      "2018-04-13T15:00:44.287354: step 1052, loss 0.226306, acc 0.9375\n",
      "2018-04-13T15:00:44.654614: step 1053, loss 0.285569, acc 0.859375\n",
      "2018-04-13T15:00:44.977842: step 1054, loss 0.25976, acc 0.890625\n",
      "2018-04-13T15:00:45.295066: step 1055, loss 0.324776, acc 0.890625\n",
      "2018-04-13T15:00:45.629301: step 1056, loss 0.359682, acc 0.84375\n",
      "2018-04-13T15:00:45.967041: step 1057, loss 0.288416, acc 0.921875\n",
      "2018-04-13T15:00:46.299274: step 1058, loss 0.433798, acc 0.828125\n",
      "2018-04-13T15:00:46.631009: step 1059, loss 0.284725, acc 0.859375\n",
      "2018-04-13T15:00:46.953737: step 1060, loss 0.314474, acc 0.875\n",
      "2018-04-13T15:00:47.270961: step 1061, loss 0.306788, acc 0.890625\n",
      "2018-04-13T15:00:47.587684: step 1062, loss 0.267608, acc 0.90625\n",
      "2018-04-13T15:00:47.911413: step 1063, loss 0.295574, acc 0.859375\n",
      "2018-04-13T15:00:48.234642: step 1064, loss 0.249303, acc 0.90625\n",
      "2018-04-13T15:00:48.555868: step 1065, loss 0.253596, acc 0.890625\n",
      "2018-04-13T15:00:48.887102: step 1066, loss 0.291256, acc 0.859375\n",
      "2018-04-13T15:00:49.201824: step 1067, loss 0.315577, acc 0.859375\n",
      "2018-04-13T15:00:49.521050: step 1068, loss 0.192502, acc 0.953125\n",
      "2018-04-13T15:00:49.854286: step 1069, loss 0.385309, acc 0.8125\n",
      "2018-04-13T15:00:50.170008: step 1070, loss 0.36414, acc 0.828125\n",
      "2018-04-13T15:00:50.491235: step 1071, loss 0.309206, acc 0.890625\n",
      "2018-04-13T15:00:50.809960: step 1072, loss 0.290768, acc 0.90625\n",
      "2018-04-13T15:00:51.122180: step 1073, loss 0.26352, acc 0.921875\n",
      "2018-04-13T15:00:51.441906: step 1074, loss 0.304763, acc 0.921875\n",
      "2018-04-13T15:00:51.771138: step 1075, loss 0.277912, acc 0.90625\n",
      "2018-04-13T15:00:52.096868: step 1076, loss 0.410766, acc 0.828125\n",
      "2018-04-13T15:00:52.423600: step 1077, loss 0.276618, acc 0.859375\n",
      "2018-04-13T15:00:52.752832: step 1078, loss 0.237389, acc 0.90625\n",
      "2018-04-13T15:00:53.083566: step 1079, loss 0.358174, acc 0.84375\n",
      "2018-04-13T15:00:53.397287: step 1080, loss 0.471522, acc 0.796875\n",
      "2018-04-13T15:00:53.719014: step 1081, loss 0.385886, acc 0.8125\n",
      "2018-04-13T15:00:54.042743: step 1082, loss 0.28823, acc 0.84375\n",
      "2018-04-13T15:00:54.359467: step 1083, loss 0.336294, acc 0.90625\n",
      "2018-04-13T15:00:54.688199: step 1084, loss 0.313192, acc 0.875\n",
      "2018-04-13T15:00:55.011427: step 1085, loss 0.299471, acc 0.859375\n",
      "2018-04-13T15:00:55.334155: step 1086, loss 0.332384, acc 0.796875\n",
      "2018-04-13T15:00:55.659885: step 1087, loss 0.285826, acc 0.875\n",
      "2018-04-13T15:00:56.003628: step 1088, loss 0.185625, acc 0.921875\n",
      "2018-04-13T15:00:56.326355: step 1089, loss 0.215347, acc 0.953125\n",
      "2018-04-13T15:00:56.643078: step 1090, loss 0.270525, acc 0.921875\n",
      "2018-04-13T15:00:56.978816: step 1091, loss 0.174424, acc 0.921875\n",
      "2018-04-13T15:00:57.304045: step 1092, loss 0.288379, acc 0.890625\n",
      "2018-04-13T15:00:57.617267: step 1093, loss 0.244308, acc 0.90625\n",
      "2018-04-13T15:00:57.939995: step 1094, loss 0.303621, acc 0.84375\n",
      "2018-04-13T15:00:58.271228: step 1095, loss 0.36981, acc 0.828125\n",
      "2018-04-13T15:00:58.596958: step 1096, loss 0.29531, acc 0.859375\n",
      "2018-04-13T15:00:58.937699: step 1097, loss 0.180401, acc 0.953125\n",
      "2018-04-13T15:00:59.268933: step 1098, loss 0.230941, acc 0.890625\n",
      "2018-04-13T15:00:59.583655: step 1099, loss 0.318049, acc 0.859375\n",
      "2018-04-13T15:00:59.906383: step 1100, loss 0.386817, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:01:00.962128: step 1100, loss 0.566179, acc 0.710131\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1100\n",
      "\n",
      "2018-04-13T15:01:02.514112: step 1101, loss 0.2749, acc 0.875\n",
      "2018-04-13T15:01:02.841344: step 1102, loss 0.297578, acc 0.875\n",
      "2018-04-13T15:01:03.159568: step 1103, loss 0.336458, acc 0.859375\n",
      "2018-04-13T15:01:03.477793: step 1104, loss 0.305859, acc 0.890625\n",
      "2018-04-13T15:01:03.798019: step 1105, loss 0.229076, acc 0.921875\n",
      "2018-04-13T15:01:04.103235: step 1106, loss 0.223468, acc 0.875\n",
      "2018-04-13T15:01:04.433968: step 1107, loss 0.43749, acc 0.8125\n",
      "2018-04-13T15:01:04.741185: step 1108, loss 0.386682, acc 0.828125\n",
      "2018-04-13T15:01:05.065415: step 1109, loss 0.240159, acc 0.921875\n",
      "2018-04-13T15:01:05.391644: step 1110, loss 0.36981, acc 0.8125\n",
      "2018-04-13T15:01:05.713872: step 1111, loss 0.220625, acc 0.890625\n",
      "2018-04-13T15:01:06.026592: step 1112, loss 0.332915, acc 0.796875\n",
      "2018-04-13T15:01:06.353323: step 1113, loss 0.233918, acc 0.9375\n",
      "2018-04-13T15:01:06.674552: step 1114, loss 0.328714, acc 0.828125\n",
      "2018-04-13T15:01:07.000781: step 1115, loss 0.243001, acc 0.890625\n",
      "2018-04-13T15:01:07.331514: step 1116, loss 0.214503, acc 0.9375\n",
      "2018-04-13T15:01:07.660746: step 1117, loss 0.341709, acc 0.796875\n",
      "2018-04-13T15:01:07.993481: step 1118, loss 0.271012, acc 0.921875\n",
      "2018-04-13T15:01:08.315209: step 1119, loss 0.1822, acc 0.953125\n",
      "2018-04-13T15:01:08.648444: step 1120, loss 0.404491, acc 0.84375\n",
      "2018-04-13T15:01:08.986683: step 1121, loss 0.241177, acc 0.90625\n",
      "2018-04-13T15:01:09.306408: step 1122, loss 0.318286, acc 0.859375\n",
      "2018-04-13T15:01:09.623132: step 1123, loss 0.221899, acc 0.890625\n",
      "2018-04-13T15:01:09.954867: step 1124, loss 0.208371, acc 0.9375\n",
      "2018-04-13T15:01:10.264585: step 1125, loss 0.381363, acc 0.84375\n",
      "2018-04-13T15:01:10.573803: step 1126, loss 0.307143, acc 0.875\n",
      "2018-04-13T15:01:10.893031: step 1127, loss 0.199715, acc 0.921875\n",
      "2018-04-13T15:01:11.220263: step 1128, loss 0.264019, acc 0.890625\n",
      "2018-04-13T15:01:11.540987: step 1129, loss 0.414678, acc 0.84375\n",
      "2018-04-13T15:01:11.868217: step 1130, loss 0.214703, acc 0.90625\n",
      "2018-04-13T15:01:12.190945: step 1131, loss 0.263145, acc 0.875\n",
      "2018-04-13T15:01:12.507669: step 1132, loss 0.477299, acc 0.8125\n",
      "2018-04-13T15:01:12.827895: step 1133, loss 0.267171, acc 0.921875\n",
      "2018-04-13T15:01:13.155627: step 1134, loss 0.24295, acc 0.875\n",
      "2018-04-13T15:01:13.475353: step 1135, loss 0.2022, acc 0.9375\n",
      "2018-04-13T15:01:13.799581: step 1136, loss 0.278215, acc 0.90625\n",
      "2018-04-13T15:01:14.129313: step 1137, loss 0.118421, acc 0.984375\n",
      "2018-04-13T15:01:14.449540: step 1138, loss 0.215356, acc 0.890625\n",
      "2018-04-13T15:01:14.764765: step 1139, loss 0.297428, acc 0.875\n",
      "2018-04-13T15:01:15.095496: step 1140, loss 0.17597, acc 0.921875\n",
      "2018-04-13T15:01:15.403713: step 1141, loss 0.266537, acc 0.859375\n",
      "2018-04-13T15:01:15.720938: step 1142, loss 0.276183, acc 0.90625\n",
      "2018-04-13T15:01:16.036661: step 1143, loss 0.252485, acc 0.90625\n",
      "2018-04-13T15:01:16.350382: step 1144, loss 0.22151, acc 0.9375\n",
      "2018-04-13T15:01:16.672115: step 1145, loss 0.232751, acc 0.859375\n",
      "2018-04-13T15:01:16.997348: step 1146, loss 0.155907, acc 0.953125\n",
      "2018-04-13T15:01:17.321574: step 1147, loss 0.177049, acc 0.953125\n",
      "2018-04-13T15:01:17.637797: step 1148, loss 0.27739, acc 0.890625\n",
      "2018-04-13T15:01:17.965528: step 1149, loss 0.316863, acc 0.890625\n",
      "2018-04-13T15:01:18.292259: step 1150, loss 0.192996, acc 0.921875\n",
      "2018-04-13T15:01:18.608482: step 1151, loss 0.33477, acc 0.859375\n",
      "2018-04-13T15:01:18.939216: step 1152, loss 0.351726, acc 0.859375\n",
      "2018-04-13T15:01:19.262444: step 1153, loss 0.20031, acc 0.921875\n",
      "2018-04-13T15:01:19.590176: step 1154, loss 0.252733, acc 0.890625\n",
      "2018-04-13T15:01:19.919908: step 1155, loss 0.306671, acc 0.875\n",
      "2018-04-13T15:01:20.240635: step 1156, loss 0.387956, acc 0.859375\n",
      "2018-04-13T15:01:20.563363: step 1157, loss 0.392149, acc 0.859375\n",
      "2018-04-13T15:01:20.889593: step 1158, loss 0.298543, acc 0.828125\n",
      "2018-04-13T15:01:21.215824: step 1159, loss 0.284872, acc 0.875\n",
      "2018-04-13T15:01:21.520039: step 1160, loss 0.292239, acc 0.90625\n",
      "2018-04-13T15:01:21.847769: step 1161, loss 0.388743, acc 0.8125\n",
      "2018-04-13T15:01:22.157988: step 1162, loss 0.292443, acc 0.90625\n",
      "2018-04-13T15:01:22.488353: step 1163, loss 0.207115, acc 0.875\n",
      "2018-04-13T15:01:22.809579: step 1164, loss 0.458302, acc 0.78125\n",
      "2018-04-13T15:01:23.128304: step 1165, loss 0.414976, acc 0.8125\n",
      "2018-04-13T15:01:23.445528: step 1166, loss 0.197147, acc 0.96875\n",
      "2018-04-13T15:01:23.759258: step 1167, loss 0.35146, acc 0.859375\n",
      "2018-04-13T15:01:24.077982: step 1168, loss 0.239174, acc 0.9375\n",
      "2018-04-13T15:01:24.390707: step 1169, loss 0.393727, acc 0.8125\n",
      "2018-04-13T15:01:24.728442: step 1170, loss 0.250302, acc 0.859375\n",
      "2018-04-13T15:01:25.045166: step 1171, loss 0.300154, acc 0.859375\n",
      "2018-04-13T15:01:25.376900: step 1172, loss 0.298845, acc 0.859375\n",
      "2018-04-13T15:01:25.701629: step 1173, loss 0.355638, acc 0.828125\n",
      "2018-04-13T15:01:26.021855: step 1174, loss 0.289782, acc 0.84375\n",
      "2018-04-13T15:01:26.345083: step 1175, loss 0.258745, acc 0.890625\n",
      "2018-04-13T15:01:26.661306: step 1176, loss 0.28385, acc 0.875\n",
      "2018-04-13T15:01:26.982033: step 1177, loss 0.376685, acc 0.84375\n",
      "2018-04-13T15:01:27.293252: step 1178, loss 0.297515, acc 0.875\n",
      "2018-04-13T15:01:27.612478: step 1179, loss 0.292492, acc 0.875\n",
      "2018-04-13T15:01:27.940210: step 1180, loss 0.201004, acc 0.90625\n",
      "2018-04-13T15:01:28.251430: step 1181, loss 0.173291, acc 0.9375\n",
      "2018-04-13T15:01:28.569654: step 1182, loss 0.277673, acc 0.875\n",
      "2018-04-13T15:01:28.893383: step 1183, loss 0.22507, acc 0.90625\n",
      "2018-04-13T15:01:29.213609: step 1184, loss 0.194067, acc 0.90625\n",
      "2018-04-13T15:01:29.541340: step 1185, loss 0.280091, acc 0.875\n",
      "2018-04-13T15:01:29.876077: step 1186, loss 0.24013, acc 0.890625\n",
      "2018-04-13T15:01:30.190298: step 1187, loss 0.338596, acc 0.828125\n",
      "2018-04-13T15:01:30.501518: step 1188, loss 0.337432, acc 0.828125\n",
      "2018-04-13T15:01:30.823246: step 1189, loss 0.278071, acc 0.859375\n",
      "2018-04-13T15:01:31.149980: step 1190, loss 0.361977, acc 0.828125\n",
      "2018-04-13T15:01:31.480711: step 1191, loss 0.416451, acc 0.859375\n",
      "2018-04-13T15:01:31.842965: step 1192, loss 0.297536, acc 0.875\n",
      "2018-04-13T15:01:32.170697: step 1193, loss 0.332778, acc 0.90625\n",
      "2018-04-13T15:01:32.503932: step 1194, loss 0.238373, acc 0.9375\n",
      "2018-04-13T15:01:32.828662: step 1195, loss 0.248125, acc 0.890625\n",
      "2018-04-13T15:01:33.150889: step 1196, loss 0.319092, acc 0.859375\n",
      "2018-04-13T15:01:33.462644: step 1197, loss 0.186133, acc 0.953125\n",
      "2018-04-13T15:01:33.778366: step 1198, loss 0.314479, acc 0.890625\n",
      "2018-04-13T15:01:34.098092: step 1199, loss 0.300714, acc 0.890625\n",
      "2018-04-13T15:01:34.417319: step 1200, loss 0.302481, acc 0.8\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:01:35.491576: step 1200, loss 0.574063, acc 0.712008\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1200\n",
      "\n",
      "2018-04-13T15:01:36.965018: step 1201, loss 0.305315, acc 0.859375\n",
      "2018-04-13T15:01:37.278740: step 1202, loss 0.225851, acc 0.9375\n",
      "2018-04-13T15:01:37.593464: step 1203, loss 0.328696, acc 0.890625\n",
      "2018-04-13T15:01:37.918698: step 1204, loss 0.332121, acc 0.828125\n",
      "2018-04-13T15:01:38.241420: step 1205, loss 0.159345, acc 0.953125\n",
      "2018-04-13T15:01:38.568150: step 1206, loss 0.160293, acc 0.984375\n",
      "2018-04-13T15:01:38.906889: step 1207, loss 0.234269, acc 0.890625\n",
      "2018-04-13T15:01:39.221612: step 1208, loss 0.234713, acc 0.90625\n",
      "2018-04-13T15:01:39.547342: step 1209, loss 0.228358, acc 0.90625\n",
      "2018-04-13T15:01:39.864565: step 1210, loss 0.235407, acc 0.859375\n",
      "2018-04-13T15:01:40.185293: step 1211, loss 0.2171, acc 0.921875\n",
      "2018-04-13T15:01:40.500015: step 1212, loss 0.158719, acc 0.953125\n",
      "2018-04-13T15:01:40.826244: step 1213, loss 0.208732, acc 0.875\n",
      "2018-04-13T15:01:41.173490: step 1214, loss 0.141219, acc 0.9375\n",
      "2018-04-13T15:01:41.491714: step 1215, loss 0.274187, acc 0.890625\n",
      "2018-04-13T15:01:41.816444: step 1216, loss 0.252406, acc 0.890625\n",
      "2018-04-13T15:01:42.140172: step 1217, loss 0.292871, acc 0.921875\n",
      "2018-04-13T15:01:42.465402: step 1218, loss 0.14969, acc 0.953125\n",
      "2018-04-13T15:01:42.784127: step 1219, loss 0.219706, acc 0.890625\n",
      "2018-04-13T15:01:43.109357: step 1220, loss 0.206461, acc 0.890625\n",
      "2018-04-13T15:01:43.438589: step 1221, loss 0.178721, acc 0.953125\n",
      "2018-04-13T15:01:43.784833: step 1222, loss 0.234111, acc 0.890625\n",
      "2018-04-13T15:01:44.118569: step 1223, loss 0.155888, acc 0.921875\n",
      "2018-04-13T15:01:44.443298: step 1224, loss 0.299112, acc 0.875\n",
      "2018-04-13T15:01:44.764525: step 1225, loss 0.201405, acc 0.9375\n",
      "2018-04-13T15:01:45.079748: step 1226, loss 0.191435, acc 0.9375\n",
      "2018-04-13T15:01:45.393970: step 1227, loss 0.144475, acc 0.984375\n",
      "2018-04-13T15:01:45.721201: step 1228, loss 0.202156, acc 0.90625\n",
      "2018-04-13T15:01:46.046931: step 1229, loss 0.316589, acc 0.875\n",
      "2018-04-13T15:01:46.377665: step 1230, loss 0.258666, acc 0.890625\n",
      "2018-04-13T15:01:46.694388: step 1231, loss 0.334331, acc 0.828125\n",
      "2018-04-13T15:01:47.015115: step 1232, loss 0.282871, acc 0.859375\n",
      "2018-04-13T15:01:47.319830: step 1233, loss 0.227905, acc 0.890625\n",
      "2018-04-13T15:01:47.633052: step 1234, loss 0.191323, acc 0.9375\n",
      "2018-04-13T15:01:47.973292: step 1235, loss 0.278566, acc 0.90625\n",
      "2018-04-13T15:01:48.289514: step 1236, loss 0.315284, acc 0.859375\n",
      "2018-04-13T15:01:48.599233: step 1237, loss 0.221664, acc 0.890625\n",
      "2018-04-13T15:01:48.922962: step 1238, loss 0.29572, acc 0.875\n",
      "2018-04-13T15:01:49.240686: step 1239, loss 0.140311, acc 0.953125\n",
      "2018-04-13T15:01:49.551906: step 1240, loss 0.187472, acc 0.96875\n",
      "2018-04-13T15:01:49.872132: step 1241, loss 0.27473, acc 0.84375\n",
      "2018-04-13T15:01:50.237390: step 1242, loss 0.212957, acc 0.921875\n",
      "2018-04-13T15:01:50.565122: step 1243, loss 0.335234, acc 0.859375\n",
      "2018-04-13T15:01:50.905362: step 1244, loss 0.182405, acc 0.921875\n",
      "2018-04-13T15:01:51.219584: step 1245, loss 0.217037, acc 0.921875\n",
      "2018-04-13T15:01:51.528804: step 1246, loss 0.231613, acc 0.9375\n",
      "2018-04-13T15:01:51.843525: step 1247, loss 0.186226, acc 0.90625\n",
      "2018-04-13T15:01:52.164250: step 1248, loss 0.209023, acc 0.9375\n",
      "2018-04-13T15:01:52.482475: step 1249, loss 0.330142, acc 0.828125\n",
      "2018-04-13T15:01:52.811708: step 1250, loss 0.223253, acc 0.921875\n",
      "2018-04-13T15:01:53.136938: step 1251, loss 0.19672, acc 0.953125\n",
      "2018-04-13T15:01:53.466169: step 1252, loss 0.19826, acc 0.9375\n",
      "2018-04-13T15:01:53.793401: step 1253, loss 0.167088, acc 0.890625\n",
      "2018-04-13T15:01:54.114127: step 1254, loss 0.250683, acc 0.875\n",
      "2018-04-13T15:01:54.441859: step 1255, loss 0.237175, acc 0.890625\n",
      "2018-04-13T15:01:54.762086: step 1256, loss 0.293244, acc 0.875\n",
      "2018-04-13T15:01:55.096822: step 1257, loss 0.351616, acc 0.875\n",
      "2018-04-13T15:01:55.415046: step 1258, loss 0.287089, acc 0.828125\n",
      "2018-04-13T15:01:55.743278: step 1259, loss 0.171097, acc 0.9375\n",
      "2018-04-13T15:01:56.068007: step 1260, loss 0.329507, acc 0.859375\n",
      "2018-04-13T15:01:56.393738: step 1261, loss 0.250176, acc 0.90625\n",
      "2018-04-13T15:01:56.725972: step 1262, loss 0.170709, acc 0.921875\n",
      "2018-04-13T15:01:57.065211: step 1263, loss 0.215517, acc 0.953125\n",
      "2018-04-13T15:01:57.402950: step 1264, loss 0.170824, acc 0.90625\n",
      "2018-04-13T15:01:57.736685: step 1265, loss 0.189888, acc 0.9375\n",
      "2018-04-13T15:01:58.071423: step 1266, loss 0.321576, acc 0.890625\n",
      "2018-04-13T15:01:58.402656: step 1267, loss 0.251919, acc 0.875\n",
      "2018-04-13T15:01:58.725883: step 1268, loss 0.237186, acc 0.875\n",
      "2018-04-13T15:01:59.051613: step 1269, loss 0.285811, acc 0.828125\n",
      "2018-04-13T15:01:59.390853: step 1270, loss 0.220655, acc 0.90625\n",
      "2018-04-13T15:01:59.711580: step 1271, loss 0.180589, acc 0.953125\n",
      "2018-04-13T15:02:00.048318: step 1272, loss 0.181711, acc 0.9375\n",
      "2018-04-13T15:02:00.378051: step 1273, loss 0.418602, acc 0.828125\n",
      "2018-04-13T15:02:00.703781: step 1274, loss 0.229706, acc 0.890625\n",
      "2018-04-13T15:02:01.039017: step 1275, loss 0.201822, acc 0.90625\n",
      "2018-04-13T15:02:01.366748: step 1276, loss 0.45838, acc 0.78125\n",
      "2018-04-13T15:02:01.692478: step 1277, loss 0.22385, acc 0.921875\n",
      "2018-04-13T15:02:02.027715: step 1278, loss 0.292921, acc 0.859375\n",
      "2018-04-13T15:02:02.353946: step 1279, loss 0.196068, acc 0.921875\n",
      "2018-04-13T15:02:02.680676: step 1280, loss 0.273365, acc 0.890625\n",
      "2018-04-13T15:02:03.015913: step 1281, loss 0.257848, acc 0.875\n",
      "2018-04-13T15:02:03.349148: step 1282, loss 0.355009, acc 0.875\n",
      "2018-04-13T15:02:03.664871: step 1283, loss 0.270639, acc 0.890625\n",
      "2018-04-13T15:02:03.996105: step 1284, loss 0.246245, acc 0.890625\n",
      "2018-04-13T15:02:04.307826: step 1285, loss 0.230436, acc 0.9375\n",
      "2018-04-13T15:02:04.636057: step 1286, loss 0.198956, acc 0.890625\n",
      "2018-04-13T15:02:04.956283: step 1287, loss 0.249419, acc 0.90625\n",
      "2018-04-13T15:02:05.277009: step 1288, loss 0.219141, acc 0.921875\n",
      "2018-04-13T15:02:05.592232: step 1289, loss 0.323086, acc 0.84375\n",
      "2018-04-13T15:02:05.931972: step 1290, loss 0.159122, acc 0.9375\n",
      "2018-04-13T15:02:06.275215: step 1291, loss 0.379319, acc 0.890625\n",
      "2018-04-13T15:02:06.611452: step 1292, loss 0.178842, acc 0.921875\n",
      "2018-04-13T15:02:06.951693: step 1293, loss 0.263888, acc 0.875\n",
      "2018-04-13T15:02:07.280925: step 1294, loss 0.199683, acc 0.921875\n",
      "2018-04-13T15:02:07.623667: step 1295, loss 0.195266, acc 0.90625\n",
      "2018-04-13T15:02:07.967910: step 1296, loss 0.137859, acc 0.96875\n",
      "2018-04-13T15:02:08.304147: step 1297, loss 0.258582, acc 0.84375\n",
      "2018-04-13T15:02:08.639384: step 1298, loss 0.168402, acc 0.90625\n",
      "2018-04-13T15:02:08.976622: step 1299, loss 0.234294, acc 0.90625\n",
      "2018-04-13T15:02:09.315361: step 1300, loss 0.247821, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:02:10.444159: step 1300, loss 0.575203, acc 0.725141\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1300\n",
      "\n",
      "2018-04-13T15:02:11.967980: step 1301, loss 0.143019, acc 0.96875\n",
      "2018-04-13T15:02:12.295212: step 1302, loss 0.315614, acc 0.828125\n",
      "2018-04-13T15:02:12.606432: step 1303, loss 0.179058, acc 0.90625\n",
      "2018-04-13T15:02:12.921153: step 1304, loss 0.195263, acc 0.9375\n",
      "2018-04-13T15:02:13.253888: step 1305, loss 0.376141, acc 0.8125\n",
      "2018-04-13T15:02:13.574615: step 1306, loss 0.196577, acc 0.9375\n",
      "2018-04-13T15:02:13.908850: step 1307, loss 0.219618, acc 0.890625\n",
      "2018-04-13T15:02:14.226074: step 1308, loss 0.29457, acc 0.84375\n",
      "2018-04-13T15:02:14.541798: step 1309, loss 0.219718, acc 0.9375\n",
      "2018-04-13T15:02:14.875032: step 1310, loss 0.188387, acc 0.90625\n",
      "2018-04-13T15:02:15.199261: step 1311, loss 0.314263, acc 0.890625\n",
      "2018-04-13T15:02:15.524992: step 1312, loss 0.198574, acc 0.953125\n",
      "2018-04-13T15:02:15.841716: step 1313, loss 0.301257, acc 0.859375\n",
      "2018-04-13T15:02:16.158939: step 1314, loss 0.187688, acc 0.953125\n",
      "2018-04-13T15:02:16.482668: step 1315, loss 0.226478, acc 0.890625\n",
      "2018-04-13T15:02:16.814403: step 1316, loss 0.277009, acc 0.875\n",
      "2018-04-13T15:02:17.130626: step 1317, loss 0.145347, acc 0.953125\n",
      "2018-04-13T15:02:17.460859: step 1318, loss 0.219233, acc 0.90625\n",
      "2018-04-13T15:02:17.777582: step 1319, loss 0.258009, acc 0.890625\n",
      "2018-04-13T15:02:18.099810: step 1320, loss 0.266323, acc 0.890625\n",
      "2018-04-13T15:02:18.425540: step 1321, loss 0.255545, acc 0.90625\n",
      "2018-04-13T15:02:18.741764: step 1322, loss 0.262937, acc 0.921875\n",
      "2018-04-13T15:02:19.054984: step 1323, loss 0.191922, acc 0.9375\n",
      "2018-04-13T15:02:19.377212: step 1324, loss 0.412606, acc 0.78125\n",
      "2018-04-13T15:02:19.696437: step 1325, loss 0.357752, acc 0.78125\n",
      "2018-04-13T15:02:20.018166: step 1326, loss 0.253526, acc 0.859375\n",
      "2018-04-13T15:02:20.345396: step 1327, loss 0.193604, acc 0.953125\n",
      "2018-04-13T15:02:20.663620: step 1328, loss 0.142595, acc 0.953125\n",
      "2018-04-13T15:02:20.999865: step 1329, loss 0.182879, acc 0.921875\n",
      "2018-04-13T15:02:21.313080: step 1330, loss 0.16947, acc 0.9375\n",
      "2018-04-13T15:02:21.627802: step 1331, loss 0.187352, acc 0.90625\n",
      "2018-04-13T15:02:21.937019: step 1332, loss 0.249223, acc 0.921875\n",
      "2018-04-13T15:02:22.273257: step 1333, loss 0.106054, acc 0.96875\n",
      "2018-04-13T15:02:22.581975: step 1334, loss 0.213709, acc 0.9375\n",
      "2018-04-13T15:02:22.900700: step 1335, loss 0.157378, acc 0.9375\n",
      "2018-04-13T15:02:23.201413: step 1336, loss 0.193313, acc 0.9375\n",
      "2018-04-13T15:02:23.513132: step 1337, loss 0.255984, acc 0.921875\n",
      "2018-04-13T15:02:23.834359: step 1338, loss 0.196392, acc 0.90625\n",
      "2018-04-13T15:02:24.163091: step 1339, loss 0.254885, acc 0.90625\n",
      "2018-04-13T15:02:24.474312: step 1340, loss 0.260981, acc 0.875\n",
      "2018-04-13T15:02:24.808047: step 1341, loss 0.118596, acc 0.984375\n",
      "2018-04-13T15:02:25.140281: step 1342, loss 0.250959, acc 0.921875\n",
      "2018-04-13T15:02:25.457005: step 1343, loss 0.199449, acc 0.921875\n",
      "2018-04-13T15:02:25.784737: step 1344, loss 0.196364, acc 0.9375\n",
      "2018-04-13T15:02:26.103962: step 1345, loss 0.215282, acc 0.90625\n",
      "2018-04-13T15:02:26.428691: step 1346, loss 0.137666, acc 0.921875\n",
      "2018-04-13T15:02:26.758424: step 1347, loss 0.254065, acc 0.875\n",
      "2018-04-13T15:02:27.096163: step 1348, loss 0.222335, acc 0.84375\n",
      "2018-04-13T15:02:27.410885: step 1349, loss 0.237984, acc 0.875\n",
      "2018-04-13T15:02:27.720103: step 1350, loss 0.197318, acc 0.916667\n",
      "2018-04-13T15:02:28.055841: step 1351, loss 0.230745, acc 0.875\n",
      "2018-04-13T15:02:28.362556: step 1352, loss 0.108488, acc 0.96875\n",
      "2018-04-13T15:02:28.681282: step 1353, loss 0.131197, acc 0.96875\n",
      "2018-04-13T15:02:29.012016: step 1354, loss 0.182123, acc 0.9375\n",
      "2018-04-13T15:02:29.321233: step 1355, loss 0.141461, acc 0.953125\n",
      "2018-04-13T15:02:29.640960: step 1356, loss 0.108523, acc 0.984375\n",
      "2018-04-13T15:02:29.968190: step 1357, loss 0.118962, acc 0.953125\n",
      "2018-04-13T15:02:30.292920: step 1358, loss 0.233102, acc 0.90625\n",
      "2018-04-13T15:02:30.614647: step 1359, loss 0.148247, acc 0.921875\n",
      "2018-04-13T15:02:30.935874: step 1360, loss 0.188703, acc 0.921875\n",
      "2018-04-13T15:02:31.252597: step 1361, loss 0.153939, acc 0.9375\n",
      "2018-04-13T15:02:31.578327: step 1362, loss 0.212007, acc 0.90625\n",
      "2018-04-13T15:02:31.897053: step 1363, loss 0.261538, acc 0.875\n",
      "2018-04-13T15:02:32.213776: step 1364, loss 0.321163, acc 0.859375\n",
      "2018-04-13T15:02:32.524997: step 1365, loss 0.253402, acc 0.875\n",
      "2018-04-13T15:02:32.854729: step 1366, loss 0.179967, acc 0.921875\n",
      "2018-04-13T15:02:33.185073: step 1367, loss 0.115677, acc 0.96875\n",
      "2018-04-13T15:02:33.500296: step 1368, loss 0.114306, acc 0.984375\n",
      "2018-04-13T15:02:33.830029: step 1369, loss 0.186169, acc 0.875\n",
      "2018-04-13T15:02:34.158766: step 1370, loss 0.285275, acc 0.890625\n",
      "2018-04-13T15:02:34.474484: step 1371, loss 0.120724, acc 0.96875\n",
      "2018-04-13T15:02:34.790206: step 1372, loss 0.157102, acc 0.953125\n",
      "2018-04-13T15:02:35.102927: step 1373, loss 0.194729, acc 0.890625\n",
      "2018-04-13T15:02:35.409149: step 1374, loss 0.214222, acc 0.921875\n",
      "2018-04-13T15:02:35.726368: step 1375, loss 0.146965, acc 0.921875\n",
      "2018-04-13T15:02:36.059102: step 1376, loss 0.210848, acc 0.953125\n",
      "2018-04-13T15:02:36.383832: step 1377, loss 0.168222, acc 0.90625\n",
      "2018-04-13T15:02:36.704058: step 1378, loss 0.204585, acc 0.921875\n",
      "2018-04-13T15:02:37.021283: step 1379, loss 0.152669, acc 0.921875\n",
      "2018-04-13T15:02:37.333005: step 1380, loss 0.205346, acc 0.890625\n",
      "2018-04-13T15:02:37.648225: step 1381, loss 0.219983, acc 0.921875\n",
      "2018-04-13T15:02:37.977000: step 1382, loss 0.24607, acc 0.890625\n",
      "2018-04-13T15:02:38.304232: step 1383, loss 0.107398, acc 0.96875\n",
      "2018-04-13T15:02:38.618454: step 1384, loss 0.179201, acc 0.90625\n",
      "2018-04-13T15:02:38.954691: step 1385, loss 0.348184, acc 0.859375\n",
      "2018-04-13T15:02:39.283423: step 1386, loss 0.133435, acc 0.96875\n",
      "2018-04-13T15:02:39.608152: step 1387, loss 0.143231, acc 0.96875\n",
      "2018-04-13T15:02:39.930881: step 1388, loss 0.172104, acc 0.9375\n",
      "2018-04-13T15:02:40.286130: step 1389, loss 0.235759, acc 0.890625\n",
      "2018-04-13T15:02:40.616864: step 1390, loss 0.266069, acc 0.875\n",
      "2018-04-13T15:02:40.947098: step 1391, loss 0.172473, acc 0.9375\n",
      "2018-04-13T15:02:41.275829: step 1392, loss 0.204762, acc 0.921875\n",
      "2018-04-13T15:02:41.607064: step 1393, loss 0.136997, acc 0.953125\n",
      "2018-04-13T15:02:41.938298: step 1394, loss 0.085452, acc 0.984375\n",
      "2018-04-13T15:02:42.271032: step 1395, loss 0.277469, acc 0.890625\n",
      "2018-04-13T15:02:42.595761: step 1396, loss 0.121407, acc 0.9375\n",
      "2018-04-13T15:02:42.921491: step 1397, loss 0.189112, acc 0.90625\n",
      "2018-04-13T15:02:43.249724: step 1398, loss 0.131265, acc 0.953125\n",
      "2018-04-13T15:02:43.572451: step 1399, loss 0.131847, acc 0.96875\n",
      "2018-04-13T15:02:43.895179: step 1400, loss 0.14081, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:02:45.010967: step 1400, loss 0.586259, acc 0.736398\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1400\n",
      "\n",
      "2018-04-13T15:02:46.589377: step 1401, loss 0.186449, acc 0.90625\n",
      "2018-04-13T15:02:46.970145: step 1402, loss 0.311998, acc 0.890625\n",
      "2018-04-13T15:02:47.282867: step 1403, loss 0.234568, acc 0.90625\n",
      "2018-04-13T15:02:47.614602: step 1404, loss 0.0995496, acc 0.9375\n",
      "2018-04-13T15:02:47.948337: step 1405, loss 0.143238, acc 0.953125\n",
      "2018-04-13T15:02:48.289577: step 1406, loss 0.251123, acc 0.890625\n",
      "2018-04-13T15:02:48.608303: step 1407, loss 0.147702, acc 0.953125\n",
      "2018-04-13T15:02:48.939540: step 1408, loss 0.206587, acc 0.953125\n",
      "2018-04-13T15:02:49.275774: step 1409, loss 0.239737, acc 0.890625\n",
      "2018-04-13T15:02:49.604006: step 1410, loss 0.147237, acc 0.921875\n",
      "2018-04-13T15:02:49.929735: step 1411, loss 0.0977329, acc 0.96875\n",
      "2018-04-13T15:02:50.261970: step 1412, loss 0.144336, acc 0.953125\n",
      "2018-04-13T15:02:50.570188: step 1413, loss 0.130012, acc 0.953125\n",
      "2018-04-13T15:02:50.897419: step 1414, loss 0.14555, acc 0.9375\n",
      "2018-04-13T15:02:51.238660: step 1415, loss 0.212767, acc 0.953125\n",
      "2018-04-13T15:02:51.557885: step 1416, loss 0.215179, acc 0.90625\n",
      "2018-04-13T15:02:51.885617: step 1417, loss 0.114631, acc 0.96875\n",
      "2018-04-13T15:02:52.212848: step 1418, loss 0.120317, acc 0.984375\n",
      "2018-04-13T15:02:52.523066: step 1419, loss 0.165805, acc 0.921875\n",
      "2018-04-13T15:02:52.844294: step 1420, loss 0.16267, acc 0.9375\n",
      "2018-04-13T15:02:53.158516: step 1421, loss 0.305057, acc 0.875\n",
      "2018-04-13T15:02:53.483246: step 1422, loss 0.225215, acc 0.90625\n",
      "2018-04-13T15:02:53.812478: step 1423, loss 0.112148, acc 0.953125\n",
      "2018-04-13T15:02:54.139208: step 1424, loss 0.126711, acc 0.96875\n",
      "2018-04-13T15:02:54.463937: step 1425, loss 0.228416, acc 0.90625\n",
      "2018-04-13T15:02:54.785665: step 1426, loss 0.12964, acc 0.921875\n",
      "2018-04-13T15:02:55.110394: step 1427, loss 0.332503, acc 0.859375\n",
      "2018-04-13T15:02:55.437125: step 1428, loss 0.131468, acc 0.953125\n",
      "2018-04-13T15:02:55.769359: step 1429, loss 0.185852, acc 0.921875\n",
      "2018-04-13T15:02:56.074575: step 1430, loss 0.0899975, acc 0.984375\n",
      "2018-04-13T15:02:56.408310: step 1431, loss 0.194901, acc 0.953125\n",
      "2018-04-13T15:02:56.734041: step 1432, loss 0.263614, acc 0.859375\n",
      "2018-04-13T15:02:57.065274: step 1433, loss 0.127188, acc 0.953125\n",
      "2018-04-13T15:02:57.385500: step 1434, loss 0.259413, acc 0.90625\n",
      "2018-04-13T15:02:57.703725: step 1435, loss 0.105757, acc 0.953125\n",
      "2018-04-13T15:02:58.022950: step 1436, loss 0.113888, acc 0.984375\n",
      "2018-04-13T15:02:58.340175: step 1437, loss 0.240194, acc 0.90625\n",
      "2018-04-13T15:02:58.665404: step 1438, loss 0.148882, acc 0.96875\n",
      "2018-04-13T15:02:58.996137: step 1439, loss 0.159693, acc 0.9375\n",
      "2018-04-13T15:02:59.321368: step 1440, loss 0.189193, acc 0.953125\n",
      "2018-04-13T15:02:59.632587: step 1441, loss 0.214876, acc 0.921875\n",
      "2018-04-13T15:02:59.952814: step 1442, loss 0.219627, acc 0.875\n",
      "2018-04-13T15:03:00.295055: step 1443, loss 0.274896, acc 0.890625\n",
      "2018-04-13T15:03:00.613279: step 1444, loss 0.174555, acc 0.953125\n",
      "2018-04-13T15:03:00.934006: step 1445, loss 0.127522, acc 0.96875\n",
      "2018-04-13T15:03:01.254732: step 1446, loss 0.159977, acc 0.9375\n",
      "2018-04-13T15:03:01.571456: step 1447, loss 0.141544, acc 0.96875\n",
      "2018-04-13T15:03:01.911196: step 1448, loss 0.182818, acc 0.90625\n",
      "2018-04-13T15:03:02.242431: step 1449, loss 0.32712, acc 0.875\n",
      "2018-04-13T15:03:02.562156: step 1450, loss 0.0919266, acc 0.96875\n",
      "2018-04-13T15:03:02.884884: step 1451, loss 0.198696, acc 0.90625\n",
      "2018-04-13T15:03:03.198605: step 1452, loss 0.116064, acc 0.96875\n",
      "2018-04-13T15:03:03.516830: step 1453, loss 0.209981, acc 0.90625\n",
      "2018-04-13T15:03:03.836055: step 1454, loss 0.149166, acc 0.9375\n",
      "2018-04-13T15:03:04.154780: step 1455, loss 0.196579, acc 0.890625\n",
      "2018-04-13T15:03:04.473505: step 1456, loss 0.217223, acc 0.9375\n",
      "2018-04-13T15:03:04.796734: step 1457, loss 0.136543, acc 0.9375\n",
      "2018-04-13T15:03:05.111456: step 1458, loss 0.158313, acc 0.9375\n",
      "2018-04-13T15:03:05.439689: step 1459, loss 0.165467, acc 0.9375\n",
      "2018-04-13T15:03:05.759913: step 1460, loss 0.141257, acc 0.9375\n",
      "2018-04-13T15:03:06.078138: step 1461, loss 0.102504, acc 0.984375\n",
      "2018-04-13T15:03:06.392361: step 1462, loss 0.277242, acc 0.859375\n",
      "2018-04-13T15:03:06.701579: step 1463, loss 0.155568, acc 0.9375\n",
      "2018-04-13T15:03:07.030310: step 1464, loss 0.153692, acc 0.953125\n",
      "2018-04-13T15:03:07.357041: step 1465, loss 0.209964, acc 0.921875\n",
      "2018-04-13T15:03:07.683272: step 1466, loss 0.128271, acc 0.953125\n",
      "2018-04-13T15:03:08.012003: step 1467, loss 0.190787, acc 0.90625\n",
      "2018-04-13T15:03:08.379763: step 1468, loss 0.172068, acc 0.96875\n",
      "2018-04-13T15:03:08.782048: step 1469, loss 0.227829, acc 0.921875\n",
      "2018-04-13T15:03:09.113281: step 1470, loss 0.235746, acc 0.9375\n",
      "2018-04-13T15:03:09.451520: step 1471, loss 0.21491, acc 0.890625\n",
      "2018-04-13T15:03:09.786757: step 1472, loss 0.261214, acc 0.90625\n",
      "2018-04-13T15:03:10.189542: step 1473, loss 0.219867, acc 0.90625\n",
      "2018-04-13T15:03:10.543291: step 1474, loss 0.194335, acc 0.921875\n",
      "2018-04-13T15:03:10.904547: step 1475, loss 0.345384, acc 0.84375\n",
      "2018-04-13T15:03:11.345863: step 1476, loss 0.255339, acc 0.890625\n",
      "2018-04-13T15:03:11.878165: step 1477, loss 0.131031, acc 0.953125\n",
      "2018-04-13T15:03:12.231415: step 1478, loss 0.160831, acc 0.9375\n",
      "2018-04-13T15:03:12.600175: step 1479, loss 0.16788, acc 0.953125\n",
      "2018-04-13T15:03:12.972438: step 1480, loss 0.103027, acc 0.953125\n",
      "2018-04-13T15:03:13.380226: step 1481, loss 0.180145, acc 0.921875\n",
      "2018-04-13T15:03:13.776505: step 1482, loss 0.146419, acc 0.96875\n",
      "2018-04-13T15:03:14.115745: step 1483, loss 0.174451, acc 0.90625\n",
      "2018-04-13T15:03:14.598085: step 1484, loss 0.0784657, acc 0.96875\n",
      "2018-04-13T15:03:14.993364: step 1485, loss 0.171739, acc 0.90625\n",
      "2018-04-13T15:03:15.382213: step 1486, loss 0.149312, acc 0.953125\n",
      "2018-04-13T15:03:15.746897: step 1487, loss 0.165902, acc 0.953125\n",
      "2018-04-13T15:03:16.137672: step 1488, loss 0.244338, acc 0.921875\n",
      "2018-04-13T15:03:16.532953: step 1489, loss 0.151788, acc 0.984375\n",
      "2018-04-13T15:03:16.895208: step 1490, loss 0.20933, acc 0.90625\n",
      "2018-04-13T15:03:17.211431: step 1491, loss 0.11484, acc 0.953125\n",
      "2018-04-13T15:03:17.524652: step 1492, loss 0.236092, acc 0.859375\n",
      "2018-04-13T15:03:17.856886: step 1493, loss 0.266348, acc 0.859375\n",
      "2018-04-13T15:03:18.176112: step 1494, loss 0.239662, acc 0.90625\n",
      "2018-04-13T15:03:18.487331: step 1495, loss 0.228213, acc 0.890625\n",
      "2018-04-13T15:03:18.816565: step 1496, loss 0.208397, acc 0.890625\n",
      "2018-04-13T15:03:19.148298: step 1497, loss 0.147452, acc 0.9375\n",
      "2018-04-13T15:03:19.503049: step 1498, loss 0.212356, acc 0.921875\n",
      "2018-04-13T15:03:19.848292: step 1499, loss 0.226225, acc 0.90625\n",
      "2018-04-13T15:03:20.153508: step 1500, loss 0.193341, acc 0.9\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:03:21.212256: step 1500, loss 0.596787, acc 0.73546\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1500\n",
      "\n",
      "2018-04-13T15:03:23.149276: step 1501, loss 0.0894892, acc 0.96875\n",
      "2018-04-13T15:03:23.469003: step 1502, loss 0.180715, acc 0.90625\n",
      "2018-04-13T15:03:23.796232: step 1503, loss 0.072099, acc 0.984375\n",
      "2018-04-13T15:03:24.113957: step 1504, loss 0.111184, acc 0.953125\n",
      "2018-04-13T15:03:24.427178: step 1505, loss 0.124719, acc 0.953125\n",
      "2018-04-13T15:03:24.746404: step 1506, loss 0.151722, acc 0.921875\n",
      "2018-04-13T15:03:25.074135: step 1507, loss 0.142512, acc 0.953125\n",
      "2018-04-13T15:03:25.398364: step 1508, loss 0.110208, acc 0.96875\n",
      "2018-04-13T15:03:25.766624: step 1509, loss 0.154796, acc 0.953125\n",
      "2018-04-13T15:03:26.123876: step 1510, loss 0.1108, acc 0.96875\n",
      "2018-04-13T15:03:26.431093: step 1511, loss 0.169408, acc 0.96875\n",
      "2018-04-13T15:03:26.763828: step 1512, loss 0.163216, acc 0.921875\n",
      "2018-04-13T15:03:27.079051: step 1513, loss 0.122749, acc 0.9375\n",
      "2018-04-13T15:03:27.405782: step 1514, loss 0.0614351, acc 0.984375\n",
      "2018-04-13T15:03:27.736515: step 1515, loss 0.0798316, acc 0.96875\n",
      "2018-04-13T15:03:28.072752: step 1516, loss 0.188773, acc 0.921875\n",
      "2018-04-13T15:03:28.420999: step 1517, loss 0.135251, acc 0.96875\n",
      "2018-04-13T15:03:28.776749: step 1518, loss 0.142021, acc 0.9375\n",
      "2018-04-13T15:03:29.099478: step 1519, loss 0.122305, acc 0.96875\n",
      "2018-04-13T15:03:29.425708: step 1520, loss 0.130257, acc 0.953125\n",
      "2018-04-13T15:03:29.770451: step 1521, loss 0.222054, acc 0.9375\n",
      "2018-04-13T15:03:30.103686: step 1522, loss 0.127517, acc 0.96875\n",
      "2018-04-13T15:03:30.434920: step 1523, loss 0.172685, acc 0.90625\n",
      "2018-04-13T15:03:30.767655: step 1524, loss 0.0737027, acc 0.96875\n",
      "2018-04-13T15:03:31.093385: step 1525, loss 0.114428, acc 0.96875\n",
      "2018-04-13T15:03:31.435627: step 1526, loss 0.0523293, acc 1\n",
      "2018-04-13T15:03:31.819417: step 1527, loss 0.080505, acc 0.984375\n",
      "2018-04-13T15:03:32.197688: step 1528, loss 0.157563, acc 0.9375\n",
      "2018-04-13T15:03:32.525916: step 1529, loss 0.120819, acc 0.9375\n",
      "2018-04-13T15:03:32.919695: step 1530, loss 0.16549, acc 0.9375\n",
      "2018-04-13T15:03:33.272443: step 1531, loss 0.0903876, acc 0.953125\n",
      "2018-04-13T15:03:33.599175: step 1532, loss 0.210702, acc 0.9375\n",
      "2018-04-13T15:03:33.927906: step 1533, loss 0.130408, acc 0.953125\n",
      "2018-04-13T15:03:34.262142: step 1534, loss 0.158572, acc 0.9375\n",
      "2018-04-13T15:03:34.613390: step 1535, loss 0.135078, acc 0.96875\n",
      "2018-04-13T15:03:34.934116: step 1536, loss 0.171698, acc 0.921875\n",
      "2018-04-13T15:03:35.250340: step 1537, loss 0.153574, acc 0.9375\n",
      "2018-04-13T15:03:35.570565: step 1538, loss 0.109735, acc 0.96875\n",
      "2018-04-13T15:03:35.889791: step 1539, loss 0.179217, acc 0.921875\n",
      "2018-04-13T15:03:36.219023: step 1540, loss 0.117912, acc 0.96875\n",
      "2018-04-13T15:03:36.542252: step 1541, loss 0.14401, acc 0.953125\n",
      "2018-04-13T15:03:36.869983: step 1542, loss 0.113625, acc 0.953125\n",
      "2018-04-13T15:03:37.195713: step 1543, loss 0.0989562, acc 0.984375\n",
      "2018-04-13T15:03:37.544959: step 1544, loss 0.0809403, acc 1\n",
      "2018-04-13T15:03:37.877695: step 1545, loss 0.129958, acc 0.953125\n",
      "2018-04-13T15:03:38.209429: step 1546, loss 0.124185, acc 0.96875\n",
      "2018-04-13T15:03:38.524151: step 1547, loss 0.120008, acc 0.9375\n",
      "2018-04-13T15:03:38.861390: step 1548, loss 0.235596, acc 0.90625\n",
      "2018-04-13T15:03:39.180615: step 1549, loss 0.104682, acc 0.9375\n",
      "2018-04-13T15:03:39.504344: step 1550, loss 0.0769179, acc 0.984375\n",
      "2018-04-13T15:03:39.827572: step 1551, loss 0.0797735, acc 1\n",
      "2018-04-13T15:03:40.158305: step 1552, loss 0.117494, acc 0.9375\n",
      "2018-04-13T15:03:40.507552: step 1553, loss 0.12546, acc 0.953125\n",
      "2018-04-13T15:03:40.830780: step 1554, loss 0.129924, acc 0.953125\n",
      "2018-04-13T15:03:41.167518: step 1555, loss 0.211913, acc 0.921875\n",
      "2018-04-13T15:03:41.497250: step 1556, loss 0.0991058, acc 0.984375\n",
      "2018-04-13T15:03:41.810472: step 1557, loss 0.0692935, acc 0.96875\n",
      "2018-04-13T15:03:42.137203: step 1558, loss 0.181275, acc 0.953125\n",
      "2018-04-13T15:03:42.447435: step 1559, loss 0.175474, acc 0.9375\n",
      "2018-04-13T15:03:42.765160: step 1560, loss 0.0930682, acc 0.953125\n",
      "2018-04-13T15:03:43.088388: step 1561, loss 0.151687, acc 0.9375\n",
      "2018-04-13T15:03:43.419121: step 1562, loss 0.0932455, acc 0.96875\n",
      "2018-04-13T15:03:43.761363: step 1563, loss 0.142108, acc 0.96875\n",
      "2018-04-13T15:03:44.085092: step 1564, loss 0.170897, acc 0.921875\n",
      "2018-04-13T15:03:44.395311: step 1565, loss 0.120372, acc 0.984375\n",
      "2018-04-13T15:03:44.720041: step 1566, loss 0.0637252, acc 0.984375\n",
      "2018-04-13T15:03:45.040267: step 1567, loss 0.174872, acc 0.921875\n",
      "2018-04-13T15:03:45.362994: step 1568, loss 0.12379, acc 0.953125\n",
      "2018-04-13T15:03:45.686723: step 1569, loss 0.121362, acc 0.96875\n",
      "2018-04-13T15:03:45.996441: step 1570, loss 0.185151, acc 0.921875\n",
      "2018-04-13T15:03:46.319669: step 1571, loss 0.158569, acc 0.953125\n",
      "2018-04-13T15:03:46.665413: step 1572, loss 0.111174, acc 0.984375\n",
      "2018-04-13T15:03:46.983639: step 1573, loss 0.109472, acc 0.984375\n",
      "2018-04-13T15:03:47.311870: step 1574, loss 0.0618542, acc 0.984375\n",
      "2018-04-13T15:03:47.630096: step 1575, loss 0.160849, acc 0.890625\n",
      "2018-04-13T15:03:47.960328: step 1576, loss 0.235873, acc 0.9375\n",
      "2018-04-13T15:03:48.278053: step 1577, loss 0.175241, acc 0.953125\n",
      "2018-04-13T15:03:48.593275: step 1578, loss 0.164457, acc 0.921875\n",
      "2018-04-13T15:03:48.919005: step 1579, loss 0.130191, acc 0.96875\n",
      "2018-04-13T15:03:49.231226: step 1580, loss 0.193386, acc 0.890625\n",
      "2018-04-13T15:03:49.572969: step 1581, loss 0.118309, acc 0.953125\n",
      "2018-04-13T15:03:49.913707: step 1582, loss 0.143041, acc 0.96875\n",
      "2018-04-13T15:03:50.237436: step 1583, loss 0.186509, acc 0.921875\n",
      "2018-04-13T15:03:50.561665: step 1584, loss 0.160313, acc 0.96875\n",
      "2018-04-13T15:03:50.886394: step 1585, loss 0.106156, acc 0.953125\n",
      "2018-04-13T15:03:51.211123: step 1586, loss 0.117779, acc 0.953125\n",
      "2018-04-13T15:03:51.527347: step 1587, loss 0.158925, acc 0.9375\n",
      "2018-04-13T15:03:51.854578: step 1588, loss 0.172251, acc 0.90625\n",
      "2018-04-13T15:03:52.173303: step 1589, loss 0.123002, acc 0.953125\n",
      "2018-04-13T15:03:52.505037: step 1590, loss 0.144324, acc 0.96875\n",
      "2018-04-13T15:03:52.860788: step 1591, loss 0.150003, acc 0.9375\n",
      "2018-04-13T15:03:53.187519: step 1592, loss 0.115131, acc 0.9375\n",
      "2018-04-13T15:03:53.514750: step 1593, loss 0.142959, acc 0.921875\n",
      "2018-04-13T15:03:53.843482: step 1594, loss 0.135545, acc 0.953125\n",
      "2018-04-13T15:03:54.193230: step 1595, loss 0.0927039, acc 0.96875\n",
      "2018-04-13T15:03:54.516458: step 1596, loss 0.0892441, acc 0.953125\n",
      "2018-04-13T15:03:54.853696: step 1597, loss 0.0912285, acc 0.953125\n",
      "2018-04-13T15:03:55.225959: step 1598, loss 0.118324, acc 0.96875\n",
      "2018-04-13T15:03:55.653260: step 1599, loss 0.0928365, acc 0.984375\n",
      "2018-04-13T15:03:56.050041: step 1600, loss 0.252416, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:03:57.233876: step 1600, loss 0.64851, acc 0.723265\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1600\n",
      "\n",
      "2018-04-13T15:03:59.041932: step 1601, loss 0.144029, acc 0.953125\n",
      "2018-04-13T15:03:59.387677: step 1602, loss 0.177043, acc 0.96875\n",
      "2018-04-13T15:03:59.765444: step 1603, loss 0.104037, acc 0.96875\n",
      "2018-04-13T15:04:00.094176: step 1604, loss 0.306815, acc 0.859375\n",
      "2018-04-13T15:04:00.416161: step 1605, loss 0.0936543, acc 0.96875\n",
      "2018-04-13T15:04:00.735629: step 1606, loss 0.173254, acc 0.9375\n",
      "2018-04-13T15:04:01.053854: step 1607, loss 0.0862107, acc 0.984375\n",
      "2018-04-13T15:04:01.384587: step 1608, loss 0.0882082, acc 0.984375\n",
      "2018-04-13T15:04:01.759351: step 1609, loss 0.181551, acc 0.9375\n",
      "2018-04-13T15:04:02.087584: step 1610, loss 0.195173, acc 0.859375\n",
      "2018-04-13T15:04:02.401805: step 1611, loss 0.215486, acc 0.921875\n",
      "2018-04-13T15:04:02.726535: step 1612, loss 0.114603, acc 0.953125\n",
      "2018-04-13T15:04:03.049762: step 1613, loss 0.370718, acc 0.890625\n",
      "2018-04-13T15:04:03.366987: step 1614, loss 0.315956, acc 0.859375\n",
      "2018-04-13T15:04:03.691716: step 1615, loss 0.118983, acc 0.9375\n",
      "2018-04-13T15:04:04.004937: step 1616, loss 0.142784, acc 0.9375\n",
      "2018-04-13T15:04:04.337672: step 1617, loss 0.148418, acc 0.953125\n",
      "2018-04-13T15:04:04.695925: step 1618, loss 0.103213, acc 0.96875\n",
      "2018-04-13T15:04:05.019155: step 1619, loss 0.199671, acc 0.921875\n",
      "2018-04-13T15:04:05.332375: step 1620, loss 0.114996, acc 0.96875\n",
      "2018-04-13T15:04:05.659105: step 1621, loss 0.338916, acc 0.875\n",
      "2018-04-13T15:04:05.989839: step 1622, loss 0.232744, acc 0.9375\n",
      "2018-04-13T15:04:06.301559: step 1623, loss 0.143069, acc 0.9375\n",
      "2018-04-13T15:04:06.621785: step 1624, loss 0.131156, acc 0.953125\n",
      "2018-04-13T15:04:06.953020: step 1625, loss 0.120819, acc 0.953125\n",
      "2018-04-13T15:04:07.268742: step 1626, loss 0.088169, acc 0.96875\n",
      "2018-04-13T15:04:07.605479: step 1627, loss 0.119515, acc 0.96875\n",
      "2018-04-13T15:04:07.955727: step 1628, loss 0.145103, acc 0.9375\n",
      "2018-04-13T15:04:08.264945: step 1629, loss 0.13462, acc 0.953125\n",
      "2018-04-13T15:04:08.580668: step 1630, loss 0.145577, acc 0.9375\n",
      "2018-04-13T15:04:08.906899: step 1631, loss 0.185994, acc 0.921875\n",
      "2018-04-13T15:04:09.221120: step 1632, loss 0.124539, acc 0.96875\n",
      "2018-04-13T15:04:09.549852: step 1633, loss 0.132228, acc 0.96875\n",
      "2018-04-13T15:04:09.919114: step 1634, loss 0.149547, acc 0.921875\n",
      "2018-04-13T15:04:10.255852: step 1635, loss 0.199848, acc 0.921875\n",
      "2018-04-13T15:04:10.663140: step 1636, loss 0.318727, acc 0.875\n",
      "2018-04-13T15:04:11.019891: step 1637, loss 0.142858, acc 0.953125\n",
      "2018-04-13T15:04:11.371640: step 1638, loss 0.127882, acc 0.921875\n",
      "2018-04-13T15:04:11.700371: step 1639, loss 0.215362, acc 0.90625\n",
      "2018-04-13T15:04:12.062126: step 1640, loss 0.113274, acc 0.953125\n",
      "2018-04-13T15:04:12.427885: step 1641, loss 0.167452, acc 0.890625\n",
      "2018-04-13T15:04:12.734101: step 1642, loss 0.0874068, acc 0.953125\n",
      "2018-04-13T15:04:13.040318: step 1643, loss 0.146936, acc 0.9375\n",
      "2018-04-13T15:04:13.318513: step 1644, loss 0.0517427, acc 0.984375\n",
      "2018-04-13T15:04:13.625731: step 1645, loss 0.147942, acc 0.9375\n",
      "2018-04-13T15:04:13.932959: step 1646, loss 0.128158, acc 0.921875\n",
      "2018-04-13T15:04:14.206652: step 1647, loss 0.0645746, acc 1\n",
      "2018-04-13T15:04:14.477843: step 1648, loss 0.177462, acc 0.921875\n",
      "2018-04-13T15:04:14.746533: step 1649, loss 0.181, acc 0.890625\n",
      "2018-04-13T15:04:15.015724: step 1650, loss 0.112566, acc 0.95\n",
      "2018-04-13T15:04:15.296921: step 1651, loss 0.0991191, acc 0.953125\n",
      "2018-04-13T15:04:15.596634: step 1652, loss 0.165814, acc 0.953125\n",
      "2018-04-13T15:04:15.887339: step 1653, loss 0.136238, acc 0.921875\n",
      "2018-04-13T15:04:16.160531: step 1654, loss 0.123657, acc 0.9375\n",
      "2018-04-13T15:04:16.435226: step 1655, loss 0.0741631, acc 1\n",
      "2018-04-13T15:04:16.764959: step 1656, loss 0.114561, acc 0.96875\n",
      "2018-04-13T15:04:17.043655: step 1657, loss 0.189712, acc 0.90625\n",
      "2018-04-13T15:04:17.315347: step 1658, loss 0.135608, acc 0.9375\n",
      "2018-04-13T15:04:17.594043: step 1659, loss 0.10098, acc 0.96875\n",
      "2018-04-13T15:04:17.873241: step 1660, loss 0.101742, acc 0.953125\n",
      "2018-04-13T15:04:18.153939: step 1661, loss 0.0682518, acc 0.953125\n",
      "2018-04-13T15:04:18.433637: step 1662, loss 0.162948, acc 0.90625\n",
      "2018-04-13T15:04:18.722841: step 1663, loss 0.103772, acc 0.9375\n",
      "2018-04-13T15:04:19.005040: step 1664, loss 0.181637, acc 0.9375\n",
      "2018-04-13T15:04:19.278733: step 1665, loss 0.0872364, acc 0.953125\n",
      "2018-04-13T15:04:19.557930: step 1666, loss 0.101603, acc 0.96875\n",
      "2018-04-13T15:04:19.856643: step 1667, loss 0.146131, acc 0.9375\n",
      "2018-04-13T15:04:20.138841: step 1668, loss 0.148944, acc 0.9375\n",
      "2018-04-13T15:04:20.431547: step 1669, loss 0.0522971, acc 1\n",
      "2018-04-13T15:04:20.730259: step 1670, loss 0.23425, acc 0.890625\n",
      "2018-04-13T15:04:21.003951: step 1671, loss 0.0502374, acc 1\n",
      "2018-04-13T15:04:21.272641: step 1672, loss 0.0914151, acc 0.96875\n",
      "2018-04-13T15:04:21.541832: step 1673, loss 0.138221, acc 0.96875\n",
      "2018-04-13T15:04:21.824031: step 1674, loss 0.0521276, acc 0.984375\n",
      "2018-04-13T15:04:22.102227: step 1675, loss 0.166065, acc 0.921875\n",
      "2018-04-13T15:04:22.379423: step 1676, loss 0.13458, acc 0.953125\n",
      "2018-04-13T15:04:22.667126: step 1677, loss 0.104407, acc 0.953125\n",
      "2018-04-13T15:04:22.948324: step 1678, loss 0.0820628, acc 0.984375\n",
      "2018-04-13T15:04:23.220017: step 1679, loss 0.112686, acc 0.953125\n",
      "2018-04-13T15:04:23.495212: step 1680, loss 0.0846147, acc 0.984375\n",
      "2018-04-13T15:04:23.772406: step 1681, loss 0.108472, acc 0.953125\n",
      "2018-04-13T15:04:24.050103: step 1682, loss 0.206898, acc 0.921875\n",
      "2018-04-13T15:04:24.315289: step 1683, loss 0.0776612, acc 0.96875\n",
      "2018-04-13T15:04:24.585981: step 1684, loss 0.0561695, acc 1\n",
      "2018-04-13T15:04:24.867680: step 1685, loss 0.12193, acc 0.9375\n",
      "2018-04-13T15:04:25.138371: step 1686, loss 0.0796999, acc 0.953125\n",
      "2018-04-13T15:04:25.409062: step 1687, loss 0.0954909, acc 0.953125\n",
      "2018-04-13T15:04:25.706272: step 1688, loss 0.182506, acc 0.953125\n",
      "2018-04-13T15:04:25.987971: step 1689, loss 0.113848, acc 0.953125\n",
      "2018-04-13T15:04:26.264166: step 1690, loss 0.069241, acc 0.984375\n",
      "2018-04-13T15:04:26.540361: step 1691, loss 0.0756707, acc 0.984375\n",
      "2018-04-13T15:04:26.836571: step 1692, loss 0.0624724, acc 1\n",
      "2018-04-13T15:04:27.132779: step 1693, loss 0.111645, acc 0.96875\n",
      "2018-04-13T15:04:27.515550: step 1694, loss 0.184118, acc 0.9375\n",
      "2018-04-13T15:04:27.857792: step 1695, loss 0.169214, acc 0.953125\n",
      "2018-04-13T15:04:28.206538: step 1696, loss 0.160523, acc 0.9375\n",
      "2018-04-13T15:04:28.552782: step 1697, loss 0.0923874, acc 0.953125\n",
      "2018-04-13T15:04:28.949562: step 1698, loss 0.0730822, acc 0.984375\n",
      "2018-04-13T15:04:29.355349: step 1699, loss 0.109344, acc 0.96875\n",
      "2018-04-13T15:04:29.727612: step 1700, loss 0.0949413, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:04:30.873421: step 1700, loss 0.684173, acc 0.724203\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1700\n",
      "\n",
      "2018-04-13T15:04:32.323284: step 1701, loss 0.130425, acc 0.96875\n",
      "2018-04-13T15:04:32.634226: step 1702, loss 0.133003, acc 0.96875\n",
      "2018-04-13T15:04:32.987476: step 1703, loss 0.202416, acc 0.953125\n",
      "2018-04-13T15:04:33.311706: step 1704, loss 0.110172, acc 0.984375\n",
      "2018-04-13T15:04:33.620423: step 1705, loss 0.0624588, acc 0.984375\n",
      "2018-04-13T15:04:33.949155: step 1706, loss 0.124906, acc 0.9375\n",
      "2018-04-13T15:04:34.271883: step 1707, loss 0.107588, acc 0.96875\n",
      "2018-04-13T15:04:34.608121: step 1708, loss 0.116398, acc 0.96875\n",
      "2018-04-13T15:04:34.962371: step 1709, loss 0.219251, acc 0.90625\n",
      "2018-04-13T15:04:35.280096: step 1710, loss 0.226972, acc 0.875\n",
      "2018-04-13T15:04:35.607826: step 1711, loss 0.0511431, acc 0.984375\n",
      "2018-04-13T15:04:35.931555: step 1712, loss 0.154257, acc 0.921875\n",
      "2018-04-13T15:04:36.241274: step 1713, loss 0.0466563, acc 1\n",
      "2018-04-13T15:04:36.574009: step 1714, loss 0.188314, acc 0.90625\n",
      "2018-04-13T15:04:36.903742: step 1715, loss 0.101475, acc 0.96875\n",
      "2018-04-13T15:04:37.220465: step 1716, loss 0.104922, acc 0.984375\n",
      "2018-04-13T15:04:37.543193: step 1717, loss 0.174041, acc 0.921875\n",
      "2018-04-13T15:04:37.902948: step 1718, loss 0.119415, acc 0.9375\n",
      "2018-04-13T15:04:38.225175: step 1719, loss 0.0773601, acc 0.96875\n",
      "2018-04-13T15:04:38.553907: step 1720, loss 0.13523, acc 0.96875\n",
      "2018-04-13T15:04:38.878136: step 1721, loss 0.115881, acc 0.921875\n",
      "2018-04-13T15:04:39.213372: step 1722, loss 0.0865496, acc 0.984375\n",
      "2018-04-13T15:04:39.543606: step 1723, loss 0.108852, acc 0.953125\n",
      "2018-04-13T15:04:39.886848: step 1724, loss 0.1361, acc 0.9375\n",
      "2018-04-13T15:04:40.291634: step 1725, loss 0.0932441, acc 0.984375\n",
      "2018-04-13T15:04:40.633376: step 1726, loss 0.108058, acc 0.953125\n",
      "2018-04-13T15:04:40.980120: step 1727, loss 0.107829, acc 0.96875\n",
      "2018-04-13T15:04:41.286837: step 1728, loss 0.0821572, acc 0.96875\n",
      "2018-04-13T15:04:41.611565: step 1729, loss 0.131877, acc 0.9375\n",
      "2018-04-13T15:04:41.937796: step 1730, loss 0.164448, acc 0.9375\n",
      "2018-04-13T15:04:42.257021: step 1731, loss 0.100042, acc 0.96875\n",
      "2018-04-13T15:04:42.575747: step 1732, loss 0.0866584, acc 0.96875\n",
      "2018-04-13T15:04:42.886967: step 1733, loss 0.179528, acc 0.9375\n",
      "2018-04-13T15:04:43.197186: step 1734, loss 0.100673, acc 0.9375\n",
      "2018-04-13T15:04:43.525417: step 1735, loss 0.0775606, acc 0.96875\n",
      "2018-04-13T15:04:43.882671: step 1736, loss 0.164139, acc 0.9375\n",
      "2018-04-13T15:04:44.211902: step 1737, loss 0.228236, acc 0.875\n",
      "2018-04-13T15:04:44.528625: step 1738, loss 0.162643, acc 0.953125\n",
      "2018-04-13T15:04:44.848852: step 1739, loss 0.0673736, acc 0.984375\n",
      "2018-04-13T15:04:45.172581: step 1740, loss 0.173515, acc 0.921875\n",
      "2018-04-13T15:04:45.489308: step 1741, loss 0.146608, acc 0.9375\n",
      "2018-04-13T15:04:45.817536: step 1742, loss 0.0823295, acc 0.96875\n",
      "2018-04-13T15:04:46.147268: step 1743, loss 0.0719925, acc 0.984375\n",
      "2018-04-13T15:04:46.461491: step 1744, loss 0.114459, acc 0.9375\n",
      "2018-04-13T15:04:46.831252: step 1745, loss 0.0965283, acc 0.953125\n",
      "2018-04-13T15:04:47.190005: step 1746, loss 0.0898329, acc 0.953125\n",
      "2018-04-13T15:04:47.504227: step 1747, loss 0.113746, acc 0.96875\n",
      "2018-04-13T15:04:47.835961: step 1748, loss 0.17689, acc 0.953125\n",
      "2018-04-13T15:04:48.142678: step 1749, loss 0.150031, acc 0.953125\n",
      "2018-04-13T15:04:48.450896: step 1750, loss 0.19184, acc 0.9375\n",
      "2018-04-13T15:04:48.777125: step 1751, loss 0.121023, acc 0.953125\n",
      "2018-04-13T15:04:49.092849: step 1752, loss 0.186368, acc 0.90625\n",
      "2018-04-13T15:04:49.410073: step 1753, loss 0.119393, acc 0.96875\n",
      "2018-04-13T15:04:49.772828: step 1754, loss 0.0508257, acc 0.984375\n",
      "2018-04-13T15:04:50.115571: step 1755, loss 0.11058, acc 0.953125\n",
      "2018-04-13T15:04:50.433295: step 1756, loss 0.0781085, acc 0.984375\n",
      "2018-04-13T15:04:50.756523: step 1757, loss 0.12565, acc 0.953125\n",
      "2018-04-13T15:04:51.061739: step 1758, loss 0.0437051, acc 0.984375\n",
      "2018-04-13T15:04:51.382965: step 1759, loss 0.127779, acc 0.984375\n",
      "2018-04-13T15:04:51.705693: step 1760, loss 0.0370352, acc 1\n",
      "2018-04-13T15:04:52.032925: step 1761, loss 0.119478, acc 0.9375\n",
      "2018-04-13T15:04:52.341643: step 1762, loss 0.0763545, acc 0.96875\n",
      "2018-04-13T15:04:52.684385: step 1763, loss 0.124213, acc 0.921875\n",
      "2018-04-13T15:04:53.048141: step 1764, loss 0.146272, acc 0.9375\n",
      "2018-04-13T15:04:53.368869: step 1765, loss 0.0498249, acc 1\n",
      "2018-04-13T15:04:53.693597: step 1766, loss 0.107455, acc 0.953125\n",
      "2018-04-13T15:04:54.027338: step 1767, loss 0.126635, acc 0.953125\n",
      "2018-04-13T15:04:54.343060: step 1768, loss 0.207827, acc 0.953125\n",
      "2018-04-13T15:04:54.668790: step 1769, loss 0.12456, acc 0.953125\n",
      "2018-04-13T15:04:54.997522: step 1770, loss 0.0567058, acc 0.984375\n",
      "2018-04-13T15:04:55.319250: step 1771, loss 0.0834922, acc 0.96875\n",
      "2018-04-13T15:04:55.662992: step 1772, loss 0.0808385, acc 0.96875\n",
      "2018-04-13T15:04:56.020744: step 1773, loss 0.155825, acc 0.953125\n",
      "2018-04-13T15:04:56.339470: step 1774, loss 0.111651, acc 0.96875\n",
      "2018-04-13T15:04:56.655193: step 1775, loss 0.110862, acc 0.96875\n",
      "2018-04-13T15:04:56.973417: step 1776, loss 0.10254, acc 0.9375\n",
      "2018-04-13T15:04:57.303150: step 1777, loss 0.106754, acc 0.953125\n",
      "2018-04-13T15:04:57.627380: step 1778, loss 0.100268, acc 0.9375\n",
      "2018-04-13T15:04:57.959113: step 1779, loss 0.0679155, acc 0.96875\n",
      "2018-04-13T15:04:58.269333: step 1780, loss 0.0689578, acc 0.984375\n",
      "2018-04-13T15:04:58.595563: step 1781, loss 0.110241, acc 0.953125\n",
      "2018-04-13T15:04:58.981836: step 1782, loss 0.0919416, acc 0.953125\n",
      "2018-04-13T15:04:59.291054: step 1783, loss 0.148648, acc 0.953125\n",
      "2018-04-13T15:04:59.616284: step 1784, loss 0.130954, acc 0.9375\n",
      "2018-04-13T15:04:59.935509: step 1785, loss 0.1096, acc 0.984375\n",
      "2018-04-13T15:05:00.255235: step 1786, loss 0.0544965, acc 0.96875\n",
      "2018-04-13T15:05:00.580965: step 1787, loss 0.243904, acc 0.890625\n",
      "2018-04-13T15:05:00.906194: step 1788, loss 0.0728233, acc 0.96875\n",
      "2018-04-13T15:05:01.223919: step 1789, loss 0.0719548, acc 0.984375\n",
      "2018-04-13T15:05:01.557654: step 1790, loss 0.0930774, acc 0.96875\n",
      "2018-04-13T15:05:01.921412: step 1791, loss 0.122079, acc 0.96875\n",
      "2018-04-13T15:05:02.249643: step 1792, loss 0.0835825, acc 0.96875\n",
      "2018-04-13T15:05:02.574374: step 1793, loss 0.127602, acc 0.953125\n",
      "2018-04-13T15:05:02.924620: step 1794, loss 0.0917824, acc 0.953125\n",
      "2018-04-13T15:05:03.282373: step 1795, loss 0.150329, acc 0.890625\n",
      "2018-04-13T15:05:03.607603: step 1796, loss 0.0582911, acc 0.984375\n",
      "2018-04-13T15:05:03.950344: step 1797, loss 0.132612, acc 0.96875\n",
      "2018-04-13T15:05:04.259563: step 1798, loss 0.177394, acc 0.953125\n",
      "2018-04-13T15:05:04.598802: step 1799, loss 0.121037, acc 0.953125\n",
      "2018-04-13T15:05:04.955554: step 1800, loss 0.0980451, acc 0.95\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:05:06.151399: step 1800, loss 0.67505, acc 0.727017\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1800\n",
      "\n",
      "2018-04-13T15:05:07.690615: step 1801, loss 0.0702709, acc 0.96875\n",
      "2018-04-13T15:05:08.031857: step 1802, loss 0.0534179, acc 1\n",
      "2018-04-13T15:05:08.370595: step 1803, loss 0.0645042, acc 0.984375\n",
      "2018-04-13T15:05:08.717839: step 1804, loss 0.107414, acc 0.96875\n",
      "2018-04-13T15:05:09.057580: step 1805, loss 0.110324, acc 0.96875\n",
      "2018-04-13T15:05:09.408828: step 1806, loss 0.0736595, acc 0.96875\n",
      "2018-04-13T15:05:09.755072: step 1807, loss 0.060222, acc 1\n",
      "2018-04-13T15:05:10.124333: step 1808, loss 0.100248, acc 0.984375\n",
      "2018-04-13T15:05:10.447061: step 1809, loss 0.0626894, acc 1\n",
      "2018-04-13T15:05:10.771789: step 1810, loss 0.153359, acc 0.96875\n",
      "2018-04-13T15:05:11.113031: step 1811, loss 0.0940173, acc 0.96875\n",
      "2018-04-13T15:05:11.433257: step 1812, loss 0.0491018, acc 0.984375\n",
      "2018-04-13T15:05:11.750481: step 1813, loss 0.0755901, acc 0.984375\n",
      "2018-04-13T15:05:12.078213: step 1814, loss 0.104265, acc 0.984375\n",
      "2018-04-13T15:05:12.405444: step 1815, loss 0.0651536, acc 0.96875\n",
      "2018-04-13T15:05:12.736177: step 1816, loss 0.0235235, acc 1\n",
      "2018-04-13T15:05:13.067911: step 1817, loss 0.10659, acc 0.96875\n",
      "2018-04-13T15:05:13.382634: step 1818, loss 0.0414591, acc 0.984375\n",
      "2018-04-13T15:05:13.703360: step 1819, loss 0.104607, acc 0.953125\n",
      "2018-04-13T15:05:14.047604: step 1820, loss 0.0714236, acc 0.96875\n",
      "2018-04-13T15:05:14.376836: step 1821, loss 0.069808, acc 0.984375\n",
      "2018-04-13T15:05:14.722080: step 1822, loss 0.0847878, acc 0.96875\n",
      "2018-04-13T15:05:15.046809: step 1823, loss 0.087238, acc 0.984375\n",
      "2018-04-13T15:05:15.358028: step 1824, loss 0.0870021, acc 0.96875\n",
      "2018-04-13T15:05:15.690264: step 1825, loss 0.0927156, acc 0.9375\n",
      "2018-04-13T15:05:16.007988: step 1826, loss 0.137088, acc 0.96875\n",
      "2018-04-13T15:05:16.332216: step 1827, loss 0.0583871, acc 1\n",
      "2018-04-13T15:05:16.664451: step 1828, loss 0.0752238, acc 0.96875\n",
      "2018-04-13T15:05:17.025706: step 1829, loss 0.0835866, acc 0.984375\n",
      "2018-04-13T15:05:17.366448: step 1830, loss 0.0509917, acc 1\n",
      "2018-04-13T15:05:17.690176: step 1831, loss 0.0842809, acc 0.984375\n",
      "2018-04-13T15:05:18.020409: step 1832, loss 0.0387304, acc 1\n",
      "2018-04-13T15:05:18.350642: step 1833, loss 0.0336836, acc 1\n",
      "2018-04-13T15:05:18.665364: step 1834, loss 0.146522, acc 0.96875\n",
      "2018-04-13T15:05:19.003102: step 1835, loss 0.0877059, acc 0.953125\n",
      "2018-04-13T15:05:19.316323: step 1836, loss 0.0549591, acc 0.984375\n",
      "2018-04-13T15:05:19.683582: step 1837, loss 0.0804706, acc 0.984375\n",
      "2018-04-13T15:05:20.030828: step 1838, loss 0.07614, acc 0.96875\n",
      "2018-04-13T15:05:20.365064: step 1839, loss 0.0505557, acc 1\n",
      "2018-04-13T15:05:20.679788: step 1840, loss 0.0773518, acc 0.96875\n",
      "2018-04-13T15:05:20.998512: step 1841, loss 0.0650522, acc 0.984375\n",
      "2018-04-13T15:05:21.330245: step 1842, loss 0.0657555, acc 0.984375\n",
      "2018-04-13T15:05:21.661980: step 1843, loss 0.0900871, acc 0.953125\n",
      "2018-04-13T15:05:22.003220: step 1844, loss 0.09274, acc 0.96875\n",
      "2018-04-13T15:05:22.320445: step 1845, loss 0.0882371, acc 0.984375\n",
      "2018-04-13T15:05:22.646675: step 1846, loss 0.051966, acc 0.984375\n",
      "2018-04-13T15:05:23.006930: step 1847, loss 0.0442234, acc 1\n",
      "2018-04-13T15:05:23.327656: step 1848, loss 0.0387238, acc 1\n",
      "2018-04-13T15:05:23.657889: step 1849, loss 0.12061, acc 0.9375\n",
      "2018-04-13T15:05:23.983621: step 1850, loss 0.0551881, acc 0.96875\n",
      "2018-04-13T15:05:24.298342: step 1851, loss 0.0399332, acc 0.984375\n",
      "2018-04-13T15:05:24.629075: step 1852, loss 0.0828878, acc 0.953125\n",
      "2018-04-13T15:05:24.951803: step 1853, loss 0.0820116, acc 0.984375\n",
      "2018-04-13T15:05:25.286539: step 1854, loss 0.116944, acc 0.96875\n",
      "2018-04-13T15:05:25.601761: step 1855, loss 0.141428, acc 0.890625\n",
      "2018-04-13T15:05:25.949507: step 1856, loss 0.0641722, acc 0.984375\n",
      "2018-04-13T15:05:26.283243: step 1857, loss 0.121655, acc 0.9375\n",
      "2018-04-13T15:05:26.600468: step 1858, loss 0.0829857, acc 0.9375\n",
      "2018-04-13T15:05:26.941708: step 1859, loss 0.0301293, acc 1\n",
      "2018-04-13T15:05:27.273442: step 1860, loss 0.0561596, acc 0.984375\n",
      "2018-04-13T15:05:27.601173: step 1861, loss 0.0704224, acc 0.953125\n",
      "2018-04-13T15:05:27.929408: step 1862, loss 0.056854, acc 0.984375\n",
      "2018-04-13T15:05:28.238123: step 1863, loss 0.063713, acc 0.984375\n",
      "2018-04-13T15:05:28.566855: step 1864, loss 0.0927724, acc 0.984375\n",
      "2018-04-13T15:05:28.915601: step 1865, loss 0.0419958, acc 0.984375\n",
      "2018-04-13T15:05:29.256342: step 1866, loss 0.0744767, acc 0.96875\n",
      "2018-04-13T15:05:29.576069: step 1867, loss 0.103784, acc 0.9375\n",
      "2018-04-13T15:05:29.906801: step 1868, loss 0.0868659, acc 0.96875\n",
      "2018-04-13T15:05:30.240037: step 1869, loss 0.0706566, acc 0.96875\n",
      "2018-04-13T15:05:30.565767: step 1870, loss 0.0697473, acc 0.953125\n",
      "2018-04-13T15:05:30.901004: step 1871, loss 0.0926644, acc 0.96875\n",
      "2018-04-13T15:05:31.218228: step 1872, loss 0.140562, acc 0.953125\n",
      "2018-04-13T15:05:31.549962: step 1873, loss 0.116261, acc 0.953125\n",
      "2018-04-13T15:05:31.917221: step 1874, loss 0.115536, acc 0.9375\n",
      "2018-04-13T15:05:32.252457: step 1875, loss 0.0587173, acc 0.984375\n",
      "2018-04-13T15:05:32.585693: step 1876, loss 0.0679767, acc 0.96875\n",
      "2018-04-13T15:05:32.903418: step 1877, loss 0.0460368, acc 0.984375\n",
      "2018-04-13T15:05:33.225645: step 1878, loss 0.0874369, acc 0.96875\n",
      "2018-04-13T15:05:33.540868: step 1879, loss 0.078227, acc 0.96875\n",
      "2018-04-13T15:05:33.867098: step 1880, loss 0.0750043, acc 0.984375\n",
      "2018-04-13T15:05:34.195830: step 1881, loss 0.124094, acc 0.953125\n",
      "2018-04-13T15:05:34.510554: step 1882, loss 0.0514502, acc 0.984375\n",
      "2018-04-13T15:05:34.867804: step 1883, loss 0.076803, acc 0.953125\n",
      "2018-04-13T15:05:35.205043: step 1884, loss 0.0670072, acc 0.953125\n",
      "2018-04-13T15:05:35.526770: step 1885, loss 0.0589506, acc 0.96875\n",
      "2018-04-13T15:05:35.860006: step 1886, loss 0.149447, acc 0.921875\n",
      "2018-04-13T15:05:36.172729: step 1887, loss 0.0574844, acc 0.96875\n",
      "2018-04-13T15:05:36.493029: step 1888, loss 0.086939, acc 0.984375\n",
      "2018-04-13T15:05:36.810254: step 1889, loss 0.125902, acc 0.953125\n",
      "2018-04-13T15:05:37.143489: step 1890, loss 0.0517641, acc 0.984375\n",
      "2018-04-13T15:05:37.456210: step 1891, loss 0.121338, acc 0.953125\n",
      "2018-04-13T15:05:37.811461: step 1892, loss 0.0468656, acc 0.984375\n",
      "2018-04-13T15:05:38.170728: step 1893, loss 0.0293841, acc 1\n",
      "2018-04-13T15:05:38.494456: step 1894, loss 0.0979235, acc 0.96875\n",
      "2018-04-13T15:05:38.828192: step 1895, loss 0.0930988, acc 0.96875\n",
      "2018-04-13T15:05:39.172435: step 1896, loss 0.0277839, acc 1\n",
      "2018-04-13T15:05:39.497664: step 1897, loss 0.076955, acc 0.984375\n",
      "2018-04-13T15:05:39.826396: step 1898, loss 0.30557, acc 0.890625\n",
      "2018-04-13T15:05:40.155629: step 1899, loss 0.115122, acc 0.9375\n",
      "2018-04-13T15:05:40.477356: step 1900, loss 0.102116, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:05:41.694907: step 1900, loss 0.700327, acc 0.729831\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-1900\n",
      "\n",
      "2018-04-13T15:05:43.357135: step 1901, loss 0.0273182, acc 1\n",
      "2018-04-13T15:05:43.676361: step 1902, loss 0.0513046, acc 0.984375\n",
      "2018-04-13T15:05:44.044120: step 1903, loss 0.0977238, acc 0.953125\n",
      "2018-04-13T15:05:44.363846: step 1904, loss 0.0704999, acc 0.984375\n",
      "2018-04-13T15:05:44.698082: step 1905, loss 0.099861, acc 0.9375\n",
      "2018-04-13T15:05:45.014305: step 1906, loss 0.0905915, acc 0.921875\n",
      "2018-04-13T15:05:45.339034: step 1907, loss 0.0735616, acc 0.96875\n",
      "2018-04-13T15:05:45.665765: step 1908, loss 0.0412922, acc 0.984375\n",
      "2018-04-13T15:05:45.993505: step 1909, loss 0.0297186, acc 1\n",
      "2018-04-13T15:05:46.324230: step 1910, loss 0.0826089, acc 0.9375\n",
      "2018-04-13T15:05:46.644456: step 1911, loss 0.0657265, acc 0.96875\n",
      "2018-04-13T15:05:47.008714: step 1912, loss 0.115153, acc 0.96875\n",
      "2018-04-13T15:05:47.328940: step 1913, loss 0.054483, acc 0.984375\n",
      "2018-04-13T15:05:47.651167: step 1914, loss 0.0704976, acc 0.96875\n",
      "2018-04-13T15:05:47.982401: step 1915, loss 0.111676, acc 0.953125\n",
      "2018-04-13T15:05:48.315636: step 1916, loss 0.0523022, acc 1\n",
      "2018-04-13T15:05:48.653375: step 1917, loss 0.0568216, acc 0.984375\n",
      "2018-04-13T15:05:48.976602: step 1918, loss 0.0307835, acc 0.984375\n",
      "2018-04-13T15:05:49.295829: step 1919, loss 0.132469, acc 0.953125\n",
      "2018-04-13T15:05:49.607548: step 1920, loss 0.0940087, acc 0.96875\n",
      "2018-04-13T15:05:49.978811: step 1921, loss 0.0469705, acc 0.984375\n",
      "2018-04-13T15:05:50.311045: step 1922, loss 0.0168064, acc 1\n",
      "2018-04-13T15:05:50.647282: step 1923, loss 0.0550734, acc 0.984375\n",
      "2018-04-13T15:05:50.983019: step 1924, loss 0.0179, acc 1\n",
      "2018-04-13T15:05:51.324261: step 1925, loss 0.0680751, acc 0.984375\n",
      "2018-04-13T15:05:51.653493: step 1926, loss 0.24469, acc 0.9375\n",
      "2018-04-13T15:05:51.983726: step 1927, loss 0.172782, acc 0.96875\n",
      "2018-04-13T15:05:52.310958: step 1928, loss 0.0499779, acc 0.984375\n",
      "2018-04-13T15:05:52.634186: step 1929, loss 0.0744598, acc 0.96875\n",
      "2018-04-13T15:05:52.981931: step 1930, loss 0.116834, acc 0.96875\n",
      "2018-04-13T15:05:53.313165: step 1931, loss 0.103271, acc 0.921875\n",
      "2018-04-13T15:05:53.646400: step 1932, loss 0.0586919, acc 0.96875\n",
      "2018-04-13T15:05:53.978635: step 1933, loss 0.11688, acc 0.9375\n",
      "2018-04-13T15:05:54.312371: step 1934, loss 0.0905744, acc 0.96875\n",
      "2018-04-13T15:05:54.625091: step 1935, loss 0.0747191, acc 0.96875\n",
      "2018-04-13T15:05:54.966332: step 1936, loss 0.124987, acc 0.921875\n",
      "2018-04-13T15:05:55.287059: step 1937, loss 0.0805512, acc 1\n",
      "2018-04-13T15:05:55.610288: step 1938, loss 0.0471284, acc 0.984375\n",
      "2018-04-13T15:05:55.968541: step 1939, loss 0.0997081, acc 0.953125\n",
      "2018-04-13T15:05:56.298774: step 1940, loss 0.0944619, acc 0.953125\n",
      "2018-04-13T15:05:56.625504: step 1941, loss 0.0896913, acc 0.9375\n",
      "2018-04-13T15:05:56.946231: step 1942, loss 0.0483867, acc 0.984375\n",
      "2018-04-13T15:05:57.276464: step 1943, loss 0.0999621, acc 0.96875\n",
      "2018-04-13T15:05:57.610201: step 1944, loss 0.140903, acc 0.953125\n",
      "2018-04-13T15:05:57.950940: step 1945, loss 0.0685915, acc 0.984375\n",
      "2018-04-13T15:05:58.285176: step 1946, loss 0.0894877, acc 0.953125\n",
      "2018-04-13T15:05:58.607904: step 1947, loss 0.0667701, acc 0.984375\n",
      "2018-04-13T15:05:58.956650: step 1948, loss 0.0832234, acc 0.9375\n",
      "2018-04-13T15:05:59.291887: step 1949, loss 0.0889358, acc 0.96875\n",
      "2018-04-13T15:05:59.609611: step 1950, loss 0.0736682, acc 0.966667\n",
      "2018-04-13T15:05:59.938343: step 1951, loss 0.0452717, acc 1\n",
      "2018-04-13T15:06:00.271579: step 1952, loss 0.0773619, acc 0.96875\n",
      "2018-04-13T15:06:00.591305: step 1953, loss 0.0528573, acc 1\n",
      "2018-04-13T15:06:00.922538: step 1954, loss 0.0364562, acc 1\n",
      "2018-04-13T15:06:01.252271: step 1955, loss 0.0648942, acc 0.984375\n",
      "2018-04-13T15:06:01.588508: step 1956, loss 0.0260699, acc 1\n",
      "2018-04-13T15:06:01.924746: step 1957, loss 0.0533897, acc 0.984375\n",
      "2018-04-13T15:06:02.266988: step 1958, loss 0.0447527, acc 0.984375\n",
      "2018-04-13T15:06:02.591717: step 1959, loss 0.0495887, acc 1\n",
      "2018-04-13T15:06:02.921950: step 1960, loss 0.0460901, acc 0.984375\n",
      "2018-04-13T15:06:03.271197: step 1961, loss 0.0539969, acc 0.96875\n",
      "2018-04-13T15:06:03.583417: step 1962, loss 0.0521672, acc 0.96875\n",
      "2018-04-13T15:06:03.931663: step 1963, loss 0.0241502, acc 1\n",
      "2018-04-13T15:06:04.265899: step 1964, loss 0.0380245, acc 1\n",
      "2018-04-13T15:06:04.634159: step 1965, loss 0.0889741, acc 0.9375\n",
      "2018-04-13T15:06:05.015929: step 1966, loss 0.0486037, acc 0.984375\n",
      "2018-04-13T15:06:05.453737: step 1967, loss 0.0927434, acc 0.953125\n",
      "2018-04-13T15:06:05.782470: step 1968, loss 0.0676964, acc 0.984375\n",
      "2018-04-13T15:06:06.127713: step 1969, loss 0.101394, acc 0.953125\n",
      "2018-04-13T15:06:06.536502: step 1970, loss 0.0606368, acc 0.984375\n",
      "2018-04-13T15:06:06.931782: step 1971, loss 0.0348325, acc 0.984375\n",
      "2018-04-13T15:06:07.324058: step 1972, loss 0.0863195, acc 0.96875\n",
      "2018-04-13T15:06:07.642283: step 1973, loss 0.106115, acc 0.984375\n",
      "2018-04-13T15:06:08.008047: step 1974, loss 0.0401598, acc 0.984375\n",
      "2018-04-13T15:06:08.366795: step 1975, loss 0.0494431, acc 0.984375\n",
      "2018-04-13T15:06:08.714540: step 1976, loss 0.0641973, acc 0.96875\n",
      "2018-04-13T15:06:09.048275: step 1977, loss 0.106192, acc 0.96875\n",
      "2018-04-13T15:06:09.413034: step 1978, loss 0.0342668, acc 1\n",
      "2018-04-13T15:06:09.791301: step 1979, loss 0.121809, acc 0.953125\n",
      "2018-04-13T15:06:10.189582: step 1980, loss 0.0356987, acc 1\n",
      "2018-04-13T15:06:10.599872: step 1981, loss 0.0539956, acc 0.96875\n",
      "2018-04-13T15:06:10.946617: step 1982, loss 0.080133, acc 0.96875\n",
      "2018-04-13T15:06:11.280852: step 1983, loss 0.0861462, acc 0.984375\n",
      "2018-04-13T15:06:11.606583: step 1984, loss 0.0407776, acc 1\n",
      "2018-04-13T15:06:11.957330: step 1985, loss 0.088654, acc 0.953125\n",
      "2018-04-13T15:06:12.328593: step 1986, loss 0.0594324, acc 0.984375\n",
      "2018-04-13T15:06:12.720369: step 1987, loss 0.0665941, acc 0.953125\n",
      "2018-04-13T15:06:13.070616: step 1988, loss 0.0165677, acc 1\n",
      "2018-04-13T15:06:13.406854: step 1989, loss 0.0670851, acc 0.96875\n",
      "2018-04-13T15:06:13.731083: step 1990, loss 0.047304, acc 0.96875\n",
      "2018-04-13T15:06:14.093338: step 1991, loss 0.108249, acc 0.9375\n",
      "2018-04-13T15:06:14.464100: step 1992, loss 0.0717612, acc 0.984375\n",
      "2018-04-13T15:06:14.852374: step 1993, loss 0.0641055, acc 0.984375\n",
      "2018-04-13T15:06:15.181109: step 1994, loss 0.0405639, acc 1\n",
      "2018-04-13T15:06:15.514842: step 1995, loss 0.0743075, acc 0.96875\n",
      "2018-04-13T15:06:15.849078: step 1996, loss 0.0343885, acc 0.984375\n",
      "2018-04-13T15:06:16.177810: step 1997, loss 0.0654158, acc 0.984375\n",
      "2018-04-13T15:06:16.504041: step 1998, loss 0.0164447, acc 1\n",
      "2018-04-13T15:06:16.823267: step 1999, loss 0.0133208, acc 1\n",
      "2018-04-13T15:06:17.203034: step 2000, loss 0.061466, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:06:18.318322: step 2000, loss 0.727432, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2000\n",
      "\n",
      "2018-04-13T15:06:19.929071: step 2001, loss 0.120959, acc 0.953125\n",
      "2018-04-13T15:06:20.266809: step 2002, loss 0.077964, acc 0.96875\n",
      "2018-04-13T15:06:20.597543: step 2003, loss 0.069671, acc 0.96875\n",
      "2018-04-13T15:06:20.920304: step 2004, loss 0.053688, acc 0.96875\n",
      "2018-04-13T15:06:21.244533: step 2005, loss 0.0362002, acc 1\n",
      "2018-04-13T15:06:21.563763: step 2006, loss 0.0391398, acc 0.984375\n",
      "2018-04-13T15:06:21.889488: step 2007, loss 0.0389902, acc 0.984375\n",
      "2018-04-13T15:06:22.209214: step 2008, loss 0.105458, acc 0.96875\n",
      "2018-04-13T15:06:22.519934: step 2009, loss 0.0505472, acc 0.984375\n",
      "2018-04-13T15:06:22.843665: step 2010, loss 0.0255979, acc 1\n",
      "2018-04-13T15:06:23.198413: step 2011, loss 0.0192136, acc 1\n",
      "2018-04-13T15:06:23.527645: step 2012, loss 0.0644874, acc 0.96875\n",
      "2018-04-13T15:06:23.853875: step 2013, loss 0.0615961, acc 0.984375\n",
      "2018-04-13T15:06:24.181607: step 2014, loss 0.0568169, acc 0.96875\n",
      "2018-04-13T15:06:24.523354: step 2015, loss 0.0705055, acc 0.96875\n",
      "2018-04-13T15:06:24.862589: step 2016, loss 0.0511954, acc 0.984375\n",
      "2018-04-13T15:06:25.184815: step 2017, loss 0.0717056, acc 0.984375\n",
      "2018-04-13T15:06:25.512546: step 2018, loss 0.0627168, acc 0.984375\n",
      "2018-04-13T15:06:25.837276: step 2019, loss 0.0489772, acc 0.984375\n",
      "2018-04-13T15:06:26.214042: step 2020, loss 0.0649201, acc 0.96875\n",
      "2018-04-13T15:06:26.542274: step 2021, loss 0.0531304, acc 0.984375\n",
      "2018-04-13T15:06:26.867003: step 2022, loss 0.0499811, acc 0.96875\n",
      "2018-04-13T15:06:27.208744: step 2023, loss 0.0271687, acc 1\n",
      "2018-04-13T15:06:27.525468: step 2024, loss 0.0260868, acc 1\n",
      "2018-04-13T15:06:27.849196: step 2025, loss 0.0104573, acc 1\n",
      "2018-04-13T15:06:28.160417: step 2026, loss 0.0431121, acc 0.984375\n",
      "2018-04-13T15:06:28.489649: step 2027, loss 0.0366169, acc 1\n",
      "2018-04-13T15:06:28.821883: step 2028, loss 0.0843736, acc 0.9375\n",
      "2018-04-13T15:06:29.186641: step 2029, loss 0.110721, acc 0.96875\n",
      "2018-04-13T15:06:29.518375: step 2030, loss 0.0602413, acc 0.984375\n",
      "2018-04-13T15:06:29.838101: step 2031, loss 0.013254, acc 1\n",
      "2018-04-13T15:06:30.165833: step 2032, loss 0.0523419, acc 0.984375\n",
      "2018-04-13T15:06:30.500584: step 2033, loss 0.0745206, acc 0.984375\n",
      "2018-04-13T15:06:30.827300: step 2034, loss 0.0551224, acc 0.96875\n",
      "2018-04-13T15:06:31.141522: step 2035, loss 0.0980697, acc 0.9375\n",
      "2018-04-13T15:06:31.462748: step 2036, loss 0.0878295, acc 0.953125\n",
      "2018-04-13T15:06:31.783474: step 2037, loss 0.059971, acc 0.984375\n",
      "2018-04-13T15:06:32.155237: step 2038, loss 0.0522432, acc 1\n",
      "2018-04-13T15:06:32.473962: step 2039, loss 0.0271858, acc 0.984375\n",
      "2018-04-13T15:06:32.805196: step 2040, loss 0.0327343, acc 0.984375\n",
      "2018-04-13T15:06:33.129427: step 2041, loss 0.0804827, acc 0.96875\n",
      "2018-04-13T15:06:33.447149: step 2042, loss 0.0335569, acc 1\n",
      "2018-04-13T15:06:33.762873: step 2043, loss 0.0423662, acc 0.984375\n",
      "2018-04-13T15:06:34.086601: step 2044, loss 0.0670458, acc 0.984375\n",
      "2018-04-13T15:06:34.404825: step 2045, loss 0.0816543, acc 0.953125\n",
      "2018-04-13T15:06:34.727053: step 2046, loss 0.0637132, acc 0.96875\n",
      "2018-04-13T15:06:35.084306: step 2047, loss 0.0616272, acc 0.96875\n",
      "2018-04-13T15:06:35.401530: step 2048, loss 0.0456118, acc 0.96875\n",
      "2018-04-13T15:06:35.718253: step 2049, loss 0.16512, acc 0.953125\n",
      "2018-04-13T15:06:36.043483: step 2050, loss 0.16879, acc 0.921875\n",
      "2018-04-13T15:06:36.368212: step 2051, loss 0.0645829, acc 0.984375\n",
      "2018-04-13T15:06:36.684935: step 2052, loss 0.103606, acc 0.953125\n",
      "2018-04-13T15:06:37.013668: step 2053, loss 0.0894162, acc 0.96875\n",
      "2018-04-13T15:06:37.330892: step 2054, loss 0.0747334, acc 0.953125\n",
      "2018-04-13T15:06:37.662125: step 2055, loss 0.054954, acc 0.984375\n",
      "2018-04-13T15:06:38.003867: step 2056, loss 0.0326983, acc 0.984375\n",
      "2018-04-13T15:06:38.340104: step 2057, loss 0.0347634, acc 1\n",
      "2018-04-13T15:06:38.662832: step 2058, loss 0.0859352, acc 0.953125\n",
      "2018-04-13T15:06:38.992064: step 2059, loss 0.155486, acc 0.953125\n",
      "2018-04-13T15:06:39.308788: step 2060, loss 0.0872271, acc 0.96875\n",
      "2018-04-13T15:06:39.628514: step 2061, loss 0.109283, acc 0.953125\n",
      "2018-04-13T15:06:39.964751: step 2062, loss 0.02869, acc 1\n",
      "2018-04-13T15:06:40.293484: step 2063, loss 0.0238971, acc 1\n",
      "2018-04-13T15:06:40.612709: step 2064, loss 0.0457311, acc 1\n",
      "2018-04-13T15:06:40.959954: step 2065, loss 0.0480903, acc 0.96875\n",
      "2018-04-13T15:06:41.296191: step 2066, loss 0.0512851, acc 0.984375\n",
      "2018-04-13T15:06:41.622923: step 2067, loss 0.0391073, acc 0.984375\n",
      "2018-04-13T15:06:41.948653: step 2068, loss 0.0175613, acc 1\n",
      "2018-04-13T15:06:42.263374: step 2069, loss 0.0450618, acc 1\n",
      "2018-04-13T15:06:42.659659: step 2070, loss 0.0999399, acc 0.953125\n",
      "2018-04-13T15:06:43.030468: step 2071, loss 0.0277216, acc 1\n",
      "2018-04-13T15:06:43.370208: step 2072, loss 0.0172829, acc 1\n",
      "2018-04-13T15:06:43.706946: step 2073, loss 0.0852407, acc 0.953125\n",
      "2018-04-13T15:06:44.055191: step 2074, loss 0.0527114, acc 0.96875\n",
      "2018-04-13T15:06:44.391429: step 2075, loss 0.0629849, acc 0.96875\n",
      "2018-04-13T15:06:44.719661: step 2076, loss 0.0323796, acc 0.984375\n",
      "2018-04-13T15:06:45.044390: step 2077, loss 0.0346604, acc 1\n",
      "2018-04-13T15:06:45.425659: step 2078, loss 0.0658282, acc 0.96875\n",
      "2018-04-13T15:06:45.752891: step 2079, loss 0.0903017, acc 0.96875\n",
      "2018-04-13T15:06:46.088628: step 2080, loss 0.153692, acc 0.921875\n",
      "2018-04-13T15:06:46.410354: step 2081, loss 0.0790237, acc 0.984375\n",
      "2018-04-13T15:06:46.783118: step 2082, loss 0.0680801, acc 0.984375\n",
      "2018-04-13T15:06:47.123858: step 2083, loss 0.0788806, acc 0.96875\n",
      "2018-04-13T15:06:47.492118: step 2084, loss 0.0578969, acc 0.984375\n",
      "2018-04-13T15:06:47.805840: step 2085, loss 0.0646911, acc 0.96875\n",
      "2018-04-13T15:06:48.129068: step 2086, loss 0.0611874, acc 0.984375\n",
      "2018-04-13T15:06:48.437285: step 2087, loss 0.0627896, acc 0.96875\n",
      "2018-04-13T15:06:48.758512: step 2088, loss 0.0577487, acc 0.96875\n",
      "2018-04-13T15:06:49.075236: step 2089, loss 0.0938089, acc 0.96875\n",
      "2018-04-13T15:06:49.385455: step 2090, loss 0.0635839, acc 0.96875\n",
      "2018-04-13T15:06:49.703680: step 2091, loss 0.0280663, acc 1\n",
      "2018-04-13T15:06:50.034914: step 2092, loss 0.0472999, acc 1\n",
      "2018-04-13T15:06:50.362646: step 2093, loss 0.0652892, acc 0.984375\n",
      "2018-04-13T15:06:50.691378: step 2094, loss 0.0516985, acc 0.984375\n",
      "2018-04-13T15:06:51.043126: step 2095, loss 0.0655536, acc 0.984375\n",
      "2018-04-13T15:06:51.371357: step 2096, loss 0.0691585, acc 0.984375\n",
      "2018-04-13T15:06:51.688081: step 2097, loss 0.0923287, acc 0.96875\n",
      "2018-04-13T15:06:52.002803: step 2098, loss 0.0938478, acc 0.96875\n",
      "2018-04-13T15:06:52.333037: step 2099, loss 0.0526738, acc 0.984375\n",
      "2018-04-13T15:06:52.639253: step 2100, loss 0.100238, acc 0.966667\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:06:53.804576: step 2100, loss 0.749602, acc 0.73546\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2100\n",
      "\n",
      "2018-04-13T15:06:55.486329: step 2101, loss 0.0362464, acc 1\n",
      "2018-04-13T15:06:55.816063: step 2102, loss 0.0423355, acc 1\n",
      "2018-04-13T15:06:56.163809: step 2103, loss 0.0273966, acc 1\n",
      "2018-04-13T15:06:56.482533: step 2104, loss 0.0243534, acc 1\n",
      "2018-04-13T15:06:56.814267: step 2105, loss 0.00870604, acc 1\n",
      "2018-04-13T15:06:57.134993: step 2106, loss 0.0223829, acc 1\n",
      "2018-04-13T15:06:57.466728: step 2107, loss 0.0706692, acc 0.984375\n",
      "2018-04-13T15:06:57.789956: step 2108, loss 0.0685589, acc 0.96875\n",
      "2018-04-13T15:06:58.108682: step 2109, loss 0.0273944, acc 1\n",
      "2018-04-13T15:06:58.428908: step 2110, loss 0.0396279, acc 0.984375\n",
      "2018-04-13T15:06:58.757639: step 2111, loss 0.0170928, acc 1\n",
      "2018-04-13T15:06:59.082869: step 2112, loss 0.0239754, acc 1\n",
      "2018-04-13T15:06:59.418105: step 2113, loss 0.0265068, acc 1\n",
      "2018-04-13T15:06:59.730326: step 2114, loss 0.0349482, acc 1\n",
      "2018-04-13T15:07:00.069072: step 2115, loss 0.0612519, acc 0.984375\n",
      "2018-04-13T15:07:00.379285: step 2116, loss 0.0703004, acc 0.96875\n",
      "2018-04-13T15:07:00.707016: step 2117, loss 0.0510644, acc 0.984375\n",
      "2018-04-13T15:07:01.020738: step 2118, loss 0.0422946, acc 0.984375\n",
      "2018-04-13T15:07:01.339462: step 2119, loss 0.0322409, acc 1\n",
      "2018-04-13T15:07:01.662691: step 2120, loss 0.0327077, acc 1\n",
      "2018-04-13T15:07:01.992423: step 2121, loss 0.05293, acc 0.96875\n",
      "2018-04-13T15:07:02.340169: step 2122, loss 0.0623028, acc 0.96875\n",
      "2018-04-13T15:07:02.654892: step 2123, loss 0.0536703, acc 0.984375\n",
      "2018-04-13T15:07:02.971615: step 2124, loss 0.0242824, acc 1\n",
      "2018-04-13T15:07:03.288338: step 2125, loss 0.0532284, acc 0.96875\n",
      "2018-04-13T15:07:03.614569: step 2126, loss 0.0545158, acc 0.96875\n",
      "2018-04-13T15:07:03.958312: step 2127, loss 0.0503936, acc 0.984375\n",
      "2018-04-13T15:07:04.276036: step 2128, loss 0.0395917, acc 0.984375\n",
      "2018-04-13T15:07:04.590258: step 2129, loss 0.122662, acc 0.953125\n",
      "2018-04-13T15:07:04.914988: step 2130, loss 0.0486161, acc 0.96875\n",
      "2018-04-13T15:07:05.260732: step 2131, loss 0.0323684, acc 1\n",
      "2018-04-13T15:07:05.584960: step 2132, loss 0.0284071, acc 1\n",
      "2018-04-13T15:07:05.902684: step 2133, loss 0.0215916, acc 1\n",
      "2018-04-13T15:07:06.211403: step 2134, loss 0.0343972, acc 0.984375\n",
      "2018-04-13T15:07:06.528626: step 2135, loss 0.0466409, acc 0.96875\n",
      "2018-04-13T15:07:06.857859: step 2136, loss 0.0474329, acc 0.984375\n",
      "2018-04-13T15:07:07.177084: step 2137, loss 0.025605, acc 1\n",
      "2018-04-13T15:07:07.489805: step 2138, loss 0.0659572, acc 0.953125\n",
      "2018-04-13T15:07:07.813534: step 2139, loss 0.0459259, acc 0.984375\n",
      "2018-04-13T15:07:08.160780: step 2140, loss 0.0367313, acc 0.984375\n",
      "2018-04-13T15:07:08.485008: step 2141, loss 0.0464942, acc 0.984375\n",
      "2018-04-13T15:07:08.811239: step 2142, loss 0.0277489, acc 1\n",
      "2018-04-13T15:07:09.135968: step 2143, loss 0.0523283, acc 0.984375\n",
      "2018-04-13T15:07:09.453192: step 2144, loss 0.00970652, acc 1\n",
      "2018-04-13T15:07:09.772417: step 2145, loss 0.100782, acc 0.953125\n",
      "2018-04-13T15:07:10.088641: step 2146, loss 0.0282671, acc 1\n",
      "2018-04-13T15:07:10.396358: step 2147, loss 0.0414541, acc 1\n",
      "2018-04-13T15:07:10.720588: step 2148, loss 0.0295603, acc 1\n",
      "2018-04-13T15:07:11.038811: step 2149, loss 0.0415065, acc 0.984375\n",
      "2018-04-13T15:07:11.395063: step 2150, loss 0.029483, acc 1\n",
      "2018-04-13T15:07:11.707785: step 2151, loss 0.0369013, acc 0.984375\n",
      "2018-04-13T15:07:12.035015: step 2152, loss 0.0177821, acc 1\n",
      "2018-04-13T15:07:12.352238: step 2153, loss 0.0658754, acc 0.953125\n",
      "2018-04-13T15:07:12.685974: step 2154, loss 0.0486633, acc 0.96875\n",
      "2018-04-13T15:07:13.007201: step 2155, loss 0.0960005, acc 0.984375\n",
      "2018-04-13T15:07:13.325425: step 2156, loss 0.0167136, acc 1\n",
      "2018-04-13T15:07:13.644652: step 2157, loss 0.0615241, acc 0.984375\n",
      "2018-04-13T15:07:13.980889: step 2158, loss 0.0549114, acc 0.984375\n",
      "2018-04-13T15:07:14.336640: step 2159, loss 0.0435228, acc 1\n",
      "2018-04-13T15:07:14.668374: step 2160, loss 0.00927282, acc 1\n",
      "2018-04-13T15:07:14.982096: step 2161, loss 0.0118626, acc 1\n",
      "2018-04-13T15:07:15.297819: step 2162, loss 0.0553551, acc 0.984375\n",
      "2018-04-13T15:07:15.610540: step 2163, loss 0.0386189, acc 1\n",
      "2018-04-13T15:07:15.931266: step 2164, loss 0.0514829, acc 0.984375\n",
      "2018-04-13T15:07:16.244488: step 2165, loss 0.0384792, acc 0.984375\n",
      "2018-04-13T15:07:16.574220: step 2166, loss 0.0200284, acc 1\n",
      "2018-04-13T15:07:16.897449: step 2167, loss 0.0880502, acc 0.9375\n",
      "2018-04-13T15:07:17.253199: step 2168, loss 0.0569494, acc 0.96875\n",
      "2018-04-13T15:07:17.557915: step 2169, loss 0.0307538, acc 0.984375\n",
      "2018-04-13T15:07:17.886146: step 2170, loss 0.0181316, acc 1\n",
      "2018-04-13T15:07:18.204871: step 2171, loss 0.0641097, acc 0.953125\n",
      "2018-04-13T15:07:18.531124: step 2172, loss 0.0699881, acc 0.96875\n",
      "2018-04-13T15:07:18.853853: step 2173, loss 0.0766893, acc 0.953125\n",
      "2018-04-13T15:07:19.178593: step 2174, loss 0.0248895, acc 0.984375\n",
      "2018-04-13T15:07:19.488812: step 2175, loss 0.0340068, acc 1\n",
      "2018-04-13T15:07:19.813540: step 2176, loss 0.0457965, acc 0.984375\n",
      "2018-04-13T15:07:20.146777: step 2177, loss 0.0450212, acc 0.984375\n",
      "2018-04-13T15:07:20.484014: step 2178, loss 0.0758109, acc 0.96875\n",
      "2018-04-13T15:07:20.801738: step 2179, loss 0.053049, acc 0.96875\n",
      "2018-04-13T15:07:21.126968: step 2180, loss 0.051347, acc 0.96875\n",
      "2018-04-13T15:07:21.443192: step 2181, loss 0.0434878, acc 0.984375\n",
      "2018-04-13T15:07:21.762917: step 2182, loss 0.0960203, acc 0.984375\n",
      "2018-04-13T15:07:22.079141: step 2183, loss 0.0342651, acc 0.984375\n",
      "2018-04-13T15:07:22.404370: step 2184, loss 0.104903, acc 0.9375\n",
      "2018-04-13T15:07:22.726610: step 2185, loss 0.0920996, acc 0.96875\n",
      "2018-04-13T15:07:23.060345: step 2186, loss 0.0261107, acc 1\n",
      "2018-04-13T15:07:23.418098: step 2187, loss 0.0539359, acc 0.984375\n",
      "2018-04-13T15:07:23.755837: step 2188, loss 0.0564519, acc 0.96875\n",
      "2018-04-13T15:07:24.082067: step 2189, loss 0.0445342, acc 0.984375\n",
      "2018-04-13T15:07:24.401793: step 2190, loss 0.0205047, acc 1\n",
      "2018-04-13T15:07:24.720522: step 2191, loss 0.0399314, acc 0.984375\n",
      "2018-04-13T15:07:25.042745: step 2192, loss 0.0653096, acc 0.96875\n",
      "2018-04-13T15:07:25.362472: step 2193, loss 0.0267665, acc 1\n",
      "2018-04-13T15:07:25.672690: step 2194, loss 0.0379311, acc 0.984375\n",
      "2018-04-13T15:07:25.992916: step 2195, loss 0.0701451, acc 0.96875\n",
      "2018-04-13T15:07:26.359680: step 2196, loss 0.0533344, acc 0.984375\n",
      "2018-04-13T15:07:26.680902: step 2197, loss 0.066582, acc 0.96875\n",
      "2018-04-13T15:07:27.015138: step 2198, loss 0.0597702, acc 0.984375\n",
      "2018-04-13T15:07:27.336366: step 2199, loss 0.0747314, acc 0.96875\n",
      "2018-04-13T15:07:27.652589: step 2200, loss 0.0205856, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:07:28.771879: step 2200, loss 0.774941, acc 0.73546\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2200\n",
      "\n",
      "2018-04-13T15:07:30.349282: step 2201, loss 0.0198255, acc 1\n",
      "2018-04-13T15:07:30.665506: step 2202, loss 0.0703829, acc 0.984375\n",
      "2018-04-13T15:07:30.990235: step 2203, loss 0.0146134, acc 1\n",
      "2018-04-13T15:07:31.308460: step 2204, loss 0.0515359, acc 0.96875\n",
      "2018-04-13T15:07:31.626685: step 2205, loss 0.0144509, acc 1\n",
      "2018-04-13T15:07:31.946410: step 2206, loss 0.122997, acc 0.953125\n",
      "2018-04-13T15:07:32.293655: step 2207, loss 0.0633327, acc 0.984375\n",
      "2018-04-13T15:07:32.599371: step 2208, loss 0.0720543, acc 0.96875\n",
      "2018-04-13T15:07:32.938611: step 2209, loss 0.0463343, acc 0.984375\n",
      "2018-04-13T15:07:33.263840: step 2210, loss 0.10582, acc 0.96875\n",
      "2018-04-13T15:07:33.575061: step 2211, loss 0.0222345, acc 0.984375\n",
      "2018-04-13T15:07:33.896787: step 2212, loss 0.0489025, acc 0.984375\n",
      "2018-04-13T15:07:34.216513: step 2213, loss 0.105258, acc 0.984375\n",
      "2018-04-13T15:07:34.525732: step 2214, loss 0.0675167, acc 0.984375\n",
      "2018-04-13T15:07:34.854464: step 2215, loss 0.0542937, acc 0.984375\n",
      "2018-04-13T15:07:35.172688: step 2216, loss 0.051579, acc 0.984375\n",
      "2018-04-13T15:07:35.501423: step 2217, loss 0.0193057, acc 1\n",
      "2018-04-13T15:07:35.828652: step 2218, loss 0.0526127, acc 1\n",
      "2018-04-13T15:07:36.157886: step 2219, loss 0.0674681, acc 0.984375\n",
      "2018-04-13T15:07:36.477110: step 2220, loss 0.0774666, acc 0.953125\n",
      "2018-04-13T15:07:36.788831: step 2221, loss 0.0766727, acc 0.984375\n",
      "2018-04-13T15:07:37.125067: step 2222, loss 0.0403044, acc 1\n",
      "2018-04-13T15:07:37.437287: step 2223, loss 0.0717386, acc 0.953125\n",
      "2018-04-13T15:07:37.752510: step 2224, loss 0.0545885, acc 0.984375\n",
      "2018-04-13T15:07:38.088747: step 2225, loss 0.0169336, acc 1\n",
      "2018-04-13T15:07:38.428987: step 2226, loss 0.0739533, acc 0.984375\n",
      "2018-04-13T15:07:38.749215: step 2227, loss 0.0458692, acc 0.984375\n",
      "2018-04-13T15:07:39.080948: step 2228, loss 0.0300754, acc 1\n",
      "2018-04-13T15:07:39.399673: step 2229, loss 0.0872846, acc 0.96875\n",
      "2018-04-13T15:07:39.722401: step 2230, loss 0.0337101, acc 1\n",
      "2018-04-13T15:07:40.041627: step 2231, loss 0.0482531, acc 0.984375\n",
      "2018-04-13T15:07:40.351845: step 2232, loss 0.0187556, acc 1\n",
      "2018-04-13T15:07:40.668069: step 2233, loss 0.137447, acc 0.9375\n",
      "2018-04-13T15:07:41.012813: step 2234, loss 0.0515181, acc 0.96875\n",
      "2018-04-13T15:07:41.365562: step 2235, loss 0.0203052, acc 1\n",
      "2018-04-13T15:07:41.706302: step 2236, loss 0.027983, acc 0.984375\n",
      "2018-04-13T15:07:42.022525: step 2237, loss 0.0331027, acc 0.984375\n",
      "2018-04-13T15:07:42.344252: step 2238, loss 0.0686942, acc 0.96875\n",
      "2018-04-13T15:07:42.663978: step 2239, loss 0.0337961, acc 0.984375\n",
      "2018-04-13T15:07:43.003718: step 2240, loss 0.0878779, acc 0.96875\n",
      "2018-04-13T15:07:43.326446: step 2241, loss 0.0789151, acc 0.984375\n",
      "2018-04-13T15:07:43.643670: step 2242, loss 0.082381, acc 0.984375\n",
      "2018-04-13T15:07:43.991916: step 2243, loss 0.0627383, acc 0.984375\n",
      "2018-04-13T15:07:44.341662: step 2244, loss 0.0421194, acc 0.96875\n",
      "2018-04-13T15:07:44.673897: step 2245, loss 0.0875232, acc 0.953125\n",
      "2018-04-13T15:07:45.004131: step 2246, loss 0.0753023, acc 0.96875\n",
      "2018-04-13T15:07:45.326358: step 2247, loss 0.0463267, acc 0.984375\n",
      "2018-04-13T15:07:45.633575: step 2248, loss 0.101782, acc 0.96875\n",
      "2018-04-13T15:07:45.970817: step 2249, loss 0.0211788, acc 1\n",
      "2018-04-13T15:07:46.282533: step 2250, loss 0.0450612, acc 0.983333\n",
      "2018-04-13T15:07:46.606267: step 2251, loss 0.0150235, acc 1\n",
      "2018-04-13T15:07:46.932993: step 2252, loss 0.0526092, acc 0.984375\n",
      "2018-04-13T15:07:47.258723: step 2253, loss 0.0127063, acc 1\n",
      "2018-04-13T15:07:47.593959: step 2254, loss 0.0770998, acc 0.96875\n",
      "2018-04-13T15:07:47.920190: step 2255, loss 0.0423253, acc 0.984375\n",
      "2018-04-13T15:07:48.252924: step 2256, loss 0.0363775, acc 0.984375\n",
      "2018-04-13T15:07:48.573651: step 2257, loss 0.0311815, acc 0.984375\n",
      "2018-04-13T15:07:48.899381: step 2258, loss 0.024434, acc 1\n",
      "2018-04-13T15:07:49.224110: step 2259, loss 0.0519928, acc 0.984375\n",
      "2018-04-13T15:07:49.538333: step 2260, loss 0.0763792, acc 0.953125\n",
      "2018-04-13T15:07:49.846050: step 2261, loss 0.0124287, acc 1\n",
      "2018-04-13T15:07:50.178785: step 2262, loss 0.0422167, acc 0.984375\n",
      "2018-04-13T15:07:50.520026: step 2263, loss 0.0154269, acc 1\n",
      "2018-04-13T15:07:50.849258: step 2264, loss 0.0302374, acc 0.984375\n",
      "2018-04-13T15:07:51.170985: step 2265, loss 0.0246231, acc 0.984375\n",
      "2018-04-13T15:07:51.488210: step 2266, loss 0.0130314, acc 1\n",
      "2018-04-13T15:07:51.801431: step 2267, loss 0.0700033, acc 0.96875\n",
      "2018-04-13T15:07:52.124658: step 2268, loss 0.034052, acc 0.984375\n",
      "2018-04-13T15:07:52.443384: step 2269, loss 0.0335232, acc 0.984375\n",
      "2018-04-13T15:07:52.780622: step 2270, loss 0.0386204, acc 1\n",
      "2018-04-13T15:07:53.107352: step 2271, loss 0.026739, acc 1\n",
      "2018-04-13T15:07:53.448093: step 2272, loss 0.0294522, acc 0.984375\n",
      "2018-04-13T15:07:53.765317: step 2273, loss 0.0356312, acc 1\n",
      "2018-04-13T15:07:54.085042: step 2274, loss 0.0269267, acc 0.984375\n",
      "2018-04-13T15:07:54.400766: step 2275, loss 0.0280738, acc 1\n",
      "2018-04-13T15:07:54.727496: step 2276, loss 0.0812403, acc 0.984375\n",
      "2018-04-13T15:07:55.056729: step 2277, loss 0.0268641, acc 0.984375\n",
      "2018-04-13T15:07:55.381959: step 2278, loss 0.0312694, acc 0.984375\n",
      "2018-04-13T15:07:55.694179: step 2279, loss 0.0146246, acc 1\n",
      "2018-04-13T15:07:56.022411: step 2280, loss 0.0151422, acc 1\n",
      "2018-04-13T15:07:56.385167: step 2281, loss 0.0553798, acc 0.984375\n",
      "2018-04-13T15:07:56.707394: step 2282, loss 0.0942013, acc 0.9375\n",
      "2018-04-13T15:07:57.032123: step 2283, loss 0.0197222, acc 1\n",
      "2018-04-13T15:07:57.358856: step 2284, loss 0.0456601, acc 0.984375\n",
      "2018-04-13T15:07:57.673076: step 2285, loss 0.0349117, acc 1\n",
      "2018-04-13T15:07:58.005811: step 2286, loss 0.0384369, acc 1\n",
      "2018-04-13T15:07:58.328540: step 2287, loss 0.0609803, acc 0.953125\n",
      "2018-04-13T15:07:58.643769: step 2288, loss 0.00988894, acc 1\n",
      "2018-04-13T15:07:58.968991: step 2289, loss 0.0326003, acc 1\n",
      "2018-04-13T15:07:59.312734: step 2290, loss 0.0116302, acc 1\n",
      "2018-04-13T15:07:59.633960: step 2291, loss 0.00947963, acc 1\n",
      "2018-04-13T15:07:59.967697: step 2292, loss 0.0755895, acc 0.953125\n",
      "2018-04-13T15:08:00.284920: step 2293, loss 0.0249717, acc 1\n",
      "2018-04-13T15:08:00.602644: step 2294, loss 0.163509, acc 0.921875\n",
      "2018-04-13T15:08:00.917868: step 2295, loss 0.0152979, acc 1\n",
      "2018-04-13T15:08:01.235091: step 2296, loss 0.0144827, acc 1\n",
      "2018-04-13T15:08:01.567326: step 2297, loss 0.0916898, acc 0.9375\n",
      "2018-04-13T15:08:01.909570: step 2298, loss 0.131751, acc 0.953125\n",
      "2018-04-13T15:08:02.245305: step 2299, loss 0.0395428, acc 0.984375\n",
      "2018-04-13T15:08:02.589047: step 2300, loss 0.0333228, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:08:03.715343: step 2300, loss 0.811272, acc 0.727955\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2300\n",
      "\n",
      "2018-04-13T15:08:05.316775: step 2301, loss 0.034948, acc 0.984375\n",
      "2018-04-13T15:08:05.648509: step 2302, loss 0.0182282, acc 1\n",
      "2018-04-13T15:08:05.981244: step 2303, loss 0.0318766, acc 1\n",
      "2018-04-13T15:08:06.288961: step 2304, loss 0.0409841, acc 0.984375\n",
      "2018-04-13T15:08:06.609688: step 2305, loss 0.0459589, acc 0.984375\n",
      "2018-04-13T15:08:06.934920: step 2306, loss 0.021731, acc 1\n",
      "2018-04-13T15:08:07.253643: step 2307, loss 0.0785968, acc 0.96875\n",
      "2018-04-13T15:08:07.571368: step 2308, loss 0.0550358, acc 0.96875\n",
      "2018-04-13T15:08:07.897598: step 2309, loss 0.0319068, acc 1\n",
      "2018-04-13T15:08:08.226329: step 2310, loss 0.0923254, acc 0.96875\n",
      "2018-04-13T15:08:08.575576: step 2311, loss 0.0433799, acc 0.984375\n",
      "2018-04-13T15:08:08.901807: step 2312, loss 0.0415367, acc 0.984375\n",
      "2018-04-13T15:08:09.222032: step 2313, loss 0.0306363, acc 0.984375\n",
      "2018-04-13T15:08:09.540758: step 2314, loss 0.0384373, acc 1\n",
      "2018-04-13T15:08:09.856481: step 2315, loss 0.0412526, acc 0.984375\n",
      "2018-04-13T15:08:10.209231: step 2316, loss 0.0416542, acc 1\n",
      "2018-04-13T15:08:10.536962: step 2317, loss 0.0835269, acc 0.953125\n",
      "2018-04-13T15:08:10.888710: step 2318, loss 0.0631022, acc 0.96875\n",
      "2018-04-13T15:08:11.229450: step 2319, loss 0.0139143, acc 1\n",
      "2018-04-13T15:08:11.604715: step 2320, loss 0.00778722, acc 1\n",
      "2018-04-13T15:08:11.931946: step 2321, loss 0.0726299, acc 0.953125\n",
      "2018-04-13T15:08:12.276690: step 2322, loss 0.0265793, acc 0.984375\n",
      "2018-04-13T15:08:12.608424: step 2323, loss 0.0390305, acc 0.984375\n",
      "2018-04-13T15:08:12.974682: step 2324, loss 0.0178836, acc 1\n",
      "2018-04-13T15:08:13.340942: step 2325, loss 0.014177, acc 1\n",
      "2018-04-13T15:08:13.680181: step 2326, loss 0.0142871, acc 1\n",
      "2018-04-13T15:08:14.008412: step 2327, loss 0.0429188, acc 1\n",
      "2018-04-13T15:08:14.381176: step 2328, loss 0.0423757, acc 0.984375\n",
      "2018-04-13T15:08:14.712409: step 2329, loss 0.0293529, acc 0.984375\n",
      "2018-04-13T15:08:15.047146: step 2330, loss 0.0579129, acc 0.96875\n",
      "2018-04-13T15:08:15.362369: step 2331, loss 0.0314188, acc 1\n",
      "2018-04-13T15:08:15.694603: step 2332, loss 0.0834668, acc 0.9375\n",
      "2018-04-13T15:08:16.047852: step 2333, loss 0.0339915, acc 0.984375\n",
      "2018-04-13T15:08:16.392097: step 2334, loss 0.0269459, acc 0.984375\n",
      "2018-04-13T15:08:16.732836: step 2335, loss 0.0916593, acc 0.953125\n",
      "2018-04-13T15:08:17.065572: step 2336, loss 0.0818149, acc 0.984375\n",
      "2018-04-13T15:08:17.428828: step 2337, loss 0.0215707, acc 1\n",
      "2018-04-13T15:08:17.764566: step 2338, loss 0.0228495, acc 1\n",
      "2018-04-13T15:08:18.185862: step 2339, loss 0.0682673, acc 0.96875\n",
      "2018-04-13T15:08:18.514594: step 2340, loss 0.0178613, acc 1\n",
      "2018-04-13T15:08:18.852332: step 2341, loss 0.0324525, acc 0.984375\n",
      "2018-04-13T15:08:19.261122: step 2342, loss 0.0473219, acc 0.984375\n",
      "2018-04-13T15:08:19.635886: step 2343, loss 0.00962515, acc 1\n",
      "2018-04-13T15:08:19.977127: step 2344, loss 0.0691299, acc 0.984375\n",
      "2018-04-13T15:08:20.340884: step 2345, loss 0.0188392, acc 1\n",
      "2018-04-13T15:08:20.689130: step 2346, loss 0.0125795, acc 1\n",
      "2018-04-13T15:08:21.034875: step 2347, loss 0.0407554, acc 0.984375\n",
      "2018-04-13T15:08:21.351598: step 2348, loss 0.0123778, acc 1\n",
      "2018-04-13T15:08:21.681330: step 2349, loss 0.0980815, acc 0.984375\n",
      "2018-04-13T15:08:22.035080: step 2350, loss 0.0486559, acc 0.96875\n",
      "2018-04-13T15:08:22.359809: step 2351, loss 0.0951168, acc 0.96875\n",
      "2018-04-13T15:08:22.698548: step 2352, loss 0.0189794, acc 1\n",
      "2018-04-13T15:08:23.012270: step 2353, loss 0.0376433, acc 0.984375\n",
      "2018-04-13T15:08:23.337500: step 2354, loss 0.0411419, acc 0.96875\n",
      "2018-04-13T15:08:23.662730: step 2355, loss 0.060636, acc 0.96875\n",
      "2018-04-13T15:08:23.992962: step 2356, loss 0.0244731, acc 1\n",
      "2018-04-13T15:08:24.306184: step 2357, loss 0.0197614, acc 1\n",
      "2018-04-13T15:08:24.639920: step 2358, loss 0.0219031, acc 0.984375\n",
      "2018-04-13T15:08:24.963648: step 2359, loss 0.0232581, acc 1\n",
      "2018-04-13T15:08:25.280372: step 2360, loss 0.0363863, acc 0.984375\n",
      "2018-04-13T15:08:25.600598: step 2361, loss 0.0549522, acc 0.96875\n",
      "2018-04-13T15:08:25.913819: step 2362, loss 0.0157912, acc 1\n",
      "2018-04-13T15:08:26.240049: step 2363, loss 0.0694257, acc 0.953125\n",
      "2018-04-13T15:08:26.551769: step 2364, loss 0.11319, acc 0.96875\n",
      "2018-04-13T15:08:26.887007: step 2365, loss 0.0137738, acc 1\n",
      "2018-04-13T15:08:27.201729: step 2366, loss 0.0301555, acc 1\n",
      "2018-04-13T15:08:27.519453: step 2367, loss 0.0117553, acc 1\n",
      "2018-04-13T15:08:27.871701: step 2368, loss 0.0245653, acc 1\n",
      "2018-04-13T15:08:28.192429: step 2369, loss 0.030497, acc 1\n",
      "2018-04-13T15:08:28.522661: step 2370, loss 0.0425557, acc 0.984375\n",
      "2018-04-13T15:08:28.855896: step 2371, loss 0.0841796, acc 0.953125\n",
      "2018-04-13T15:08:29.172120: step 2372, loss 0.0402084, acc 0.984375\n",
      "2018-04-13T15:08:29.492346: step 2373, loss 0.0177212, acc 1\n",
      "2018-04-13T15:08:29.811571: step 2374, loss 0.0162714, acc 1\n",
      "2018-04-13T15:08:30.126793: step 2375, loss 0.0915702, acc 0.96875\n",
      "2018-04-13T15:08:30.436012: step 2376, loss 0.033712, acc 0.984375\n",
      "2018-04-13T15:08:30.764244: step 2377, loss 0.0343588, acc 0.984375\n",
      "2018-04-13T15:08:31.097979: step 2378, loss 0.0181903, acc 1\n",
      "2018-04-13T15:08:31.416705: step 2379, loss 0.0180873, acc 1\n",
      "2018-04-13T15:08:31.730927: step 2380, loss 0.0518729, acc 0.96875\n",
      "2018-04-13T15:08:32.050163: step 2381, loss 0.0451926, acc 0.984375\n",
      "2018-04-13T15:08:32.382898: step 2382, loss 0.0203733, acc 0.984375\n",
      "2018-04-13T15:08:32.708128: step 2383, loss 0.124452, acc 0.9375\n",
      "2018-04-13T15:08:33.024852: step 2384, loss 0.0147525, acc 1\n",
      "2018-04-13T15:08:33.396614: step 2385, loss 0.0201499, acc 1\n",
      "2018-04-13T15:08:33.737354: step 2386, loss 0.0101274, acc 1\n",
      "2018-04-13T15:08:34.056079: step 2387, loss 0.029898, acc 1\n",
      "2018-04-13T15:08:34.369801: step 2388, loss 0.0084429, acc 1\n",
      "2018-04-13T15:08:34.681021: step 2389, loss 0.020331, acc 1\n",
      "2018-04-13T15:08:35.009252: step 2390, loss 0.0955865, acc 0.953125\n",
      "2018-04-13T15:08:35.323975: step 2391, loss 0.0490064, acc 0.984375\n",
      "2018-04-13T15:08:35.645702: step 2392, loss 0.0101009, acc 1\n",
      "2018-04-13T15:08:35.966929: step 2393, loss 0.0269902, acc 1\n",
      "2018-04-13T15:08:36.277648: step 2394, loss 0.0306437, acc 1\n",
      "2018-04-13T15:08:36.607381: step 2395, loss 0.0318446, acc 1\n",
      "2018-04-13T15:08:36.930609: step 2396, loss 0.026689, acc 0.984375\n",
      "2018-04-13T15:08:37.246833: step 2397, loss 0.0350208, acc 0.984375\n",
      "2018-04-13T15:08:37.564056: step 2398, loss 0.0494011, acc 0.984375\n",
      "2018-04-13T15:08:37.881781: step 2399, loss 0.115244, acc 0.9375\n",
      "2018-04-13T15:08:38.187497: step 2400, loss 0.0276679, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:08:39.327301: step 2400, loss 0.816263, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2400\n",
      "\n",
      "2018-04-13T15:08:40.864450: step 2401, loss 0.0425082, acc 0.984375\n",
      "2018-04-13T15:08:41.179173: step 2402, loss 0.0690082, acc 0.953125\n",
      "2018-04-13T15:08:41.512908: step 2403, loss 0.0253873, acc 1\n",
      "2018-04-13T15:08:41.821126: step 2404, loss 0.106362, acc 0.984375\n",
      "2018-04-13T15:08:42.144359: step 2405, loss 0.0213009, acc 1\n",
      "2018-04-13T15:08:42.468582: step 2406, loss 0.0502624, acc 0.984375\n",
      "2018-04-13T15:08:42.812326: step 2407, loss 0.0223995, acc 1\n",
      "2018-04-13T15:08:43.143059: step 2408, loss 0.0374583, acc 0.984375\n",
      "2018-04-13T15:08:43.454779: step 2409, loss 0.0842366, acc 0.9375\n",
      "2018-04-13T15:08:43.794018: step 2410, loss 0.0155005, acc 1\n",
      "2018-04-13T15:08:44.114746: step 2411, loss 0.0392728, acc 0.984375\n",
      "2018-04-13T15:08:44.437473: step 2412, loss 0.0263174, acc 0.984375\n",
      "2018-04-13T15:08:44.761703: step 2413, loss 0.0329276, acc 0.984375\n",
      "2018-04-13T15:08:45.083930: step 2414, loss 0.0162447, acc 1\n",
      "2018-04-13T15:08:45.406657: step 2415, loss 0.0320627, acc 0.984375\n",
      "2018-04-13T15:08:45.750901: step 2416, loss 0.0631384, acc 0.984375\n",
      "2018-04-13T15:08:46.063121: step 2417, loss 0.0108365, acc 1\n",
      "2018-04-13T15:08:46.385849: step 2418, loss 0.020355, acc 1\n",
      "2018-04-13T15:08:46.744102: step 2419, loss 0.0372391, acc 0.984375\n",
      "2018-04-13T15:08:47.070833: step 2420, loss 0.0364212, acc 1\n",
      "2018-04-13T15:08:47.406069: step 2421, loss 0.0282817, acc 0.984375\n",
      "2018-04-13T15:08:47.765824: step 2422, loss 0.027491, acc 1\n",
      "2018-04-13T15:08:48.085549: step 2423, loss 0.0177839, acc 0.984375\n",
      "2018-04-13T15:08:48.395269: step 2424, loss 0.0363015, acc 1\n",
      "2018-04-13T15:08:48.743514: step 2425, loss 0.0184284, acc 1\n",
      "2018-04-13T15:08:49.059237: step 2426, loss 0.0109231, acc 1\n",
      "2018-04-13T15:08:49.385467: step 2427, loss 0.0222591, acc 1\n",
      "2018-04-13T15:08:49.705193: step 2428, loss 0.034922, acc 0.984375\n",
      "2018-04-13T15:08:50.006906: step 2429, loss 0.0235009, acc 1\n",
      "2018-04-13T15:08:50.318126: step 2430, loss 0.0282983, acc 0.984375\n",
      "2018-04-13T15:08:50.650361: step 2431, loss 0.034911, acc 0.984375\n",
      "2018-04-13T15:08:50.972088: step 2432, loss 0.0251611, acc 1\n",
      "2018-04-13T15:08:51.290313: step 2433, loss 0.0392905, acc 0.984375\n",
      "2018-04-13T15:08:51.626049: step 2434, loss 0.0117011, acc 1\n",
      "2018-04-13T15:08:51.982800: step 2435, loss 0.0217556, acc 1\n",
      "2018-04-13T15:08:52.305029: step 2436, loss 0.0260443, acc 1\n",
      "2018-04-13T15:08:52.621252: step 2437, loss 0.0503187, acc 0.984375\n",
      "2018-04-13T15:08:52.949483: step 2438, loss 0.0198321, acc 0.984375\n",
      "2018-04-13T15:08:53.262205: step 2439, loss 0.0218417, acc 1\n",
      "2018-04-13T15:08:53.616481: step 2440, loss 0.0207627, acc 1\n",
      "2018-04-13T15:08:53.943212: step 2441, loss 0.0102083, acc 1\n",
      "2018-04-13T15:08:54.260936: step 2442, loss 0.0169991, acc 0.984375\n",
      "2018-04-13T15:08:54.583164: step 2443, loss 0.00980511, acc 1\n",
      "2018-04-13T15:08:54.956427: step 2444, loss 0.0183255, acc 1\n",
      "2018-04-13T15:08:55.267146: step 2445, loss 0.0295184, acc 1\n",
      "2018-04-13T15:08:55.579367: step 2446, loss 0.00757823, acc 1\n",
      "2018-04-13T15:08:55.904596: step 2447, loss 0.0171237, acc 1\n",
      "2018-04-13T15:08:56.220320: step 2448, loss 0.0270582, acc 0.984375\n",
      "2018-04-13T15:08:56.547051: step 2449, loss 0.0347218, acc 0.984375\n",
      "2018-04-13T15:08:56.869779: step 2450, loss 0.0239054, acc 1\n",
      "2018-04-13T15:08:57.184000: step 2451, loss 0.0287556, acc 0.984375\n",
      "2018-04-13T15:08:57.495220: step 2452, loss 0.0222897, acc 0.984375\n",
      "2018-04-13T15:08:57.843466: step 2453, loss 0.00414297, acc 1\n",
      "2018-04-13T15:08:58.157688: step 2454, loss 0.0238732, acc 0.984375\n",
      "2018-04-13T15:08:58.489422: step 2455, loss 0.0417237, acc 0.96875\n",
      "2018-04-13T15:08:58.816654: step 2456, loss 0.0758851, acc 0.96875\n",
      "2018-04-13T15:08:59.131404: step 2457, loss 0.0118101, acc 1\n",
      "2018-04-13T15:08:59.450130: step 2458, loss 0.0153666, acc 1\n",
      "2018-04-13T15:08:59.786367: step 2459, loss 0.0444533, acc 0.984375\n",
      "2018-04-13T15:09:00.122604: step 2460, loss 0.0298698, acc 1\n",
      "2018-04-13T15:09:00.425319: step 2461, loss 0.0543399, acc 0.953125\n",
      "2018-04-13T15:09:00.787074: step 2462, loss 0.0476509, acc 0.984375\n",
      "2018-04-13T15:09:01.116806: step 2463, loss 0.0121801, acc 1\n",
      "2018-04-13T15:09:01.436532: step 2464, loss 0.0381225, acc 1\n",
      "2018-04-13T15:09:01.753756: step 2465, loss 0.0754412, acc 0.984375\n",
      "2018-04-13T15:09:02.069980: step 2466, loss 0.028539, acc 1\n",
      "2018-04-13T15:09:02.375195: step 2467, loss 0.030127, acc 0.984375\n",
      "2018-04-13T15:09:02.710432: step 2468, loss 0.0811396, acc 0.96875\n",
      "2018-04-13T15:09:03.036161: step 2469, loss 0.051056, acc 0.96875\n",
      "2018-04-13T15:09:03.367395: step 2470, loss 0.0115406, acc 1\n",
      "2018-04-13T15:09:03.699130: step 2471, loss 0.0206207, acc 1\n",
      "2018-04-13T15:09:04.031864: step 2472, loss 0.0154507, acc 1\n",
      "2018-04-13T15:09:04.348588: step 2473, loss 0.0358099, acc 0.984375\n",
      "2018-04-13T15:09:04.655805: step 2474, loss 0.0314302, acc 0.984375\n",
      "2018-04-13T15:09:04.976532: step 2475, loss 0.0586641, acc 0.984375\n",
      "2018-04-13T15:09:05.293756: step 2476, loss 0.0318209, acc 0.984375\n",
      "2018-04-13T15:09:05.620487: step 2477, loss 0.0437246, acc 0.96875\n",
      "2018-04-13T15:09:05.942214: step 2478, loss 0.0134305, acc 1\n",
      "2018-04-13T15:09:06.258938: step 2479, loss 0.0282286, acc 0.984375\n",
      "2018-04-13T15:09:06.579164: step 2480, loss 0.0658953, acc 0.96875\n",
      "2018-04-13T15:09:06.938417: step 2481, loss 0.101952, acc 0.984375\n",
      "2018-04-13T15:09:07.253639: step 2482, loss 0.022948, acc 0.984375\n",
      "2018-04-13T15:09:07.572365: step 2483, loss 0.00355701, acc 1\n",
      "2018-04-13T15:09:07.893592: step 2484, loss 0.0416551, acc 0.984375\n",
      "2018-04-13T15:09:08.216321: step 2485, loss 0.0499945, acc 0.96875\n",
      "2018-04-13T15:09:08.535045: step 2486, loss 0.0763825, acc 0.96875\n",
      "2018-04-13T15:09:08.873283: step 2487, loss 0.0227689, acc 1\n",
      "2018-04-13T15:09:09.181000: step 2488, loss 0.00640172, acc 1\n",
      "2018-04-13T15:09:09.494722: step 2489, loss 0.0106047, acc 1\n",
      "2018-04-13T15:09:09.835963: step 2490, loss 0.0321734, acc 0.984375\n",
      "2018-04-13T15:09:10.163195: step 2491, loss 0.0527929, acc 0.96875\n",
      "2018-04-13T15:09:10.485922: step 2492, loss 0.00654554, acc 1\n",
      "2018-04-13T15:09:10.805147: step 2493, loss 0.0161765, acc 1\n",
      "2018-04-13T15:09:11.126875: step 2494, loss 0.0208625, acc 1\n",
      "2018-04-13T15:09:11.434592: step 2495, loss 0.0258723, acc 1\n",
      "2018-04-13T15:09:11.755818: step 2496, loss 0.0573153, acc 0.96875\n",
      "2018-04-13T15:09:12.074044: step 2497, loss 0.0838884, acc 0.96875\n",
      "2018-04-13T15:09:12.384262: step 2498, loss 0.12118, acc 0.9375\n",
      "2018-04-13T15:09:12.705491: step 2499, loss 0.0186843, acc 1\n",
      "2018-04-13T15:09:13.046230: step 2500, loss 0.0168341, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:09:14.169523: step 2500, loss 0.84751, acc 0.743902\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2500\n",
      "\n",
      "2018-04-13T15:09:15.552751: step 2501, loss 0.0518855, acc 0.984375\n",
      "2018-04-13T15:09:15.878481: step 2502, loss 0.115998, acc 0.953125\n",
      "2018-04-13T15:09:16.202209: step 2503, loss 0.015373, acc 1\n",
      "2018-04-13T15:09:16.522435: step 2504, loss 0.0495655, acc 0.984375\n",
      "2018-04-13T15:09:16.851167: step 2505, loss 0.0568964, acc 0.984375\n",
      "2018-04-13T15:09:17.174896: step 2506, loss 0.0123501, acc 1\n",
      "2018-04-13T15:09:17.484615: step 2507, loss 0.0127791, acc 1\n",
      "2018-04-13T15:09:17.818851: step 2508, loss 0.0429602, acc 0.984375\n",
      "2018-04-13T15:09:18.136575: step 2509, loss 0.0629624, acc 0.984375\n",
      "2018-04-13T15:09:18.460304: step 2510, loss 0.0682806, acc 0.96875\n",
      "2018-04-13T15:09:18.776026: step 2511, loss 0.0435083, acc 0.96875\n",
      "2018-04-13T15:09:19.109262: step 2512, loss 0.0219632, acc 1\n",
      "2018-04-13T15:09:19.430989: step 2513, loss 0.00717064, acc 1\n",
      "2018-04-13T15:09:19.743209: step 2514, loss 0.0116879, acc 1\n",
      "2018-04-13T15:09:20.059433: step 2515, loss 0.0237488, acc 1\n",
      "2018-04-13T15:09:20.392668: step 2516, loss 0.038774, acc 0.984375\n",
      "2018-04-13T15:09:20.724402: step 2517, loss 0.0697006, acc 0.96875\n",
      "2018-04-13T15:09:21.050633: step 2518, loss 0.0503904, acc 0.984375\n",
      "2018-04-13T15:09:21.369858: step 2519, loss 0.0487324, acc 0.96875\n",
      "2018-04-13T15:09:21.707597: step 2520, loss 0.00833953, acc 1\n",
      "2018-04-13T15:09:22.045835: step 2521, loss 0.0372652, acc 0.96875\n",
      "2018-04-13T15:09:22.371065: step 2522, loss 0.0130398, acc 1\n",
      "2018-04-13T15:09:22.689790: step 2523, loss 0.00927504, acc 1\n",
      "2018-04-13T15:09:23.011517: step 2524, loss 0.0552217, acc 0.96875\n",
      "2018-04-13T15:09:23.335348: step 2525, loss 0.0316263, acc 0.984375\n",
      "2018-04-13T15:09:23.655573: step 2526, loss 0.0331976, acc 0.984375\n",
      "2018-04-13T15:09:23.977301: step 2527, loss 0.0877318, acc 0.96875\n",
      "2018-04-13T15:09:24.291023: step 2528, loss 0.0255338, acc 0.984375\n",
      "2018-04-13T15:09:24.612749: step 2529, loss 0.0167467, acc 1\n",
      "2018-04-13T15:09:24.941482: step 2530, loss 0.0310296, acc 1\n",
      "2018-04-13T15:09:25.276719: step 2531, loss 0.0125828, acc 1\n",
      "2018-04-13T15:09:25.583435: step 2532, loss 0.0236953, acc 0.984375\n",
      "2018-04-13T15:09:25.907664: step 2533, loss 0.0462505, acc 0.96875\n",
      "2018-04-13T15:09:26.219384: step 2534, loss 0.0303069, acc 0.984375\n",
      "2018-04-13T15:09:26.541619: step 2535, loss 0.0302341, acc 0.984375\n",
      "2018-04-13T15:09:26.859836: step 2536, loss 0.0167353, acc 1\n",
      "2018-04-13T15:09:27.173057: step 2537, loss 0.0508226, acc 0.984375\n",
      "2018-04-13T15:09:27.492283: step 2538, loss 0.0104286, acc 1\n",
      "2018-04-13T15:09:27.820516: step 2539, loss 0.0317545, acc 0.984375\n",
      "2018-04-13T15:09:28.164258: step 2540, loss 0.0304513, acc 0.984375\n",
      "2018-04-13T15:09:28.478479: step 2541, loss 0.00780659, acc 1\n",
      "2018-04-13T15:09:28.803209: step 2542, loss 0.0139585, acc 1\n",
      "2018-04-13T15:09:29.128439: step 2543, loss 0.0587568, acc 0.96875\n",
      "2018-04-13T15:09:29.461674: step 2544, loss 0.0326326, acc 0.984375\n",
      "2018-04-13T15:09:29.791407: step 2545, loss 0.0107647, acc 1\n",
      "2018-04-13T15:09:30.107130: step 2546, loss 0.0275731, acc 1\n",
      "2018-04-13T15:09:30.431858: step 2547, loss 0.0793956, acc 0.984375\n",
      "2018-04-13T15:09:30.747581: step 2548, loss 0.0172941, acc 1\n",
      "2018-04-13T15:09:31.087822: step 2549, loss 0.00576507, acc 1\n",
      "2018-04-13T15:09:31.388534: step 2550, loss 0.0413995, acc 0.983333\n",
      "2018-04-13T15:09:31.705258: step 2551, loss 0.00729286, acc 1\n",
      "2018-04-13T15:09:32.033489: step 2552, loss 0.0151901, acc 1\n",
      "2018-04-13T15:09:32.344709: step 2553, loss 0.0428432, acc 0.984375\n",
      "2018-04-13T15:09:32.675443: step 2554, loss 0.0196644, acc 0.984375\n",
      "2018-04-13T15:09:33.019686: step 2555, loss 0.0073968, acc 1\n",
      "2018-04-13T15:09:33.346917: step 2556, loss 0.0111358, acc 1\n",
      "2018-04-13T15:09:33.664642: step 2557, loss 0.0145547, acc 1\n",
      "2018-04-13T15:09:34.016890: step 2558, loss 0.0255898, acc 0.984375\n",
      "2018-04-13T15:09:34.344121: step 2559, loss 0.00838943, acc 1\n",
      "2018-04-13T15:09:34.654841: step 2560, loss 0.0163954, acc 1\n",
      "2018-04-13T15:09:34.984073: step 2561, loss 0.0501761, acc 0.984375\n",
      "2018-04-13T15:09:35.302299: step 2562, loss 0.0176858, acc 1\n",
      "2018-04-13T15:09:35.634032: step 2563, loss 0.024081, acc 1\n",
      "2018-04-13T15:09:35.959261: step 2564, loss 0.0104003, acc 1\n",
      "2018-04-13T15:09:36.276986: step 2565, loss 0.0270504, acc 0.984375\n",
      "2018-04-13T15:09:36.598713: step 2566, loss 0.0206417, acc 1\n",
      "2018-04-13T15:09:36.952963: step 2567, loss 0.0343804, acc 0.984375\n",
      "2018-04-13T15:09:37.283696: step 2568, loss 0.014319, acc 1\n",
      "2018-04-13T15:09:37.596918: step 2569, loss 0.0136096, acc 1\n",
      "2018-04-13T15:09:37.920646: step 2570, loss 0.032969, acc 0.984375\n",
      "2018-04-13T15:09:38.228364: step 2571, loss 0.0311224, acc 0.984375\n",
      "2018-04-13T15:09:38.548590: step 2572, loss 0.0149504, acc 1\n",
      "2018-04-13T15:09:38.897336: step 2573, loss 0.0072243, acc 1\n",
      "2018-04-13T15:09:39.206554: step 2574, loss 0.00769135, acc 1\n",
      "2018-04-13T15:09:39.540790: step 2575, loss 0.0601696, acc 0.96875\n",
      "2018-04-13T15:09:39.887035: step 2576, loss 0.0347249, acc 0.984375\n",
      "2018-04-13T15:09:40.218269: step 2577, loss 0.019368, acc 1\n",
      "2018-04-13T15:09:40.532701: step 2578, loss 0.0146657, acc 1\n",
      "2018-04-13T15:09:40.852927: step 2579, loss 0.0462914, acc 0.984375\n",
      "2018-04-13T15:09:41.166148: step 2580, loss 0.0194924, acc 1\n",
      "2018-04-13T15:09:41.474866: step 2581, loss 0.0348618, acc 0.984375\n",
      "2018-04-13T15:09:41.806603: step 2582, loss 0.0784185, acc 0.953125\n",
      "2018-04-13T15:09:42.126326: step 2583, loss 0.00663012, acc 1\n",
      "2018-04-13T15:09:42.432042: step 2584, loss 0.0139787, acc 1\n",
      "2018-04-13T15:09:42.758273: step 2585, loss 0.0104965, acc 1\n",
      "2018-04-13T15:09:43.107019: step 2586, loss 0.0127209, acc 1\n",
      "2018-04-13T15:09:43.438259: step 2587, loss 0.0166215, acc 0.984375\n",
      "2018-04-13T15:09:43.753977: step 2588, loss 0.0324553, acc 1\n",
      "2018-04-13T15:09:44.079906: step 2589, loss 0.0142926, acc 1\n",
      "2018-04-13T15:09:44.392627: step 2590, loss 0.0129967, acc 1\n",
      "2018-04-13T15:09:44.718857: step 2591, loss 0.036894, acc 1\n",
      "2018-04-13T15:09:45.029577: step 2592, loss 0.0810539, acc 0.96875\n",
      "2018-04-13T15:09:45.345799: step 2593, loss 0.0726903, acc 0.96875\n",
      "2018-04-13T15:09:45.665025: step 2594, loss 0.0201396, acc 1\n",
      "2018-04-13T15:09:46.024780: step 2595, loss 0.0398802, acc 1\n",
      "2018-04-13T15:09:46.354513: step 2596, loss 0.0103942, acc 1\n",
      "2018-04-13T15:09:46.673237: step 2597, loss 0.0124068, acc 1\n",
      "2018-04-13T15:09:46.992963: step 2598, loss 0.00637779, acc 1\n",
      "2018-04-13T15:09:47.310187: step 2599, loss 0.0131723, acc 1\n",
      "2018-04-13T15:09:47.629913: step 2600, loss 0.0091941, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:09:48.742198: step 2600, loss 0.880423, acc 0.745779\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2600\n",
      "\n",
      "2018-04-13T15:09:50.180615: step 2601, loss 0.0127973, acc 1\n",
      "2018-04-13T15:09:50.500341: step 2602, loss 0.00496694, acc 1\n",
      "2018-04-13T15:09:50.831074: step 2603, loss 0.0137541, acc 1\n",
      "2018-04-13T15:09:51.147797: step 2604, loss 0.00987368, acc 1\n",
      "2018-04-13T15:09:51.461520: step 2605, loss 0.0158491, acc 1\n",
      "2018-04-13T15:09:51.778291: step 2606, loss 0.0277761, acc 1\n",
      "2018-04-13T15:09:52.124988: step 2607, loss 0.00346621, acc 1\n",
      "2018-04-13T15:09:52.443213: step 2608, loss 0.0100519, acc 1\n",
      "2018-04-13T15:09:52.770443: step 2609, loss 0.0200946, acc 1\n",
      "2018-04-13T15:09:53.099676: step 2610, loss 0.0139548, acc 1\n",
      "2018-04-13T15:09:53.423904: step 2611, loss 0.00652571, acc 1\n",
      "2018-04-13T15:09:53.754639: step 2612, loss 0.0819184, acc 0.953125\n",
      "2018-04-13T15:09:54.083871: step 2613, loss 0.030873, acc 0.984375\n",
      "2018-04-13T15:09:54.400093: step 2614, loss 0.0372195, acc 0.984375\n",
      "2018-04-13T15:09:54.712816: step 2615, loss 0.0259101, acc 1\n",
      "2018-04-13T15:09:55.080574: step 2616, loss 0.0338555, acc 1\n",
      "2018-04-13T15:09:55.396298: step 2617, loss 0.0113471, acc 1\n",
      "2018-04-13T15:09:55.714022: step 2618, loss 0.00986, acc 1\n",
      "2018-04-13T15:09:56.018236: step 2619, loss 0.0180506, acc 1\n",
      "2018-04-13T15:09:56.331458: step 2620, loss 0.0178147, acc 0.984375\n",
      "2018-04-13T15:09:56.672198: step 2621, loss 0.0414082, acc 0.96875\n",
      "2018-04-13T15:09:56.989422: step 2622, loss 0.0663373, acc 0.953125\n",
      "2018-04-13T15:09:57.305172: step 2623, loss 0.0241822, acc 0.984375\n",
      "2018-04-13T15:09:57.617893: step 2624, loss 0.0440567, acc 0.984375\n",
      "2018-04-13T15:09:57.974650: step 2625, loss 0.00833993, acc 1\n",
      "2018-04-13T15:09:58.292869: step 2626, loss 0.024393, acc 1\n",
      "2018-04-13T15:09:58.606591: step 2627, loss 0.058167, acc 0.96875\n",
      "2018-04-13T15:09:58.942828: step 2628, loss 0.0151904, acc 1\n",
      "2018-04-13T15:09:59.258551: step 2629, loss 0.0370649, acc 0.984375\n",
      "2018-04-13T15:09:59.599791: step 2630, loss 0.052675, acc 0.96875\n",
      "2018-04-13T15:09:59.931026: step 2631, loss 0.0126104, acc 1\n",
      "2018-04-13T15:10:00.267764: step 2632, loss 0.0151576, acc 1\n",
      "2018-04-13T15:10:00.599998: step 2633, loss 0.0202857, acc 1\n",
      "2018-04-13T15:10:00.955250: step 2634, loss 0.0450868, acc 0.984375\n",
      "2018-04-13T15:10:01.299024: step 2635, loss 0.0146682, acc 0.984375\n",
      "2018-04-13T15:10:01.615747: step 2636, loss 0.00763397, acc 1\n",
      "2018-04-13T15:10:01.945980: step 2637, loss 0.0159054, acc 1\n",
      "2018-04-13T15:10:02.257700: step 2638, loss 0.0527964, acc 0.984375\n",
      "2018-04-13T15:10:02.571441: step 2639, loss 0.0335127, acc 0.984375\n",
      "2018-04-13T15:10:02.907678: step 2640, loss 0.0148495, acc 1\n",
      "2018-04-13T15:10:03.215896: step 2641, loss 0.0117871, acc 1\n",
      "2018-04-13T15:10:03.539625: step 2642, loss 0.00940066, acc 1\n",
      "2018-04-13T15:10:03.863853: step 2643, loss 0.00940936, acc 1\n",
      "2018-04-13T15:10:04.201592: step 2644, loss 0.0378818, acc 0.984375\n",
      "2018-04-13T15:10:04.532825: step 2645, loss 0.0185834, acc 1\n",
      "2018-04-13T15:10:04.863559: step 2646, loss 0.0377554, acc 1\n",
      "2018-04-13T15:10:05.198295: step 2647, loss 0.0293582, acc 0.984375\n",
      "2018-04-13T15:10:05.531530: step 2648, loss 0.0145562, acc 1\n",
      "2018-04-13T15:10:05.870769: step 2649, loss 0.0338887, acc 0.984375\n",
      "2018-04-13T15:10:06.187994: step 2650, loss 0.00493453, acc 1\n",
      "2018-04-13T15:10:06.501716: step 2651, loss 0.0560294, acc 0.984375\n",
      "2018-04-13T15:10:06.815437: step 2652, loss 0.0575776, acc 0.984375\n",
      "2018-04-13T15:10:07.156178: step 2653, loss 0.0646308, acc 0.984375\n",
      "2018-04-13T15:10:07.464395: step 2654, loss 0.00608375, acc 1\n",
      "2018-04-13T15:10:07.778618: step 2655, loss 0.0136846, acc 1\n",
      "2018-04-13T15:10:08.094840: step 2656, loss 0.0107576, acc 1\n",
      "2018-04-13T15:10:08.404559: step 2657, loss 0.0180428, acc 1\n",
      "2018-04-13T15:10:08.750304: step 2658, loss 0.0114248, acc 1\n",
      "2018-04-13T15:10:09.079536: step 2659, loss 0.0183875, acc 1\n",
      "2018-04-13T15:10:09.400763: step 2660, loss 0.0330446, acc 0.984375\n",
      "2018-04-13T15:10:09.755013: step 2661, loss 0.0075538, acc 1\n",
      "2018-04-13T15:10:10.129278: step 2662, loss 0.0248864, acc 1\n",
      "2018-04-13T15:10:10.454007: step 2663, loss 0.0246213, acc 1\n",
      "2018-04-13T15:10:10.808257: step 2664, loss 0.121991, acc 0.984375\n",
      "2018-04-13T15:10:11.148997: step 2665, loss 0.0179821, acc 1\n",
      "2018-04-13T15:10:11.517758: step 2666, loss 0.0170959, acc 1\n",
      "2018-04-13T15:10:11.896026: step 2667, loss 0.00308644, acc 1\n",
      "2018-04-13T15:10:12.254278: step 2668, loss 0.0114633, acc 1\n",
      "2018-04-13T15:10:12.594018: step 2669, loss 0.0210051, acc 1\n",
      "2018-04-13T15:10:12.943765: step 2670, loss 0.0166462, acc 1\n",
      "2018-04-13T15:10:13.274498: step 2671, loss 0.012977, acc 1\n",
      "2018-04-13T15:10:13.597726: step 2672, loss 0.0266779, acc 0.984375\n",
      "2018-04-13T15:10:14.031536: step 2673, loss 0.00888092, acc 1\n",
      "2018-04-13T15:10:14.493219: step 2674, loss 0.0168714, acc 1\n",
      "2018-04-13T15:10:14.885996: step 2675, loss 0.0158268, acc 1\n",
      "2018-04-13T15:10:15.215730: step 2676, loss 0.0206832, acc 0.984375\n",
      "2018-04-13T15:10:15.541959: step 2677, loss 0.00981638, acc 1\n",
      "2018-04-13T15:10:15.899211: step 2678, loss 0.00738552, acc 1\n",
      "2018-04-13T15:10:16.246957: step 2679, loss 0.0425086, acc 0.984375\n",
      "2018-04-13T15:10:16.579692: step 2680, loss 0.00701664, acc 1\n",
      "2018-04-13T15:10:16.911927: step 2681, loss 0.00929254, acc 1\n",
      "2018-04-13T15:10:17.258672: step 2682, loss 0.0262823, acc 0.984375\n",
      "2018-04-13T15:10:17.620428: step 2683, loss 0.00837528, acc 1\n",
      "2018-04-13T15:10:17.973676: step 2684, loss 0.0206027, acc 1\n",
      "2018-04-13T15:10:18.306411: step 2685, loss 0.00937791, acc 1\n",
      "2018-04-13T15:10:18.641148: step 2686, loss 0.0143867, acc 1\n",
      "2018-04-13T15:10:18.961874: step 2687, loss 0.00322153, acc 1\n",
      "2018-04-13T15:10:19.304616: step 2688, loss 0.00357876, acc 1\n",
      "2018-04-13T15:10:19.639368: step 2689, loss 0.0148151, acc 1\n",
      "2018-04-13T15:10:19.978608: step 2690, loss 0.0083523, acc 1\n",
      "2018-04-13T15:10:20.295331: step 2691, loss 0.0197331, acc 1\n",
      "2018-04-13T15:10:20.624564: step 2692, loss 0.0171861, acc 1\n",
      "2018-04-13T15:10:21.006833: step 2693, loss 0.0194098, acc 1\n",
      "2018-04-13T15:10:21.322556: step 2694, loss 0.0103368, acc 1\n",
      "2018-04-13T15:10:21.642782: step 2695, loss 0.0141413, acc 1\n",
      "2018-04-13T15:10:21.975518: step 2696, loss 0.0104668, acc 1\n",
      "2018-04-13T15:10:22.297745: step 2697, loss 0.0390681, acc 0.96875\n",
      "2018-04-13T15:10:22.634993: step 2698, loss 0.074171, acc 0.96875\n",
      "2018-04-13T15:10:22.953718: step 2699, loss 0.00947353, acc 1\n",
      "2018-04-13T15:10:23.247426: step 2700, loss 0.0425226, acc 0.983333\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:10:24.418253: step 2700, loss 0.918892, acc 0.739212\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2700\n",
      "\n",
      "2018-04-13T15:10:26.066219: step 2701, loss 0.01002, acc 1\n",
      "2018-04-13T15:10:26.378940: step 2702, loss 0.00824672, acc 1\n",
      "2018-04-13T15:10:26.707171: step 2703, loss 0.00971817, acc 1\n",
      "2018-04-13T15:10:27.038905: step 2704, loss 0.0170516, acc 1\n",
      "2018-04-13T15:10:27.351126: step 2705, loss 0.0504708, acc 0.984375\n",
      "2018-04-13T15:10:27.666849: step 2706, loss 0.0334684, acc 0.984375\n",
      "2018-04-13T15:10:28.020099: step 2707, loss 0.0430523, acc 0.984375\n",
      "2018-04-13T15:10:28.384857: step 2708, loss 0.00448483, acc 1\n",
      "2018-04-13T15:10:28.722094: step 2709, loss 0.00838229, acc 1\n",
      "2018-04-13T15:10:29.044322: step 2710, loss 0.0134912, acc 1\n",
      "2018-04-13T15:10:29.391067: step 2711, loss 0.010828, acc 1\n",
      "2018-04-13T15:10:29.743315: step 2712, loss 0.0363214, acc 0.984375\n",
      "2018-04-13T15:10:30.098066: step 2713, loss 0.0331265, acc 0.984375\n",
      "2018-04-13T15:10:30.439807: step 2714, loss 0.0137013, acc 1\n",
      "2018-04-13T15:10:30.760033: step 2715, loss 0.0116571, acc 1\n",
      "2018-04-13T15:10:31.129294: step 2716, loss 0.0088988, acc 1\n",
      "2018-04-13T15:10:31.464114: step 2717, loss 0.0133288, acc 1\n",
      "2018-04-13T15:10:31.793346: step 2718, loss 0.0126758, acc 1\n",
      "2018-04-13T15:10:32.137089: step 2719, loss 0.010068, acc 1\n",
      "2018-04-13T15:10:32.485335: step 2720, loss 0.0128494, acc 1\n",
      "2018-04-13T15:10:32.862101: step 2721, loss 0.0140977, acc 1\n",
      "2018-04-13T15:10:33.212848: step 2722, loss 0.0348915, acc 0.984375\n",
      "2018-04-13T15:10:33.565599: step 2723, loss 0.00445179, acc 1\n",
      "2018-04-13T15:10:33.912843: step 2724, loss 0.0150447, acc 1\n",
      "2018-04-13T15:10:34.274098: step 2725, loss 0.00271737, acc 1\n",
      "2018-04-13T15:10:34.603331: step 2726, loss 0.0176903, acc 1\n",
      "2018-04-13T15:10:34.926058: step 2727, loss 0.0124616, acc 1\n",
      "2018-04-13T15:10:35.244282: step 2728, loss 0.0189044, acc 1\n",
      "2018-04-13T15:10:35.572514: step 2729, loss 0.00990772, acc 1\n",
      "2018-04-13T15:10:35.911254: step 2730, loss 0.0181972, acc 1\n",
      "2018-04-13T15:10:36.242988: step 2731, loss 0.0536133, acc 0.96875\n",
      "2018-04-13T15:10:36.560712: step 2732, loss 0.0219465, acc 0.984375\n",
      "2018-04-13T15:10:36.891446: step 2733, loss 0.0162884, acc 1\n",
      "2018-04-13T15:10:37.246197: step 2734, loss 0.00969153, acc 1\n",
      "2018-04-13T15:10:37.565421: step 2735, loss 0.0045441, acc 1\n",
      "2018-04-13T15:10:37.889150: step 2736, loss 0.0284501, acc 0.984375\n",
      "2018-04-13T15:10:38.196868: step 2737, loss 0.0132702, acc 1\n",
      "2018-04-13T15:10:38.527101: step 2738, loss 0.0178542, acc 1\n",
      "2018-04-13T15:10:38.870844: step 2739, loss 0.0105465, acc 1\n",
      "2018-04-13T15:10:39.184565: step 2740, loss 0.00981641, acc 1\n",
      "2018-04-13T15:10:39.520802: step 2741, loss 0.0356999, acc 0.984375\n",
      "2018-04-13T15:10:39.839527: step 2742, loss 0.0332997, acc 0.984375\n",
      "2018-04-13T15:10:40.206287: step 2743, loss 0.0230383, acc 1\n",
      "2018-04-13T15:10:40.522510: step 2744, loss 0.0266993, acc 0.984375\n",
      "2018-04-13T15:10:40.837232: step 2745, loss 0.0090056, acc 1\n",
      "2018-04-13T15:10:41.163473: step 2746, loss 0.0350324, acc 0.96875\n",
      "2018-04-13T15:10:41.487691: step 2747, loss 0.0585821, acc 0.984375\n",
      "2018-04-13T15:10:41.831935: step 2748, loss 0.00373785, acc 1\n",
      "2018-04-13T15:10:42.151660: step 2749, loss 0.0257429, acc 1\n",
      "2018-04-13T15:10:42.466383: step 2750, loss 0.0222938, acc 1\n",
      "2018-04-13T15:10:42.804621: step 2751, loss 0.00921873, acc 1\n",
      "2018-04-13T15:10:43.149365: step 2752, loss 0.00842958, acc 1\n",
      "2018-04-13T15:10:43.475095: step 2753, loss 0.020472, acc 0.984375\n",
      "2018-04-13T15:10:43.796822: step 2754, loss 0.0149441, acc 1\n",
      "2018-04-13T15:10:44.113045: step 2755, loss 0.0122186, acc 1\n",
      "2018-04-13T15:10:44.432271: step 2756, loss 0.0480125, acc 0.96875\n",
      "2018-04-13T15:10:44.765506: step 2757, loss 0.00946033, acc 1\n",
      "2018-04-13T15:10:45.087734: step 2758, loss 0.0160538, acc 0.984375\n",
      "2018-04-13T15:10:45.404958: step 2759, loss 0.02356, acc 0.984375\n",
      "2018-04-13T15:10:45.722682: step 2760, loss 0.0531061, acc 0.96875\n",
      "2018-04-13T15:10:46.070927: step 2761, loss 0.0115265, acc 1\n",
      "2018-04-13T15:10:46.409666: step 2762, loss 0.0105041, acc 1\n",
      "2018-04-13T15:10:46.741902: step 2763, loss 0.0113397, acc 1\n",
      "2018-04-13T15:10:47.062628: step 2764, loss 0.0174514, acc 1\n",
      "2018-04-13T15:10:47.383355: step 2765, loss 0.00750627, acc 1\n",
      "2018-04-13T15:10:47.717590: step 2766, loss 0.0262828, acc 0.984375\n",
      "2018-04-13T15:10:48.128381: step 2767, loss 0.0262983, acc 0.984375\n",
      "2018-04-13T15:10:48.448106: step 2768, loss 0.00386049, acc 1\n",
      "2018-04-13T15:10:48.765831: step 2769, loss 0.0130259, acc 1\n",
      "2018-04-13T15:10:49.115077: step 2770, loss 0.00613603, acc 1\n",
      "2018-04-13T15:10:49.446811: step 2771, loss 0.0174695, acc 0.984375\n",
      "2018-04-13T15:10:49.778545: step 2772, loss 0.00968504, acc 1\n",
      "2018-04-13T15:10:50.093268: step 2773, loss 0.0070702, acc 1\n",
      "2018-04-13T15:10:50.409991: step 2774, loss 0.0121836, acc 1\n",
      "2018-04-13T15:10:50.758237: step 2775, loss 0.0371104, acc 0.984375\n",
      "2018-04-13T15:10:51.084468: step 2776, loss 0.0131608, acc 1\n",
      "2018-04-13T15:10:51.411198: step 2777, loss 0.0101485, acc 1\n",
      "2018-04-13T15:10:51.730924: step 2778, loss 0.0230139, acc 1\n",
      "2018-04-13T15:10:52.055153: step 2779, loss 0.017728, acc 1\n",
      "2018-04-13T15:10:52.402899: step 2780, loss 0.0131168, acc 1\n",
      "2018-04-13T15:10:52.730630: step 2781, loss 0.00502591, acc 1\n",
      "2018-04-13T15:10:53.052858: step 2782, loss 0.0138014, acc 1\n",
      "2018-04-13T15:10:53.376086: step 2783, loss 0.032106, acc 0.984375\n",
      "2018-04-13T15:10:53.707320: step 2784, loss 0.00518128, acc 1\n",
      "2018-04-13T15:10:54.040555: step 2785, loss 0.101329, acc 0.953125\n",
      "2018-04-13T15:10:54.367286: step 2786, loss 0.01982, acc 1\n",
      "2018-04-13T15:10:54.704525: step 2787, loss 0.0097517, acc 1\n",
      "2018-04-13T15:10:55.028753: step 2788, loss 0.0280525, acc 0.984375\n",
      "2018-04-13T15:10:55.358987: step 2789, loss 0.019425, acc 1\n",
      "2018-04-13T15:10:55.680713: step 2790, loss 0.0422185, acc 0.96875\n",
      "2018-04-13T15:10:55.997437: step 2791, loss 0.00750713, acc 1\n",
      "2018-04-13T15:10:56.306657: step 2792, loss 0.0389152, acc 0.984375\n",
      "2018-04-13T15:10:56.637389: step 2793, loss 0.00908649, acc 1\n",
      "2018-04-13T15:10:56.966121: step 2794, loss 0.00666641, acc 1\n",
      "2018-04-13T15:10:57.281343: step 2795, loss 0.00744228, acc 1\n",
      "2018-04-13T15:10:57.600069: step 2796, loss 0.00893348, acc 1\n",
      "2018-04-13T15:10:57.931802: step 2797, loss 0.0346545, acc 1\n",
      "2018-04-13T15:10:58.262538: step 2798, loss 0.0344395, acc 0.984375\n",
      "2018-04-13T15:10:58.586265: step 2799, loss 0.0156151, acc 1\n",
      "2018-04-13T15:10:58.919000: step 2800, loss 0.00865158, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:11:00.055803: step 2800, loss 0.945193, acc 0.730769\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2800\n",
      "\n",
      "2018-04-13T15:11:01.734653: step 2801, loss 0.0160725, acc 1\n",
      "2018-04-13T15:11:02.045372: step 2802, loss 0.0219548, acc 0.984375\n",
      "2018-04-13T15:11:02.365100: step 2803, loss 0.0112004, acc 1\n",
      "2018-04-13T15:11:02.693830: step 2804, loss 0.0168663, acc 1\n",
      "2018-04-13T15:11:03.022563: step 2805, loss 0.00857957, acc 1\n",
      "2018-04-13T15:11:03.342789: step 2806, loss 0.0210367, acc 0.984375\n",
      "2018-04-13T15:11:03.669019: step 2807, loss 0.0143193, acc 1\n",
      "2018-04-13T15:11:04.007764: step 2808, loss 0.0237055, acc 1\n",
      "2018-04-13T15:11:04.363509: step 2809, loss 0.023315, acc 1\n",
      "2018-04-13T15:11:04.672247: step 2810, loss 0.0260071, acc 0.984375\n",
      "2018-04-13T15:11:05.002980: step 2811, loss 0.0057362, acc 1\n",
      "2018-04-13T15:11:05.322208: step 2812, loss 0.0379895, acc 0.96875\n",
      "2018-04-13T15:11:05.636929: step 2813, loss 0.0201966, acc 0.984375\n",
      "2018-04-13T15:11:05.981171: step 2814, loss 0.029306, acc 0.984375\n",
      "2018-04-13T15:11:06.292891: step 2815, loss 0.00628621, acc 1\n",
      "2018-04-13T15:11:06.616620: step 2816, loss 0.0261458, acc 1\n",
      "2018-04-13T15:11:06.945352: step 2817, loss 0.0320527, acc 0.984375\n",
      "2018-04-13T15:11:07.274585: step 2818, loss 0.0253221, acc 1\n",
      "2018-04-13T15:11:07.608321: step 2819, loss 0.0122096, acc 1\n",
      "2018-04-13T15:11:07.936552: step 2820, loss 0.00945328, acc 1\n",
      "2018-04-13T15:11:08.250775: step 2821, loss 0.0185368, acc 1\n",
      "2018-04-13T15:11:08.576003: step 2822, loss 0.0108876, acc 1\n",
      "2018-04-13T15:11:08.903735: step 2823, loss 0.0110255, acc 1\n",
      "2018-04-13T15:11:09.231467: step 2824, loss 0.0213062, acc 1\n",
      "2018-04-13T15:11:09.558197: step 2825, loss 0.0411161, acc 0.984375\n",
      "2018-04-13T15:11:09.887430: step 2826, loss 0.0107622, acc 1\n",
      "2018-04-13T15:11:10.218164: step 2827, loss 0.00715269, acc 1\n",
      "2018-04-13T15:11:10.539390: step 2828, loss 0.0616969, acc 0.96875\n",
      "2018-04-13T15:11:10.877129: step 2829, loss 0.00765826, acc 1\n",
      "2018-04-13T15:11:11.195854: step 2830, loss 0.026948, acc 1\n",
      "2018-04-13T15:11:11.518581: step 2831, loss 0.0350568, acc 1\n",
      "2018-04-13T15:11:11.847313: step 2832, loss 0.0129869, acc 1\n",
      "2018-04-13T15:11:12.166538: step 2833, loss 0.0470882, acc 0.984375\n",
      "2018-04-13T15:11:12.493769: step 2834, loss 0.0169421, acc 0.984375\n",
      "2018-04-13T15:11:12.821502: step 2835, loss 0.0568285, acc 0.984375\n",
      "2018-04-13T15:11:13.160741: step 2836, loss 0.0152224, acc 1\n",
      "2018-04-13T15:11:13.508487: step 2837, loss 0.0681393, acc 0.984375\n",
      "2018-04-13T15:11:13.835717: step 2838, loss 0.00648899, acc 1\n",
      "2018-04-13T15:11:14.161447: step 2839, loss 0.00460612, acc 1\n",
      "2018-04-13T15:11:14.486176: step 2840, loss 0.0113627, acc 1\n",
      "2018-04-13T15:11:14.820413: step 2841, loss 0.00910049, acc 1\n",
      "2018-04-13T15:11:15.147144: step 2842, loss 0.0276179, acc 0.984375\n",
      "2018-04-13T15:11:15.460364: step 2843, loss 0.0172011, acc 1\n",
      "2018-04-13T15:11:15.785594: step 2844, loss 0.0121534, acc 1\n",
      "2018-04-13T15:11:16.112827: step 2845, loss 0.0130007, acc 1\n",
      "2018-04-13T15:11:16.459070: step 2846, loss 0.0299134, acc 1\n",
      "2018-04-13T15:11:16.787302: step 2847, loss 0.0225436, acc 1\n",
      "2018-04-13T15:11:17.114032: step 2848, loss 0.0242431, acc 0.984375\n",
      "2018-04-13T15:11:17.451270: step 2849, loss 0.0157723, acc 1\n",
      "2018-04-13T15:11:17.760992: step 2850, loss 0.0726312, acc 0.983333\n",
      "2018-04-13T15:11:18.091723: step 2851, loss 0.0247755, acc 0.984375\n",
      "2018-04-13T15:11:18.418454: step 2852, loss 0.0164615, acc 1\n",
      "2018-04-13T15:11:18.738679: step 2853, loss 0.00520609, acc 1\n",
      "2018-04-13T15:11:19.062909: step 2854, loss 0.0797917, acc 0.984375\n",
      "2018-04-13T15:11:19.415658: step 2855, loss 0.0239375, acc 1\n",
      "2018-04-13T15:11:19.737885: step 2856, loss 0.0434812, acc 0.96875\n",
      "2018-04-13T15:11:20.064616: step 2857, loss 0.00557177, acc 1\n",
      "2018-04-13T15:11:20.383341: step 2858, loss 0.013219, acc 1\n",
      "2018-04-13T15:11:20.713073: step 2859, loss 0.00263682, acc 1\n",
      "2018-04-13T15:11:21.046809: step 2860, loss 0.00661926, acc 1\n",
      "2018-04-13T15:11:21.363533: step 2861, loss 0.0106578, acc 1\n",
      "2018-04-13T15:11:21.687762: step 2862, loss 0.0124067, acc 1\n",
      "2018-04-13T15:11:22.007488: step 2863, loss 0.00171997, acc 1\n",
      "2018-04-13T15:11:22.358744: step 2864, loss 0.00727255, acc 1\n",
      "2018-04-13T15:11:22.676460: step 2865, loss 0.0114889, acc 1\n",
      "2018-04-13T15:11:23.000188: step 2866, loss 0.0105145, acc 1\n",
      "2018-04-13T15:11:23.323417: step 2867, loss 0.0219574, acc 1\n",
      "2018-04-13T15:11:23.643143: step 2868, loss 0.00450233, acc 1\n",
      "2018-04-13T15:11:23.973877: step 2869, loss 0.021869, acc 0.984375\n",
      "2018-04-13T15:11:24.296605: step 2870, loss 0.0132817, acc 1\n",
      "2018-04-13T15:11:24.614829: step 2871, loss 0.00452037, acc 1\n",
      "2018-04-13T15:11:24.946563: step 2872, loss 0.0124141, acc 1\n",
      "2018-04-13T15:11:25.284301: step 2873, loss 0.00976726, acc 1\n",
      "2018-04-13T15:11:25.608031: step 2874, loss 0.00450558, acc 1\n",
      "2018-04-13T15:11:25.941266: step 2875, loss 0.00409897, acc 1\n",
      "2018-04-13T15:11:26.260991: step 2876, loss 0.00750971, acc 1\n",
      "2018-04-13T15:11:26.593726: step 2877, loss 0.00357047, acc 1\n",
      "2018-04-13T15:11:26.927462: step 2878, loss 0.00728755, acc 1\n",
      "2018-04-13T15:11:27.252692: step 2879, loss 0.0298878, acc 1\n",
      "2018-04-13T15:11:27.577421: step 2880, loss 0.0133632, acc 1\n",
      "2018-04-13T15:11:27.909655: step 2881, loss 0.0132142, acc 1\n",
      "2018-04-13T15:11:28.247394: step 2882, loss 0.013245, acc 1\n",
      "2018-04-13T15:11:28.586133: step 2883, loss 0.0132699, acc 1\n",
      "2018-04-13T15:11:28.916366: step 2884, loss 0.016625, acc 1\n",
      "2018-04-13T15:11:29.243103: step 2885, loss 0.0201762, acc 1\n",
      "2018-04-13T15:11:29.559821: step 2886, loss 0.0507858, acc 0.96875\n",
      "2018-04-13T15:11:29.891562: step 2887, loss 0.0126944, acc 1\n",
      "2018-04-13T15:11:30.235805: step 2888, loss 0.00633183, acc 1\n",
      "2018-04-13T15:11:30.555031: step 2889, loss 0.00753172, acc 1\n",
      "2018-04-13T15:11:30.868252: step 2890, loss 0.00589793, acc 1\n",
      "2018-04-13T15:11:31.207492: step 2891, loss 0.00590646, acc 1\n",
      "2018-04-13T15:11:31.546731: step 2892, loss 0.012584, acc 1\n",
      "2018-04-13T15:11:31.869459: step 2893, loss 0.0171184, acc 1\n",
      "2018-04-13T15:11:32.206197: step 2894, loss 0.0181046, acc 1\n",
      "2018-04-13T15:11:32.518423: step 2895, loss 0.0477798, acc 0.984375\n",
      "2018-04-13T15:11:32.844154: step 2896, loss 0.00692296, acc 1\n",
      "2018-04-13T15:11:33.158375: step 2897, loss 0.0231666, acc 0.984375\n",
      "2018-04-13T15:11:33.473598: step 2898, loss 0.0193262, acc 1\n",
      "2018-04-13T15:11:33.811337: step 2899, loss 0.0050311, acc 1\n",
      "2018-04-13T15:11:34.140569: step 2900, loss 0.00677244, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:11:35.303390: step 2900, loss 0.959025, acc 0.743902\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-2900\n",
      "\n",
      "2018-04-13T15:11:36.780908: step 2901, loss 0.00499148, acc 1\n",
      "2018-04-13T15:11:37.100133: step 2902, loss 0.00390596, acc 1\n",
      "2018-04-13T15:11:37.436872: step 2903, loss 0.0118734, acc 1\n",
      "2018-04-13T15:11:37.761600: step 2904, loss 0.0199705, acc 1\n",
      "2018-04-13T15:11:38.070820: step 2905, loss 0.0110355, acc 1\n",
      "2018-04-13T15:11:38.395548: step 2906, loss 0.00273395, acc 1\n",
      "2018-04-13T15:11:38.713273: step 2907, loss 0.018728, acc 0.984375\n",
      "2018-04-13T15:11:39.041004: step 2908, loss 0.00596788, acc 1\n",
      "2018-04-13T15:11:39.373739: step 2909, loss 0.0227354, acc 0.984375\n",
      "2018-04-13T15:11:39.690462: step 2910, loss 0.0158821, acc 1\n",
      "2018-04-13T15:11:40.000682: step 2911, loss 0.0153329, acc 1\n",
      "2018-04-13T15:11:40.348427: step 2912, loss 0.00570375, acc 1\n",
      "2018-04-13T15:11:40.677660: step 2913, loss 0.00635821, acc 1\n",
      "2018-04-13T15:11:40.997385: step 2914, loss 0.0196007, acc 0.984375\n",
      "2018-04-13T15:11:41.320118: step 2915, loss 0.00686466, acc 1\n",
      "2018-04-13T15:11:41.637838: step 2916, loss 0.0126283, acc 1\n",
      "2018-04-13T15:11:41.973575: step 2917, loss 0.0151491, acc 1\n",
      "2018-04-13T15:11:42.293801: step 2918, loss 0.0141195, acc 1\n",
      "2018-04-13T15:11:42.609023: step 2919, loss 0.0094374, acc 1\n",
      "2018-04-13T15:11:42.932752: step 2920, loss 0.00634414, acc 1\n",
      "2018-04-13T15:11:43.251478: step 2921, loss 0.00350666, acc 1\n",
      "2018-04-13T15:11:43.590216: step 2922, loss 0.0225901, acc 1\n",
      "2018-04-13T15:11:43.918448: step 2923, loss 0.00325366, acc 1\n",
      "2018-04-13T15:11:44.236673: step 2924, loss 0.00410768, acc 1\n",
      "2018-04-13T15:11:44.571909: step 2925, loss 0.0190945, acc 1\n",
      "2018-04-13T15:11:44.912650: step 2926, loss 0.0127415, acc 1\n",
      "2018-04-13T15:11:45.238880: step 2927, loss 0.0234979, acc 0.984375\n",
      "2018-04-13T15:11:45.569113: step 2928, loss 0.0252554, acc 1\n",
      "2018-04-13T15:11:45.906852: step 2929, loss 0.0379392, acc 0.984375\n",
      "2018-04-13T15:11:46.237086: step 2930, loss 0.00776209, acc 1\n",
      "2018-04-13T15:11:46.565818: step 2931, loss 0.0348781, acc 0.984375\n",
      "2018-04-13T15:11:46.885543: step 2932, loss 0.00589798, acc 1\n",
      "2018-04-13T15:11:47.203767: step 2933, loss 0.0103927, acc 1\n",
      "2018-04-13T15:11:47.525692: step 2934, loss 0.0590626, acc 0.984375\n",
      "2018-04-13T15:11:47.857928: step 2935, loss 0.0211291, acc 0.984375\n",
      "2018-04-13T15:11:48.173149: step 2936, loss 0.0111742, acc 1\n",
      "2018-04-13T15:11:48.497378: step 2937, loss 0.0104789, acc 1\n",
      "2018-04-13T15:11:48.821607: step 2938, loss 0.0111558, acc 1\n",
      "2018-04-13T15:11:49.144336: step 2939, loss 0.0145996, acc 1\n",
      "2018-04-13T15:11:49.486577: step 2940, loss 0.0514498, acc 0.96875\n",
      "2018-04-13T15:11:49.821312: step 2941, loss 0.00835203, acc 1\n",
      "2018-04-13T15:11:50.137036: step 2942, loss 0.00530625, acc 1\n",
      "2018-04-13T15:11:50.453760: step 2943, loss 0.0274619, acc 0.984375\n",
      "2018-04-13T15:11:50.762978: step 2944, loss 0.0140452, acc 1\n",
      "2018-04-13T15:11:51.094712: step 2945, loss 0.00708065, acc 1\n",
      "2018-04-13T15:11:51.413437: step 2946, loss 0.0049562, acc 1\n",
      "2018-04-13T15:11:51.740668: step 2947, loss 0.00447642, acc 1\n",
      "2018-04-13T15:11:52.057893: step 2948, loss 0.0229243, acc 0.984375\n",
      "2018-04-13T15:11:52.458676: step 2949, loss 0.0067421, acc 1\n",
      "2018-04-13T15:11:52.776900: step 2950, loss 0.0120175, acc 1\n",
      "2018-04-13T15:11:53.102130: step 2951, loss 0.0031172, acc 1\n",
      "2018-04-13T15:11:53.422857: step 2952, loss 0.0159973, acc 1\n",
      "2018-04-13T15:11:53.745584: step 2953, loss 0.00614917, acc 1\n",
      "2018-04-13T15:11:54.087326: step 2954, loss 0.0411202, acc 0.984375\n",
      "2018-04-13T15:11:54.400047: step 2955, loss 0.0149384, acc 1\n",
      "2018-04-13T15:11:54.722274: step 2956, loss 0.00987449, acc 1\n",
      "2018-04-13T15:11:55.050006: step 2957, loss 0.00786414, acc 1\n",
      "2018-04-13T15:11:55.396250: step 2958, loss 0.00811151, acc 1\n",
      "2018-04-13T15:11:55.725482: step 2959, loss 0.00554533, acc 1\n",
      "2018-04-13T15:11:56.039204: step 2960, loss 0.00994055, acc 1\n",
      "2018-04-13T15:11:56.361931: step 2961, loss 0.0738566, acc 0.96875\n",
      "2018-04-13T15:11:56.695667: step 2962, loss 0.00703044, acc 1\n",
      "2018-04-13T15:11:57.015393: step 2963, loss 0.0391663, acc 0.984375\n",
      "2018-04-13T15:11:57.337621: step 2964, loss 0.00275202, acc 1\n",
      "2018-04-13T15:11:57.663350: step 2965, loss 0.00624532, acc 1\n",
      "2018-04-13T15:11:57.978073: step 2966, loss 0.0117149, acc 1\n",
      "2018-04-13T15:11:58.316312: step 2967, loss 0.00422431, acc 1\n",
      "2018-04-13T15:11:58.652549: step 2968, loss 0.021193, acc 1\n",
      "2018-04-13T15:11:58.972275: step 2969, loss 0.0301085, acc 0.984375\n",
      "2018-04-13T15:11:59.298005: step 2970, loss 0.0135723, acc 1\n",
      "2018-04-13T15:11:59.633742: step 2971, loss 0.00385788, acc 1\n",
      "2018-04-13T15:11:59.957481: step 2972, loss 0.0129104, acc 1\n",
      "2018-04-13T15:12:00.299723: step 2973, loss 0.0557893, acc 0.984375\n",
      "2018-04-13T15:12:00.624952: step 2974, loss 0.00516604, acc 1\n",
      "2018-04-13T15:12:00.963191: step 2975, loss 0.0176719, acc 1\n",
      "2018-04-13T15:12:01.306934: step 2976, loss 0.00615195, acc 1\n",
      "2018-04-13T15:12:01.631162: step 2977, loss 0.00326418, acc 1\n",
      "2018-04-13T15:12:01.951889: step 2978, loss 0.0348112, acc 0.984375\n",
      "2018-04-13T15:12:02.273117: step 2979, loss 0.00721453, acc 1\n",
      "2018-04-13T15:12:02.598846: step 2980, loss 0.0372556, acc 0.984375\n",
      "2018-04-13T15:12:02.931081: step 2981, loss 0.0260521, acc 0.984375\n",
      "2018-04-13T15:12:03.259813: step 2982, loss 0.0125717, acc 1\n",
      "2018-04-13T15:12:03.573034: step 2983, loss 0.00545468, acc 1\n",
      "2018-04-13T15:12:03.905268: step 2984, loss 0.0134679, acc 1\n",
      "2018-04-13T15:12:04.217489: step 2985, loss 0.0127774, acc 1\n",
      "2018-04-13T15:12:04.566235: step 2986, loss 0.0428068, acc 0.96875\n",
      "2018-04-13T15:12:04.901472: step 2987, loss 0.0104353, acc 1\n",
      "2018-04-13T15:12:05.209689: step 2988, loss 0.0243629, acc 0.984375\n",
      "2018-04-13T15:12:05.525913: step 2989, loss 0.00446364, acc 1\n",
      "2018-04-13T15:12:05.853144: step 2990, loss 0.00775121, acc 1\n",
      "2018-04-13T15:12:06.178374: step 2991, loss 0.00638445, acc 1\n",
      "2018-04-13T15:12:06.511112: step 2992, loss 0.00262845, acc 1\n",
      "2018-04-13T15:12:06.843844: step 2993, loss 0.0417797, acc 0.984375\n",
      "2018-04-13T15:12:07.168072: step 2994, loss 0.00660858, acc 1\n",
      "2018-04-13T15:12:07.532330: step 2995, loss 0.00513654, acc 1\n",
      "2018-04-13T15:12:07.857559: step 2996, loss 0.029777, acc 0.984375\n",
      "2018-04-13T15:12:08.185291: step 2997, loss 0.0133098, acc 1\n",
      "2018-04-13T15:12:08.509527: step 2998, loss 0.00216722, acc 1\n",
      "2018-04-13T15:12:08.846257: step 2999, loss 0.011028, acc 1\n",
      "2018-04-13T15:12:09.170987: step 3000, loss 0.00573583, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:12:10.330306: step 3000, loss 0.996111, acc 0.738274\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3000\n",
      "\n",
      "2018-04-13T15:12:11.982622: step 3001, loss 0.0118944, acc 1\n",
      "2018-04-13T15:12:12.319860: step 3002, loss 0.00538218, acc 1\n",
      "2018-04-13T15:12:12.635583: step 3003, loss 0.0191471, acc 1\n",
      "2018-04-13T15:12:12.977824: step 3004, loss 0.00706157, acc 1\n",
      "2018-04-13T15:12:13.309058: step 3005, loss 0.0178334, acc 0.984375\n",
      "2018-04-13T15:12:13.658311: step 3006, loss 0.0483283, acc 0.984375\n",
      "2018-04-13T15:12:14.000547: step 3007, loss 0.00239651, acc 1\n",
      "2018-04-13T15:12:14.330780: step 3008, loss 0.0052589, acc 1\n",
      "2018-04-13T15:12:14.651006: step 3009, loss 0.0139695, acc 1\n",
      "2018-04-13T15:12:14.980739: step 3010, loss 0.00974604, acc 1\n",
      "2018-04-13T15:12:15.312473: step 3011, loss 0.0112603, acc 1\n",
      "2018-04-13T15:12:15.636203: step 3012, loss 0.00641977, acc 1\n",
      "2018-04-13T15:12:15.963933: step 3013, loss 0.0316877, acc 0.984375\n",
      "2018-04-13T15:12:16.299170: step 3014, loss 0.00846978, acc 1\n",
      "2018-04-13T15:12:16.669431: step 3015, loss 0.00953486, acc 1\n",
      "2018-04-13T15:12:16.998163: step 3016, loss 0.00479939, acc 1\n",
      "2018-04-13T15:12:17.311885: step 3017, loss 0.0062338, acc 1\n",
      "2018-04-13T15:12:17.635114: step 3018, loss 0.0445807, acc 0.984375\n",
      "2018-04-13T15:12:17.960343: step 3019, loss 0.020638, acc 0.984375\n",
      "2018-04-13T15:12:18.291589: step 3020, loss 0.00803904, acc 1\n",
      "2018-04-13T15:12:18.614817: step 3021, loss 0.00518667, acc 1\n",
      "2018-04-13T15:12:18.951054: step 3022, loss 0.0114292, acc 1\n",
      "2018-04-13T15:12:19.283290: step 3023, loss 0.00525085, acc 1\n",
      "2018-04-13T15:12:19.632536: step 3024, loss 0.00807848, acc 1\n",
      "2018-04-13T15:12:19.949259: step 3025, loss 0.0416517, acc 0.96875\n",
      "2018-04-13T15:12:20.262480: step 3026, loss 0.0251879, acc 1\n",
      "2018-04-13T15:12:20.594715: step 3027, loss 0.0195161, acc 0.984375\n",
      "2018-04-13T15:12:20.934455: step 3028, loss 0.00542991, acc 1\n",
      "2018-04-13T15:12:21.257182: step 3029, loss 0.00882605, acc 1\n",
      "2018-04-13T15:12:21.573406: step 3030, loss 0.00357101, acc 1\n",
      "2018-04-13T15:12:21.892632: step 3031, loss 0.00420211, acc 1\n",
      "2018-04-13T15:12:22.208354: step 3032, loss 0.028759, acc 0.984375\n",
      "2018-04-13T15:12:22.563606: step 3033, loss 0.0435332, acc 0.984375\n",
      "2018-04-13T15:12:22.886333: step 3034, loss 0.00907607, acc 1\n",
      "2018-04-13T15:12:23.203557: step 3035, loss 0.00949983, acc 1\n",
      "2018-04-13T15:12:23.526284: step 3036, loss 0.00594509, acc 1\n",
      "2018-04-13T15:12:23.854516: step 3037, loss 0.018405, acc 1\n",
      "2018-04-13T15:12:24.182749: step 3038, loss 0.00548959, acc 1\n",
      "2018-04-13T15:12:24.512481: step 3039, loss 0.0599649, acc 0.984375\n",
      "2018-04-13T15:12:24.832707: step 3040, loss 0.0139922, acc 1\n",
      "2018-04-13T15:12:25.151432: step 3041, loss 0.00692394, acc 1\n",
      "2018-04-13T15:12:25.508186: step 3042, loss 0.00608558, acc 1\n",
      "2018-04-13T15:12:25.834414: step 3043, loss 0.0220891, acc 0.984375\n",
      "2018-04-13T15:12:26.159143: step 3044, loss 0.0241692, acc 0.984375\n",
      "2018-04-13T15:12:26.476408: step 3045, loss 0.0148897, acc 0.984375\n",
      "2018-04-13T15:12:26.804139: step 3046, loss 0.0206793, acc 0.984375\n",
      "2018-04-13T15:12:27.131870: step 3047, loss 0.0126525, acc 1\n",
      "2018-04-13T15:12:27.448594: step 3048, loss 0.00722376, acc 1\n",
      "2018-04-13T15:12:27.772823: step 3049, loss 0.0183413, acc 1\n",
      "2018-04-13T15:12:28.105557: step 3050, loss 0.0147388, acc 1\n",
      "2018-04-13T15:12:28.427785: step 3051, loss 0.00274875, acc 1\n",
      "2018-04-13T15:12:28.747011: step 3052, loss 0.0646298, acc 0.984375\n",
      "2018-04-13T15:12:29.060732: step 3053, loss 0.00709357, acc 1\n",
      "2018-04-13T15:12:29.374953: step 3054, loss 0.00341436, acc 1\n",
      "2018-04-13T15:12:29.712192: step 3055, loss 0.0079247, acc 1\n",
      "2018-04-13T15:12:30.035421: step 3056, loss 0.00783402, acc 1\n",
      "2018-04-13T15:12:30.354146: step 3057, loss 0.0237514, acc 0.984375\n",
      "2018-04-13T15:12:30.665364: step 3058, loss 0.0435595, acc 0.96875\n",
      "2018-04-13T15:12:30.985591: step 3059, loss 0.00720426, acc 1\n",
      "2018-04-13T15:12:31.308820: step 3060, loss 0.0108495, acc 1\n",
      "2018-04-13T15:12:31.656565: step 3061, loss 0.00406633, acc 1\n",
      "2018-04-13T15:12:31.985801: step 3062, loss 0.0255985, acc 1\n",
      "2018-04-13T15:12:32.308025: step 3063, loss 0.0160155, acc 0.984375\n",
      "2018-04-13T15:12:32.623248: step 3064, loss 0.00177736, acc 1\n",
      "2018-04-13T15:12:32.945975: step 3065, loss 0.0141073, acc 1\n",
      "2018-04-13T15:12:33.271705: step 3066, loss 0.00649582, acc 1\n",
      "2018-04-13T15:12:33.585927: step 3067, loss 0.00600018, acc 1\n",
      "2018-04-13T15:12:33.911657: step 3068, loss 0.0056285, acc 1\n",
      "2018-04-13T15:12:34.228381: step 3069, loss 0.00691713, acc 1\n",
      "2018-04-13T15:12:34.572624: step 3070, loss 0.00567349, acc 1\n",
      "2018-04-13T15:12:34.902357: step 3071, loss 0.00946116, acc 1\n",
      "2018-04-13T15:12:35.225584: step 3072, loss 0.00848719, acc 1\n",
      "2018-04-13T15:12:35.538806: step 3073, loss 0.122536, acc 0.96875\n",
      "2018-04-13T15:12:35.862537: step 3074, loss 0.0237671, acc 0.984375\n",
      "2018-04-13T15:12:36.183261: step 3075, loss 0.00335426, acc 1\n",
      "2018-04-13T15:12:36.500485: step 3076, loss 0.0218331, acc 1\n",
      "2018-04-13T15:12:36.825714: step 3077, loss 0.0014657, acc 1\n",
      "2018-04-13T15:12:37.145440: step 3078, loss 0.0327975, acc 0.984375\n",
      "2018-04-13T15:12:37.468168: step 3079, loss 0.00327935, acc 1\n",
      "2018-04-13T15:12:37.804406: step 3080, loss 0.017218, acc 0.984375\n",
      "2018-04-13T15:12:38.120629: step 3081, loss 0.0136237, acc 1\n",
      "2018-04-13T15:12:38.435852: step 3082, loss 0.00894411, acc 1\n",
      "2018-04-13T15:12:38.768086: step 3083, loss 0.00326986, acc 1\n",
      "2018-04-13T15:12:39.091815: step 3084, loss 0.00347478, acc 1\n",
      "2018-04-13T15:12:39.410541: step 3085, loss 0.00869983, acc 1\n",
      "2018-04-13T15:12:39.743275: step 3086, loss 0.0486254, acc 0.984375\n",
      "2018-04-13T15:12:40.069506: step 3087, loss 0.0331206, acc 0.984375\n",
      "2018-04-13T15:12:40.404742: step 3088, loss 0.00383316, acc 1\n",
      "2018-04-13T15:12:40.744481: step 3089, loss 0.0361751, acc 0.96875\n",
      "2018-04-13T15:12:41.069212: step 3090, loss 0.0130901, acc 1\n",
      "2018-04-13T15:12:41.402947: step 3091, loss 0.00397255, acc 1\n",
      "2018-04-13T15:12:41.717669: step 3092, loss 0.00333754, acc 1\n",
      "2018-04-13T15:12:42.085429: step 3093, loss 0.0108792, acc 1\n",
      "2018-04-13T15:12:42.500222: step 3094, loss 0.00848886, acc 1\n",
      "2018-04-13T15:12:42.872985: step 3095, loss 0.0132464, acc 1\n",
      "2018-04-13T15:12:43.230738: step 3096, loss 0.00892309, acc 1\n",
      "2018-04-13T15:12:43.680555: step 3097, loss 0.0161424, acc 1\n",
      "2018-04-13T15:12:44.025298: step 3098, loss 0.00792583, acc 1\n",
      "2018-04-13T15:12:44.408069: step 3099, loss 0.0149025, acc 1\n",
      "2018-04-13T15:12:44.755815: step 3100, loss 0.00927762, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:12:45.966169: step 3100, loss 0.989971, acc 0.749531\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3100\n",
      "\n",
      "2018-04-13T15:12:47.654653: step 3101, loss 0.00140014, acc 1\n",
      "2018-04-13T15:12:48.013906: step 3102, loss 0.00987068, acc 1\n",
      "2018-04-13T15:12:48.399179: step 3103, loss 0.0322524, acc 0.984375\n",
      "2018-04-13T15:12:48.744923: step 3104, loss 0.0087628, acc 1\n",
      "2018-04-13T15:12:49.061146: step 3105, loss 0.00576051, acc 1\n",
      "2018-04-13T15:12:49.392380: step 3106, loss 0.00806414, acc 1\n",
      "2018-04-13T15:12:49.753135: step 3107, loss 0.0429433, acc 0.984375\n",
      "2018-04-13T15:12:50.078364: step 3108, loss 0.0290495, acc 0.984375\n",
      "2018-04-13T15:12:50.405595: step 3109, loss 0.0216373, acc 1\n",
      "2018-04-13T15:12:50.722820: step 3110, loss 0.00184366, acc 1\n",
      "2018-04-13T15:12:51.032038: step 3111, loss 0.0109855, acc 1\n",
      "2018-04-13T15:12:51.367774: step 3112, loss 0.00188869, acc 1\n",
      "2018-04-13T15:12:51.676994: step 3113, loss 0.00654684, acc 1\n",
      "2018-04-13T15:12:52.004724: step 3114, loss 0.0226916, acc 0.984375\n",
      "2018-04-13T15:12:52.317946: step 3115, loss 0.00726154, acc 1\n",
      "2018-04-13T15:12:52.666692: step 3116, loss 0.0232767, acc 0.984375\n",
      "2018-04-13T15:12:52.994926: step 3117, loss 0.0131051, acc 1\n",
      "2018-04-13T15:12:53.308145: step 3118, loss 0.00935652, acc 1\n",
      "2018-04-13T15:12:53.616363: step 3119, loss 0.0125302, acc 1\n",
      "2018-04-13T15:12:53.941092: step 3120, loss 0.0116814, acc 1\n",
      "2018-04-13T15:12:54.278329: step 3121, loss 0.00616759, acc 1\n",
      "2018-04-13T15:12:54.605560: step 3122, loss 0.00778664, acc 1\n",
      "2018-04-13T15:12:54.944300: step 3123, loss 0.013968, acc 1\n",
      "2018-04-13T15:12:55.258022: step 3124, loss 0.00467677, acc 1\n",
      "2018-04-13T15:12:55.605267: step 3125, loss 0.0184929, acc 0.984375\n",
      "2018-04-13T15:12:55.942004: step 3126, loss 0.0133518, acc 0.984375\n",
      "2018-04-13T15:12:56.262731: step 3127, loss 0.0107507, acc 1\n",
      "2018-04-13T15:12:56.591965: step 3128, loss 0.0352809, acc 0.984375\n",
      "2018-04-13T15:12:56.921697: step 3129, loss 0.0142541, acc 1\n",
      "2018-04-13T15:12:57.251429: step 3130, loss 0.00819531, acc 1\n",
      "2018-04-13T15:12:57.574657: step 3131, loss 0.0062612, acc 1\n",
      "2018-04-13T15:12:57.903389: step 3132, loss 0.0216874, acc 1\n",
      "2018-04-13T15:12:58.226618: step 3133, loss 0.00354471, acc 1\n",
      "2018-04-13T15:12:58.587383: step 3134, loss 0.00470784, acc 1\n",
      "2018-04-13T15:12:58.931126: step 3135, loss 0.0131944, acc 1\n",
      "2018-04-13T15:12:59.249852: step 3136, loss 0.0172987, acc 1\n",
      "2018-04-13T15:12:59.578095: step 3137, loss 0.0086458, acc 1\n",
      "2018-04-13T15:12:59.900823: step 3138, loss 0.0113744, acc 1\n",
      "2018-04-13T15:13:00.240562: step 3139, loss 0.0203793, acc 0.984375\n",
      "2018-04-13T15:13:00.559288: step 3140, loss 0.0128568, acc 1\n",
      "2018-04-13T15:13:00.876011: step 3141, loss 0.00181002, acc 1\n",
      "2018-04-13T15:13:01.198739: step 3142, loss 0.00872036, acc 1\n",
      "2018-04-13T15:13:01.524970: step 3143, loss 0.00821215, acc 1\n",
      "2018-04-13T15:13:01.868212: step 3144, loss 0.029728, acc 0.984375\n",
      "2018-04-13T15:13:02.198445: step 3145, loss 0.0549329, acc 0.984375\n",
      "2018-04-13T15:13:02.515168: step 3146, loss 0.0254382, acc 0.984375\n",
      "2018-04-13T15:13:02.845903: step 3147, loss 0.0123825, acc 1\n",
      "2018-04-13T15:13:03.179638: step 3148, loss 0.00825152, acc 1\n",
      "2018-04-13T15:13:03.509371: step 3149, loss 0.0407483, acc 0.96875\n",
      "2018-04-13T15:13:03.828096: step 3150, loss 0.0124148, acc 1\n",
      "2018-04-13T15:13:04.148322: step 3151, loss 0.0114727, acc 1\n",
      "2018-04-13T15:13:04.477554: step 3152, loss 0.0135068, acc 1\n",
      "2018-04-13T15:13:04.833305: step 3153, loss 0.00562395, acc 1\n",
      "2018-04-13T15:13:05.165541: step 3154, loss 0.0257634, acc 1\n",
      "2018-04-13T15:13:05.483265: step 3155, loss 0.00478569, acc 1\n",
      "2018-04-13T15:13:05.807997: step 3156, loss 0.00848907, acc 1\n",
      "2018-04-13T15:13:06.133724: step 3157, loss 0.00907086, acc 1\n",
      "2018-04-13T15:13:06.463957: step 3158, loss 0.106355, acc 0.984375\n",
      "2018-04-13T15:13:06.779679: step 3159, loss 0.00811446, acc 1\n",
      "2018-04-13T15:13:07.106410: step 3160, loss 0.00389717, acc 1\n",
      "2018-04-13T15:13:07.427638: step 3161, loss 0.0149484, acc 1\n",
      "2018-04-13T15:13:07.776884: step 3162, loss 0.0408118, acc 0.96875\n",
      "2018-04-13T15:13:08.108619: step 3163, loss 0.00508457, acc 1\n",
      "2018-04-13T15:13:08.428344: step 3164, loss 0.00588151, acc 1\n",
      "2018-04-13T15:13:08.750572: step 3165, loss 0.0155343, acc 0.984375\n",
      "2018-04-13T15:13:09.071798: step 3166, loss 0.0181115, acc 1\n",
      "2018-04-13T15:13:09.397529: step 3167, loss 0.0336238, acc 0.96875\n",
      "2018-04-13T15:13:09.731765: step 3168, loss 0.00588672, acc 1\n",
      "2018-04-13T15:13:10.043485: step 3169, loss 0.00227943, acc 1\n",
      "2018-04-13T15:13:10.358707: step 3170, loss 0.00404102, acc 1\n",
      "2018-04-13T15:13:10.722464: step 3171, loss 0.00595522, acc 1\n",
      "2018-04-13T15:13:11.046220: step 3172, loss 0.00613323, acc 1\n",
      "2018-04-13T15:13:11.356413: step 3173, loss 0.024802, acc 0.984375\n",
      "2018-04-13T15:13:11.691648: step 3174, loss 0.00977267, acc 1\n",
      "2018-04-13T15:13:12.019380: step 3175, loss 0.00320659, acc 1\n",
      "2018-04-13T15:13:12.349613: step 3176, loss 0.0118953, acc 1\n",
      "2018-04-13T15:13:12.662834: step 3177, loss 0.0147455, acc 1\n",
      "2018-04-13T15:13:12.983061: step 3178, loss 0.0288906, acc 0.984375\n",
      "2018-04-13T15:13:13.317296: step 3179, loss 0.012638, acc 1\n",
      "2018-04-13T15:13:13.660040: step 3180, loss 0.00588464, acc 1\n",
      "2018-04-13T15:13:13.981767: step 3181, loss 0.00601743, acc 1\n",
      "2018-04-13T15:13:14.319003: step 3182, loss 0.0116787, acc 1\n",
      "2018-04-13T15:13:14.649237: step 3183, loss 0.0182789, acc 1\n",
      "2018-04-13T15:13:14.972986: step 3184, loss 0.00140145, acc 1\n",
      "2018-04-13T15:13:15.304220: step 3185, loss 0.00256454, acc 1\n",
      "2018-04-13T15:13:15.621944: step 3186, loss 0.00652938, acc 1\n",
      "2018-04-13T15:13:15.943178: step 3187, loss 0.00872933, acc 1\n",
      "2018-04-13T15:13:16.258895: step 3188, loss 0.00422237, acc 1\n",
      "2018-04-13T15:13:16.590137: step 3189, loss 0.0120413, acc 1\n",
      "2018-04-13T15:13:16.930876: step 3190, loss 0.00588043, acc 1\n",
      "2018-04-13T15:13:17.240095: step 3191, loss 0.0129938, acc 1\n",
      "2018-04-13T15:13:17.564323: step 3192, loss 0.010919, acc 1\n",
      "2018-04-13T15:13:17.884550: step 3193, loss 0.0106168, acc 1\n",
      "2018-04-13T15:13:18.211280: step 3194, loss 0.0167005, acc 1\n",
      "2018-04-13T15:13:18.545517: step 3195, loss 0.0420076, acc 0.984375\n",
      "2018-04-13T15:13:18.868745: step 3196, loss 0.0023796, acc 1\n",
      "2018-04-13T15:13:19.173960: step 3197, loss 0.00226855, acc 1\n",
      "2018-04-13T15:13:19.494186: step 3198, loss 0.00252607, acc 1\n",
      "2018-04-13T15:13:19.832925: step 3199, loss 0.05304, acc 0.96875\n",
      "2018-04-13T15:13:20.161658: step 3200, loss 0.0227961, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:13:21.296959: step 3200, loss 1.02344, acc 0.751407\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3200\n",
      "\n",
      "2018-04-13T15:13:23.037243: step 3201, loss 0.0025823, acc 1\n",
      "2018-04-13T15:13:23.352472: step 3202, loss 0.00732992, acc 1\n",
      "2018-04-13T15:13:23.669696: step 3203, loss 0.0624749, acc 0.984375\n",
      "2018-04-13T15:13:23.995426: step 3204, loss 0.00137117, acc 1\n",
      "2018-04-13T15:13:24.310649: step 3205, loss 0.0230516, acc 0.984375\n",
      "2018-04-13T15:13:24.632879: step 3206, loss 0.010119, acc 1\n",
      "2018-04-13T15:13:24.963609: step 3207, loss 0.0262517, acc 0.984375\n",
      "2018-04-13T15:13:25.291341: step 3208, loss 0.0224497, acc 1\n",
      "2018-04-13T15:13:25.619573: step 3209, loss 0.0172072, acc 1\n",
      "2018-04-13T15:13:25.957311: step 3210, loss 0.00435901, acc 1\n",
      "2018-04-13T15:13:26.274535: step 3211, loss 0.00116984, acc 1\n",
      "2018-04-13T15:13:26.590259: step 3212, loss 0.0136815, acc 1\n",
      "2018-04-13T15:13:26.918490: step 3213, loss 0.0109444, acc 1\n",
      "2018-04-13T15:13:27.234713: step 3214, loss 0.00854344, acc 1\n",
      "2018-04-13T15:13:27.558942: step 3215, loss 0.00448681, acc 1\n",
      "2018-04-13T15:13:27.890676: step 3216, loss 0.0106598, acc 1\n",
      "2018-04-13T15:13:28.211403: step 3217, loss 0.00170405, acc 1\n",
      "2018-04-13T15:13:28.537133: step 3218, loss 0.0015158, acc 1\n",
      "2018-04-13T15:13:28.882877: step 3219, loss 0.0156778, acc 1\n",
      "2018-04-13T15:13:29.202603: step 3220, loss 0.00798573, acc 1\n",
      "2018-04-13T15:13:29.519326: step 3221, loss 0.00551398, acc 1\n",
      "2018-04-13T15:13:29.846057: step 3222, loss 0.00359086, acc 1\n",
      "2018-04-13T15:13:30.159780: step 3223, loss 0.00715358, acc 1\n",
      "2018-04-13T15:13:30.494516: step 3224, loss 0.00587692, acc 1\n",
      "2018-04-13T15:13:30.817243: step 3225, loss 0.00999333, acc 1\n",
      "2018-04-13T15:13:31.134467: step 3226, loss 0.00810377, acc 1\n",
      "2018-04-13T15:13:31.468704: step 3227, loss 0.0111101, acc 1\n",
      "2018-04-13T15:13:31.815948: step 3228, loss 0.00961986, acc 1\n",
      "2018-04-13T15:13:32.145181: step 3229, loss 0.013194, acc 1\n",
      "2018-04-13T15:13:32.468417: step 3230, loss 0.0130301, acc 1\n",
      "2018-04-13T15:13:32.818656: step 3231, loss 0.0083608, acc 1\n",
      "2018-04-13T15:13:33.141385: step 3232, loss 0.00189069, acc 1\n",
      "2018-04-13T15:13:33.464112: step 3233, loss 0.00638003, acc 1\n",
      "2018-04-13T15:13:33.785839: step 3234, loss 0.0130919, acc 1\n",
      "2018-04-13T15:13:34.104564: step 3235, loss 0.0071116, acc 1\n",
      "2018-04-13T15:13:34.424790: step 3236, loss 0.010494, acc 1\n",
      "2018-04-13T15:13:34.772036: step 3237, loss 0.0201511, acc 1\n",
      "2018-04-13T15:13:35.089760: step 3238, loss 0.00213204, acc 1\n",
      "2018-04-13T15:13:35.402982: step 3239, loss 0.0136469, acc 1\n",
      "2018-04-13T15:13:35.716702: step 3240, loss 0.00378747, acc 1\n",
      "2018-04-13T15:13:36.056942: step 3241, loss 0.0100888, acc 1\n",
      "2018-04-13T15:13:36.381673: step 3242, loss 0.0135638, acc 1\n",
      "2018-04-13T15:13:36.696895: step 3243, loss 0.00737208, acc 1\n",
      "2018-04-13T15:13:37.010616: step 3244, loss 0.00738709, acc 1\n",
      "2018-04-13T15:13:37.322842: step 3245, loss 0.0719642, acc 0.96875\n",
      "2018-04-13T15:13:37.665078: step 3246, loss 0.00988886, acc 1\n",
      "2018-04-13T15:13:37.988807: step 3247, loss 0.00261733, acc 1\n",
      "2018-04-13T15:13:38.306532: step 3248, loss 0.00358099, acc 1\n",
      "2018-04-13T15:13:38.639266: step 3249, loss 0.0234409, acc 0.984375\n",
      "2018-04-13T15:13:38.975003: step 3250, loss 0.0052969, acc 1\n",
      "2018-04-13T15:13:39.303235: step 3251, loss 0.0351451, acc 0.984375\n",
      "2018-04-13T15:13:39.626964: step 3252, loss 0.0106785, acc 1\n",
      "2018-04-13T15:13:39.949192: step 3253, loss 0.0023597, acc 1\n",
      "2018-04-13T15:13:40.270418: step 3254, loss 0.00919177, acc 1\n",
      "2018-04-13T15:13:40.591145: step 3255, loss 0.00778865, acc 1\n",
      "2018-04-13T15:13:40.936388: step 3256, loss 0.00216951, acc 1\n",
      "2018-04-13T15:13:41.248609: step 3257, loss 0.00290224, acc 1\n",
      "2018-04-13T15:13:41.560329: step 3258, loss 0.0250719, acc 1\n",
      "2018-04-13T15:13:41.894565: step 3259, loss 0.00689633, acc 1\n",
      "2018-04-13T15:13:42.226800: step 3260, loss 0.00822871, acc 1\n",
      "2018-04-13T15:13:42.555031: step 3261, loss 0.00914016, acc 1\n",
      "2018-04-13T15:13:42.881262: step 3262, loss 0.00788881, acc 1\n",
      "2018-04-13T15:13:43.198986: step 3263, loss 0.00747568, acc 1\n",
      "2018-04-13T15:13:43.514209: step 3264, loss 0.00736073, acc 1\n",
      "2018-04-13T15:13:43.880472: step 3265, loss 0.0233514, acc 1\n",
      "2018-04-13T15:13:44.207698: step 3266, loss 0.0865698, acc 0.984375\n",
      "2018-04-13T15:13:44.518918: step 3267, loss 0.0042087, acc 1\n",
      "2018-04-13T15:13:44.832139: step 3268, loss 0.0279271, acc 0.984375\n",
      "2018-04-13T15:13:45.171882: step 3269, loss 0.0477653, acc 0.96875\n",
      "2018-04-13T15:13:45.572760: step 3270, loss 0.00627151, acc 1\n",
      "2018-04-13T15:13:45.925510: step 3271, loss 0.0074136, acc 1\n",
      "2018-04-13T15:13:46.252740: step 3272, loss 0.00349242, acc 1\n",
      "2018-04-13T15:13:46.574467: step 3273, loss 0.059563, acc 0.984375\n",
      "2018-04-13T15:13:46.928218: step 3274, loss 0.0360754, acc 0.984375\n",
      "2018-04-13T15:13:47.249944: step 3275, loss 0.025685, acc 0.984375\n",
      "2018-04-13T15:13:47.575174: step 3276, loss 0.0028258, acc 1\n",
      "2018-04-13T15:13:47.890897: step 3277, loss 0.0117328, acc 1\n",
      "2018-04-13T15:13:48.226134: step 3278, loss 0.00661113, acc 1\n",
      "2018-04-13T15:13:48.552864: step 3279, loss 0.00603959, acc 1\n",
      "2018-04-13T15:13:48.870089: step 3280, loss 0.0345424, acc 0.984375\n",
      "2018-04-13T15:13:49.191316: step 3281, loss 0.0138384, acc 1\n",
      "2018-04-13T15:13:49.504536: step 3282, loss 0.00949941, acc 1\n",
      "2018-04-13T15:13:49.872797: step 3283, loss 0.00178029, acc 1\n",
      "2018-04-13T15:13:50.211535: step 3284, loss 0.00455476, acc 1\n",
      "2018-04-13T15:13:50.526258: step 3285, loss 0.0030547, acc 1\n",
      "2018-04-13T15:13:50.850987: step 3286, loss 0.00416151, acc 1\n",
      "2018-04-13T15:13:51.183222: step 3287, loss 0.00412212, acc 1\n",
      "2018-04-13T15:13:51.515457: step 3288, loss 0.0113083, acc 1\n",
      "2018-04-13T15:13:51.838185: step 3289, loss 0.00608171, acc 1\n",
      "2018-04-13T15:13:52.158911: step 3290, loss 0.00776561, acc 1\n",
      "2018-04-13T15:13:52.473633: step 3291, loss 0.0087136, acc 1\n",
      "2018-04-13T15:13:52.840392: step 3292, loss 0.00370783, acc 1\n",
      "2018-04-13T15:13:53.169124: step 3293, loss 0.0193764, acc 0.984375\n",
      "2018-04-13T15:13:53.492852: step 3294, loss 0.019892, acc 1\n",
      "2018-04-13T15:13:53.802572: step 3295, loss 0.0111071, acc 1\n",
      "2018-04-13T15:13:54.131304: step 3296, loss 0.00506867, acc 1\n",
      "2018-04-13T15:13:54.457534: step 3297, loss 0.0169208, acc 0.984375\n",
      "2018-04-13T15:13:54.774257: step 3298, loss 0.0309294, acc 0.984375\n",
      "2018-04-13T15:13:55.104991: step 3299, loss 0.00584468, acc 1\n",
      "2018-04-13T15:13:55.395696: step 3300, loss 0.00766688, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:13:56.576030: step 3300, loss 1.05099, acc 0.741088\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3300\n",
      "\n",
      "2018-04-13T15:13:58.182497: step 3301, loss 0.00383411, acc 1\n",
      "2018-04-13T15:13:58.505225: step 3302, loss 0.00672718, acc 1\n",
      "2018-04-13T15:13:58.866480: step 3303, loss 0.0231481, acc 0.984375\n",
      "2018-04-13T15:13:59.184205: step 3304, loss 0.0128953, acc 1\n",
      "2018-04-13T15:13:59.494924: step 3305, loss 0.00806513, acc 1\n",
      "2018-04-13T15:13:59.812648: step 3306, loss 0.00826814, acc 1\n",
      "2018-04-13T15:14:00.136877: step 3307, loss 0.0145897, acc 1\n",
      "2018-04-13T15:14:00.474616: step 3308, loss 0.0072631, acc 1\n",
      "2018-04-13T15:14:00.799845: step 3309, loss 0.00261354, acc 1\n",
      "2018-04-13T15:14:01.134581: step 3310, loss 0.00461995, acc 1\n",
      "2018-04-13T15:14:01.461313: step 3311, loss 0.00200516, acc 1\n",
      "2018-04-13T15:14:01.812561: step 3312, loss 0.0213417, acc 1\n",
      "2018-04-13T15:14:02.145295: step 3313, loss 0.0118289, acc 1\n",
      "2018-04-13T15:14:02.459017: step 3314, loss 0.00455561, acc 1\n",
      "2018-04-13T15:14:02.781245: step 3315, loss 0.0203637, acc 0.984375\n",
      "2018-04-13T15:14:03.094466: step 3316, loss 0.0140922, acc 1\n",
      "2018-04-13T15:14:03.415692: step 3317, loss 0.00598086, acc 1\n",
      "2018-04-13T15:14:03.730414: step 3318, loss 0.0312586, acc 0.984375\n",
      "2018-04-13T15:14:04.065150: step 3319, loss 0.00394051, acc 1\n",
      "2018-04-13T15:14:04.391381: step 3320, loss 0.00336314, acc 1\n",
      "2018-04-13T15:14:04.727118: step 3321, loss 0.0019346, acc 1\n",
      "2018-04-13T15:14:05.068359: step 3322, loss 0.029277, acc 0.984375\n",
      "2018-04-13T15:14:05.380080: step 3323, loss 0.0109816, acc 1\n",
      "2018-04-13T15:14:05.700806: step 3324, loss 0.00536166, acc 1\n",
      "2018-04-13T15:14:06.020031: step 3325, loss 0.0316425, acc 0.96875\n",
      "2018-04-13T15:14:06.342259: step 3326, loss 0.00370904, acc 1\n",
      "2018-04-13T15:14:06.663986: step 3327, loss 0.0140457, acc 1\n",
      "2018-04-13T15:14:07.014734: step 3328, loss 0.0190203, acc 1\n",
      "2018-04-13T15:14:07.336461: step 3329, loss 0.00924434, acc 1\n",
      "2018-04-13T15:14:07.666194: step 3330, loss 0.00274219, acc 1\n",
      "2018-04-13T15:14:08.006434: step 3331, loss 0.00984903, acc 1\n",
      "2018-04-13T15:14:08.321156: step 3332, loss 0.00582571, acc 1\n",
      "2018-04-13T15:14:08.635378: step 3333, loss 0.00372437, acc 1\n",
      "2018-04-13T15:14:08.980621: step 3334, loss 0.00297106, acc 1\n",
      "2018-04-13T15:14:09.291341: step 3335, loss 0.0025103, acc 1\n",
      "2018-04-13T15:14:09.616071: step 3336, loss 0.00393587, acc 1\n",
      "2018-04-13T15:14:09.946804: step 3337, loss 0.00241481, acc 1\n",
      "2018-04-13T15:14:10.275536: step 3338, loss 0.00254651, acc 1\n",
      "2018-04-13T15:14:10.589758: step 3339, loss 0.0127833, acc 1\n",
      "2018-04-13T15:14:10.943008: step 3340, loss 0.00783046, acc 1\n",
      "2018-04-13T15:14:11.257229: step 3341, loss 0.00755499, acc 1\n",
      "2018-04-13T15:14:11.571452: step 3342, loss 0.0143895, acc 1\n",
      "2018-04-13T15:14:11.896189: step 3343, loss 0.00530983, acc 1\n",
      "2018-04-13T15:14:12.213413: step 3344, loss 0.0145294, acc 1\n",
      "2018-04-13T15:14:12.537642: step 3345, loss 0.00510844, acc 1\n",
      "2018-04-13T15:14:12.867875: step 3346, loss 0.0128596, acc 0.984375\n",
      "2018-04-13T15:14:13.187100: step 3347, loss 0.0142686, acc 1\n",
      "2018-04-13T15:14:13.513331: step 3348, loss 0.00354274, acc 1\n",
      "2018-04-13T15:14:13.848568: step 3349, loss 0.0105723, acc 1\n",
      "2018-04-13T15:14:14.168293: step 3350, loss 0.00265735, acc 1\n",
      "2018-04-13T15:14:14.485017: step 3351, loss 0.00198315, acc 1\n",
      "2018-04-13T15:14:14.814249: step 3352, loss 0.0207239, acc 1\n",
      "2018-04-13T15:14:15.134976: step 3353, loss 0.00321115, acc 1\n",
      "2018-04-13T15:14:15.467211: step 3354, loss 0.00651124, acc 1\n",
      "2018-04-13T15:14:15.798944: step 3355, loss 0.00239929, acc 1\n",
      "2018-04-13T15:14:16.133181: step 3356, loss 0.0459448, acc 0.984375\n",
      "2018-04-13T15:14:16.444901: step 3357, loss 0.0311091, acc 0.984375\n",
      "2018-04-13T15:14:16.798150: step 3358, loss 0.00786288, acc 1\n",
      "2018-04-13T15:14:17.132886: step 3359, loss 0.0057534, acc 1\n",
      "2018-04-13T15:14:17.450612: step 3360, loss 0.00594162, acc 1\n",
      "2018-04-13T15:14:17.786348: step 3361, loss 0.00745444, acc 1\n",
      "2018-04-13T15:14:18.117082: step 3362, loss 0.00728193, acc 1\n",
      "2018-04-13T15:14:18.455321: step 3363, loss 0.0055184, acc 1\n",
      "2018-04-13T15:14:18.775046: step 3364, loss 0.00435693, acc 1\n",
      "2018-04-13T15:14:19.093271: step 3365, loss 0.00440453, acc 1\n",
      "2018-04-13T15:14:19.405992: step 3366, loss 0.00283356, acc 1\n",
      "2018-04-13T15:14:19.732722: step 3367, loss 0.00803143, acc 1\n",
      "2018-04-13T15:14:20.071962: step 3368, loss 0.00202797, acc 1\n",
      "2018-04-13T15:14:20.399693: step 3369, loss 0.00816233, acc 1\n",
      "2018-04-13T15:14:20.723422: step 3370, loss 0.00967939, acc 1\n",
      "2018-04-13T15:14:21.046650: step 3371, loss 0.00960518, acc 1\n",
      "2018-04-13T15:14:21.372881: step 3372, loss 0.0167302, acc 1\n",
      "2018-04-13T15:14:21.700112: step 3373, loss 0.0114675, acc 1\n",
      "2018-04-13T15:14:22.026342: step 3374, loss 0.00933556, acc 1\n",
      "2018-04-13T15:14:22.345067: step 3375, loss 0.0284522, acc 0.984375\n",
      "2018-04-13T15:14:22.709826: step 3376, loss 0.00814222, acc 1\n",
      "2018-04-13T15:14:23.068078: step 3377, loss 0.0147356, acc 1\n",
      "2018-04-13T15:14:23.393808: step 3378, loss 0.00570314, acc 1\n",
      "2018-04-13T15:14:23.721539: step 3379, loss 0.00440609, acc 1\n",
      "2018-04-13T15:14:24.043766: step 3380, loss 0.00945379, acc 1\n",
      "2018-04-13T15:14:24.372499: step 3381, loss 0.00256574, acc 1\n",
      "2018-04-13T15:14:24.707235: step 3382, loss 0.00783297, acc 1\n",
      "2018-04-13T15:14:25.012451: step 3383, loss 0.0125834, acc 1\n",
      "2018-04-13T15:14:25.334178: step 3384, loss 0.00599656, acc 1\n",
      "2018-04-13T15:14:25.681923: step 3385, loss 0.0457323, acc 0.984375\n",
      "2018-04-13T15:14:26.022664: step 3386, loss 0.00693287, acc 1\n",
      "2018-04-13T15:14:26.342890: step 3387, loss 0.0339876, acc 0.984375\n",
      "2018-04-13T15:14:26.674624: step 3388, loss 0.0136848, acc 1\n",
      "2018-04-13T15:14:26.990848: step 3389, loss 0.0744148, acc 0.984375\n",
      "2018-04-13T15:14:27.303569: step 3390, loss 0.00488147, acc 1\n",
      "2018-04-13T15:14:27.637304: step 3391, loss 0.0325852, acc 0.984375\n",
      "2018-04-13T15:14:27.967037: step 3392, loss 0.00426333, acc 1\n",
      "2018-04-13T15:14:28.282259: step 3393, loss 0.00379549, acc 1\n",
      "2018-04-13T15:14:28.608990: step 3394, loss 0.0114479, acc 1\n",
      "2018-04-13T15:14:28.975749: step 3395, loss 0.00548126, acc 1\n",
      "2018-04-13T15:14:29.295976: step 3396, loss 0.00808145, acc 1\n",
      "2018-04-13T15:14:29.628212: step 3397, loss 0.0258768, acc 0.984375\n",
      "2018-04-13T15:14:29.957442: step 3398, loss 0.00460313, acc 1\n",
      "2018-04-13T15:14:30.264659: step 3399, loss 0.0165882, acc 1\n",
      "2018-04-13T15:14:30.592892: step 3400, loss 0.00366076, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:14:31.757214: step 3400, loss 1.06026, acc 0.742026\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3400\n",
      "\n",
      "2018-04-13T15:14:33.509988: step 3401, loss 0.00620037, acc 1\n",
      "2018-04-13T15:14:33.834718: step 3402, loss 0.0095898, acc 1\n",
      "2018-04-13T15:14:34.158446: step 3403, loss 0.00399167, acc 1\n",
      "2018-04-13T15:14:34.486178: step 3404, loss 0.00370202, acc 1\n",
      "2018-04-13T15:14:34.826918: step 3405, loss 0.0042129, acc 1\n",
      "2018-04-13T15:14:35.151648: step 3406, loss 0.00466934, acc 1\n",
      "2018-04-13T15:14:35.480880: step 3407, loss 0.00143714, acc 1\n",
      "2018-04-13T15:14:35.807611: step 3408, loss 0.00830297, acc 1\n",
      "2018-04-13T15:14:36.116342: step 3409, loss 0.00718308, acc 1\n",
      "2018-04-13T15:14:36.460085: step 3410, loss 0.0113229, acc 1\n",
      "2018-04-13T15:14:36.789317: step 3411, loss 0.0356402, acc 0.984375\n",
      "2018-04-13T15:14:37.100537: step 3412, loss 0.00190787, acc 1\n",
      "2018-04-13T15:14:37.425266: step 3413, loss 0.00350721, acc 1\n",
      "2018-04-13T15:14:37.752498: step 3414, loss 0.00716367, acc 1\n",
      "2018-04-13T15:14:38.083732: step 3415, loss 0.00185637, acc 1\n",
      "2018-04-13T15:14:38.414965: step 3416, loss 0.00209596, acc 1\n",
      "2018-04-13T15:14:38.741195: step 3417, loss 0.0171191, acc 1\n",
      "2018-04-13T15:14:39.072429: step 3418, loss 0.0115769, acc 1\n",
      "2018-04-13T15:14:39.398160: step 3419, loss 0.0354438, acc 0.984375\n",
      "2018-04-13T15:14:39.732896: step 3420, loss 0.00422642, acc 1\n",
      "2018-04-13T15:14:40.071135: step 3421, loss 0.00701925, acc 1\n",
      "2018-04-13T15:14:40.392362: step 3422, loss 0.00229669, acc 1\n",
      "2018-04-13T15:14:40.718592: step 3423, loss 0.014023, acc 1\n",
      "2018-04-13T15:14:41.053328: step 3424, loss 0.00866456, acc 1\n",
      "2018-04-13T15:14:41.370052: step 3425, loss 0.0266188, acc 0.984375\n",
      "2018-04-13T15:14:41.695282: step 3426, loss 0.0120079, acc 1\n",
      "2018-04-13T15:14:42.011005: step 3427, loss 0.00540725, acc 1\n",
      "2018-04-13T15:14:42.337235: step 3428, loss 0.00128316, acc 1\n",
      "2018-04-13T15:14:42.674473: step 3429, loss 0.00279143, acc 1\n",
      "2018-04-13T15:14:43.009710: step 3430, loss 0.0122675, acc 1\n",
      "2018-04-13T15:14:43.327434: step 3431, loss 0.0461411, acc 0.96875\n",
      "2018-04-13T15:14:43.651663: step 3432, loss 0.00358681, acc 1\n",
      "2018-04-13T15:14:44.009916: step 3433, loss 0.00689378, acc 1\n",
      "2018-04-13T15:14:44.344653: step 3434, loss 0.00558947, acc 1\n",
      "2018-04-13T15:14:44.673384: step 3435, loss 0.00466375, acc 1\n",
      "2018-04-13T15:14:45.003618: step 3436, loss 0.00980372, acc 1\n",
      "2018-04-13T15:14:45.315339: step 3437, loss 0.00430547, acc 1\n",
      "2018-04-13T15:14:45.645072: step 3438, loss 0.0106412, acc 1\n",
      "2018-04-13T15:14:45.963296: step 3439, loss 0.00677921, acc 1\n",
      "2018-04-13T15:14:46.271513: step 3440, loss 0.0128612, acc 1\n",
      "2018-04-13T15:14:46.598243: step 3441, loss 0.0412945, acc 0.96875\n",
      "2018-04-13T15:14:46.957498: step 3442, loss 0.00188434, acc 1\n",
      "2018-04-13T15:14:47.276223: step 3443, loss 0.0324273, acc 0.984375\n",
      "2018-04-13T15:14:47.601952: step 3444, loss 0.0440587, acc 0.984375\n",
      "2018-04-13T15:14:47.925181: step 3445, loss 0.0143614, acc 1\n",
      "2018-04-13T15:14:48.242905: step 3446, loss 0.0258552, acc 0.984375\n",
      "2018-04-13T15:14:48.662201: step 3447, loss 0.00734765, acc 1\n",
      "2018-04-13T15:14:48.977924: step 3448, loss 0.0439255, acc 0.984375\n",
      "2018-04-13T15:14:49.296149: step 3449, loss 0.0040383, acc 1\n",
      "2018-04-13T15:14:49.607368: step 3450, loss 0.00690099, acc 1\n",
      "2018-04-13T15:14:49.961128: step 3451, loss 0.00996801, acc 1\n",
      "2018-04-13T15:14:50.294854: step 3452, loss 0.00701653, acc 1\n",
      "2018-04-13T15:14:50.620584: step 3453, loss 0.0414489, acc 0.984375\n",
      "2018-04-13T15:14:50.940810: step 3454, loss 0.00778814, acc 1\n",
      "2018-04-13T15:14:51.258034: step 3455, loss 0.0588519, acc 0.984375\n",
      "2018-04-13T15:14:51.587266: step 3456, loss 0.00327769, acc 1\n",
      "2018-04-13T15:14:51.912001: step 3457, loss 0.0108163, acc 1\n",
      "2018-04-13T15:14:52.231221: step 3458, loss 0.000742287, acc 1\n",
      "2018-04-13T15:14:52.551447: step 3459, loss 0.0147411, acc 0.984375\n",
      "2018-04-13T15:14:52.897193: step 3460, loss 0.00288267, acc 1\n",
      "2018-04-13T15:14:53.228425: step 3461, loss 0.00616603, acc 1\n",
      "2018-04-13T15:14:53.555657: step 3462, loss 0.00595392, acc 1\n",
      "2018-04-13T15:14:53.876883: step 3463, loss 0.00215853, acc 1\n",
      "2018-04-13T15:14:54.198110: step 3464, loss 0.00404727, acc 1\n",
      "2018-04-13T15:14:54.522839: step 3465, loss 0.00341629, acc 1\n",
      "2018-04-13T15:14:54.862579: step 3466, loss 0.00663764, acc 1\n",
      "2018-04-13T15:14:55.180804: step 3467, loss 0.0712612, acc 0.984375\n",
      "2018-04-13T15:14:55.525547: step 3468, loss 0.0128768, acc 1\n",
      "2018-04-13T15:14:55.859783: step 3469, loss 0.0145826, acc 0.984375\n",
      "2018-04-13T15:14:56.185514: step 3470, loss 0.00646373, acc 1\n",
      "2018-04-13T15:14:56.508742: step 3471, loss 0.000955239, acc 1\n",
      "2018-04-13T15:14:56.826466: step 3472, loss 0.0149658, acc 0.984375\n",
      "2018-04-13T15:14:57.157700: step 3473, loss 0.000733139, acc 1\n",
      "2018-04-13T15:14:57.483430: step 3474, loss 0.0105347, acc 1\n",
      "2018-04-13T15:14:57.815665: step 3475, loss 0.0168027, acc 0.984375\n",
      "2018-04-13T15:14:58.128386: step 3476, loss 0.00652284, acc 1\n",
      "2018-04-13T15:14:58.447611: step 3477, loss 0.00342444, acc 1\n",
      "2018-04-13T15:14:58.777343: step 3478, loss 0.0140738, acc 1\n",
      "2018-04-13T15:14:59.098070: step 3479, loss 0.00403023, acc 1\n",
      "2018-04-13T15:14:59.441814: step 3480, loss 0.00654657, acc 1\n",
      "2018-04-13T15:14:59.773547: step 3481, loss 0.00375769, acc 1\n",
      "2018-04-13T15:15:00.097775: step 3482, loss 0.00684653, acc 1\n",
      "2018-04-13T15:15:00.417501: step 3483, loss 0.00167179, acc 1\n",
      "2018-04-13T15:15:00.755741: step 3484, loss 0.00220357, acc 1\n",
      "2018-04-13T15:15:01.074465: step 3485, loss 0.000538451, acc 1\n",
      "2018-04-13T15:15:01.411704: step 3486, loss 0.00538557, acc 1\n",
      "2018-04-13T15:15:01.738434: step 3487, loss 0.00884656, acc 1\n",
      "2018-04-13T15:15:02.073671: step 3488, loss 0.0113396, acc 1\n",
      "2018-04-13T15:15:02.389895: step 3489, loss 0.00655405, acc 1\n",
      "2018-04-13T15:15:02.712622: step 3490, loss 0.00269605, acc 1\n",
      "2018-04-13T15:15:03.027845: step 3491, loss 0.0188665, acc 0.984375\n",
      "2018-04-13T15:15:03.339575: step 3492, loss 0.00498585, acc 1\n",
      "2018-04-13T15:15:03.669307: step 3493, loss 0.00223646, acc 1\n",
      "2018-04-13T15:15:03.990034: step 3494, loss 0.00349542, acc 1\n",
      "2018-04-13T15:15:04.309259: step 3495, loss 0.00738618, acc 1\n",
      "2018-04-13T15:15:04.624482: step 3496, loss 0.00641817, acc 1\n",
      "2018-04-13T15:15:04.974228: step 3497, loss 0.00557246, acc 1\n",
      "2018-04-13T15:15:05.285448: step 3498, loss 0.0299567, acc 0.984375\n",
      "2018-04-13T15:15:05.604673: step 3499, loss 0.00349055, acc 1\n",
      "2018-04-13T15:15:05.931404: step 3500, loss 0.00286306, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:15:07.110237: step 3500, loss 1.0926, acc 0.742026\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3500\n",
      "\n",
      "2018-04-13T15:15:08.662107: step 3501, loss 0.0077318, acc 1\n",
      "2018-04-13T15:15:08.974827: step 3502, loss 0.00228731, acc 1\n",
      "2018-04-13T15:15:09.288548: step 3503, loss 0.0112251, acc 1\n",
      "2018-04-13T15:15:09.629289: step 3504, loss 0.00332596, acc 1\n",
      "2018-04-13T15:15:09.941509: step 3505, loss 0.00475439, acc 1\n",
      "2018-04-13T15:15:10.260236: step 3506, loss 0.00518192, acc 1\n",
      "2018-04-13T15:15:10.579460: step 3507, loss 0.00314442, acc 1\n",
      "2018-04-13T15:15:10.911194: step 3508, loss 0.00756897, acc 1\n",
      "2018-04-13T15:15:11.227918: step 3509, loss 0.00738095, acc 1\n",
      "2018-04-13T15:15:11.540638: step 3510, loss 0.0197368, acc 1\n",
      "2018-04-13T15:15:11.865368: step 3511, loss 0.0201532, acc 1\n",
      "2018-04-13T15:15:12.183094: step 3512, loss 0.0112206, acc 1\n",
      "2018-04-13T15:15:12.498816: step 3513, loss 0.00335344, acc 1\n",
      "2018-04-13T15:15:12.839055: step 3514, loss 0.0589005, acc 0.984375\n",
      "2018-04-13T15:15:13.167787: step 3515, loss 0.0148032, acc 0.984375\n",
      "2018-04-13T15:15:13.497521: step 3516, loss 0.00326839, acc 1\n",
      "2018-04-13T15:15:13.840263: step 3517, loss 0.0140639, acc 1\n",
      "2018-04-13T15:15:14.183004: step 3518, loss 0.0492912, acc 0.984375\n",
      "2018-04-13T15:15:14.508233: step 3519, loss 0.0093455, acc 1\n",
      "2018-04-13T15:15:14.834965: step 3520, loss 0.00268621, acc 1\n",
      "2018-04-13T15:15:15.157192: step 3521, loss 0.00143471, acc 1\n",
      "2018-04-13T15:15:15.475917: step 3522, loss 0.00204051, acc 1\n",
      "2018-04-13T15:15:15.822162: step 3523, loss 0.0149577, acc 0.984375\n",
      "2018-04-13T15:15:16.147391: step 3524, loss 0.00174678, acc 1\n",
      "2018-04-13T15:15:16.472120: step 3525, loss 0.00609727, acc 1\n",
      "2018-04-13T15:15:16.819867: step 3526, loss 0.00563296, acc 1\n",
      "2018-04-13T15:15:17.188627: step 3527, loss 0.00616737, acc 1\n",
      "2018-04-13T15:15:17.516358: step 3528, loss 0.00843089, acc 1\n",
      "2018-04-13T15:15:17.847092: step 3529, loss 0.00512443, acc 1\n",
      "2018-04-13T15:15:18.170320: step 3530, loss 0.00346224, acc 1\n",
      "2018-04-13T15:15:18.493548: step 3531, loss 0.00275474, acc 1\n",
      "2018-04-13T15:15:18.838292: step 3532, loss 0.00427603, acc 1\n",
      "2018-04-13T15:15:19.151512: step 3533, loss 0.00492888, acc 1\n",
      "2018-04-13T15:15:19.471739: step 3534, loss 0.00763734, acc 1\n",
      "2018-04-13T15:15:19.818484: step 3535, loss 0.00634074, acc 1\n",
      "2018-04-13T15:15:20.154721: step 3536, loss 0.0141343, acc 0.984375\n",
      "2018-04-13T15:15:20.474447: step 3537, loss 0.0170346, acc 1\n",
      "2018-04-13T15:15:20.792171: step 3538, loss 0.0353245, acc 0.984375\n",
      "2018-04-13T15:15:21.115399: step 3539, loss 0.00269766, acc 1\n",
      "2018-04-13T15:15:21.442630: step 3540, loss 0.00341742, acc 1\n",
      "2018-04-13T15:15:21.772363: step 3541, loss 0.0124732, acc 1\n",
      "2018-04-13T15:15:22.096092: step 3542, loss 0.00641064, acc 1\n",
      "2018-04-13T15:15:22.406811: step 3543, loss 0.00596026, acc 1\n",
      "2018-04-13T15:15:22.741547: step 3544, loss 0.00627326, acc 1\n",
      "2018-04-13T15:15:23.098299: step 3545, loss 0.00346381, acc 1\n",
      "2018-04-13T15:15:23.434037: step 3546, loss 0.0228117, acc 0.984375\n",
      "2018-04-13T15:15:23.763271: step 3547, loss 0.00379867, acc 1\n",
      "2018-04-13T15:15:24.096505: step 3548, loss 0.00402297, acc 1\n",
      "2018-04-13T15:15:24.409225: step 3549, loss 0.0023411, acc 1\n",
      "2018-04-13T15:15:24.753969: step 3550, loss 0.00174189, acc 1\n",
      "2018-04-13T15:15:25.070692: step 3551, loss 0.00465352, acc 1\n",
      "2018-04-13T15:15:25.391419: step 3552, loss 0.00614398, acc 1\n",
      "2018-04-13T15:15:25.719150: step 3553, loss 0.0159285, acc 1\n",
      "2018-04-13T15:15:26.082907: step 3554, loss 0.00908086, acc 1\n",
      "2018-04-13T15:15:26.398630: step 3555, loss 0.00773375, acc 1\n",
      "2018-04-13T15:15:26.716856: step 3556, loss 0.0293088, acc 0.984375\n",
      "2018-04-13T15:15:27.038081: step 3557, loss 0.0129905, acc 1\n",
      "2018-04-13T15:15:27.351303: step 3558, loss 0.0035698, acc 1\n",
      "2018-04-13T15:15:27.678034: step 3559, loss 0.00467026, acc 1\n",
      "2018-04-13T15:15:28.012269: step 3560, loss 0.00276461, acc 1\n",
      "2018-04-13T15:15:28.330994: step 3561, loss 0.00509687, acc 1\n",
      "2018-04-13T15:15:28.643215: step 3562, loss 0.0089026, acc 1\n",
      "2018-04-13T15:15:28.992462: step 3563, loss 0.00558297, acc 1\n",
      "2018-04-13T15:15:29.313188: step 3564, loss 0.0206898, acc 0.984375\n",
      "2018-04-13T15:15:29.642420: step 3565, loss 0.00265777, acc 1\n",
      "2018-04-13T15:15:29.960645: step 3566, loss 0.0142938, acc 1\n",
      "2018-04-13T15:15:30.283873: step 3567, loss 0.00469982, acc 1\n",
      "2018-04-13T15:15:30.613606: step 3568, loss 0.014143, acc 1\n",
      "2018-04-13T15:15:30.931331: step 3569, loss 0.0134374, acc 1\n",
      "2018-04-13T15:15:31.261073: step 3570, loss 0.00531382, acc 1\n",
      "2018-04-13T15:15:31.582800: step 3571, loss 0.00362388, acc 1\n",
      "2018-04-13T15:15:31.967071: step 3572, loss 0.00797711, acc 1\n",
      "2018-04-13T15:15:32.322323: step 3573, loss 0.00690428, acc 1\n",
      "2018-04-13T15:15:32.653557: step 3574, loss 0.00619006, acc 1\n",
      "2018-04-13T15:15:32.978285: step 3575, loss 0.0143052, acc 1\n",
      "2018-04-13T15:15:33.337039: step 3576, loss 0.00791231, acc 1\n",
      "2018-04-13T15:15:33.673276: step 3577, loss 0.0253037, acc 0.984375\n",
      "2018-04-13T15:15:34.034532: step 3578, loss 0.00770779, acc 1\n",
      "2018-04-13T15:15:34.365265: step 3579, loss 0.00713348, acc 1\n",
      "2018-04-13T15:15:34.693496: step 3580, loss 0.00720858, acc 1\n",
      "2018-04-13T15:15:35.043744: step 3581, loss 0.00508791, acc 1\n",
      "2018-04-13T15:15:35.362969: step 3582, loss 0.0144055, acc 1\n",
      "2018-04-13T15:15:35.690701: step 3583, loss 0.00191956, acc 1\n",
      "2018-04-13T15:15:36.011427: step 3584, loss 0.00301277, acc 1\n",
      "2018-04-13T15:15:36.332654: step 3585, loss 0.00629668, acc 1\n",
      "2018-04-13T15:15:36.661887: step 3586, loss 0.00204646, acc 1\n",
      "2018-04-13T15:15:36.989117: step 3587, loss 0.0100057, acc 1\n",
      "2018-04-13T15:15:37.305842: step 3588, loss 0.00263188, acc 1\n",
      "2018-04-13T15:15:37.628069: step 3589, loss 0.00530682, acc 1\n",
      "2018-04-13T15:15:37.962805: step 3590, loss 0.00150639, acc 1\n",
      "2018-04-13T15:15:38.299043: step 3591, loss 0.00128041, acc 1\n",
      "2018-04-13T15:15:38.621271: step 3592, loss 0.0043583, acc 1\n",
      "2018-04-13T15:15:38.974529: step 3593, loss 0.0425393, acc 0.984375\n",
      "2018-04-13T15:15:39.299259: step 3594, loss 0.0199091, acc 0.984375\n",
      "2018-04-13T15:15:39.630993: step 3595, loss 0.00392393, acc 1\n",
      "2018-04-13T15:15:39.966229: step 3596, loss 0.0403241, acc 0.96875\n",
      "2018-04-13T15:15:40.284453: step 3597, loss 0.0058567, acc 1\n",
      "2018-04-13T15:15:40.611186: step 3598, loss 0.00511635, acc 1\n",
      "2018-04-13T15:15:40.931912: step 3599, loss 0.00314923, acc 1\n",
      "2018-04-13T15:15:41.250636: step 3600, loss 0.011038, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:15:42.383436: step 3600, loss 1.09953, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3600\n",
      "\n",
      "2018-04-13T15:15:44.055628: step 3601, loss 0.0266425, acc 0.984375\n",
      "2018-04-13T15:15:44.373353: step 3602, loss 0.00263617, acc 1\n",
      "2018-04-13T15:15:44.679569: step 3603, loss 0.0101853, acc 1\n",
      "2018-04-13T15:15:44.995292: step 3604, loss 0.00351913, acc 1\n",
      "2018-04-13T15:15:45.316018: step 3605, loss 0.0015379, acc 1\n",
      "2018-04-13T15:15:45.634243: step 3606, loss 0.00757283, acc 1\n",
      "2018-04-13T15:15:45.957971: step 3607, loss 0.0036727, acc 1\n",
      "2018-04-13T15:15:46.287704: step 3608, loss 0.0159025, acc 0.984375\n",
      "2018-04-13T15:15:46.609431: step 3609, loss 0.00256128, acc 1\n",
      "2018-04-13T15:15:46.932660: step 3610, loss 0.0056012, acc 1\n",
      "2018-04-13T15:15:47.272399: step 3611, loss 0.00387506, acc 1\n",
      "2018-04-13T15:15:47.590624: step 3612, loss 0.00700281, acc 1\n",
      "2018-04-13T15:15:47.912351: step 3613, loss 0.00288214, acc 1\n",
      "2018-04-13T15:15:48.230076: step 3614, loss 0.0113437, acc 1\n",
      "2018-04-13T15:15:48.560309: step 3615, loss 0.0232425, acc 0.984375\n",
      "2018-04-13T15:15:48.889041: step 3616, loss 0.0522233, acc 0.984375\n",
      "2018-04-13T15:15:49.220776: step 3617, loss 0.0087757, acc 1\n",
      "2018-04-13T15:15:49.557013: step 3618, loss 0.00424736, acc 1\n",
      "2018-04-13T15:15:49.883743: step 3619, loss 0.00190935, acc 1\n",
      "2018-04-13T15:15:50.220481: step 3620, loss 0.0131151, acc 1\n",
      "2018-04-13T15:15:50.541208: step 3621, loss 0.000836261, acc 1\n",
      "2018-04-13T15:15:50.861434: step 3622, loss 0.00262916, acc 1\n",
      "2018-04-13T15:15:51.183161: step 3623, loss 0.00382271, acc 1\n",
      "2018-04-13T15:15:51.513894: step 3624, loss 0.0039937, acc 1\n",
      "2018-04-13T15:15:51.866644: step 3625, loss 0.00253087, acc 1\n",
      "2018-04-13T15:15:52.203382: step 3626, loss 0.0318476, acc 0.984375\n",
      "2018-04-13T15:15:52.544122: step 3627, loss 0.000694134, acc 1\n",
      "2018-04-13T15:15:52.885364: step 3628, loss 0.0410612, acc 0.984375\n",
      "2018-04-13T15:15:53.243616: step 3629, loss 0.00485583, acc 1\n",
      "2018-04-13T15:15:53.589861: step 3630, loss 0.00840563, acc 1\n",
      "2018-04-13T15:15:53.926598: step 3631, loss 0.00062606, acc 1\n",
      "2018-04-13T15:15:54.267339: step 3632, loss 0.0294329, acc 0.984375\n",
      "2018-04-13T15:15:54.615585: step 3633, loss 0.00733776, acc 1\n",
      "2018-04-13T15:15:54.966833: step 3634, loss 0.00310911, acc 1\n",
      "2018-04-13T15:15:55.299068: step 3635, loss 0.00141334, acc 1\n",
      "2018-04-13T15:15:55.638812: step 3636, loss 0.0042096, acc 1\n",
      "2018-04-13T15:15:55.976546: step 3637, loss 0.0128663, acc 1\n",
      "2018-04-13T15:15:56.298773: step 3638, loss 0.00180835, acc 1\n",
      "2018-04-13T15:15:56.618499: step 3639, loss 0.00201405, acc 1\n",
      "2018-04-13T15:15:56.943728: step 3640, loss 0.00155705, acc 1\n",
      "2018-04-13T15:15:57.258452: step 3641, loss 0.00640699, acc 1\n",
      "2018-04-13T15:15:57.582179: step 3642, loss 0.00540255, acc 1\n",
      "2018-04-13T15:15:57.925421: step 3643, loss 0.00414074, acc 1\n",
      "2018-04-13T15:15:58.239644: step 3644, loss 0.00933854, acc 1\n",
      "2018-04-13T15:15:58.553365: step 3645, loss 0.0650935, acc 0.984375\n",
      "2018-04-13T15:15:58.875094: step 3646, loss 0.00305282, acc 1\n",
      "2018-04-13T15:15:59.224339: step 3647, loss 0.00484211, acc 1\n",
      "2018-04-13T15:15:59.550569: step 3648, loss 0.0039757, acc 1\n",
      "2018-04-13T15:15:59.885306: step 3649, loss 0.0149915, acc 0.984375\n",
      "2018-04-13T15:16:00.211036: step 3650, loss 0.0140197, acc 1\n",
      "2018-04-13T15:16:00.538266: step 3651, loss 0.0260808, acc 0.984375\n",
      "2018-04-13T15:16:00.881521: step 3652, loss 0.00438637, acc 1\n",
      "2018-04-13T15:16:01.223262: step 3653, loss 0.00228621, acc 1\n",
      "2018-04-13T15:16:01.542487: step 3654, loss 0.00516829, acc 1\n",
      "2018-04-13T15:16:01.856709: step 3655, loss 0.00437231, acc 1\n",
      "2018-04-13T15:16:02.213962: step 3656, loss 0.0040021, acc 1\n",
      "2018-04-13T15:16:02.536189: step 3657, loss 0.0021707, acc 1\n",
      "2018-04-13T15:16:02.872927: step 3658, loss 0.00429703, acc 1\n",
      "2018-04-13T15:16:03.208664: step 3659, loss 0.0155336, acc 0.984375\n",
      "2018-04-13T15:16:03.520384: step 3660, loss 0.00658328, acc 1\n",
      "2018-04-13T15:16:03.861625: step 3661, loss 0.00214482, acc 1\n",
      "2018-04-13T15:16:04.182352: step 3662, loss 0.0184779, acc 0.984375\n",
      "2018-04-13T15:16:04.495572: step 3663, loss 0.00124813, acc 1\n",
      "2018-04-13T15:16:04.818300: step 3664, loss 0.00471415, acc 1\n",
      "2018-04-13T15:16:05.165045: step 3665, loss 0.00281849, acc 1\n",
      "2018-04-13T15:16:05.496279: step 3666, loss 0.00855093, acc 1\n",
      "2018-04-13T15:16:05.822510: step 3667, loss 0.00120929, acc 1\n",
      "2018-04-13T15:16:06.126724: step 3668, loss 0.00135511, acc 1\n",
      "2018-04-13T15:16:06.452455: step 3669, loss 0.00402058, acc 1\n",
      "2018-04-13T15:16:06.788192: step 3670, loss 0.00125351, acc 1\n",
      "2018-04-13T15:16:07.112420: step 3671, loss 0.00419113, acc 1\n",
      "2018-04-13T15:16:07.429144: step 3672, loss 0.0119076, acc 1\n",
      "2018-04-13T15:16:07.746869: step 3673, loss 0.0181647, acc 1\n",
      "2018-04-13T15:16:08.097616: step 3674, loss 0.0189687, acc 0.984375\n",
      "2018-04-13T15:16:08.437356: step 3675, loss 0.00184296, acc 1\n",
      "2018-04-13T15:16:08.768090: step 3676, loss 0.00427907, acc 1\n",
      "2018-04-13T15:16:09.082311: step 3677, loss 0.0123857, acc 1\n",
      "2018-04-13T15:16:09.402037: step 3678, loss 0.00261755, acc 1\n",
      "2018-04-13T15:16:09.751784: step 3679, loss 0.0107148, acc 1\n",
      "2018-04-13T15:16:10.064505: step 3680, loss 0.0100997, acc 1\n",
      "2018-04-13T15:16:10.381228: step 3681, loss 0.0015026, acc 1\n",
      "2018-04-13T15:16:10.708460: step 3682, loss 0.0348345, acc 0.984375\n",
      "2018-04-13T15:16:11.039693: step 3683, loss 0.0210894, acc 0.984375\n",
      "2018-04-13T15:16:11.366925: step 3684, loss 0.00704403, acc 1\n",
      "2018-04-13T15:16:11.686650: step 3685, loss 0.0235461, acc 0.984375\n",
      "2018-04-13T15:16:12.006376: step 3686, loss 0.0331877, acc 0.984375\n",
      "2018-04-13T15:16:12.321099: step 3687, loss 0.00389619, acc 1\n",
      "2018-04-13T15:16:12.643826: step 3688, loss 0.00298515, acc 1\n",
      "2018-04-13T15:16:12.975061: step 3689, loss 0.00342514, acc 1\n",
      "2018-04-13T15:16:13.286780: step 3690, loss 0.00638087, acc 1\n",
      "2018-04-13T15:16:13.611512: step 3691, loss 0.00259813, acc 1\n",
      "2018-04-13T15:16:13.966259: step 3692, loss 0.0162636, acc 1\n",
      "2018-04-13T15:16:14.333519: step 3693, loss 0.0184603, acc 0.984375\n",
      "2018-04-13T15:16:14.657748: step 3694, loss 0.000799041, acc 1\n",
      "2018-04-13T15:16:14.991984: step 3695, loss 0.0138582, acc 1\n",
      "2018-04-13T15:16:15.419787: step 3696, loss 0.00557857, acc 1\n",
      "2018-04-13T15:16:15.777039: step 3697, loss 0.00486653, acc 1\n",
      "2018-04-13T15:16:16.173819: step 3698, loss 0.00155059, acc 1\n",
      "2018-04-13T15:16:16.507054: step 3699, loss 0.00916801, acc 1\n",
      "2018-04-13T15:16:16.886322: step 3700, loss 0.00322373, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:16:18.139707: step 3700, loss 1.13229, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3700\n",
      "\n",
      "2018-04-13T15:16:19.577733: step 3701, loss 0.00313774, acc 1\n",
      "2018-04-13T15:16:19.894457: step 3702, loss 0.00691257, acc 1\n",
      "2018-04-13T15:16:20.258214: step 3703, loss 0.00158128, acc 1\n",
      "2018-04-13T15:16:20.576938: step 3704, loss 0.00652589, acc 1\n",
      "2018-04-13T15:16:20.896664: step 3705, loss 0.00807259, acc 1\n",
      "2018-04-13T15:16:21.217891: step 3706, loss 0.0133097, acc 0.984375\n",
      "2018-04-13T15:16:21.544121: step 3707, loss 0.000844647, acc 1\n",
      "2018-04-13T15:16:21.872853: step 3708, loss 0.00280307, acc 1\n",
      "2018-04-13T15:16:22.187576: step 3709, loss 0.00270377, acc 1\n",
      "2018-04-13T15:16:22.499296: step 3710, loss 0.00978335, acc 1\n",
      "2018-04-13T15:16:22.819522: step 3711, loss 0.000844399, acc 1\n",
      "2018-04-13T15:16:23.163265: step 3712, loss 0.0161249, acc 0.984375\n",
      "2018-04-13T15:16:23.497501: step 3713, loss 0.00520252, acc 1\n",
      "2018-04-13T15:16:23.814224: step 3714, loss 0.0204711, acc 0.984375\n",
      "2018-04-13T15:16:24.149461: step 3715, loss 0.00288437, acc 1\n",
      "2018-04-13T15:16:24.479194: step 3716, loss 0.0250709, acc 0.96875\n",
      "2018-04-13T15:16:24.808427: step 3717, loss 0.00169876, acc 1\n",
      "2018-04-13T15:16:25.137158: step 3718, loss 0.0149369, acc 1\n",
      "2018-04-13T15:16:25.451381: step 3719, loss 0.011663, acc 1\n",
      "2018-04-13T15:16:25.770105: step 3720, loss 0.00785637, acc 1\n",
      "2018-04-13T15:16:26.109346: step 3721, loss 0.00745281, acc 1\n",
      "2018-04-13T15:16:26.443581: step 3722, loss 0.00360205, acc 1\n",
      "2018-04-13T15:16:26.766310: step 3723, loss 0.00370815, acc 1\n",
      "2018-04-13T15:16:27.084534: step 3724, loss 0.000834545, acc 1\n",
      "2018-04-13T15:16:27.405260: step 3725, loss 0.00875992, acc 1\n",
      "2018-04-13T15:16:27.736994: step 3726, loss 0.0078357, acc 1\n",
      "2018-04-13T15:16:28.059722: step 3727, loss 0.00237713, acc 1\n",
      "2018-04-13T15:16:28.382950: step 3728, loss 0.00380367, acc 1\n",
      "2018-04-13T15:16:28.704677: step 3729, loss 0.00354424, acc 1\n",
      "2018-04-13T15:16:29.019400: step 3730, loss 0.00238319, acc 1\n",
      "2018-04-13T15:16:29.348632: step 3731, loss 0.0028831, acc 1\n",
      "2018-04-13T15:16:29.674362: step 3732, loss 0.0048471, acc 1\n",
      "2018-04-13T15:16:29.994589: step 3733, loss 0.0100407, acc 1\n",
      "2018-04-13T15:16:30.319818: step 3734, loss 0.000766537, acc 1\n",
      "2018-04-13T15:16:30.651552: step 3735, loss 0.00120551, acc 1\n",
      "2018-04-13T15:16:30.972779: step 3736, loss 0.00431481, acc 1\n",
      "2018-04-13T15:16:31.289503: step 3737, loss 0.00653149, acc 1\n",
      "2018-04-13T15:16:31.617734: step 3738, loss 0.00641335, acc 1\n",
      "2018-04-13T15:16:31.943465: step 3739, loss 0.00539758, acc 1\n",
      "2018-04-13T15:16:32.278701: step 3740, loss 0.0350988, acc 0.984375\n",
      "2018-04-13T15:16:32.602430: step 3741, loss 0.00658327, acc 1\n",
      "2018-04-13T15:16:32.930161: step 3742, loss 0.0125745, acc 0.984375\n",
      "2018-04-13T15:16:33.244384: step 3743, loss 0.00933866, acc 1\n",
      "2018-04-13T15:16:33.565610: step 3744, loss 0.0140774, acc 0.984375\n",
      "2018-04-13T15:16:33.905850: step 3745, loss 0.000828174, acc 1\n",
      "2018-04-13T15:16:34.215569: step 3746, loss 0.00176439, acc 1\n",
      "2018-04-13T15:16:34.528790: step 3747, loss 0.0239084, acc 0.984375\n",
      "2018-04-13T15:16:34.844013: step 3748, loss 0.0595478, acc 0.984375\n",
      "2018-04-13T15:16:35.187755: step 3749, loss 0.00229701, acc 1\n",
      "2018-04-13T15:16:35.502477: step 3750, loss 0.0285954, acc 0.983333\n",
      "2018-04-13T15:16:35.829209: step 3751, loss 0.0013799, acc 1\n",
      "2018-04-13T15:16:36.147933: step 3752, loss 0.0023855, acc 1\n",
      "2018-04-13T15:16:36.465158: step 3753, loss 0.00203692, acc 1\n",
      "2018-04-13T15:16:36.795891: step 3754, loss 0.0302478, acc 0.984375\n",
      "2018-04-13T15:16:37.119119: step 3755, loss 0.00467112, acc 1\n",
      "2018-04-13T15:16:37.442848: step 3756, loss 0.00179968, acc 1\n",
      "2018-04-13T15:16:37.771585: step 3757, loss 0.00363107, acc 1\n",
      "2018-04-13T15:16:38.097310: step 3758, loss 0.0172482, acc 0.984375\n",
      "2018-04-13T15:16:38.442053: step 3759, loss 0.00532067, acc 1\n",
      "2018-04-13T15:16:38.761778: step 3760, loss 0.00248544, acc 1\n",
      "2018-04-13T15:16:39.082005: step 3761, loss 0.00217619, acc 1\n",
      "2018-04-13T15:16:39.409236: step 3762, loss 0.00361694, acc 1\n",
      "2018-04-13T15:16:39.732465: step 3763, loss 0.00529593, acc 1\n",
      "2018-04-13T15:16:40.067200: step 3764, loss 0.00121618, acc 1\n",
      "2018-04-13T15:16:40.399435: step 3765, loss 0.00452328, acc 1\n",
      "2018-04-13T15:16:40.726166: step 3766, loss 0.00681807, acc 1\n",
      "2018-04-13T15:16:41.050395: step 3767, loss 0.0130564, acc 1\n",
      "2018-04-13T15:16:41.405146: step 3768, loss 0.0156564, acc 1\n",
      "2018-04-13T15:16:41.743384: step 3769, loss 0.0205127, acc 0.984375\n",
      "2018-04-13T15:16:42.072617: step 3770, loss 0.00216731, acc 1\n",
      "2018-04-13T15:16:42.395345: step 3771, loss 0.00435077, acc 1\n",
      "2018-04-13T15:16:42.713570: step 3772, loss 0.00244412, acc 1\n",
      "2018-04-13T15:16:43.044803: step 3773, loss 0.00485971, acc 1\n",
      "2018-04-13T15:16:43.363027: step 3774, loss 0.00816157, acc 1\n",
      "2018-04-13T15:16:43.688758: step 3775, loss 0.0551485, acc 0.984375\n",
      "2018-04-13T15:16:44.022493: step 3776, loss 0.00108164, acc 1\n",
      "2018-04-13T15:16:44.367738: step 3777, loss 0.00697276, acc 1\n",
      "2018-04-13T15:16:44.700473: step 3778, loss 0.00230957, acc 1\n",
      "2018-04-13T15:16:45.026202: step 3779, loss 0.00113582, acc 1\n",
      "2018-04-13T15:16:45.343927: step 3780, loss 0.00232485, acc 1\n",
      "2018-04-13T15:16:45.671659: step 3781, loss 0.00351884, acc 1\n",
      "2018-04-13T15:16:46.009396: step 3782, loss 0.00229129, acc 1\n",
      "2018-04-13T15:16:46.322117: step 3783, loss 0.00291519, acc 1\n",
      "2018-04-13T15:16:46.637840: step 3784, loss 0.0765078, acc 0.96875\n",
      "2018-04-13T15:16:46.971576: step 3785, loss 0.00624057, acc 1\n",
      "2018-04-13T15:16:47.305312: step 3786, loss 0.00748812, acc 1\n",
      "2018-04-13T15:16:47.629541: step 3787, loss 0.00796336, acc 1\n",
      "2018-04-13T15:16:47.963276: step 3788, loss 0.015887, acc 0.984375\n",
      "2018-04-13T15:16:48.275496: step 3789, loss 0.0347878, acc 0.984375\n",
      "2018-04-13T15:16:48.637252: step 3790, loss 0.0123403, acc 1\n",
      "2018-04-13T15:16:48.984998: step 3791, loss 0.00240046, acc 1\n",
      "2018-04-13T15:16:49.311229: step 3792, loss 0.00230903, acc 1\n",
      "2018-04-13T15:16:49.631955: step 3793, loss 0.00592515, acc 1\n",
      "2018-04-13T15:16:49.970694: step 3794, loss 0.00465374, acc 1\n",
      "2018-04-13T15:16:50.311434: step 3795, loss 0.017429, acc 1\n",
      "2018-04-13T15:16:50.643169: step 3796, loss 0.00387779, acc 1\n",
      "2018-04-13T15:16:50.986411: step 3797, loss 0.0194398, acc 0.984375\n",
      "2018-04-13T15:16:51.325651: step 3798, loss 0.00902002, acc 1\n",
      "2018-04-13T15:16:51.639873: step 3799, loss 0.0320625, acc 0.96875\n",
      "2018-04-13T15:16:51.976610: step 3800, loss 0.0062987, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:16:53.115915: step 3800, loss 1.14349, acc 0.741088\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3800\n",
      "\n",
      "2018-04-13T15:16:54.886224: step 3801, loss 0.0023473, acc 1\n",
      "2018-04-13T15:16:55.208451: step 3802, loss 0.0199847, acc 0.984375\n",
      "2018-04-13T15:16:55.521672: step 3803, loss 0.0117706, acc 1\n",
      "2018-04-13T15:16:55.845901: step 3804, loss 0.00258402, acc 1\n",
      "2018-04-13T15:16:56.199650: step 3805, loss 0.00311521, acc 1\n",
      "2018-04-13T15:16:56.537390: step 3806, loss 0.0242399, acc 0.984375\n",
      "2018-04-13T15:16:56.867122: step 3807, loss 0.00286206, acc 1\n",
      "2018-04-13T15:16:57.195854: step 3808, loss 0.0732951, acc 0.96875\n",
      "2018-04-13T15:16:57.512578: step 3809, loss 0.0262566, acc 0.984375\n",
      "2018-04-13T15:16:57.840309: step 3810, loss 0.0129635, acc 1\n",
      "2018-04-13T15:16:58.183052: step 3811, loss 0.0027973, acc 1\n",
      "2018-04-13T15:16:58.502276: step 3812, loss 0.00927228, acc 1\n",
      "2018-04-13T15:16:58.826005: step 3813, loss 0.00232904, acc 1\n",
      "2018-04-13T15:16:59.159241: step 3814, loss 0.00397482, acc 1\n",
      "2018-04-13T15:16:59.518495: step 3815, loss 0.0103031, acc 1\n",
      "2018-04-13T15:16:59.837220: step 3816, loss 0.0105817, acc 1\n",
      "2018-04-13T15:17:00.164951: step 3817, loss 0.00885064, acc 1\n",
      "2018-04-13T15:17:00.500688: step 3818, loss 0.0100084, acc 1\n",
      "2018-04-13T15:17:00.833423: step 3819, loss 0.00073143, acc 1\n",
      "2018-04-13T15:17:01.163155: step 3820, loss 0.0271487, acc 0.984375\n",
      "2018-04-13T15:17:01.501894: step 3821, loss 0.00645506, acc 1\n",
      "2018-04-13T15:17:01.844636: step 3822, loss 0.0157158, acc 0.984375\n",
      "2018-04-13T15:17:02.174869: step 3823, loss 0.00164272, acc 1\n",
      "2018-04-13T15:17:02.519613: step 3824, loss 0.0119323, acc 1\n",
      "2018-04-13T15:17:02.849846: step 3825, loss 0.00671031, acc 1\n",
      "2018-04-13T15:17:03.171074: step 3826, loss 0.00269563, acc 1\n",
      "2018-04-13T15:17:03.498305: step 3827, loss 0.00486875, acc 1\n",
      "2018-04-13T15:17:03.836043: step 3828, loss 0.0108284, acc 1\n",
      "2018-04-13T15:17:04.161773: step 3829, loss 0.0709378, acc 0.984375\n",
      "2018-04-13T15:17:04.481999: step 3830, loss 0.0621261, acc 0.984375\n",
      "2018-04-13T15:17:04.815234: step 3831, loss 0.00257003, acc 1\n",
      "2018-04-13T15:17:05.138463: step 3832, loss 0.00669254, acc 1\n",
      "2018-04-13T15:17:05.479703: step 3833, loss 0.00484088, acc 1\n",
      "2018-04-13T15:17:05.801431: step 3834, loss 0.00351557, acc 1\n",
      "2018-04-13T15:17:06.124159: step 3835, loss 0.00134554, acc 1\n",
      "2018-04-13T15:17:06.444885: step 3836, loss 0.0340782, acc 0.984375\n",
      "2018-04-13T15:17:06.771615: step 3837, loss 0.00713718, acc 1\n",
      "2018-04-13T15:17:07.099848: step 3838, loss 0.0135093, acc 1\n",
      "2018-04-13T15:17:07.412568: step 3839, loss 0.0050429, acc 1\n",
      "2018-04-13T15:17:07.742802: step 3840, loss 0.00231259, acc 1\n",
      "2018-04-13T15:17:08.067031: step 3841, loss 0.00222001, acc 1\n",
      "2018-04-13T15:17:08.437793: step 3842, loss 0.00357609, acc 1\n",
      "2018-04-13T15:17:08.764022: step 3843, loss 0.00992851, acc 1\n",
      "2018-04-13T15:17:09.080246: step 3844, loss 0.00391188, acc 1\n",
      "2018-04-13T15:17:09.404975: step 3845, loss 0.00251957, acc 1\n",
      "2018-04-13T15:17:09.727703: step 3846, loss 0.0177837, acc 1\n",
      "2018-04-13T15:17:10.055436: step 3847, loss 0.00267227, acc 1\n",
      "2018-04-13T15:17:10.374660: step 3848, loss 0.0268118, acc 1\n",
      "2018-04-13T15:17:10.692384: step 3849, loss 0.00247576, acc 1\n",
      "2018-04-13T15:17:11.022621: step 3850, loss 0.00408903, acc 1\n",
      "2018-04-13T15:17:11.362857: step 3851, loss 0.00204773, acc 1\n",
      "2018-04-13T15:17:11.695592: step 3852, loss 0.0122543, acc 1\n",
      "2018-04-13T15:17:12.012816: step 3853, loss 0.00422067, acc 1\n",
      "2018-04-13T15:17:12.319534: step 3854, loss 0.0107419, acc 1\n",
      "2018-04-13T15:17:12.638759: step 3855, loss 0.0060883, acc 1\n",
      "2018-04-13T15:17:12.966991: step 3856, loss 0.00292154, acc 1\n",
      "2018-04-13T15:17:13.289218: step 3857, loss 0.00433816, acc 1\n",
      "2018-04-13T15:17:13.606943: step 3858, loss 0.0303443, acc 0.96875\n",
      "2018-04-13T15:17:13.929170: step 3859, loss 0.00699372, acc 1\n",
      "2018-04-13T15:17:14.254901: step 3860, loss 0.00346569, acc 1\n",
      "2018-04-13T15:17:14.591638: step 3861, loss 0.002547, acc 1\n",
      "2018-04-13T15:17:14.920370: step 3862, loss 0.0038314, acc 1\n",
      "2018-04-13T15:17:15.243097: step 3863, loss 0.00274468, acc 1\n",
      "2018-04-13T15:17:15.550345: step 3864, loss 0.00879716, acc 1\n",
      "2018-04-13T15:17:15.879547: step 3865, loss 0.00289584, acc 1\n",
      "2018-04-13T15:17:16.215284: step 3866, loss 0.003885, acc 1\n",
      "2018-04-13T15:17:16.534510: step 3867, loss 0.00332134, acc 1\n",
      "2018-04-13T15:17:16.857738: step 3868, loss 0.00303144, acc 1\n",
      "2018-04-13T15:17:17.179464: step 3869, loss 0.0405501, acc 0.984375\n",
      "2018-04-13T15:17:17.527711: step 3870, loss 0.0042179, acc 1\n",
      "2018-04-13T15:17:17.849438: step 3871, loss 0.03637, acc 0.984375\n",
      "2018-04-13T15:17:18.160158: step 3872, loss 0.0322942, acc 0.984375\n",
      "2018-04-13T15:17:18.497899: step 3873, loss 0.00216376, acc 1\n",
      "2018-04-13T15:17:18.819623: step 3874, loss 0.0119787, acc 1\n",
      "2018-04-13T15:17:19.144352: step 3875, loss 0.000578417, acc 1\n",
      "2018-04-13T15:17:19.466080: step 3876, loss 0.000542056, acc 1\n",
      "2018-04-13T15:17:19.795312: step 3877, loss 0.00533438, acc 1\n",
      "2018-04-13T15:17:20.108534: step 3878, loss 0.00271633, acc 1\n",
      "2018-04-13T15:17:20.457279: step 3879, loss 0.0184705, acc 0.984375\n",
      "2018-04-13T15:17:20.841231: step 3880, loss 0.016198, acc 0.984375\n",
      "2018-04-13T15:17:21.262029: step 3881, loss 0.00479774, acc 1\n",
      "2018-04-13T15:17:21.617780: step 3882, loss 0.0050828, acc 1\n",
      "2018-04-13T15:17:22.035074: step 3883, loss 0.00193694, acc 1\n",
      "2018-04-13T15:17:22.368310: step 3884, loss 0.0106028, acc 1\n",
      "2018-04-13T15:17:22.685534: step 3885, loss 0.00481965, acc 1\n",
      "2018-04-13T15:17:23.000256: step 3886, loss 0.00957859, acc 1\n",
      "2018-04-13T15:17:23.328488: step 3887, loss 0.0131315, acc 1\n",
      "2018-04-13T15:17:23.655244: step 3888, loss 0.0121566, acc 1\n",
      "2018-04-13T15:17:23.979474: step 3889, loss 0.013406, acc 0.984375\n",
      "2018-04-13T15:17:24.295196: step 3890, loss 0.0105908, acc 1\n",
      "2018-04-13T15:17:24.617924: step 3891, loss 0.001011, acc 1\n",
      "2018-04-13T15:17:24.946156: step 3892, loss 0.00232146, acc 1\n",
      "2018-04-13T15:17:25.279391: step 3893, loss 0.00120825, acc 1\n",
      "2018-04-13T15:17:25.604621: step 3894, loss 0.00152957, acc 1\n",
      "2018-04-13T15:17:25.924847: step 3895, loss 0.00625879, acc 1\n",
      "2018-04-13T15:17:26.240570: step 3896, loss 0.0148148, acc 0.984375\n",
      "2018-04-13T15:17:26.572806: step 3897, loss 0.00262517, acc 1\n",
      "2018-04-13T15:17:26.905041: step 3898, loss 0.00574893, acc 1\n",
      "2018-04-13T15:17:27.227767: step 3899, loss 0.00459632, acc 1\n",
      "2018-04-13T15:17:27.542990: step 3900, loss 0.0134607, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:17:28.775627: step 3900, loss 1.20174, acc 0.741088\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-3900\n",
      "\n",
      "2018-04-13T15:17:30.690178: step 3901, loss 0.0103257, acc 1\n",
      "2018-04-13T15:17:31.016408: step 3902, loss 0.0018849, acc 1\n",
      "2018-04-13T15:17:31.334637: step 3903, loss 0.0013964, acc 1\n",
      "2018-04-13T15:17:31.642850: step 3904, loss 0.00162901, acc 1\n",
      "2018-04-13T15:17:31.964578: step 3905, loss 0.00558687, acc 1\n",
      "2018-04-13T15:17:32.284306: step 3906, loss 0.00118252, acc 1\n",
      "2018-04-13T15:17:32.646560: step 3907, loss 0.00690306, acc 1\n",
      "2018-04-13T15:17:32.967286: step 3908, loss 0.000889362, acc 1\n",
      "2018-04-13T15:17:33.286511: step 3909, loss 0.00118204, acc 1\n",
      "2018-04-13T15:17:33.598231: step 3910, loss 0.00996394, acc 1\n",
      "2018-04-13T15:17:33.937971: step 3911, loss 0.00166036, acc 1\n",
      "2018-04-13T15:17:34.276710: step 3912, loss 0.00537558, acc 1\n",
      "2018-04-13T15:17:34.598439: step 3913, loss 0.0113357, acc 1\n",
      "2018-04-13T15:17:34.920165: step 3914, loss 0.00320862, acc 1\n",
      "2018-04-13T15:17:35.241891: step 3915, loss 0.00167821, acc 1\n",
      "2018-04-13T15:17:35.593140: step 3916, loss 0.0115615, acc 1\n",
      "2018-04-13T15:17:35.921873: step 3917, loss 0.00757939, acc 1\n",
      "2018-04-13T15:17:36.238095: step 3918, loss 0.00451703, acc 1\n",
      "2018-04-13T15:17:36.554318: step 3919, loss 0.00639563, acc 1\n",
      "2018-04-13T15:17:36.873544: step 3920, loss 0.00128109, acc 1\n",
      "2018-04-13T15:17:37.195772: step 3921, loss 0.00198341, acc 1\n",
      "2018-04-13T15:17:37.519500: step 3922, loss 0.00326099, acc 1\n",
      "2018-04-13T15:17:37.861742: step 3923, loss 0.00423465, acc 1\n",
      "2018-04-13T15:17:38.172961: step 3924, loss 0.00499549, acc 1\n",
      "2018-04-13T15:17:38.518705: step 3925, loss 0.00441388, acc 1\n",
      "2018-04-13T15:17:38.849939: step 3926, loss 0.0025441, acc 1\n",
      "2018-04-13T15:17:39.162160: step 3927, loss 0.00149185, acc 1\n",
      "2018-04-13T15:17:39.475882: step 3928, loss 0.00453924, acc 1\n",
      "2018-04-13T15:17:39.808617: step 3929, loss 0.00573441, acc 1\n",
      "2018-04-13T15:17:40.154861: step 3930, loss 0.00389412, acc 1\n",
      "2018-04-13T15:17:40.486095: step 3931, loss 0.00236338, acc 1\n",
      "2018-04-13T15:17:40.812325: step 3932, loss 0.00787411, acc 1\n",
      "2018-04-13T15:17:41.149563: step 3933, loss 0.0323344, acc 0.984375\n",
      "2018-04-13T15:17:41.508817: step 3934, loss 0.00209581, acc 1\n",
      "2018-04-13T15:17:41.828544: step 3935, loss 0.00183644, acc 1\n",
      "2018-04-13T15:17:42.158776: step 3936, loss 0.00220659, acc 1\n",
      "2018-04-13T15:17:42.476500: step 3937, loss 0.000705419, acc 1\n",
      "2018-04-13T15:17:42.810737: step 3938, loss 0.00595703, acc 1\n",
      "2018-04-13T15:17:43.167989: step 3939, loss 0.00309849, acc 1\n",
      "2018-04-13T15:17:43.515234: step 3940, loss 0.00264961, acc 1\n",
      "2018-04-13T15:17:43.872986: step 3941, loss 0.00179047, acc 1\n",
      "2018-04-13T15:17:44.217730: step 3942, loss 0.00491361, acc 1\n",
      "2018-04-13T15:17:44.581987: step 3943, loss 0.000589209, acc 1\n",
      "2018-04-13T15:17:44.921226: step 3944, loss 0.00757045, acc 1\n",
      "2018-04-13T15:17:45.233947: step 3945, loss 0.00709104, acc 1\n",
      "2018-04-13T15:17:45.555175: step 3946, loss 0.00529977, acc 1\n",
      "2018-04-13T15:17:45.883907: step 3947, loss 0.00571968, acc 1\n",
      "2018-04-13T15:17:46.207635: step 3948, loss 0.000886569, acc 1\n",
      "2018-04-13T15:17:46.530376: step 3949, loss 0.0938082, acc 0.96875\n",
      "2018-04-13T15:17:46.867614: step 3950, loss 0.00772515, acc 1\n",
      "2018-04-13T15:17:47.189841: step 3951, loss 0.00283787, acc 1\n",
      "2018-04-13T15:17:47.546593: step 3952, loss 0.00397251, acc 1\n",
      "2018-04-13T15:17:47.865819: step 3953, loss 0.00546791, acc 1\n",
      "2018-04-13T15:17:48.206559: step 3954, loss 0.00118275, acc 1\n",
      "2018-04-13T15:17:48.534292: step 3955, loss 0.00651215, acc 1\n",
      "2018-04-13T15:17:48.848512: step 3956, loss 0.00226896, acc 1\n",
      "2018-04-13T15:17:49.181748: step 3957, loss 0.00169314, acc 1\n",
      "2018-04-13T15:17:49.516484: step 3958, loss 0.00327331, acc 1\n",
      "2018-04-13T15:17:49.842715: step 3959, loss 0.00918063, acc 1\n",
      "2018-04-13T15:17:50.163942: step 3960, loss 0.00295041, acc 1\n",
      "2018-04-13T15:17:50.515190: step 3961, loss 0.00139569, acc 1\n",
      "2018-04-13T15:17:50.834415: step 3962, loss 0.0127856, acc 0.984375\n",
      "2018-04-13T15:17:51.155141: step 3963, loss 0.00692407, acc 1\n",
      "2018-04-13T15:17:51.473866: step 3964, loss 0.00425663, acc 1\n",
      "2018-04-13T15:17:51.806101: step 3965, loss 0.00137211, acc 1\n",
      "2018-04-13T15:17:52.132832: step 3966, loss 0.0168665, acc 0.984375\n",
      "2018-04-13T15:17:52.468569: step 3967, loss 0.00664517, acc 1\n",
      "2018-04-13T15:17:52.809309: step 3968, loss 0.00283894, acc 1\n",
      "2018-04-13T15:17:53.122531: step 3969, loss 0.00338998, acc 1\n",
      "2018-04-13T15:17:53.481784: step 3970, loss 0.00414813, acc 1\n",
      "2018-04-13T15:17:53.815020: step 3971, loss 0.00712156, acc 1\n",
      "2018-04-13T15:17:54.130743: step 3972, loss 0.00174513, acc 1\n",
      "2018-04-13T15:17:54.441462: step 3973, loss 0.0180159, acc 1\n",
      "2018-04-13T15:17:54.767692: step 3974, loss 0.00256965, acc 1\n",
      "2018-04-13T15:17:55.090920: step 3975, loss 0.00586709, acc 1\n",
      "2018-04-13T15:17:55.405643: step 3976, loss 0.00278455, acc 1\n",
      "2018-04-13T15:17:55.729371: step 3977, loss 0.00832173, acc 1\n",
      "2018-04-13T15:17:56.051598: step 3978, loss 0.0215883, acc 1\n",
      "2018-04-13T15:17:56.394341: step 3979, loss 0.00189037, acc 1\n",
      "2018-04-13T15:17:56.724074: step 3980, loss 0.017921, acc 0.984375\n",
      "2018-04-13T15:17:57.040797: step 3981, loss 0.0164099, acc 0.984375\n",
      "2018-04-13T15:17:57.368028: step 3982, loss 0.00566369, acc 1\n",
      "2018-04-13T15:17:57.703265: step 3983, loss 0.00570109, acc 1\n",
      "2018-04-13T15:17:58.020990: step 3984, loss 0.0028546, acc 1\n",
      "2018-04-13T15:17:58.352724: step 3985, loss 0.0052761, acc 1\n",
      "2018-04-13T15:17:58.692964: step 3986, loss 0.00224985, acc 1\n",
      "2018-04-13T15:17:59.011188: step 3987, loss 0.00822391, acc 1\n",
      "2018-04-13T15:17:59.341422: step 3988, loss 0.00185054, acc 1\n",
      "2018-04-13T15:17:59.667652: step 3989, loss 0.000935647, acc 1\n",
      "2018-04-13T15:18:00.006892: step 3990, loss 0.00218585, acc 1\n",
      "2018-04-13T15:18:00.330620: step 3991, loss 0.00202874, acc 1\n",
      "2018-04-13T15:18:00.657351: step 3992, loss 0.0226238, acc 0.984375\n",
      "2018-04-13T15:18:00.987084: step 3993, loss 0.00525469, acc 1\n",
      "2018-04-13T15:18:01.302306: step 3994, loss 0.0155767, acc 1\n",
      "2018-04-13T15:18:01.622033: step 3995, loss 0.0126068, acc 1\n",
      "2018-04-13T15:18:01.958270: step 3996, loss 0.00295237, acc 1\n",
      "2018-04-13T15:18:02.290004: step 3997, loss 0.00211181, acc 1\n",
      "2018-04-13T15:18:02.617736: step 3998, loss 0.0030311, acc 1\n",
      "2018-04-13T15:18:02.944966: step 3999, loss 0.00241623, acc 1\n",
      "2018-04-13T15:18:03.283713: step 4000, loss 0.00113071, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:18:04.443024: step 4000, loss 1.22715, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4000\n",
      "\n",
      "2018-04-13T15:18:06.140642: step 4001, loss 0.00393587, acc 1\n",
      "2018-04-13T15:18:06.462369: step 4002, loss 0.00116281, acc 1\n",
      "2018-04-13T15:18:06.787599: step 4003, loss 0.00195258, acc 1\n",
      "2018-04-13T15:18:07.112328: step 4004, loss 0.00218567, acc 1\n",
      "2018-04-13T15:18:07.434556: step 4005, loss 0.00446951, acc 1\n",
      "2018-04-13T15:18:07.760286: step 4006, loss 0.00068832, acc 1\n",
      "2018-04-13T15:18:08.084014: step 4007, loss 0.000923836, acc 1\n",
      "2018-04-13T15:18:08.412246: step 4008, loss 0.00392781, acc 1\n",
      "2018-04-13T15:18:08.740978: step 4009, loss 0.0047169, acc 1\n",
      "2018-04-13T15:18:09.056200: step 4010, loss 0.00581741, acc 1\n",
      "2018-04-13T15:18:09.369428: step 4011, loss 0.017982, acc 0.984375\n",
      "2018-04-13T15:18:09.710669: step 4012, loss 0.000936515, acc 1\n",
      "2018-04-13T15:18:10.020388: step 4013, loss 0.00204838, acc 1\n",
      "2018-04-13T15:18:10.347619: step 4014, loss 0.00176736, acc 1\n",
      "2018-04-13T15:18:10.683357: step 4015, loss 0.0014549, acc 1\n",
      "2018-04-13T15:18:11.014590: step 4016, loss 0.00411202, acc 1\n",
      "2018-04-13T15:18:11.340820: step 4017, loss 0.00364773, acc 1\n",
      "2018-04-13T15:18:11.671555: step 4018, loss 0.0010758, acc 1\n",
      "2018-04-13T15:18:11.999786: step 4019, loss 0.00239733, acc 1\n",
      "2018-04-13T15:18:12.312006: step 4020, loss 0.000918156, acc 1\n",
      "2018-04-13T15:18:12.622225: step 4021, loss 0.0052196, acc 1\n",
      "2018-04-13T15:18:12.943452: step 4022, loss 0.00131037, acc 1\n",
      "2018-04-13T15:18:13.280189: step 4023, loss 0.00211623, acc 1\n",
      "2018-04-13T15:18:13.602418: step 4024, loss 0.00236815, acc 1\n",
      "2018-04-13T15:18:13.932150: step 4025, loss 0.00105938, acc 1\n",
      "2018-04-13T15:18:14.249374: step 4026, loss 0.0113435, acc 1\n",
      "2018-04-13T15:18:14.597120: step 4027, loss 0.00573031, acc 1\n",
      "2018-04-13T15:18:14.923852: step 4028, loss 0.0051264, acc 1\n",
      "2018-04-13T15:18:15.235571: step 4029, loss 0.000360818, acc 1\n",
      "2018-04-13T15:18:15.558799: step 4030, loss 0.00326177, acc 1\n",
      "2018-04-13T15:18:15.888532: step 4031, loss 0.00468799, acc 1\n",
      "2018-04-13T15:18:16.208758: step 4032, loss 0.00111054, acc 1\n",
      "2018-04-13T15:18:16.523981: step 4033, loss 0.0044549, acc 1\n",
      "2018-04-13T15:18:16.870225: step 4034, loss 0.000565713, acc 1\n",
      "2018-04-13T15:18:17.191451: step 4035, loss 0.00333875, acc 1\n",
      "2018-04-13T15:18:17.520184: step 4036, loss 0.00612321, acc 1\n",
      "2018-04-13T15:18:17.843412: step 4037, loss 0.00473332, acc 1\n",
      "2018-04-13T15:18:18.184653: step 4038, loss 0.00754222, acc 1\n",
      "2018-04-13T15:18:18.499876: step 4039, loss 0.00112802, acc 1\n",
      "2018-04-13T15:18:18.818601: step 4040, loss 0.0128248, acc 1\n",
      "2018-04-13T15:18:19.150335: step 4041, loss 0.0265507, acc 0.984375\n",
      "2018-04-13T15:18:19.467559: step 4042, loss 0.00381804, acc 1\n",
      "2018-04-13T15:18:19.801795: step 4043, loss 0.00325053, acc 1\n",
      "2018-04-13T15:18:20.127525: step 4044, loss 0.014294, acc 1\n",
      "2018-04-13T15:18:20.482276: step 4045, loss 0.0218254, acc 0.984375\n",
      "2018-04-13T15:18:20.824016: step 4046, loss 0.000783369, acc 1\n",
      "2018-04-13T15:18:21.136738: step 4047, loss 0.0162384, acc 0.984375\n",
      "2018-04-13T15:18:21.458465: step 4048, loss 0.000794664, acc 1\n",
      "2018-04-13T15:18:21.782194: step 4049, loss 0.00131224, acc 1\n",
      "2018-04-13T15:18:22.102419: step 4050, loss 0.00188293, acc 1\n",
      "2018-04-13T15:18:22.431652: step 4051, loss 0.00398472, acc 1\n",
      "2018-04-13T15:18:22.760885: step 4052, loss 0.00318475, acc 1\n",
      "2018-04-13T15:18:23.083111: step 4053, loss 0.00555951, acc 1\n",
      "2018-04-13T15:18:23.426855: step 4054, loss 0.00360759, acc 1\n",
      "2018-04-13T15:18:23.763093: step 4055, loss 0.00415728, acc 1\n",
      "2018-04-13T15:18:24.101331: step 4056, loss 0.012326, acc 1\n",
      "2018-04-13T15:18:24.418054: step 4057, loss 0.00120621, acc 1\n",
      "2018-04-13T15:18:24.740782: step 4058, loss 0.0027141, acc 1\n",
      "2018-04-13T15:18:25.077020: step 4059, loss 0.000288398, acc 1\n",
      "2018-04-13T15:18:25.402250: step 4060, loss 0.00127455, acc 1\n",
      "2018-04-13T15:18:25.736485: step 4061, loss 0.00447073, acc 1\n",
      "2018-04-13T15:18:26.056212: step 4062, loss 0.00733935, acc 1\n",
      "2018-04-13T15:18:26.387945: step 4063, loss 0.0263887, acc 0.984375\n",
      "2018-04-13T15:18:26.743697: step 4064, loss 0.0014443, acc 1\n",
      "2018-04-13T15:18:27.068427: step 4065, loss 0.0142687, acc 0.984375\n",
      "2018-04-13T15:18:27.405664: step 4066, loss 0.00785683, acc 1\n",
      "2018-04-13T15:18:27.736397: step 4067, loss 0.000553074, acc 1\n",
      "2018-04-13T15:18:28.055122: step 4068, loss 0.00173167, acc 1\n",
      "2018-04-13T15:18:28.388859: step 4069, loss 0.0035879, acc 1\n",
      "2018-04-13T15:18:28.719091: step 4070, loss 0.000995021, acc 1\n",
      "2018-04-13T15:18:29.026809: step 4071, loss 0.00267851, acc 1\n",
      "2018-04-13T15:18:29.349537: step 4072, loss 0.00650495, acc 1\n",
      "2018-04-13T15:18:29.693780: step 4073, loss 0.00800663, acc 1\n",
      "2018-04-13T15:18:30.015507: step 4074, loss 0.0115632, acc 1\n",
      "2018-04-13T15:18:30.329729: step 4075, loss 0.00212422, acc 1\n",
      "2018-04-13T15:18:30.645952: step 4076, loss 0.00105858, acc 1\n",
      "2018-04-13T15:18:30.985192: step 4077, loss 0.00194318, acc 1\n",
      "2018-04-13T15:18:31.303917: step 4078, loss 0.00400456, acc 1\n",
      "2018-04-13T15:18:31.624644: step 4079, loss 0.00102437, acc 1\n",
      "2018-04-13T15:18:31.951374: step 4080, loss 0.00131953, acc 1\n",
      "2018-04-13T15:18:32.267598: step 4081, loss 0.000527324, acc 1\n",
      "2018-04-13T15:18:32.614843: step 4082, loss 0.0049196, acc 1\n",
      "2018-04-13T15:18:32.950079: step 4083, loss 0.00390835, acc 1\n",
      "2018-04-13T15:18:33.264802: step 4084, loss 0.00169596, acc 1\n",
      "2018-04-13T15:18:33.596535: step 4085, loss 0.000632855, acc 1\n",
      "2018-04-13T15:18:33.926769: step 4086, loss 0.027836, acc 0.984375\n",
      "2018-04-13T15:18:34.258504: step 4087, loss 0.000261842, acc 1\n",
      "2018-04-13T15:18:34.594240: step 4088, loss 0.00134979, acc 1\n",
      "2018-04-13T15:18:34.930978: step 4089, loss 0.00632496, acc 1\n",
      "2018-04-13T15:18:35.256708: step 4090, loss 0.00263154, acc 1\n",
      "2018-04-13T15:18:35.612959: step 4091, loss 0.00123485, acc 1\n",
      "2018-04-13T15:18:35.948196: step 4092, loss 0.00114601, acc 1\n",
      "2018-04-13T15:18:36.261418: step 4093, loss 0.00478179, acc 1\n",
      "2018-04-13T15:18:36.571636: step 4094, loss 0.00185143, acc 1\n",
      "2018-04-13T15:18:36.900869: step 4095, loss 0.00270423, acc 1\n",
      "2018-04-13T15:18:37.240109: step 4096, loss 0.00993316, acc 1\n",
      "2018-04-13T15:18:37.554330: step 4097, loss 0.0171844, acc 0.984375\n",
      "2018-04-13T15:18:37.881060: step 4098, loss 0.000946267, acc 1\n",
      "2018-04-13T15:18:38.209793: step 4099, loss 0.000815402, acc 1\n",
      "2018-04-13T15:18:38.542028: step 4100, loss 0.00299688, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:18:39.694343: step 4100, loss 1.23008, acc 0.750469\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4100\n",
      "\n",
      "2018-04-13T15:18:41.168498: step 4101, loss 0.0129249, acc 1\n",
      "2018-04-13T15:18:41.504235: step 4102, loss 0.00131653, acc 1\n",
      "2018-04-13T15:18:41.853982: step 4103, loss 0.00398751, acc 1\n",
      "2018-04-13T15:18:42.186220: step 4104, loss 0.00109062, acc 1\n",
      "2018-04-13T15:18:42.509945: step 4105, loss 0.00395335, acc 1\n",
      "2018-04-13T15:18:42.830172: step 4106, loss 0.000944565, acc 1\n",
      "2018-04-13T15:18:43.156401: step 4107, loss 0.0027311, acc 1\n",
      "2018-04-13T15:18:43.493640: step 4108, loss 0.000727203, acc 1\n",
      "2018-04-13T15:18:43.828876: step 4109, loss 0.00527159, acc 1\n",
      "2018-04-13T15:18:44.153606: step 4110, loss 0.00171155, acc 1\n",
      "2018-04-13T15:18:44.481892: step 4111, loss 0.0201401, acc 0.984375\n",
      "2018-04-13T15:18:44.842092: step 4112, loss 0.00772114, acc 1\n",
      "2018-04-13T15:18:45.150310: step 4113, loss 0.00174906, acc 1\n",
      "2018-04-13T15:18:45.459529: step 4114, loss 0.00489529, acc 1\n",
      "2018-04-13T15:18:45.792764: step 4115, loss 0.0247954, acc 0.984375\n",
      "2018-04-13T15:18:46.129000: step 4116, loss 0.00172559, acc 1\n",
      "2018-04-13T15:18:46.447726: step 4117, loss 0.000763099, acc 1\n",
      "2018-04-13T15:18:46.773956: step 4118, loss 0.00338811, acc 1\n",
      "2018-04-13T15:18:47.093182: step 4119, loss 0.00906847, acc 1\n",
      "2018-04-13T15:18:47.420913: step 4120, loss 0.0132228, acc 0.984375\n",
      "2018-04-13T15:18:47.772661: step 4121, loss 0.00485341, acc 1\n",
      "2018-04-13T15:18:48.083881: step 4122, loss 0.00426758, acc 1\n",
      "2018-04-13T15:18:48.406108: step 4123, loss 0.00288736, acc 1\n",
      "2018-04-13T15:18:48.788378: step 4124, loss 0.000548801, acc 1\n",
      "2018-04-13T15:18:49.105102: step 4125, loss 0.0140074, acc 0.984375\n",
      "2018-04-13T15:18:49.441340: step 4126, loss 0.00463958, acc 1\n",
      "2018-04-13T15:18:49.759564: step 4127, loss 0.00338257, acc 1\n",
      "2018-04-13T15:18:50.081291: step 4128, loss 0.000663648, acc 1\n",
      "2018-04-13T15:18:50.400517: step 4129, loss 0.00397694, acc 1\n",
      "2018-04-13T15:18:50.753266: step 4130, loss 0.00228642, acc 1\n",
      "2018-04-13T15:18:51.074993: step 4131, loss 0.00361609, acc 1\n",
      "2018-04-13T15:18:51.399722: step 4132, loss 0.00689918, acc 1\n",
      "2018-04-13T15:18:51.733958: step 4133, loss 0.00145325, acc 1\n",
      "2018-04-13T15:18:52.048680: step 4134, loss 0.00538025, acc 1\n",
      "2018-04-13T15:18:52.370408: step 4135, loss 0.0017925, acc 1\n",
      "2018-04-13T15:18:52.699640: step 4136, loss 0.00562527, acc 1\n",
      "2018-04-13T15:18:53.016864: step 4137, loss 0.0092508, acc 1\n",
      "2018-04-13T15:18:53.330085: step 4138, loss 0.00769923, acc 1\n",
      "2018-04-13T15:18:53.675330: step 4139, loss 0.00488022, acc 1\n",
      "2018-04-13T15:18:54.007064: step 4140, loss 0.000702007, acc 1\n",
      "2018-04-13T15:18:54.344802: step 4141, loss 0.00755092, acc 1\n",
      "2018-04-13T15:18:54.672534: step 4142, loss 0.00114465, acc 1\n",
      "2018-04-13T15:18:54.999264: step 4143, loss 0.000691749, acc 1\n",
      "2018-04-13T15:18:55.329497: step 4144, loss 0.00194085, acc 1\n",
      "2018-04-13T15:18:55.663734: step 4145, loss 0.00583232, acc 1\n",
      "2018-04-13T15:18:55.995467: step 4146, loss 0.00161391, acc 1\n",
      "2018-04-13T15:18:56.309689: step 4147, loss 0.00135206, acc 1\n",
      "2018-04-13T15:18:56.652431: step 4148, loss 0.000946495, acc 1\n",
      "2018-04-13T15:18:56.972157: step 4149, loss 0.00574975, acc 1\n",
      "2018-04-13T15:18:57.299389: step 4150, loss 0.00338036, acc 1\n",
      "2018-04-13T15:18:57.618113: step 4151, loss 0.00121437, acc 1\n",
      "2018-04-13T15:18:57.948352: step 4152, loss 0.00148369, acc 1\n",
      "2018-04-13T15:18:58.275578: step 4153, loss 0.00434251, acc 1\n",
      "2018-04-13T15:18:58.606311: step 4154, loss 0.00070561, acc 1\n",
      "2018-04-13T15:18:58.933542: step 4155, loss 0.00846555, acc 1\n",
      "2018-04-13T15:18:59.254769: step 4156, loss 0.00340325, acc 1\n",
      "2018-04-13T15:18:59.590506: step 4157, loss 0.00428496, acc 1\n",
      "2018-04-13T15:18:59.923742: step 4158, loss 0.00447738, acc 1\n",
      "2018-04-13T15:19:00.284997: step 4159, loss 0.0019124, acc 1\n",
      "2018-04-13T15:19:00.656760: step 4160, loss 0.00113604, acc 1\n",
      "2018-04-13T15:19:00.981488: step 4161, loss 0.00612601, acc 1\n",
      "2018-04-13T15:19:01.308719: step 4162, loss 0.0053321, acc 1\n",
      "2018-04-13T15:19:01.624943: step 4163, loss 0.00779978, acc 1\n",
      "2018-04-13T15:19:01.954175: step 4164, loss 0.00200067, acc 1\n",
      "2018-04-13T15:19:02.273400: step 4165, loss 0.00322635, acc 1\n",
      "2018-04-13T15:19:02.605135: step 4166, loss 0.00387698, acc 1\n",
      "2018-04-13T15:19:02.949878: step 4167, loss 0.00134709, acc 1\n",
      "2018-04-13T15:19:03.267602: step 4168, loss 0.00199094, acc 1\n",
      "2018-04-13T15:19:03.594333: step 4169, loss 0.00094122, acc 1\n",
      "2018-04-13T15:19:03.920063: step 4170, loss 0.0046698, acc 1\n",
      "2018-04-13T15:19:04.249296: step 4171, loss 0.00326845, acc 1\n",
      "2018-04-13T15:19:04.575526: step 4172, loss 0.00861428, acc 1\n",
      "2018-04-13T15:19:04.912263: step 4173, loss 0.00288025, acc 1\n",
      "2018-04-13T15:19:05.228487: step 4174, loss 0.00168473, acc 1\n",
      "2018-04-13T15:19:05.564224: step 4175, loss 0.00131544, acc 1\n",
      "2018-04-13T15:19:05.903464: step 4176, loss 0.000929849, acc 1\n",
      "2018-04-13T15:19:06.227693: step 4177, loss 0.00108279, acc 1\n",
      "2018-04-13T15:19:06.571435: step 4178, loss 0.0075993, acc 1\n",
      "2018-04-13T15:19:06.897165: step 4179, loss 0.00283861, acc 1\n",
      "2018-04-13T15:19:07.218392: step 4180, loss 0.000931435, acc 1\n",
      "2018-04-13T15:19:07.555131: step 4181, loss 0.00183956, acc 1\n",
      "2018-04-13T15:19:07.888865: step 4182, loss 0.00272656, acc 1\n",
      "2018-04-13T15:19:08.214596: step 4183, loss 0.0257287, acc 0.984375\n",
      "2018-04-13T15:19:08.545830: step 4184, loss 0.000689215, acc 1\n",
      "2018-04-13T15:19:08.895076: step 4185, loss 0.0144003, acc 0.984375\n",
      "2018-04-13T15:19:09.203794: step 4186, loss 0.000841935, acc 1\n",
      "2018-04-13T15:19:09.515014: step 4187, loss 0.0157622, acc 0.984375\n",
      "2018-04-13T15:19:09.848249: step 4188, loss 0.00524304, acc 1\n",
      "2018-04-13T15:19:10.188990: step 4189, loss 0.000998124, acc 1\n",
      "2018-04-13T15:19:10.522225: step 4190, loss 0.00556302, acc 1\n",
      "2018-04-13T15:19:10.869970: step 4191, loss 0.00200761, acc 1\n",
      "2018-04-13T15:19:11.191198: step 4192, loss 0.0107045, acc 1\n",
      "2018-04-13T15:19:11.526434: step 4193, loss 0.00066775, acc 1\n",
      "2018-04-13T15:19:11.870677: step 4194, loss 0.00423355, acc 1\n",
      "2018-04-13T15:19:12.198909: step 4195, loss 0.0094874, acc 1\n",
      "2018-04-13T15:19:12.528141: step 4196, loss 0.00344918, acc 1\n",
      "2018-04-13T15:19:12.869383: step 4197, loss 0.00333144, acc 1\n",
      "2018-04-13T15:19:13.184605: step 4198, loss 0.00335506, acc 1\n",
      "2018-04-13T15:19:13.508333: step 4199, loss 0.00265446, acc 1\n",
      "2018-04-13T15:19:13.834064: step 4200, loss 0.00294533, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:19:15.004390: step 4200, loss 1.26781, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4200\n",
      "\n",
      "2018-04-13T15:19:16.571532: step 4201, loss 0.00157889, acc 1\n",
      "2018-04-13T15:19:16.907770: step 4202, loss 0.000764015, acc 1\n",
      "2018-04-13T15:19:17.220491: step 4203, loss 0.000676182, acc 1\n",
      "2018-04-13T15:19:17.554226: step 4204, loss 0.00224253, acc 1\n",
      "2018-04-13T15:19:17.940499: step 4205, loss 0.00203953, acc 1\n",
      "2018-04-13T15:19:18.262726: step 4206, loss 0.0111759, acc 1\n",
      "2018-04-13T15:19:18.574446: step 4207, loss 0.000703987, acc 1\n",
      "2018-04-13T15:19:18.908683: step 4208, loss 0.000558453, acc 1\n",
      "2018-04-13T15:19:19.231410: step 4209, loss 0.00915774, acc 1\n",
      "2018-04-13T15:19:19.564646: step 4210, loss 0.00113538, acc 1\n",
      "2018-04-13T15:19:19.884872: step 4211, loss 0.00471692, acc 1\n",
      "2018-04-13T15:19:20.198593: step 4212, loss 0.000969077, acc 1\n",
      "2018-04-13T15:19:20.514316: step 4213, loss 0.0108741, acc 1\n",
      "2018-04-13T15:19:20.880075: step 4214, loss 0.000991537, acc 1\n",
      "2018-04-13T15:19:21.193296: step 4215, loss 0.00110487, acc 1\n",
      "2018-04-13T15:19:21.514522: step 4216, loss 0.00257713, acc 1\n",
      "2018-04-13T15:19:21.843755: step 4217, loss 0.00329808, acc 1\n",
      "2018-04-13T15:19:22.153975: step 4218, loss 0.00645445, acc 1\n",
      "2018-04-13T15:19:22.491212: step 4219, loss 0.0174728, acc 0.984375\n",
      "2018-04-13T15:19:22.826949: step 4220, loss 0.0009658, acc 1\n",
      "2018-04-13T15:19:23.137668: step 4221, loss 0.000980031, acc 1\n",
      "2018-04-13T15:19:23.456894: step 4222, loss 0.000460006, acc 1\n",
      "2018-04-13T15:19:23.831659: step 4223, loss 0.00563813, acc 1\n",
      "2018-04-13T15:19:24.159391: step 4224, loss 0.0119031, acc 1\n",
      "2018-04-13T15:19:24.509137: step 4225, loss 0.00913664, acc 1\n",
      "2018-04-13T15:19:24.837869: step 4226, loss 0.00724903, acc 1\n",
      "2018-04-13T15:19:25.165600: step 4227, loss 0.00190829, acc 1\n",
      "2018-04-13T15:19:25.492832: step 4228, loss 0.000580374, acc 1\n",
      "2018-04-13T15:19:25.817061: step 4229, loss 0.00506191, acc 1\n",
      "2018-04-13T15:19:26.138787: step 4230, loss 0.00244424, acc 1\n",
      "2018-04-13T15:19:26.462016: step 4231, loss 0.00019425, acc 1\n",
      "2018-04-13T15:19:26.825773: step 4232, loss 0.000883864, acc 1\n",
      "2018-04-13T15:19:27.144498: step 4233, loss 0.00188661, acc 1\n",
      "2018-04-13T15:19:27.461222: step 4234, loss 0.0049322, acc 1\n",
      "2018-04-13T15:19:27.786952: step 4235, loss 0.00125668, acc 1\n",
      "2018-04-13T15:19:28.101173: step 4236, loss 0.00177735, acc 1\n",
      "2018-04-13T15:19:28.433909: step 4237, loss 0.00411619, acc 1\n",
      "2018-04-13T15:19:28.766144: step 4238, loss 0.00466502, acc 1\n",
      "2018-04-13T15:19:29.098879: step 4239, loss 0.000988938, acc 1\n",
      "2018-04-13T15:19:29.407096: step 4240, loss 0.000942695, acc 1\n",
      "2018-04-13T15:19:29.753841: step 4241, loss 0.00660216, acc 1\n",
      "2018-04-13T15:19:30.086075: step 4242, loss 0.000745215, acc 1\n",
      "2018-04-13T15:19:30.402798: step 4243, loss 0.00548757, acc 1\n",
      "2018-04-13T15:19:30.729029: step 4244, loss 0.00414931, acc 1\n",
      "2018-04-13T15:19:31.050756: step 4245, loss 0.00649618, acc 1\n",
      "2018-04-13T15:19:31.389996: step 4246, loss 0.0109155, acc 1\n",
      "2018-04-13T15:19:31.727234: step 4247, loss 0.00270052, acc 1\n",
      "2018-04-13T15:19:32.047460: step 4248, loss 0.00335837, acc 1\n",
      "2018-04-13T15:19:32.353175: step 4249, loss 0.00310666, acc 1\n",
      "2018-04-13T15:19:32.703927: step 4250, loss 0.0017521, acc 1\n",
      "2018-04-13T15:19:33.052170: step 4251, loss 0.00215457, acc 1\n",
      "2018-04-13T15:19:33.376399: step 4252, loss 0.00264775, acc 1\n",
      "2018-04-13T15:19:33.696625: step 4253, loss 0.00254224, acc 1\n",
      "2018-04-13T15:19:34.017351: step 4254, loss 0.00174517, acc 1\n",
      "2018-04-13T15:19:34.346583: step 4255, loss 0.000423731, acc 1\n",
      "2018-04-13T15:19:34.666309: step 4256, loss 0.00227765, acc 1\n",
      "2018-04-13T15:19:34.987536: step 4257, loss 0.00805307, acc 1\n",
      "2018-04-13T15:19:35.319770: step 4258, loss 0.00732995, acc 1\n",
      "2018-04-13T15:19:35.647002: step 4259, loss 0.0110801, acc 1\n",
      "2018-04-13T15:19:35.999251: step 4260, loss 0.00220832, acc 1\n",
      "2018-04-13T15:19:36.307969: step 4261, loss 0.00273298, acc 1\n",
      "2018-04-13T15:19:36.631197: step 4262, loss 0.00101038, acc 1\n",
      "2018-04-13T15:19:36.956433: step 4263, loss 0.0173681, acc 0.984375\n",
      "2018-04-13T15:19:37.294171: step 4264, loss 0.00271046, acc 1\n",
      "2018-04-13T15:19:37.626907: step 4265, loss 0.0015815, acc 1\n",
      "2018-04-13T15:19:37.945631: step 4266, loss 0.00188752, acc 1\n",
      "2018-04-13T15:19:38.270360: step 4267, loss 0.00575773, acc 1\n",
      "2018-04-13T15:19:38.588585: step 4268, loss 0.000513548, acc 1\n",
      "2018-04-13T15:19:38.954844: step 4269, loss 0.00461881, acc 1\n",
      "2018-04-13T15:19:39.275570: step 4270, loss 0.00253947, acc 1\n",
      "2018-04-13T15:19:39.603302: step 4271, loss 0.00711132, acc 1\n",
      "2018-04-13T15:19:39.926030: step 4272, loss 0.000571306, acc 1\n",
      "2018-04-13T15:19:40.250259: step 4273, loss 0.0266431, acc 0.984375\n",
      "2018-04-13T15:19:40.574987: step 4274, loss 0.0139829, acc 0.984375\n",
      "2018-04-13T15:19:40.910225: step 4275, loss 0.0147085, acc 1\n",
      "2018-04-13T15:19:41.227449: step 4276, loss 0.00496383, acc 1\n",
      "2018-04-13T15:19:41.559683: step 4277, loss 0.00299978, acc 1\n",
      "2018-04-13T15:19:41.906929: step 4278, loss 0.0050214, acc 1\n",
      "2018-04-13T15:19:42.221651: step 4279, loss 0.0109308, acc 1\n",
      "2018-04-13T15:19:42.539375: step 4280, loss 0.00495923, acc 1\n",
      "2018-04-13T15:19:42.856599: step 4281, loss 0.000228139, acc 1\n",
      "2018-04-13T15:19:43.173823: step 4282, loss 0.000597087, acc 1\n",
      "2018-04-13T15:19:43.498552: step 4283, loss 0.00506446, acc 1\n",
      "2018-04-13T15:19:43.834793: step 4284, loss 0.00183365, acc 1\n",
      "2018-04-13T15:19:44.157017: step 4285, loss 0.00635839, acc 1\n",
      "2018-04-13T15:19:44.466736: step 4286, loss 0.00161332, acc 1\n",
      "2018-04-13T15:19:44.814982: step 4287, loss 0.00272684, acc 1\n",
      "2018-04-13T15:19:45.144714: step 4288, loss 0.00334959, acc 1\n",
      "2018-04-13T15:19:45.454934: step 4289, loss 0.00351788, acc 1\n",
      "2018-04-13T15:19:45.785667: step 4290, loss 0.00294019, acc 1\n",
      "2018-04-13T15:19:46.102390: step 4291, loss 0.00327225, acc 1\n",
      "2018-04-13T15:19:46.436627: step 4292, loss 0.00303476, acc 1\n",
      "2018-04-13T15:19:46.765859: step 4293, loss 0.00364432, acc 1\n",
      "2018-04-13T15:19:47.074077: step 4294, loss 0.0358956, acc 0.96875\n",
      "2018-04-13T15:19:47.393804: step 4295, loss 0.00139825, acc 1\n",
      "2018-04-13T15:19:47.729039: step 4296, loss 0.00426991, acc 1\n",
      "2018-04-13T15:19:48.045763: step 4297, loss 0.00628447, acc 1\n",
      "2018-04-13T15:19:48.365489: step 4298, loss 0.00486846, acc 1\n",
      "2018-04-13T15:19:48.688718: step 4299, loss 0.00933304, acc 1\n",
      "2018-04-13T15:19:49.015948: step 4300, loss 0.00398299, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:19:50.166261: step 4300, loss 1.26854, acc 0.751407\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4300\n",
      "\n",
      "2018-04-13T15:19:51.702109: step 4301, loss 0.00157953, acc 1\n",
      "2018-04-13T15:19:52.019332: step 4302, loss 0.00607145, acc 1\n",
      "2018-04-13T15:19:52.338558: step 4303, loss 0.00530617, acc 1\n",
      "2018-04-13T15:19:52.680799: step 4304, loss 0.019184, acc 0.984375\n",
      "2018-04-13T15:19:53.007530: step 4305, loss 0.00348884, acc 1\n",
      "2018-04-13T15:19:53.326755: step 4306, loss 0.00117469, acc 1\n",
      "2018-04-13T15:19:53.659490: step 4307, loss 0.000599542, acc 1\n",
      "2018-04-13T15:19:53.999732: step 4308, loss 0.0121503, acc 0.984375\n",
      "2018-04-13T15:19:54.335467: step 4309, loss 0.000436173, acc 1\n",
      "2018-04-13T15:19:54.657695: step 4310, loss 0.00304298, acc 1\n",
      "2018-04-13T15:19:54.976919: step 4311, loss 0.00151314, acc 1\n",
      "2018-04-13T15:19:55.302151: step 4312, loss 0.00637167, acc 1\n",
      "2018-04-13T15:19:55.642390: step 4313, loss 0.00207259, acc 1\n",
      "2018-04-13T15:19:55.965618: step 4314, loss 0.00920283, acc 1\n",
      "2018-04-13T15:19:56.291848: step 4315, loss 0.00191537, acc 1\n",
      "2018-04-13T15:19:56.624584: step 4316, loss 0.00100311, acc 1\n",
      "2018-04-13T15:19:56.963823: step 4317, loss 0.00214814, acc 1\n",
      "2018-04-13T15:19:57.280046: step 4318, loss 0.00528993, acc 1\n",
      "2018-04-13T15:19:57.597270: step 4319, loss 0.00118827, acc 1\n",
      "2018-04-13T15:19:57.921999: step 4320, loss 0.00101255, acc 1\n",
      "2018-04-13T15:19:58.234721: step 4321, loss 0.00706503, acc 1\n",
      "2018-04-13T15:19:58.568456: step 4322, loss 0.00206905, acc 1\n",
      "2018-04-13T15:19:58.887682: step 4323, loss 0.00146567, acc 1\n",
      "2018-04-13T15:19:59.218916: step 4324, loss 0.000346076, acc 1\n",
      "2018-04-13T15:19:59.538141: step 4325, loss 0.000509892, acc 1\n",
      "2018-04-13T15:19:59.886887: step 4326, loss 0.00167965, acc 1\n",
      "2018-04-13T15:20:00.208114: step 4327, loss 0.00184397, acc 1\n",
      "2018-04-13T15:20:00.540349: step 4328, loss 0.00527491, acc 1\n",
      "2018-04-13T15:20:00.868580: step 4329, loss 0.00203506, acc 1\n",
      "2018-04-13T15:20:01.180300: step 4330, loss 0.000933542, acc 1\n",
      "2018-04-13T15:20:01.513036: step 4331, loss 0.00291194, acc 1\n",
      "2018-04-13T15:20:01.857779: step 4332, loss 0.00552756, acc 1\n",
      "2018-04-13T15:20:02.172000: step 4333, loss 0.00226931, acc 1\n",
      "2018-04-13T15:20:02.487723: step 4334, loss 0.00154844, acc 1\n",
      "2018-04-13T15:20:02.833969: step 4335, loss 0.000819142, acc 1\n",
      "2018-04-13T15:20:03.163200: step 4336, loss 0.00334138, acc 1\n",
      "2018-04-13T15:20:03.470917: step 4337, loss 0.00402585, acc 1\n",
      "2018-04-13T15:20:03.805154: step 4338, loss 0.0216879, acc 0.984375\n",
      "2018-04-13T15:20:04.133887: step 4339, loss 0.00125606, acc 1\n",
      "2018-04-13T15:20:04.454612: step 4340, loss 0.00413449, acc 1\n",
      "2018-04-13T15:20:04.801857: step 4341, loss 0.00337042, acc 1\n",
      "2018-04-13T15:20:05.117580: step 4342, loss 0.00211864, acc 1\n",
      "2018-04-13T15:20:05.433304: step 4343, loss 0.000434282, acc 1\n",
      "2018-04-13T15:20:05.776046: step 4344, loss 0.000680524, acc 1\n",
      "2018-04-13T15:20:06.093769: step 4345, loss 0.00506238, acc 1\n",
      "2018-04-13T15:20:06.402988: step 4346, loss 0.00221614, acc 1\n",
      "2018-04-13T15:20:06.732721: step 4347, loss 0.00162181, acc 1\n",
      "2018-04-13T15:20:07.056950: step 4348, loss 0.0132313, acc 0.984375\n",
      "2018-04-13T15:20:07.379177: step 4349, loss 0.00254089, acc 1\n",
      "2018-04-13T15:20:07.700404: step 4350, loss 0.00269787, acc 1\n",
      "2018-04-13T15:20:08.022632: step 4351, loss 0.00463447, acc 1\n",
      "2018-04-13T15:20:08.347861: step 4352, loss 0.00058985, acc 1\n",
      "2018-04-13T15:20:08.682098: step 4353, loss 0.00152749, acc 1\n",
      "2018-04-13T15:20:09.029343: step 4354, loss 0.00159874, acc 1\n",
      "2018-04-13T15:20:09.359079: step 4355, loss 0.0165371, acc 0.984375\n",
      "2018-04-13T15:20:09.680302: step 4356, loss 0.0156856, acc 0.984375\n",
      "2018-04-13T15:20:10.001029: step 4357, loss 0.00238349, acc 1\n",
      "2018-04-13T15:20:10.310247: step 4358, loss 0.00171862, acc 1\n",
      "2018-04-13T15:20:10.650487: step 4359, loss 0.00104855, acc 1\n",
      "2018-04-13T15:20:10.981221: step 4360, loss 0.00686084, acc 1\n",
      "2018-04-13T15:20:11.301447: step 4361, loss 0.00164541, acc 1\n",
      "2018-04-13T15:20:11.610165: step 4362, loss 0.00344478, acc 1\n",
      "2018-04-13T15:20:11.973424: step 4363, loss 0.00644059, acc 1\n",
      "2018-04-13T15:20:12.294648: step 4364, loss 0.00379021, acc 1\n",
      "2018-04-13T15:20:12.613874: step 4365, loss 0.00246521, acc 1\n",
      "2018-04-13T15:20:12.934100: step 4366, loss 0.00343255, acc 1\n",
      "2018-04-13T15:20:13.258829: step 4367, loss 0.0028896, acc 1\n",
      "2018-04-13T15:20:13.587061: step 4368, loss 0.00162786, acc 1\n",
      "2018-04-13T15:20:13.915793: step 4369, loss 0.00146456, acc 1\n",
      "2018-04-13T15:20:14.239522: step 4370, loss 0.000753007, acc 1\n",
      "2018-04-13T15:20:14.561249: step 4371, loss 0.000241081, acc 1\n",
      "2018-04-13T15:20:14.928008: step 4372, loss 0.0044875, acc 1\n",
      "2018-04-13T15:20:15.249736: step 4373, loss 0.00251192, acc 1\n",
      "2018-04-13T15:20:15.564457: step 4374, loss 0.0024481, acc 1\n",
      "2018-04-13T15:20:15.921709: step 4375, loss 0.00548273, acc 1\n",
      "2018-04-13T15:20:16.242436: step 4376, loss 0.00049799, acc 1\n",
      "2018-04-13T15:20:16.556157: step 4377, loss 0.00193037, acc 1\n",
      "2018-04-13T15:20:16.905905: step 4378, loss 0.00155045, acc 1\n",
      "2018-04-13T15:20:17.235138: step 4379, loss 0.00225947, acc 1\n",
      "2018-04-13T15:20:17.559365: step 4380, loss 0.0181535, acc 0.984375\n",
      "2018-04-13T15:20:17.926625: step 4381, loss 0.00178276, acc 1\n",
      "2018-04-13T15:20:18.247853: step 4382, loss 0.00426091, acc 1\n",
      "2018-04-13T15:20:18.565076: step 4383, loss 0.00421367, acc 1\n",
      "2018-04-13T15:20:18.897310: step 4384, loss 0.00235868, acc 1\n",
      "2018-04-13T15:20:19.219038: step 4385, loss 0.00176968, acc 1\n",
      "2018-04-13T15:20:19.547270: step 4386, loss 0.00655814, acc 1\n",
      "2018-04-13T15:20:19.878503: step 4387, loss 0.00125519, acc 1\n",
      "2018-04-13T15:20:20.203733: step 4388, loss 0.00278253, acc 1\n",
      "2018-04-13T15:20:20.510450: step 4389, loss 0.000724235, acc 1\n",
      "2018-04-13T15:20:20.888716: step 4390, loss 0.00519229, acc 1\n",
      "2018-04-13T15:20:21.214947: step 4391, loss 0.00108741, acc 1\n",
      "2018-04-13T15:20:21.525667: step 4392, loss 0.0017409, acc 1\n",
      "2018-04-13T15:20:21.855900: step 4393, loss 0.00174014, acc 1\n",
      "2018-04-13T15:20:22.173624: step 4394, loss 0.000439098, acc 1\n",
      "2018-04-13T15:20:22.485845: step 4395, loss 0.000798493, acc 1\n",
      "2018-04-13T15:20:22.811575: step 4396, loss 0.000534838, acc 1\n",
      "2018-04-13T15:20:23.131801: step 4397, loss 0.00410186, acc 1\n",
      "2018-04-13T15:20:23.457031: step 4398, loss 0.0132264, acc 0.984375\n",
      "2018-04-13T15:20:23.790766: step 4399, loss 0.000562832, acc 1\n",
      "2018-04-13T15:20:24.129505: step 4400, loss 0.000229311, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:20:25.263806: step 4400, loss 1.30083, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4400\n",
      "\n",
      "2018-04-13T15:20:26.897866: step 4401, loss 0.00547045, acc 1\n",
      "2018-04-13T15:20:27.226599: step 4402, loss 0.00420737, acc 1\n",
      "2018-04-13T15:20:27.537818: step 4403, loss 0.0006539, acc 1\n",
      "2018-04-13T15:20:27.859546: step 4404, loss 0.00885501, acc 1\n",
      "2018-04-13T15:20:28.195783: step 4405, loss 0.00402991, acc 1\n",
      "2018-04-13T15:20:28.518512: step 4406, loss 0.000527633, acc 1\n",
      "2018-04-13T15:20:28.849245: step 4407, loss 0.00290367, acc 1\n",
      "2018-04-13T15:20:29.162966: step 4408, loss 0.00478119, acc 1\n",
      "2018-04-13T15:20:29.500705: step 4409, loss 0.000497475, acc 1\n",
      "2018-04-13T15:20:29.832940: step 4410, loss 0.000496348, acc 1\n",
      "2018-04-13T15:20:30.162672: step 4411, loss 0.00307205, acc 1\n",
      "2018-04-13T15:20:30.483902: step 4412, loss 0.00119473, acc 1\n",
      "2018-04-13T15:20:30.803124: step 4413, loss 0.0077173, acc 1\n",
      "2018-04-13T15:20:31.118346: step 4414, loss 0.00294758, acc 1\n",
      "2018-04-13T15:20:31.433069: step 4415, loss 0.000381113, acc 1\n",
      "2018-04-13T15:20:31.766305: step 4416, loss 0.0241868, acc 0.984375\n",
      "2018-04-13T15:20:32.084028: step 4417, loss 0.0338409, acc 0.984375\n",
      "2018-04-13T15:20:32.404755: step 4418, loss 0.000973618, acc 1\n",
      "2018-04-13T15:20:32.727983: step 4419, loss 0.00248227, acc 1\n",
      "2018-04-13T15:20:33.063725: step 4420, loss 0.000385608, acc 1\n",
      "2018-04-13T15:20:33.382945: step 4421, loss 0.00109761, acc 1\n",
      "2018-04-13T15:20:33.707175: step 4422, loss 0.00266379, acc 1\n",
      "2018-04-13T15:20:34.028402: step 4423, loss 0.00156077, acc 1\n",
      "2018-04-13T15:20:34.349628: step 4424, loss 0.0143002, acc 1\n",
      "2018-04-13T15:20:34.681363: step 4425, loss 0.00360088, acc 1\n",
      "2018-04-13T15:20:35.004591: step 4426, loss 0.00582, acc 1\n",
      "2018-04-13T15:20:35.318813: step 4427, loss 0.000520992, acc 1\n",
      "2018-04-13T15:20:35.635037: step 4428, loss 0.00567859, acc 1\n",
      "2018-04-13T15:20:35.991287: step 4429, loss 0.00552268, acc 1\n",
      "2018-04-13T15:20:36.308012: step 4430, loss 0.0118448, acc 1\n",
      "2018-04-13T15:20:36.619731: step 4431, loss 0.00300907, acc 1\n",
      "2018-04-13T15:20:36.959471: step 4432, loss 0.000632409, acc 1\n",
      "2018-04-13T15:20:37.276195: step 4433, loss 0.00186365, acc 1\n",
      "2018-04-13T15:20:37.596421: step 4434, loss 0.00085932, acc 1\n",
      "2018-04-13T15:20:37.933659: step 4435, loss 0.0029975, acc 1\n",
      "2018-04-13T15:20:38.243878: step 4436, loss 0.00669467, acc 1\n",
      "2018-04-13T15:20:38.575112: step 4437, loss 0.00884739, acc 1\n",
      "2018-04-13T15:20:38.926360: step 4438, loss 0.00189808, acc 1\n",
      "2018-04-13T15:20:39.282612: step 4439, loss 0.00987633, acc 1\n",
      "2018-04-13T15:20:39.653874: step 4440, loss 0.000920161, acc 1\n",
      "2018-04-13T15:20:39.996115: step 4441, loss 0.00481645, acc 1\n",
      "2018-04-13T15:20:40.341360: step 4442, loss 0.00295448, acc 1\n",
      "2018-04-13T15:20:40.712121: step 4443, loss 0.00593438, acc 1\n",
      "2018-04-13T15:20:41.134920: step 4444, loss 0.0070898, acc 1\n",
      "2018-04-13T15:20:41.463652: step 4445, loss 0.00263587, acc 1\n",
      "2018-04-13T15:20:41.795385: step 4446, loss 0.00848768, acc 1\n",
      "2018-04-13T15:20:42.247206: step 4447, loss 0.00169444, acc 1\n",
      "2018-04-13T15:20:42.655494: step 4448, loss 0.00144095, acc 1\n",
      "2018-04-13T15:20:43.107312: step 4449, loss 0.000351369, acc 1\n",
      "2018-04-13T15:20:43.489082: step 4450, loss 0.00101368, acc 1\n",
      "2018-04-13T15:20:43.880359: step 4451, loss 0.0370082, acc 0.984375\n",
      "2018-04-13T15:20:44.216096: step 4452, loss 0.00494314, acc 1\n",
      "2018-04-13T15:20:44.657911: step 4453, loss 0.000972438, acc 1\n",
      "2018-04-13T15:20:45.061192: step 4454, loss 0.00288239, acc 1\n",
      "2018-04-13T15:20:45.449466: step 4455, loss 0.00099454, acc 1\n",
      "2018-04-13T15:20:45.888777: step 4456, loss 0.000736625, acc 1\n",
      "2018-04-13T15:20:46.295063: step 4457, loss 0.00346, acc 1\n",
      "2018-04-13T15:20:46.629799: step 4458, loss 0.00193874, acc 1\n",
      "2018-04-13T15:20:46.957531: step 4459, loss 0.00145354, acc 1\n",
      "2018-04-13T15:20:47.267750: step 4460, loss 0.00128337, acc 1\n",
      "2018-04-13T15:20:47.643515: step 4461, loss 0.00849045, acc 1\n",
      "2018-04-13T15:20:48.015278: step 4462, loss 0.00107769, acc 1\n",
      "2018-04-13T15:20:48.331001: step 4463, loss 0.00154394, acc 1\n",
      "2018-04-13T15:20:48.749797: step 4464, loss 0.00718171, acc 1\n",
      "2018-04-13T15:20:49.136069: step 4465, loss 0.00193176, acc 1\n",
      "2018-04-13T15:20:49.445788: step 4466, loss 0.00439391, acc 1\n",
      "2018-04-13T15:20:49.768517: step 4467, loss 0.00560694, acc 1\n",
      "2018-04-13T15:20:50.082747: step 4468, loss 0.00138383, acc 1\n",
      "2018-04-13T15:20:50.440500: step 4469, loss 0.0180152, acc 0.984375\n",
      "2018-04-13T15:20:50.821769: step 4470, loss 0.00706948, acc 1\n",
      "2018-04-13T15:20:51.172517: step 4471, loss 0.00419733, acc 1\n",
      "2018-04-13T15:20:51.546280: step 4472, loss 0.00100004, acc 1\n",
      "2018-04-13T15:20:51.906535: step 4473, loss 0.00535795, acc 1\n",
      "2018-04-13T15:20:52.291306: step 4474, loss 0.00328138, acc 1\n",
      "2018-04-13T15:20:52.632547: step 4475, loss 0.00120644, acc 1\n",
      "2018-04-13T15:20:52.991801: step 4476, loss 0.00170389, acc 1\n",
      "2018-04-13T15:20:53.341548: step 4477, loss 0.00219861, acc 1\n",
      "2018-04-13T15:20:53.760844: step 4478, loss 0.00220788, acc 1\n",
      "2018-04-13T15:20:54.128103: step 4479, loss 0.00175778, acc 1\n",
      "2018-04-13T15:20:54.457836: step 4480, loss 0.00212401, acc 1\n",
      "2018-04-13T15:20:54.809084: step 4481, loss 0.00129293, acc 1\n",
      "2018-04-13T15:20:55.126808: step 4482, loss 0.00169278, acc 1\n",
      "2018-04-13T15:20:55.441531: step 4483, loss 0.000892063, acc 1\n",
      "2018-04-13T15:20:55.767761: step 4484, loss 0.0201514, acc 0.984375\n",
      "2018-04-13T15:20:56.086986: step 4485, loss 0.00547829, acc 1\n",
      "2018-04-13T15:20:56.415718: step 4486, loss 0.000390885, acc 1\n",
      "2018-04-13T15:20:56.754958: step 4487, loss 0.00279361, acc 1\n",
      "2018-04-13T15:20:57.066178: step 4488, loss 0.0141229, acc 0.984375\n",
      "2018-04-13T15:20:57.396911: step 4489, loss 0.00546309, acc 1\n",
      "2018-04-13T15:20:57.754164: step 4490, loss 0.0111692, acc 1\n",
      "2018-04-13T15:20:58.077893: step 4491, loss 0.0823298, acc 0.984375\n",
      "2018-04-13T15:20:58.400119: step 4492, loss 0.00146524, acc 1\n",
      "2018-04-13T15:20:58.712841: step 4493, loss 0.00571227, acc 1\n",
      "2018-04-13T15:20:59.033567: step 4494, loss 0.00326413, acc 1\n",
      "2018-04-13T15:20:59.345287: step 4495, loss 0.00703771, acc 1\n",
      "2018-04-13T15:20:59.668015: step 4496, loss 0.0147484, acc 0.984375\n",
      "2018-04-13T15:20:59.998748: step 4497, loss 0.00101057, acc 1\n",
      "2018-04-13T15:21:00.319474: step 4498, loss 0.001471, acc 1\n",
      "2018-04-13T15:21:00.680730: step 4499, loss 0.00526628, acc 1\n",
      "2018-04-13T15:21:01.005962: step 4500, loss 0.000380136, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:21:02.169281: step 4500, loss 1.3053, acc 0.751407\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4500\n",
      "\n",
      "2018-04-13T15:21:03.799576: step 4501, loss 0.00554214, acc 1\n",
      "2018-04-13T15:21:04.191853: step 4502, loss 0.00135146, acc 1\n",
      "2018-04-13T15:21:04.505075: step 4503, loss 0.00104648, acc 1\n",
      "2018-04-13T15:21:04.884843: step 4504, loss 0.000790715, acc 1\n",
      "2018-04-13T15:21:05.261109: step 4505, loss 0.00444579, acc 1\n",
      "2018-04-13T15:21:05.645380: step 4506, loss 0.00139132, acc 1\n",
      "2018-04-13T15:21:06.018144: step 4507, loss 0.00121324, acc 1\n",
      "2018-04-13T15:21:06.356882: step 4508, loss 0.00212019, acc 1\n",
      "2018-04-13T15:21:06.726143: step 4509, loss 0.000594901, acc 1\n",
      "2018-04-13T15:21:07.057377: step 4510, loss 0.0047141, acc 1\n",
      "2018-04-13T15:21:07.375101: step 4511, loss 0.0253592, acc 0.984375\n",
      "2018-04-13T15:21:07.689323: step 4512, loss 0.00618599, acc 1\n",
      "2018-04-13T15:21:08.017555: step 4513, loss 0.00295442, acc 1\n",
      "2018-04-13T15:21:08.340282: step 4514, loss 0.000459672, acc 1\n",
      "2018-04-13T15:21:08.651503: step 4515, loss 0.00763973, acc 1\n",
      "2018-04-13T15:21:08.966225: step 4516, loss 0.00200241, acc 1\n",
      "2018-04-13T15:21:09.280947: step 4517, loss 0.00433328, acc 1\n",
      "2018-04-13T15:21:09.636198: step 4518, loss 0.00970334, acc 1\n",
      "2018-04-13T15:21:09.966431: step 4519, loss 0.00210744, acc 1\n",
      "2018-04-13T15:21:10.287157: step 4520, loss 0.00225424, acc 1\n",
      "2018-04-13T15:21:10.609891: step 4521, loss 0.00694383, acc 1\n",
      "2018-04-13T15:21:10.937617: step 4522, loss 0.000721307, acc 1\n",
      "2018-04-13T15:21:11.343403: step 4523, loss 0.00148461, acc 1\n",
      "2018-04-13T15:21:11.906802: step 4524, loss 0.00366145, acc 1\n",
      "2018-04-13T15:21:12.308085: step 4525, loss 0.000753605, acc 1\n",
      "2018-04-13T15:21:12.764415: step 4526, loss 0.000328633, acc 1\n",
      "2018-04-13T15:21:13.105163: step 4527, loss 0.0016557, acc 1\n",
      "2018-04-13T15:21:13.419384: step 4528, loss 0.00217801, acc 1\n",
      "2018-04-13T15:21:13.746115: step 4529, loss 0.0010342, acc 1\n",
      "2018-04-13T15:21:14.068843: step 4530, loss 0.000774962, acc 1\n",
      "2018-04-13T15:21:14.393573: step 4531, loss 0.00566681, acc 1\n",
      "2018-04-13T15:21:14.726808: step 4532, loss 0.00237207, acc 1\n",
      "2018-04-13T15:21:15.049535: step 4533, loss 0.00165473, acc 1\n",
      "2018-04-13T15:21:15.390777: step 4534, loss 0.00323819, acc 1\n",
      "2018-04-13T15:21:15.757536: step 4535, loss 0.00120521, acc 1\n",
      "2018-04-13T15:21:16.087268: step 4536, loss 0.00192761, acc 1\n",
      "2018-04-13T15:21:16.420003: step 4537, loss 0.000721082, acc 1\n",
      "2018-04-13T15:21:16.758742: step 4538, loss 0.00844063, acc 1\n",
      "2018-04-13T15:21:17.082971: step 4539, loss 0.000963081, acc 1\n",
      "2018-04-13T15:21:17.409201: step 4540, loss 0.00120378, acc 1\n",
      "2018-04-13T15:21:17.746940: step 4541, loss 0.00230208, acc 1\n",
      "2018-04-13T15:21:18.079174: step 4542, loss 0.0116188, acc 0.984375\n",
      "2018-04-13T15:21:18.450937: step 4543, loss 0.000835482, acc 1\n",
      "2018-04-13T15:21:18.842715: step 4544, loss 0.0242115, acc 0.984375\n",
      "2018-04-13T15:21:19.160439: step 4545, loss 0.00139559, acc 1\n",
      "2018-04-13T15:21:19.496675: step 4546, loss 0.00335745, acc 1\n",
      "2018-04-13T15:21:19.830411: step 4547, loss 0.00148906, acc 1\n",
      "2018-04-13T15:21:20.308250: step 4548, loss 0.00186821, acc 1\n",
      "2018-04-13T15:21:20.733549: step 4549, loss 0.00105132, acc 1\n",
      "2018-04-13T15:21:21.084797: step 4550, loss 0.00283399, acc 1\n",
      "2018-04-13T15:21:21.433043: step 4551, loss 0.00188656, acc 1\n",
      "2018-04-13T15:21:21.840831: step 4552, loss 0.000888013, acc 1\n",
      "2018-04-13T15:21:22.244115: step 4553, loss 0.000476069, acc 1\n",
      "2018-04-13T15:21:22.583356: step 4554, loss 0.000942062, acc 1\n",
      "2018-04-13T15:21:22.912588: step 4555, loss 0.0154963, acc 1\n",
      "2018-04-13T15:21:23.274843: step 4556, loss 0.000328696, acc 1\n",
      "2018-04-13T15:21:23.616084: step 4557, loss 0.000839305, acc 1\n",
      "2018-04-13T15:21:23.935810: step 4558, loss 0.00123892, acc 1\n",
      "2018-04-13T15:21:24.253534: step 4559, loss 0.0247718, acc 0.984375\n",
      "2018-04-13T15:21:24.604782: step 4560, loss 0.00109677, acc 1\n",
      "2018-04-13T15:21:24.978547: step 4561, loss 0.00788765, acc 1\n",
      "2018-04-13T15:21:25.328293: step 4562, loss 0.0846929, acc 0.96875\n",
      "2018-04-13T15:21:25.659027: step 4563, loss 0.000194196, acc 1\n",
      "2018-04-13T15:21:26.054807: step 4564, loss 0.00132129, acc 1\n",
      "2018-04-13T15:21:26.588683: step 4565, loss 0.00347011, acc 1\n",
      "2018-04-13T15:21:26.926922: step 4566, loss 0.00129552, acc 1\n",
      "2018-04-13T15:21:27.272166: step 4567, loss 0.00179762, acc 1\n",
      "2018-04-13T15:21:27.632420: step 4568, loss 0.00215741, acc 1\n",
      "2018-04-13T15:21:27.955649: step 4569, loss 0.00416415, acc 1\n",
      "2018-04-13T15:21:28.283380: step 4570, loss 0.00272103, acc 1\n",
      "2018-04-13T15:21:28.608110: step 4571, loss 0.0204947, acc 0.984375\n",
      "2018-04-13T15:21:28.953354: step 4572, loss 0.0103412, acc 1\n",
      "2018-04-13T15:21:29.268575: step 4573, loss 0.00224238, acc 1\n",
      "2018-04-13T15:21:29.582297: step 4574, loss 0.00489359, acc 1\n",
      "2018-04-13T15:21:29.906526: step 4575, loss 0.00239246, acc 1\n",
      "2018-04-13T15:21:30.372356: step 4576, loss 0.00154802, acc 1\n",
      "2018-04-13T15:21:30.782148: step 4577, loss 0.000691449, acc 1\n",
      "2018-04-13T15:21:31.164615: step 4578, loss 0.00645432, acc 1\n",
      "2018-04-13T15:21:31.503855: step 4579, loss 0.00402339, acc 1\n",
      "2018-04-13T15:21:31.848598: step 4580, loss 0.00105973, acc 1\n",
      "2018-04-13T15:21:32.164821: step 4581, loss 0.0142386, acc 0.984375\n",
      "2018-04-13T15:21:32.476041: step 4582, loss 0.00153746, acc 1\n",
      "2018-04-13T15:21:32.807776: step 4583, loss 0.00509842, acc 1\n",
      "2018-04-13T15:21:33.136507: step 4584, loss 0.000806969, acc 1\n",
      "2018-04-13T15:21:33.472245: step 4585, loss 0.00339843, acc 1\n",
      "2018-04-13T15:21:33.855515: step 4586, loss 0.00104231, acc 1\n",
      "2018-04-13T15:21:34.181745: step 4587, loss 0.0010588, acc 1\n",
      "2018-04-13T15:21:34.500470: step 4588, loss 0.0116165, acc 1\n",
      "2018-04-13T15:21:34.815193: step 4589, loss 0.00245242, acc 1\n",
      "2018-04-13T15:21:35.136920: step 4590, loss 0.000717937, acc 1\n",
      "2018-04-13T15:21:35.459647: step 4591, loss 0.00197233, acc 1\n",
      "2018-04-13T15:21:35.791382: step 4592, loss 0.00120877, acc 1\n",
      "2018-04-13T15:21:36.114110: step 4593, loss 0.00026174, acc 1\n",
      "2018-04-13T15:21:36.432335: step 4594, loss 0.00682178, acc 1\n",
      "2018-04-13T15:21:36.788586: step 4595, loss 0.00138198, acc 1\n",
      "2018-04-13T15:21:37.098805: step 4596, loss 0.0215989, acc 0.984375\n",
      "2018-04-13T15:21:37.434042: step 4597, loss 0.00780773, acc 1\n",
      "2018-04-13T15:21:37.752767: step 4598, loss 0.000372065, acc 1\n",
      "2018-04-13T15:21:38.067489: step 4599, loss 0.000378773, acc 1\n",
      "2018-04-13T15:21:38.382211: step 4600, loss 0.00158606, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:21:39.519515: step 4600, loss 1.30976, acc 0.752345\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4600\n",
      "\n",
      "2018-04-13T15:21:41.126722: step 4601, loss 0.00108971, acc 1\n",
      "2018-04-13T15:21:41.448949: step 4602, loss 0.00625427, acc 1\n",
      "2018-04-13T15:21:41.760670: step 4603, loss 0.00119774, acc 1\n",
      "2018-04-13T15:21:42.076392: step 4604, loss 0.0019954, acc 1\n",
      "2018-04-13T15:21:42.393116: step 4605, loss 0.00433309, acc 1\n",
      "2018-04-13T15:21:42.755873: step 4606, loss 0.000499203, acc 1\n",
      "2018-04-13T15:21:43.077099: step 4607, loss 0.000891074, acc 1\n",
      "2018-04-13T15:21:43.395824: step 4608, loss 0.00105388, acc 1\n",
      "2018-04-13T15:21:43.715049: step 4609, loss 0.000693334, acc 1\n",
      "2018-04-13T15:21:44.038778: step 4610, loss 0.00204229, acc 1\n",
      "2018-04-13T15:21:44.347996: step 4611, loss 0.00815369, acc 1\n",
      "2018-04-13T15:21:44.662218: step 4612, loss 0.00223209, acc 1\n",
      "2018-04-13T15:21:44.990950: step 4613, loss 0.00467052, acc 1\n",
      "2018-04-13T15:21:45.316680: step 4614, loss 0.0555113, acc 0.96875\n",
      "2018-04-13T15:21:45.688443: step 4615, loss 0.00137297, acc 1\n",
      "2018-04-13T15:21:46.029234: step 4616, loss 0.00435304, acc 1\n",
      "2018-04-13T15:21:46.350962: step 4617, loss 0.00118617, acc 1\n",
      "2018-04-13T15:21:46.664683: step 4618, loss 0.0147737, acc 0.984375\n",
      "2018-04-13T15:21:46.986910: step 4619, loss 0.00102017, acc 1\n",
      "2018-04-13T15:21:47.311138: step 4620, loss 0.00251701, acc 1\n",
      "2018-04-13T15:21:47.638370: step 4621, loss 0.00519899, acc 1\n",
      "2018-04-13T15:21:47.995622: step 4622, loss 0.0111131, acc 1\n",
      "2018-04-13T15:21:48.310845: step 4623, loss 0.000471208, acc 1\n",
      "2018-04-13T15:21:48.670098: step 4624, loss 0.00117766, acc 1\n",
      "2018-04-13T15:21:49.012340: step 4625, loss 0.00579789, acc 1\n",
      "2018-04-13T15:21:49.363588: step 4626, loss 0.0143659, acc 1\n",
      "2018-04-13T15:21:49.704829: step 4627, loss 0.0371547, acc 0.984375\n",
      "2018-04-13T15:21:50.041066: step 4628, loss 0.00172079, acc 1\n",
      "2018-04-13T15:21:50.370299: step 4629, loss 0.00349523, acc 1\n",
      "2018-04-13T15:21:50.735056: step 4630, loss 0.00187763, acc 1\n",
      "2018-04-13T15:21:51.072294: step 4631, loss 0.00421005, acc 1\n",
      "2018-04-13T15:21:51.410033: step 4632, loss 0.000955638, acc 1\n",
      "2018-04-13T15:21:51.783797: step 4633, loss 0.0041748, acc 1\n",
      "2018-04-13T15:21:52.118533: step 4634, loss 0.000599512, acc 1\n",
      "2018-04-13T15:21:52.456772: step 4635, loss 0.00084591, acc 1\n",
      "2018-04-13T15:21:52.806020: step 4636, loss 0.00110143, acc 1\n",
      "2018-04-13T15:21:53.246831: step 4637, loss 0.00571808, acc 1\n",
      "2018-04-13T15:21:53.601580: step 4638, loss 0.00650499, acc 1\n",
      "2018-04-13T15:21:53.982849: step 4639, loss 0.00426299, acc 1\n",
      "2018-04-13T15:21:54.346607: step 4640, loss 0.000961281, acc 1\n",
      "2018-04-13T15:21:54.745388: step 4641, loss 0.00512707, acc 1\n",
      "2018-04-13T15:21:55.098638: step 4642, loss 0.0727204, acc 0.984375\n",
      "2018-04-13T15:21:55.428370: step 4643, loss 0.000414094, acc 1\n",
      "2018-04-13T15:21:55.752607: step 4644, loss 0.00145396, acc 1\n",
      "2018-04-13T15:21:56.069324: step 4645, loss 0.0104794, acc 1\n",
      "2018-04-13T15:21:56.380543: step 4646, loss 0.000725007, acc 1\n",
      "2018-04-13T15:21:56.708274: step 4647, loss 0.0022217, acc 1\n",
      "2018-04-13T15:21:57.029501: step 4648, loss 0.000993754, acc 1\n",
      "2018-04-13T15:21:57.344223: step 4649, loss 0.00249947, acc 1\n",
      "2018-04-13T15:21:57.681461: step 4650, loss 0.00648571, acc 1\n",
      "2018-04-13T15:21:58.015197: step 4651, loss 0.00415423, acc 1\n",
      "2018-04-13T15:21:58.327917: step 4652, loss 0.00878731, acc 1\n",
      "2018-04-13T15:21:58.635635: step 4653, loss 0.00130012, acc 1\n",
      "2018-04-13T15:21:58.959364: step 4654, loss 0.00388086, acc 1\n",
      "2018-04-13T15:21:59.278089: step 4655, loss 0.00179986, acc 1\n",
      "2018-04-13T15:21:59.600817: step 4656, loss 0.0201763, acc 0.984375\n",
      "2018-04-13T15:21:59.928048: step 4657, loss 0.000370433, acc 1\n",
      "2018-04-13T15:22:00.249776: step 4658, loss 0.00740853, acc 1\n",
      "2018-04-13T15:22:00.590516: step 4659, loss 0.0173079, acc 0.984375\n",
      "2018-04-13T15:22:00.951270: step 4660, loss 0.000749031, acc 1\n",
      "2018-04-13T15:22:01.267994: step 4661, loss 0.00565049, acc 1\n",
      "2018-04-13T15:22:01.583717: step 4662, loss 0.00275232, acc 1\n",
      "2018-04-13T15:22:01.907957: step 4663, loss 0.00523862, acc 1\n",
      "2018-04-13T15:22:02.243194: step 4664, loss 0.000741335, acc 1\n",
      "2018-04-13T15:22:02.560417: step 4665, loss 0.000727535, acc 1\n",
      "2018-04-13T15:22:02.888149: step 4666, loss 0.00403278, acc 1\n",
      "2018-04-13T15:22:03.211881: step 4667, loss 0.00144253, acc 1\n",
      "2018-04-13T15:22:03.556621: step 4668, loss 0.00160421, acc 1\n",
      "2018-04-13T15:22:03.897862: step 4669, loss 0.000938203, acc 1\n",
      "2018-04-13T15:22:04.218588: step 4670, loss 0.0361541, acc 0.984375\n",
      "2018-04-13T15:22:04.532810: step 4671, loss 0.00438633, acc 1\n",
      "2018-04-13T15:22:04.862543: step 4672, loss 0.001785, acc 1\n",
      "2018-04-13T15:22:05.177765: step 4673, loss 0.0225701, acc 0.984375\n",
      "2018-04-13T15:22:05.496491: step 4674, loss 0.00345418, acc 1\n",
      "2018-04-13T15:22:05.822721: step 4675, loss 0.000605406, acc 1\n",
      "2018-04-13T15:22:06.138945: step 4676, loss 0.000604309, acc 1\n",
      "2018-04-13T15:22:06.483187: step 4677, loss 0.00293756, acc 1\n",
      "2018-04-13T15:22:06.839939: step 4678, loss 0.000612287, acc 1\n",
      "2018-04-13T15:22:07.166670: step 4679, loss 0.00208234, acc 1\n",
      "2018-04-13T15:22:07.483894: step 4680, loss 0.00426564, acc 1\n",
      "2018-04-13T15:22:07.822132: step 4681, loss 0.0025273, acc 1\n",
      "2018-04-13T15:22:08.144361: step 4682, loss 0.0224269, acc 0.984375\n",
      "2018-04-13T15:22:08.458082: step 4683, loss 0.00116062, acc 1\n",
      "2018-04-13T15:22:08.770302: step 4684, loss 0.0040803, acc 1\n",
      "2018-04-13T15:22:09.090529: step 4685, loss 0.00139573, acc 1\n",
      "2018-04-13T15:22:09.410254: step 4686, loss 0.000977014, acc 1\n",
      "2018-04-13T15:22:09.795527: step 4687, loss 0.00123895, acc 1\n",
      "2018-04-13T15:22:10.123758: step 4688, loss 0.00164237, acc 1\n",
      "2018-04-13T15:22:10.442483: step 4689, loss 0.00174212, acc 1\n",
      "2018-04-13T15:22:10.761208: step 4690, loss 0.0219973, acc 0.984375\n",
      "2018-04-13T15:22:11.082935: step 4691, loss 0.021129, acc 0.984375\n",
      "2018-04-13T15:22:11.405163: step 4692, loss 0.00314752, acc 1\n",
      "2018-04-13T15:22:11.723387: step 4693, loss 0.00726194, acc 1\n",
      "2018-04-13T15:22:12.047617: step 4694, loss 0.000851382, acc 1\n",
      "2018-04-13T15:22:12.363840: step 4695, loss 0.00122187, acc 1\n",
      "2018-04-13T15:22:12.729098: step 4696, loss 0.00111887, acc 1\n",
      "2018-04-13T15:22:13.070339: step 4697, loss 0.00470862, acc 1\n",
      "2018-04-13T15:22:13.418084: step 4698, loss 0.00203097, acc 1\n",
      "2018-04-13T15:22:13.759325: step 4699, loss 0.00682221, acc 1\n",
      "2018-04-13T15:22:14.110073: step 4700, loss 0.000558814, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:22:15.260385: step 4700, loss 1.39503, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4700\n",
      "\n",
      "2018-04-13T15:22:17.032707: step 4701, loss 0.000958741, acc 1\n",
      "2018-04-13T15:22:17.367443: step 4702, loss 0.0133436, acc 1\n",
      "2018-04-13T15:22:17.680167: step 4703, loss 0.00332027, acc 1\n",
      "2018-04-13T15:22:18.008396: step 4704, loss 0.000433986, acc 1\n",
      "2018-04-13T15:22:18.336128: step 4705, loss 0.00292791, acc 1\n",
      "2018-04-13T15:22:18.686877: step 4706, loss 0.00167282, acc 1\n",
      "2018-04-13T15:22:19.019110: step 4707, loss 0.00103978, acc 1\n",
      "2018-04-13T15:22:19.341337: step 4708, loss 0.000908817, acc 1\n",
      "2018-04-13T15:22:19.664068: step 4709, loss 0.00170869, acc 1\n",
      "2018-04-13T15:22:19.978287: step 4710, loss 0.00347975, acc 1\n",
      "2018-04-13T15:22:20.296012: step 4711, loss 0.0297754, acc 0.984375\n",
      "2018-04-13T15:22:20.611234: step 4712, loss 0.000262031, acc 1\n",
      "2018-04-13T15:22:20.929459: step 4713, loss 0.0052411, acc 1\n",
      "2018-04-13T15:22:21.261193: step 4714, loss 0.000780262, acc 1\n",
      "2018-04-13T15:22:21.577416: step 4715, loss 0.00742766, acc 1\n",
      "2018-04-13T15:22:21.947678: step 4716, loss 0.00350521, acc 1\n",
      "2018-04-13T15:22:22.258897: step 4717, loss 0.00185691, acc 1\n",
      "2018-04-13T15:22:22.579124: step 4718, loss 0.00674897, acc 1\n",
      "2018-04-13T15:22:22.914360: step 4719, loss 0.00644603, acc 1\n",
      "2018-04-13T15:22:23.229082: step 4720, loss 0.00073588, acc 1\n",
      "2018-04-13T15:22:23.538801: step 4721, loss 0.00168085, acc 1\n",
      "2018-04-13T15:22:23.862530: step 4722, loss 0.0010757, acc 1\n",
      "2018-04-13T15:22:24.185758: step 4723, loss 0.00585311, acc 1\n",
      "2018-04-13T15:22:24.521495: step 4724, loss 0.000358821, acc 1\n",
      "2018-04-13T15:22:24.921778: step 4725, loss 0.00176431, acc 1\n",
      "2018-04-13T15:22:25.246007: step 4726, loss 0.0028066, acc 1\n",
      "2018-04-13T15:22:25.575741: step 4727, loss 0.00194401, acc 1\n",
      "2018-04-13T15:22:25.929490: step 4728, loss 0.000390418, acc 1\n",
      "2018-04-13T15:22:26.276235: step 4729, loss 0.00676628, acc 1\n",
      "2018-04-13T15:22:26.685023: step 4730, loss 0.000456433, acc 1\n",
      "2018-04-13T15:22:27.063791: step 4731, loss 0.00705435, acc 1\n",
      "2018-04-13T15:22:27.428047: step 4732, loss 0.00104356, acc 1\n",
      "2018-04-13T15:22:27.842846: step 4733, loss 0.000505803, acc 1\n",
      "2018-04-13T15:22:28.162566: step 4734, loss 0.00168723, acc 1\n",
      "2018-04-13T15:22:28.478789: step 4735, loss 0.000868469, acc 1\n",
      "2018-04-13T15:22:28.813025: step 4736, loss 0.00122695, acc 1\n",
      "2018-04-13T15:22:29.138755: step 4737, loss 0.00230311, acc 1\n",
      "2018-04-13T15:22:29.513019: step 4738, loss 0.0145505, acc 0.984375\n",
      "2018-04-13T15:22:29.849257: step 4739, loss 0.000692977, acc 1\n",
      "2018-04-13T15:22:30.197003: step 4740, loss 0.000510594, acc 1\n",
      "2018-04-13T15:22:30.509724: step 4741, loss 0.00642003, acc 1\n",
      "2018-04-13T15:22:30.888491: step 4742, loss 0.000759293, acc 1\n",
      "2018-04-13T15:22:31.212720: step 4743, loss 0.0122784, acc 1\n",
      "2018-04-13T15:22:31.529944: step 4744, loss 0.0308783, acc 0.984375\n",
      "2018-04-13T15:22:31.878190: step 4745, loss 0.0107263, acc 1\n",
      "2018-04-13T15:22:32.200418: step 4746, loss 0.00129159, acc 1\n",
      "2018-04-13T15:22:32.514639: step 4747, loss 0.00869717, acc 1\n",
      "2018-04-13T15:22:32.860884: step 4748, loss 0.000215205, acc 1\n",
      "2018-04-13T15:22:33.225141: step 4749, loss 0.00211963, acc 1\n",
      "2018-04-13T15:22:33.610914: step 4750, loss 0.000916693, acc 1\n",
      "2018-04-13T15:22:34.101760: step 4751, loss 0.00376966, acc 1\n",
      "2018-04-13T15:22:34.417983: step 4752, loss 0.000925937, acc 1\n",
      "2018-04-13T15:22:34.753221: step 4753, loss 0.00785569, acc 1\n",
      "2018-04-13T15:22:35.084454: step 4754, loss 0.000366131, acc 1\n",
      "2018-04-13T15:22:35.398676: step 4755, loss 0.000755097, acc 1\n",
      "2018-04-13T15:22:35.721904: step 4756, loss 0.017709, acc 1\n",
      "2018-04-13T15:22:36.055139: step 4757, loss 0.0181683, acc 0.984375\n",
      "2018-04-13T15:22:36.394882: step 4758, loss 0.00401128, acc 1\n",
      "2018-04-13T15:22:36.747127: step 4759, loss 0.00616853, acc 1\n",
      "2018-04-13T15:22:37.084867: step 4760, loss 0.000678304, acc 1\n",
      "2018-04-13T15:22:37.392083: step 4761, loss 0.00573199, acc 1\n",
      "2018-04-13T15:22:37.741329: step 4762, loss 0.000798226, acc 1\n",
      "2018-04-13T15:22:38.064558: step 4763, loss 0.000505757, acc 1\n",
      "2018-04-13T15:22:38.397794: step 4764, loss 0.00261911, acc 1\n",
      "2018-04-13T15:22:38.728027: step 4765, loss 0.00352606, acc 1\n",
      "2018-04-13T15:22:39.070769: step 4766, loss 0.00831449, acc 1\n",
      "2018-04-13T15:22:39.395498: step 4767, loss 0.00104361, acc 1\n",
      "2018-04-13T15:22:39.770263: step 4768, loss 0.000543934, acc 1\n",
      "2018-04-13T15:22:40.121010: step 4769, loss 0.000751438, acc 1\n",
      "2018-04-13T15:22:40.453745: step 4770, loss 0.000894922, acc 1\n",
      "2018-04-13T15:22:40.808501: step 4771, loss 0.00354163, acc 1\n",
      "2018-04-13T15:22:41.118715: step 4772, loss 0.00307989, acc 1\n",
      "2018-04-13T15:22:41.434938: step 4773, loss 0.0107566, acc 1\n",
      "2018-04-13T15:22:41.757666: step 4774, loss 0.0030629, acc 1\n",
      "2018-04-13T15:22:42.095405: step 4775, loss 0.00187891, acc 1\n",
      "2018-04-13T15:22:42.415130: step 4776, loss 0.00286457, acc 1\n",
      "2018-04-13T15:22:42.767378: step 4777, loss 0.0153512, acc 0.984375\n",
      "2018-04-13T15:22:43.103116: step 4778, loss 0.00467481, acc 1\n",
      "2018-04-13T15:22:43.424844: step 4779, loss 0.00125672, acc 1\n",
      "2018-04-13T15:22:43.750073: step 4780, loss 0.00151442, acc 1\n",
      "2018-04-13T15:22:44.079805: step 4781, loss 0.00195546, acc 1\n",
      "2018-04-13T15:22:44.409038: step 4782, loss 0.000421894, acc 1\n",
      "2018-04-13T15:22:44.755783: step 4783, loss 0.00511795, acc 1\n",
      "2018-04-13T15:22:45.100527: step 4784, loss 0.000793651, acc 1\n",
      "2018-04-13T15:22:45.437765: step 4785, loss 0.0217099, acc 0.984375\n",
      "2018-04-13T15:22:45.816032: step 4786, loss 0.00113701, acc 1\n",
      "2018-04-13T15:22:46.169282: step 4787, loss 0.00359191, acc 1\n",
      "2018-04-13T15:22:46.529035: step 4788, loss 0.0030201, acc 1\n",
      "2018-04-13T15:22:46.876781: step 4789, loss 0.00543608, acc 1\n",
      "2018-04-13T15:22:47.203011: step 4790, loss 0.00345527, acc 1\n",
      "2018-04-13T15:22:47.524238: step 4791, loss 0.0215508, acc 0.984375\n",
      "2018-04-13T15:22:47.857973: step 4792, loss 0.00117313, acc 1\n",
      "2018-04-13T15:22:48.170194: step 4793, loss 0.00138526, acc 1\n",
      "2018-04-13T15:22:48.494923: step 4794, loss 0.0107601, acc 1\n",
      "2018-04-13T15:22:48.847172: step 4795, loss 0.00387434, acc 1\n",
      "2018-04-13T15:22:49.220935: step 4796, loss 0.000545777, acc 1\n",
      "2018-04-13T15:22:49.522649: step 4797, loss 0.00150045, acc 1\n",
      "2018-04-13T15:22:49.857385: step 4798, loss 0.00483975, acc 1\n",
      "2018-04-13T15:22:50.189620: step 4799, loss 0.00519498, acc 1\n",
      "2018-04-13T15:22:50.494836: step 4800, loss 0.00441812, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:22:51.644147: step 4800, loss 1.3729, acc 0.754221\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4800\n",
      "\n",
      "2018-04-13T15:22:53.448004: step 4801, loss 0.0034437, acc 1\n",
      "2018-04-13T15:22:53.773233: step 4802, loss 0.000361008, acc 1\n",
      "2018-04-13T15:22:54.088956: step 4803, loss 0.00152168, acc 1\n",
      "2018-04-13T15:22:54.422692: step 4804, loss 0.0165352, acc 0.984375\n",
      "2018-04-13T15:22:54.789451: step 4805, loss 0.00800382, acc 1\n",
      "2018-04-13T15:22:55.115681: step 4806, loss 0.00166291, acc 1\n",
      "2018-04-13T15:22:55.447916: step 4807, loss 0.00301689, acc 1\n",
      "2018-04-13T15:22:55.787656: step 4808, loss 0.000386418, acc 1\n",
      "2018-04-13T15:22:56.106882: step 4809, loss 0.01031, acc 1\n",
      "2018-04-13T15:22:56.447622: step 4810, loss 0.000985322, acc 1\n",
      "2018-04-13T15:22:56.778856: step 4811, loss 0.000854387, acc 1\n",
      "2018-04-13T15:22:57.098582: step 4812, loss 0.00427064, acc 1\n",
      "2018-04-13T15:22:57.425813: step 4813, loss 4.52118e-05, acc 1\n",
      "2018-04-13T15:22:57.780563: step 4814, loss 0.00604352, acc 1\n",
      "2018-04-13T15:22:58.109295: step 4815, loss 0.00330629, acc 1\n",
      "2018-04-13T15:22:58.429521: step 4816, loss 0.00413203, acc 1\n",
      "2018-04-13T15:22:58.743243: step 4817, loss 0.000973159, acc 1\n",
      "2018-04-13T15:22:59.069974: step 4818, loss 0.00378405, acc 1\n",
      "2018-04-13T15:22:59.400207: step 4819, loss 0.000360097, acc 1\n",
      "2018-04-13T15:22:59.727938: step 4820, loss 0.0245914, acc 0.984375\n",
      "2018-04-13T15:23:00.057171: step 4821, loss 0.00103497, acc 1\n",
      "2018-04-13T15:23:00.375896: step 4822, loss 0.00391338, acc 1\n",
      "2018-04-13T15:23:00.722141: step 4823, loss 0.000885811, acc 1\n",
      "2018-04-13T15:23:01.065884: step 4824, loss 0.000361173, acc 1\n",
      "2018-04-13T15:23:01.391613: step 4825, loss 0.000318321, acc 1\n",
      "2018-04-13T15:23:01.713841: step 4826, loss 0.01976, acc 0.984375\n",
      "2018-04-13T15:23:02.041072: step 4827, loss 0.00285969, acc 1\n",
      "2018-04-13T15:23:02.363800: step 4828, loss 0.0411406, acc 0.984375\n",
      "2018-04-13T15:23:02.677020: step 4829, loss 0.000193232, acc 1\n",
      "2018-04-13T15:23:03.057790: step 4830, loss 0.00240578, acc 1\n",
      "2018-04-13T15:23:03.416044: step 4831, loss 0.000519149, acc 1\n",
      "2018-04-13T15:23:03.805318: step 4832, loss 0.000446477, acc 1\n",
      "2018-04-13T15:23:04.154063: step 4833, loss 0.00313643, acc 1\n",
      "2018-04-13T15:23:04.480293: step 4834, loss 0.00188568, acc 1\n",
      "2018-04-13T15:23:04.804523: step 4835, loss 0.00199704, acc 1\n",
      "2018-04-13T15:23:05.136257: step 4836, loss 0.0104395, acc 1\n",
      "2018-04-13T15:23:05.446976: step 4837, loss 0.0142558, acc 1\n",
      "2018-04-13T15:23:05.774708: step 4838, loss 0.0114458, acc 1\n",
      "2018-04-13T15:23:06.105942: step 4839, loss 0.0014025, acc 1\n",
      "2018-04-13T15:23:06.420163: step 4840, loss 0.00407422, acc 1\n",
      "2018-04-13T15:23:06.763907: step 4841, loss 0.000911117, acc 1\n",
      "2018-04-13T15:23:07.109150: step 4842, loss 0.00116368, acc 1\n",
      "2018-04-13T15:23:07.417868: step 4843, loss 0.022804, acc 0.984375\n",
      "2018-04-13T15:23:07.744599: step 4844, loss 0.000275912, acc 1\n",
      "2018-04-13T15:23:08.065326: step 4845, loss 0.00139597, acc 1\n",
      "2018-04-13T15:23:08.384550: step 4846, loss 0.0123414, acc 1\n",
      "2018-04-13T15:23:08.715785: step 4847, loss 0.00303603, acc 1\n",
      "2018-04-13T15:23:09.030507: step 4848, loss 0.00577197, acc 1\n",
      "2018-04-13T15:23:09.356242: step 4849, loss 0.000425984, acc 1\n",
      "2018-04-13T15:23:09.687471: step 4850, loss 0.000950682, acc 1\n",
      "2018-04-13T15:23:10.049726: step 4851, loss 0.000947842, acc 1\n",
      "2018-04-13T15:23:10.368952: step 4852, loss 0.00108888, acc 1\n",
      "2018-04-13T15:23:10.687177: step 4853, loss 0.00121384, acc 1\n",
      "2018-04-13T15:23:11.006402: step 4854, loss 0.000625829, acc 1\n",
      "2018-04-13T15:23:11.330631: step 4855, loss 0.000261663, acc 1\n",
      "2018-04-13T15:23:11.643852: step 4856, loss 0.00355819, acc 1\n",
      "2018-04-13T15:23:11.972584: step 4857, loss 0.00218576, acc 1\n",
      "2018-04-13T15:23:12.282803: step 4858, loss 0.00115936, acc 1\n",
      "2018-04-13T15:23:12.591526: step 4859, loss 0.000396559, acc 1\n",
      "2018-04-13T15:23:12.946272: step 4860, loss 0.00503175, acc 1\n",
      "2018-04-13T15:23:13.274505: step 4861, loss 0.0022251, acc 1\n",
      "2018-04-13T15:23:13.595732: step 4862, loss 0.00215856, acc 1\n",
      "2018-04-13T15:23:13.922461: step 4863, loss 0.00201056, acc 1\n",
      "2018-04-13T15:23:14.243688: step 4864, loss 0.0240008, acc 0.984375\n",
      "2018-04-13T15:23:14.567417: step 4865, loss 0.00386383, acc 1\n",
      "2018-04-13T15:23:14.888644: step 4866, loss 0.00339157, acc 1\n",
      "2018-04-13T15:23:15.232386: step 4867, loss 0.0440967, acc 0.984375\n",
      "2018-04-13T15:23:15.547609: step 4868, loss 0.00108926, acc 1\n",
      "2018-04-13T15:23:15.897356: step 4869, loss 0.00395552, acc 1\n",
      "2018-04-13T15:23:16.224586: step 4870, loss 0.000251116, acc 1\n",
      "2018-04-13T15:23:16.536807: step 4871, loss 0.00106133, acc 1\n",
      "2018-04-13T15:23:16.871048: step 4872, loss 0.0187724, acc 0.984375\n",
      "2018-04-13T15:23:17.180761: step 4873, loss 0.00487792, acc 1\n",
      "2018-04-13T15:23:17.498486: step 4874, loss 0.00381439, acc 1\n",
      "2018-04-13T15:23:17.819213: step 4875, loss 0.00281329, acc 1\n",
      "2018-04-13T15:23:18.140440: step 4876, loss 0.00168829, acc 1\n",
      "2018-04-13T15:23:18.452660: step 4877, loss 0.00184618, acc 1\n",
      "2018-04-13T15:23:18.788397: step 4878, loss 0.00197869, acc 1\n",
      "2018-04-13T15:23:19.132640: step 4879, loss 0.0258193, acc 0.984375\n",
      "2018-04-13T15:23:19.454867: step 4880, loss 0.0155326, acc 1\n",
      "2018-04-13T15:23:19.773093: step 4881, loss 0.000734632, acc 1\n",
      "2018-04-13T15:23:20.091317: step 4882, loss 0.000498018, acc 1\n",
      "2018-04-13T15:23:20.406039: step 4883, loss 0.00101884, acc 1\n",
      "2018-04-13T15:23:20.726766: step 4884, loss 0.000551878, acc 1\n",
      "2018-04-13T15:23:21.048994: step 4885, loss 0.0042344, acc 1\n",
      "2018-04-13T15:23:21.365718: step 4886, loss 0.00688348, acc 1\n",
      "2018-04-13T15:23:21.684441: step 4887, loss 0.00130509, acc 1\n",
      "2018-04-13T15:23:22.049200: step 4888, loss 0.00129335, acc 1\n",
      "2018-04-13T15:23:22.371928: step 4889, loss 0.000190821, acc 1\n",
      "2018-04-13T15:23:22.715174: step 4890, loss 0.000460062, acc 1\n",
      "2018-04-13T15:23:23.041400: step 4891, loss 0.00053607, acc 1\n",
      "2018-04-13T15:23:23.373635: step 4892, loss 0.00197095, acc 1\n",
      "2018-04-13T15:23:23.699365: step 4893, loss 0.000334364, acc 1\n",
      "2018-04-13T15:23:24.026096: step 4894, loss 0.00312134, acc 1\n",
      "2018-04-13T15:23:24.349825: step 4895, loss 0.00245986, acc 1\n",
      "2018-04-13T15:23:24.678056: step 4896, loss 0.000490511, acc 1\n",
      "2018-04-13T15:23:25.038310: step 4897, loss 0.00177257, acc 1\n",
      "2018-04-13T15:23:25.363039: step 4898, loss 0.0164507, acc 1\n",
      "2018-04-13T15:23:25.692772: step 4899, loss 0.000941512, acc 1\n",
      "2018-04-13T15:23:26.013499: step 4900, loss 0.00085998, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:23:27.163811: step 4900, loss 1.38154, acc 0.751407\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-4900\n",
      "\n",
      "2018-04-13T15:23:28.716620: step 4901, loss 0.00126165, acc 1\n",
      "2018-04-13T15:23:29.042374: step 4902, loss 0.00472182, acc 1\n",
      "2018-04-13T15:23:29.362100: step 4903, loss 0.00288654, acc 1\n",
      "2018-04-13T15:23:29.689331: step 4904, loss 0.00105914, acc 1\n",
      "2018-04-13T15:23:30.003552: step 4905, loss 0.00171187, acc 1\n",
      "2018-04-13T15:23:30.330784: step 4906, loss 0.00228204, acc 1\n",
      "2018-04-13T15:23:30.657015: step 4907, loss 0.0129467, acc 1\n",
      "2018-04-13T15:23:31.013265: step 4908, loss 0.000928224, acc 1\n",
      "2018-04-13T15:23:31.349003: step 4909, loss 0.000767103, acc 1\n",
      "2018-04-13T15:23:31.668728: step 4910, loss 0.00403552, acc 1\n",
      "2018-04-13T15:23:31.989455: step 4911, loss 0.00423398, acc 1\n",
      "2018-04-13T15:23:32.314684: step 4912, loss 0.00488252, acc 1\n",
      "2018-04-13T15:23:32.631408: step 4913, loss 0.00128171, acc 1\n",
      "2018-04-13T15:23:32.961641: step 4914, loss 0.00734125, acc 1\n",
      "2018-04-13T15:23:33.295877: step 4915, loss 0.00406518, acc 1\n",
      "2018-04-13T15:23:33.621110: step 4916, loss 0.00184682, acc 1\n",
      "2018-04-13T15:23:33.964350: step 4917, loss 0.000664338, acc 1\n",
      "2018-04-13T15:23:34.308592: step 4918, loss 0.000935344, acc 1\n",
      "2018-04-13T15:23:34.625316: step 4919, loss 0.00311736, acc 1\n",
      "2018-04-13T15:23:34.961553: step 4920, loss 0.00419666, acc 1\n",
      "2018-04-13T15:23:35.274274: step 4921, loss 0.00436954, acc 1\n",
      "2018-04-13T15:23:35.589997: step 4922, loss 0.00198571, acc 1\n",
      "2018-04-13T15:23:35.906721: step 4923, loss 0.00646205, acc 1\n",
      "2018-04-13T15:23:36.223444: step 4924, loss 0.00379972, acc 1\n",
      "2018-04-13T15:23:36.539667: step 4925, loss 0.0014739, acc 1\n",
      "2018-04-13T15:23:36.872903: step 4926, loss 0.00547817, acc 1\n",
      "2018-04-13T15:23:37.220148: step 4927, loss 0.0145345, acc 1\n",
      "2018-04-13T15:23:37.549382: step 4928, loss 0.00586348, acc 1\n",
      "2018-04-13T15:23:37.867606: step 4929, loss 0.000334146, acc 1\n",
      "2018-04-13T15:23:38.198338: step 4930, loss 0.00151862, acc 1\n",
      "2018-04-13T15:23:38.518064: step 4931, loss 0.005645, acc 1\n",
      "2018-04-13T15:23:38.856803: step 4932, loss 0.00197129, acc 1\n",
      "2018-04-13T15:23:39.178531: step 4933, loss 0.000819197, acc 1\n",
      "2018-04-13T15:23:39.500759: step 4934, loss 0.000332896, acc 1\n",
      "2018-04-13T15:23:39.829991: step 4935, loss 0.000786458, acc 1\n",
      "2018-04-13T15:23:40.178237: step 4936, loss 0.00340471, acc 1\n",
      "2018-04-13T15:23:40.481951: step 4937, loss 0.00149122, acc 1\n",
      "2018-04-13T15:23:40.815687: step 4938, loss 0.00246516, acc 1\n",
      "2018-04-13T15:23:41.146423: step 4939, loss 0.00342479, acc 1\n",
      "2018-04-13T15:23:41.473151: step 4940, loss 0.0116869, acc 1\n",
      "2018-04-13T15:23:41.798381: step 4941, loss 0.000275831, acc 1\n",
      "2018-04-13T15:23:42.118107: step 4942, loss 0.0540527, acc 0.984375\n",
      "2018-04-13T15:23:42.437332: step 4943, loss 0.00574676, acc 1\n",
      "2018-04-13T15:23:42.761061: step 4944, loss 0.00636442, acc 1\n",
      "2018-04-13T15:23:43.123316: step 4945, loss 0.00190681, acc 1\n",
      "2018-04-13T15:23:43.440040: step 4946, loss 0.000403784, acc 1\n",
      "2018-04-13T15:23:43.778779: step 4947, loss 0.0173508, acc 0.984375\n",
      "2018-04-13T15:23:44.095504: step 4948, loss 0.00137042, acc 1\n",
      "2018-04-13T15:23:44.414228: step 4949, loss 0.00500225, acc 1\n",
      "2018-04-13T15:23:44.717942: step 4950, loss 0.00663674, acc 1\n",
      "2018-04-13T15:23:45.041171: step 4951, loss 0.00277904, acc 1\n",
      "2018-04-13T15:23:45.369906: step 4952, loss 0.00540568, acc 1\n",
      "2018-04-13T15:23:45.699636: step 4953, loss 0.00047257, acc 1\n",
      "2018-04-13T15:23:46.049883: step 4954, loss 0.00326634, acc 1\n",
      "2018-04-13T15:23:46.439158: step 4955, loss 0.00383734, acc 1\n",
      "2018-04-13T15:23:46.783401: step 4956, loss 0.000919351, acc 1\n",
      "2018-04-13T15:23:47.134149: step 4957, loss 0.00660425, acc 1\n",
      "2018-04-13T15:23:47.469385: step 4958, loss 0.00178718, acc 1\n",
      "2018-04-13T15:23:47.801120: step 4959, loss 0.000919206, acc 1\n",
      "2018-04-13T15:23:48.112839: step 4960, loss 0.00327298, acc 1\n",
      "2018-04-13T15:23:48.422558: step 4961, loss 0.000964218, acc 1\n",
      "2018-04-13T15:23:48.747288: step 4962, loss 0.0166946, acc 0.984375\n",
      "2018-04-13T15:23:49.111044: step 4963, loss 0.000859207, acc 1\n",
      "2018-04-13T15:23:49.434273: step 4964, loss 0.000539988, acc 1\n",
      "2018-04-13T15:23:49.763005: step 4965, loss 0.000903118, acc 1\n",
      "2018-04-13T15:23:50.085232: step 4966, loss 0.00114949, acc 1\n",
      "2018-04-13T15:23:50.417967: step 4967, loss 0.0014924, acc 1\n",
      "2018-04-13T15:23:50.740195: step 4968, loss 0.000258145, acc 1\n",
      "2018-04-13T15:23:51.065926: step 4969, loss 0.00153307, acc 1\n",
      "2018-04-13T15:23:51.397659: step 4970, loss 0.00042045, acc 1\n",
      "2018-04-13T15:23:51.724390: step 4971, loss 0.00083145, acc 1\n",
      "2018-04-13T15:23:52.076138: step 4972, loss 0.0004833, acc 1\n",
      "2018-04-13T15:23:52.399367: step 4973, loss 0.00816555, acc 1\n",
      "2018-04-13T15:23:52.817161: step 4974, loss 0.00527514, acc 1\n",
      "2018-04-13T15:23:53.147895: step 4975, loss 0.000923762, acc 1\n",
      "2018-04-13T15:23:53.477628: step 4976, loss 0.00143745, acc 1\n",
      "2018-04-13T15:23:53.805359: step 4977, loss 0.000215104, acc 1\n",
      "2018-04-13T15:23:54.132591: step 4978, loss 0.000386131, acc 1\n",
      "2018-04-13T15:23:54.445311: step 4979, loss 0.000243725, acc 1\n",
      "2018-04-13T15:23:54.771542: step 4980, loss 0.00304201, acc 1\n",
      "2018-04-13T15:23:55.160318: step 4981, loss 0.00160181, acc 1\n",
      "2018-04-13T15:23:55.480041: step 4982, loss 0.000687271, acc 1\n",
      "2018-04-13T15:23:55.797265: step 4983, loss 0.00869216, acc 1\n",
      "2018-04-13T15:23:56.118993: step 4984, loss 0.000867729, acc 1\n",
      "2018-04-13T15:23:56.434216: step 4985, loss 0.00171977, acc 1\n",
      "2018-04-13T15:23:56.762948: step 4986, loss 0.00302154, acc 1\n",
      "2018-04-13T15:23:57.085175: step 4987, loss 0.0052892, acc 1\n",
      "2018-04-13T15:23:57.393893: step 4988, loss 0.00067291, acc 1\n",
      "2018-04-13T15:23:57.719623: step 4989, loss 0.0119157, acc 1\n",
      "2018-04-13T15:23:58.067869: step 4990, loss 0.0138529, acc 1\n",
      "2018-04-13T15:23:58.414614: step 4991, loss 0.00224893, acc 1\n",
      "2018-04-13T15:23:58.740845: step 4992, loss 0.000894418, acc 1\n",
      "2018-04-13T15:23:59.064573: step 4993, loss 0.000453364, acc 1\n",
      "2018-04-13T15:23:59.380795: step 4994, loss 0.00101004, acc 1\n",
      "2018-04-13T15:23:59.714531: step 4995, loss 0.00180503, acc 1\n",
      "2018-04-13T15:24:00.036259: step 4996, loss 0.00351352, acc 1\n",
      "2018-04-13T15:24:00.353483: step 4997, loss 0.000696185, acc 1\n",
      "2018-04-13T15:24:00.671708: step 4998, loss 0.000614632, acc 1\n",
      "2018-04-13T15:24:01.026959: step 4999, loss 0.00380942, acc 1\n",
      "2018-04-13T15:24:01.369700: step 5000, loss 0.00435061, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:24:02.513509: step 5000, loss 1.42103, acc 0.743902\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5000\n",
      "\n",
      "2018-04-13T15:24:04.220213: step 5001, loss 0.00512276, acc 1\n",
      "2018-04-13T15:24:04.547453: step 5002, loss 0.00171209, acc 1\n",
      "2018-04-13T15:24:04.865679: step 5003, loss 0.000879497, acc 1\n",
      "2018-04-13T15:24:05.188406: step 5004, loss 0.0012779, acc 1\n",
      "2018-04-13T15:24:05.506631: step 5005, loss 0.000942058, acc 1\n",
      "2018-04-13T15:24:05.849873: step 5006, loss 0.00278884, acc 1\n",
      "2018-04-13T15:24:06.181607: step 5007, loss 0.000923873, acc 1\n",
      "2018-04-13T15:24:06.500833: step 5008, loss 0.0106982, acc 1\n",
      "2018-04-13T15:24:06.838071: step 5009, loss 0.000346918, acc 1\n",
      "2018-04-13T15:24:07.178311: step 5010, loss 0.00557653, acc 1\n",
      "2018-04-13T15:24:07.501039: step 5011, loss 0.000450153, acc 1\n",
      "2018-04-13T15:24:07.835276: step 5012, loss 0.00216863, acc 1\n",
      "2018-04-13T15:24:08.145994: step 5013, loss 0.000281183, acc 1\n",
      "2018-04-13T15:24:08.455713: step 5014, loss 0.00065661, acc 1\n",
      "2018-04-13T15:24:08.786950: step 5015, loss 0.000524643, acc 1\n",
      "2018-04-13T15:24:09.096665: step 5016, loss 0.00203622, acc 1\n",
      "2018-04-13T15:24:09.407886: step 5017, loss 0.000650288, acc 1\n",
      "2018-04-13T15:24:09.730113: step 5018, loss 0.0020992, acc 1\n",
      "2018-04-13T15:24:10.070354: step 5019, loss 0.00256581, acc 1\n",
      "2018-04-13T15:24:10.396083: step 5020, loss 0.00707292, acc 1\n",
      "2018-04-13T15:24:10.721814: step 5021, loss 0.00115073, acc 1\n",
      "2018-04-13T15:24:11.053547: step 5022, loss 0.00170952, acc 1\n",
      "2018-04-13T15:24:11.379778: step 5023, loss 0.000215196, acc 1\n",
      "2018-04-13T15:24:11.697502: step 5024, loss 0.000914286, acc 1\n",
      "2018-04-13T15:24:12.023235: step 5025, loss 0.00235249, acc 1\n",
      "2018-04-13T15:24:12.338455: step 5026, loss 0.00182196, acc 1\n",
      "2018-04-13T15:24:12.654178: step 5027, loss 0.00218084, acc 1\n",
      "2018-04-13T15:24:12.985412: step 5028, loss 0.000917443, acc 1\n",
      "2018-04-13T15:24:13.334158: step 5029, loss 0.0031317, acc 1\n",
      "2018-04-13T15:24:13.645878: step 5030, loss 0.0108508, acc 1\n",
      "2018-04-13T15:24:13.970607: step 5031, loss 0.00213868, acc 1\n",
      "2018-04-13T15:24:14.292334: step 5032, loss 0.000664106, acc 1\n",
      "2018-04-13T15:24:14.614062: step 5033, loss 0.000146579, acc 1\n",
      "2018-04-13T15:24:14.937290: step 5034, loss 0.00081251, acc 1\n",
      "2018-04-13T15:24:15.262520: step 5035, loss 0.00114697, acc 1\n",
      "2018-04-13T15:24:15.575240: step 5036, loss 0.00167676, acc 1\n",
      "2018-04-13T15:24:15.911484: step 5037, loss 0.00161725, acc 1\n",
      "2018-04-13T15:24:16.290746: step 5038, loss 0.00521392, acc 1\n",
      "2018-04-13T15:24:16.609471: step 5039, loss 0.000174362, acc 1\n",
      "2018-04-13T15:24:16.933199: step 5040, loss 0.0115124, acc 1\n",
      "2018-04-13T15:24:17.255940: step 5041, loss 0.0117875, acc 0.984375\n",
      "2018-04-13T15:24:17.577667: step 5042, loss 0.0020561, acc 1\n",
      "2018-04-13T15:24:17.901396: step 5043, loss 0.000837742, acc 1\n",
      "2018-04-13T15:24:18.223123: step 5044, loss 0.00515231, acc 1\n",
      "2018-04-13T15:24:18.562863: step 5045, loss 0.000612575, acc 1\n",
      "2018-04-13T15:24:18.910107: step 5046, loss 0.000550269, acc 1\n",
      "2018-04-13T15:24:19.251349: step 5047, loss 0.000595978, acc 1\n",
      "2018-04-13T15:24:19.571575: step 5048, loss 0.00174743, acc 1\n",
      "2018-04-13T15:24:19.899807: step 5049, loss 0.000768114, acc 1\n",
      "2018-04-13T15:24:20.221534: step 5050, loss 0.00296627, acc 1\n",
      "2018-04-13T15:24:20.544262: step 5051, loss 0.00015779, acc 1\n",
      "2018-04-13T15:24:20.874495: step 5052, loss 0.0015909, acc 1\n",
      "2018-04-13T15:24:21.194721: step 5053, loss 0.00857939, acc 1\n",
      "2018-04-13T15:24:21.505941: step 5054, loss 0.000601195, acc 1\n",
      "2018-04-13T15:24:21.823665: step 5055, loss 0.00698919, acc 1\n",
      "2018-04-13T15:24:22.155404: step 5056, loss 0.0279802, acc 0.984375\n",
      "2018-04-13T15:24:22.488635: step 5057, loss 0.00325979, acc 1\n",
      "2018-04-13T15:24:22.816366: step 5058, loss 0.00025025, acc 1\n",
      "2018-04-13T15:24:23.147600: step 5059, loss 0.00294892, acc 1\n",
      "2018-04-13T15:24:23.464824: step 5060, loss 0.00236977, acc 1\n",
      "2018-04-13T15:24:23.793056: step 5061, loss 0.000851251, acc 1\n",
      "2018-04-13T15:24:24.111781: step 5062, loss 0.000648715, acc 1\n",
      "2018-04-13T15:24:24.437011: step 5063, loss 0.000701718, acc 1\n",
      "2018-04-13T15:24:24.759738: step 5064, loss 0.00701625, acc 1\n",
      "2018-04-13T15:24:25.091473: step 5065, loss 0.00820649, acc 1\n",
      "2018-04-13T15:24:25.450226: step 5066, loss 0.0021284, acc 1\n",
      "2018-04-13T15:24:25.802475: step 5067, loss 0.000497217, acc 1\n",
      "2018-04-13T15:24:26.115196: step 5068, loss 0.000216783, acc 1\n",
      "2018-04-13T15:24:26.443427: step 5069, loss 0.00353982, acc 1\n",
      "2018-04-13T15:24:26.762153: step 5070, loss 0.0501426, acc 0.984375\n",
      "2018-04-13T15:24:27.090384: step 5071, loss 0.0268905, acc 0.984375\n",
      "2018-04-13T15:24:27.397601: step 5072, loss 0.000897828, acc 1\n",
      "2018-04-13T15:24:27.724833: step 5073, loss 0.0179295, acc 0.984375\n",
      "2018-04-13T15:24:28.054065: step 5074, loss 0.000325824, acc 1\n",
      "2018-04-13T15:24:28.415819: step 5075, loss 0.0126957, acc 1\n",
      "2018-04-13T15:24:28.743552: step 5076, loss 0.000501461, acc 1\n",
      "2018-04-13T15:24:29.058274: step 5077, loss 0.0142855, acc 0.984375\n",
      "2018-04-13T15:24:29.376498: step 5078, loss 0.00239672, acc 1\n",
      "2018-04-13T15:24:29.701728: step 5079, loss 0.000552721, acc 1\n",
      "2018-04-13T15:24:30.007944: step 5080, loss 0.00165925, acc 1\n",
      "2018-04-13T15:24:30.317663: step 5081, loss 0.00119919, acc 1\n",
      "2018-04-13T15:24:30.638389: step 5082, loss 0.000631416, acc 1\n",
      "2018-04-13T15:24:30.965120: step 5083, loss 0.00131235, acc 1\n",
      "2018-04-13T15:24:31.317870: step 5084, loss 0.00133522, acc 1\n",
      "2018-04-13T15:24:31.620583: step 5085, loss 0.000600703, acc 1\n",
      "2018-04-13T15:24:31.947314: step 5086, loss 0.00181502, acc 1\n",
      "2018-04-13T15:24:32.270041: step 5087, loss 0.00249004, acc 1\n",
      "2018-04-13T15:24:32.579260: step 5088, loss 0.0144435, acc 1\n",
      "2018-04-13T15:24:32.899987: step 5089, loss 0.0114223, acc 1\n",
      "2018-04-13T15:24:33.234223: step 5090, loss 0.000828636, acc 1\n",
      "2018-04-13T15:24:33.556449: step 5091, loss 0.00232184, acc 1\n",
      "2018-04-13T15:24:33.880178: step 5092, loss 0.00200704, acc 1\n",
      "2018-04-13T15:24:34.243435: step 5093, loss 0.00604942, acc 1\n",
      "2018-04-13T15:24:34.572667: step 5094, loss 0.00151555, acc 1\n",
      "2018-04-13T15:24:34.911407: step 5095, loss 0.00142885, acc 1\n",
      "2018-04-13T15:24:35.240139: step 5096, loss 0.000199938, acc 1\n",
      "2018-04-13T15:24:35.559864: step 5097, loss 0.00246416, acc 1\n",
      "2018-04-13T15:24:35.875588: step 5098, loss 0.000605308, acc 1\n",
      "2018-04-13T15:24:36.195813: step 5099, loss 0.00841918, acc 1\n",
      "2018-04-13T15:24:36.505032: step 5100, loss 0.000961784, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:24:37.684364: step 5100, loss 1.45174, acc 0.746717\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5100\n",
      "\n",
      "2018-04-13T15:24:39.314015: step 5101, loss 0.00140679, acc 1\n",
      "2018-04-13T15:24:39.632240: step 5102, loss 0.000700106, acc 1\n",
      "2018-04-13T15:24:39.952466: step 5103, loss 0.000863455, acc 1\n",
      "2018-04-13T15:24:40.324229: step 5104, loss 0.000504904, acc 1\n",
      "2018-04-13T15:24:40.642453: step 5105, loss 0.000288059, acc 1\n",
      "2018-04-13T15:24:40.963200: step 5106, loss 0.00431176, acc 1\n",
      "2018-04-13T15:24:41.280809: step 5107, loss 0.000126619, acc 1\n",
      "2018-04-13T15:24:41.601035: step 5108, loss 0.0161046, acc 0.984375\n",
      "2018-04-13T15:24:41.937773: step 5109, loss 0.00157214, acc 1\n",
      "2018-04-13T15:24:42.279014: step 5110, loss 7.6617e-05, acc 1\n",
      "2018-04-13T15:24:42.595737: step 5111, loss 0.000596025, acc 1\n",
      "2018-04-13T15:24:42.920967: step 5112, loss 0.00294031, acc 1\n",
      "2018-04-13T15:24:43.264210: step 5113, loss 0.000738304, acc 1\n",
      "2018-04-13T15:24:43.582435: step 5114, loss 0.00104293, acc 1\n",
      "2018-04-13T15:24:43.902660: step 5115, loss 0.00126528, acc 1\n",
      "2018-04-13T15:24:44.232893: step 5116, loss 0.00196126, acc 1\n",
      "2018-04-13T15:24:44.553119: step 5117, loss 0.000432638, acc 1\n",
      "2018-04-13T15:24:44.873346: step 5118, loss 0.000524165, acc 1\n",
      "2018-04-13T15:24:45.179561: step 5119, loss 0.000247994, acc 1\n",
      "2018-04-13T15:24:45.495285: step 5120, loss 0.000978286, acc 1\n",
      "2018-04-13T15:24:45.825017: step 5121, loss 0.000369264, acc 1\n",
      "2018-04-13T15:24:46.174765: step 5122, loss 0.000520925, acc 1\n",
      "2018-04-13T15:24:46.522010: step 5123, loss 0.00016897, acc 1\n",
      "2018-04-13T15:24:46.842236: step 5124, loss 0.0040107, acc 1\n",
      "2018-04-13T15:24:47.160460: step 5125, loss 0.000160113, acc 1\n",
      "2018-04-13T15:24:47.477185: step 5126, loss 0.000909022, acc 1\n",
      "2018-04-13T15:24:47.794408: step 5127, loss 0.00222456, acc 1\n",
      "2018-04-13T15:24:48.120138: step 5128, loss 0.00214255, acc 1\n",
      "2018-04-13T15:24:48.443867: step 5129, loss 0.000233906, acc 1\n",
      "2018-04-13T15:24:48.766094: step 5130, loss 0.000438983, acc 1\n",
      "2018-04-13T15:24:49.085821: step 5131, loss 0.000215448, acc 1\n",
      "2018-04-13T15:24:49.465588: step 5132, loss 0.00128425, acc 1\n",
      "2018-04-13T15:24:49.793319: step 5133, loss 0.000982875, acc 1\n",
      "2018-04-13T15:24:50.120551: step 5134, loss 0.00468824, acc 1\n",
      "2018-04-13T15:24:50.428268: step 5135, loss 0.000534052, acc 1\n",
      "2018-04-13T15:24:50.754498: step 5136, loss 0.000372327, acc 1\n",
      "2018-04-13T15:24:51.081730: step 5137, loss 0.00146432, acc 1\n",
      "2018-04-13T15:24:51.407460: step 5138, loss 0.000753741, acc 1\n",
      "2018-04-13T15:24:51.728687: step 5139, loss 0.00179601, acc 1\n",
      "2018-04-13T15:24:52.053915: step 5140, loss 0.00129777, acc 1\n",
      "2018-04-13T15:24:52.409667: step 5141, loss 0.00528705, acc 1\n",
      "2018-04-13T15:24:52.728392: step 5142, loss 0.00123974, acc 1\n",
      "2018-04-13T15:24:53.058125: step 5143, loss 0.00365796, acc 1\n",
      "2018-04-13T15:24:53.379351: step 5144, loss 0.00783895, acc 1\n",
      "2018-04-13T15:24:53.695576: step 5145, loss 0.000613099, acc 1\n",
      "2018-04-13T15:24:54.028310: step 5146, loss 0.00267861, acc 1\n",
      "2018-04-13T15:24:54.352038: step 5147, loss 0.00412898, acc 1\n",
      "2018-04-13T15:24:54.689281: step 5148, loss 0.00127707, acc 1\n",
      "2018-04-13T15:24:55.011004: step 5149, loss 0.00213079, acc 1\n",
      "2018-04-13T15:24:55.356748: step 5150, loss 0.000673657, acc 1\n",
      "2018-04-13T15:24:55.670471: step 5151, loss 0.00196488, acc 1\n",
      "2018-04-13T15:24:56.001703: step 5152, loss 0.000474337, acc 1\n",
      "2018-04-13T15:24:56.321929: step 5153, loss 0.0206714, acc 0.984375\n",
      "2018-04-13T15:24:56.636651: step 5154, loss 0.00168721, acc 1\n",
      "2018-04-13T15:24:56.954878: step 5155, loss 0.0039895, acc 1\n",
      "2018-04-13T15:24:57.281607: step 5156, loss 0.0730391, acc 0.984375\n",
      "2018-04-13T15:24:57.610840: step 5157, loss 0.000713213, acc 1\n",
      "2018-04-13T15:24:57.938071: step 5158, loss 0.0115935, acc 1\n",
      "2018-04-13T15:24:58.268806: step 5159, loss 0.000900118, acc 1\n",
      "2018-04-13T15:24:58.595535: step 5160, loss 0.00219308, acc 1\n",
      "2018-04-13T15:24:58.938777: step 5161, loss 0.00153375, acc 1\n",
      "2018-04-13T15:24:59.254501: step 5162, loss 0.000529438, acc 1\n",
      "2018-04-13T15:24:59.575728: step 5163, loss 0.000572126, acc 1\n",
      "2018-04-13T15:24:59.908462: step 5164, loss 0.00142833, acc 1\n",
      "2018-04-13T15:25:00.226687: step 5165, loss 0.000515808, acc 1\n",
      "2018-04-13T15:25:00.534904: step 5166, loss 0.00508505, acc 1\n",
      "2018-04-13T15:25:00.862136: step 5167, loss 0.00134631, acc 1\n",
      "2018-04-13T15:25:01.183863: step 5168, loss 0.00148527, acc 1\n",
      "2018-04-13T15:25:01.522602: step 5169, loss 0.000948794, acc 1\n",
      "2018-04-13T15:25:01.855337: step 5170, loss 0.000425974, acc 1\n",
      "2018-04-13T15:25:02.176564: step 5171, loss 0.000238679, acc 1\n",
      "2018-04-13T15:25:02.489785: step 5172, loss 0.0011032, acc 1\n",
      "2018-04-13T15:25:02.825023: step 5173, loss 0.000487828, acc 1\n",
      "2018-04-13T15:25:03.145748: step 5174, loss 0.000190613, acc 1\n",
      "2018-04-13T15:25:03.456467: step 5175, loss 0.00113987, acc 1\n",
      "2018-04-13T15:25:03.781197: step 5176, loss 0.000133977, acc 1\n",
      "2018-04-13T15:25:04.100422: step 5177, loss 0.00394613, acc 1\n",
      "2018-04-13T15:25:04.443164: step 5178, loss 0.000772704, acc 1\n",
      "2018-04-13T15:25:04.763390: step 5179, loss 0.00103576, acc 1\n",
      "2018-04-13T15:25:05.080115: step 5180, loss 0.00151914, acc 1\n",
      "2018-04-13T15:25:05.395337: step 5181, loss 0.000398296, acc 1\n",
      "2018-04-13T15:25:05.724569: step 5182, loss 0.000319388, acc 1\n",
      "2018-04-13T15:25:06.057804: step 5183, loss 0.000171681, acc 1\n",
      "2018-04-13T15:25:06.383034: step 5184, loss 0.00148998, acc 1\n",
      "2018-04-13T15:25:06.713267: step 5185, loss 0.00444294, acc 1\n",
      "2018-04-13T15:25:07.036496: step 5186, loss 0.00146168, acc 1\n",
      "2018-04-13T15:25:07.371733: step 5187, loss 0.000495001, acc 1\n",
      "2018-04-13T15:25:07.710471: step 5188, loss 0.00308733, acc 1\n",
      "2018-04-13T15:25:08.042706: step 5189, loss 0.0106529, acc 1\n",
      "2018-04-13T15:25:08.365433: step 5190, loss 0.000222838, acc 1\n",
      "2018-04-13T15:25:08.674652: step 5191, loss 0.000652148, acc 1\n",
      "2018-04-13T15:25:09.000882: step 5192, loss 0.00626221, acc 1\n",
      "2018-04-13T15:25:09.331116: step 5193, loss 0.00290732, acc 1\n",
      "2018-04-13T15:25:09.659848: step 5194, loss 0.000336747, acc 1\n",
      "2018-04-13T15:25:09.984077: step 5195, loss 0.00220542, acc 1\n",
      "2018-04-13T15:25:10.329320: step 5196, loss 0.00148121, acc 1\n",
      "2018-04-13T15:25:10.670561: step 5197, loss 0.00119655, acc 1\n",
      "2018-04-13T15:25:11.012302: step 5198, loss 0.00171612, acc 1\n",
      "2018-04-13T15:25:11.335031: step 5199, loss 0.00130965, acc 1\n",
      "2018-04-13T15:25:11.656758: step 5200, loss 0.00159878, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:25:12.793560: step 5200, loss 1.42149, acc 0.748593\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5200\n",
      "\n",
      "2018-04-13T15:25:14.481536: step 5201, loss 0.0012693, acc 1\n",
      "2018-04-13T15:25:14.807766: step 5202, loss 0.00172997, acc 1\n",
      "2018-04-13T15:25:15.130994: step 5203, loss 0.000826225, acc 1\n",
      "2018-04-13T15:25:15.447717: step 5204, loss 0.000173113, acc 1\n",
      "2018-04-13T15:25:15.766443: step 5205, loss 0.00128735, acc 1\n",
      "2018-04-13T15:25:16.087669: step 5206, loss 0.00224173, acc 1\n",
      "2018-04-13T15:25:16.448925: step 5207, loss 0.000268703, acc 1\n",
      "2018-04-13T15:25:16.771652: step 5208, loss 0.000999146, acc 1\n",
      "2018-04-13T15:25:17.091378: step 5209, loss 0.00173535, acc 1\n",
      "2018-04-13T15:25:17.412605: step 5210, loss 0.000584034, acc 1\n",
      "2018-04-13T15:25:17.729329: step 5211, loss 0.00236052, acc 1\n",
      "2018-04-13T15:25:18.057060: step 5212, loss 0.00593375, acc 1\n",
      "2018-04-13T15:25:18.386292: step 5213, loss 0.000571814, acc 1\n",
      "2018-04-13T15:25:18.701515: step 5214, loss 0.0162109, acc 0.984375\n",
      "2018-04-13T15:25:19.038253: step 5215, loss 0.00441225, acc 1\n",
      "2018-04-13T15:25:19.390502: step 5216, loss 0.00197652, acc 1\n",
      "2018-04-13T15:25:19.737747: step 5217, loss 0.00258897, acc 1\n",
      "2018-04-13T15:25:20.055471: step 5218, loss 0.000295975, acc 1\n",
      "2018-04-13T15:25:20.386205: step 5219, loss 0.00057932, acc 1\n",
      "2018-04-13T15:25:20.712436: step 5220, loss 0.0014039, acc 1\n",
      "2018-04-13T15:25:21.043168: step 5221, loss 0.00189961, acc 1\n",
      "2018-04-13T15:25:21.366897: step 5222, loss 0.000244036, acc 1\n",
      "2018-04-13T15:25:21.673113: step 5223, loss 0.000934677, acc 1\n",
      "2018-04-13T15:25:22.015355: step 5224, loss 0.000279597, acc 1\n",
      "2018-04-13T15:25:22.359098: step 5225, loss 0.000508509, acc 1\n",
      "2018-04-13T15:25:22.688831: step 5226, loss 0.00293052, acc 1\n",
      "2018-04-13T15:25:23.024075: step 5227, loss 0.00348665, acc 1\n",
      "2018-04-13T15:25:23.356810: step 5228, loss 0.00697295, acc 1\n",
      "2018-04-13T15:25:23.678537: step 5229, loss 0.000471806, acc 1\n",
      "2018-04-13T15:25:24.006768: step 5230, loss 0.000911558, acc 1\n",
      "2018-04-13T15:25:24.333500: step 5231, loss 0.000852362, acc 1\n",
      "2018-04-13T15:25:24.641217: step 5232, loss 0.00361185, acc 1\n",
      "2018-04-13T15:25:24.964945: step 5233, loss 0.00103432, acc 1\n",
      "2018-04-13T15:25:25.300182: step 5234, loss 0.0272263, acc 0.984375\n",
      "2018-04-13T15:25:25.652431: step 5235, loss 0.000761473, acc 1\n",
      "2018-04-13T15:25:25.977161: step 5236, loss 0.0050978, acc 1\n",
      "2018-04-13T15:25:26.308394: step 5237, loss 0.00129416, acc 1\n",
      "2018-04-13T15:25:26.615611: step 5238, loss 0.00153576, acc 1\n",
      "2018-04-13T15:25:26.927331: step 5239, loss 0.000703577, acc 1\n",
      "2018-04-13T15:25:27.247557: step 5240, loss 0.000779253, acc 1\n",
      "2018-04-13T15:25:27.577303: step 5241, loss 0.00209827, acc 1\n",
      "2018-04-13T15:25:27.901532: step 5242, loss 0.00285524, acc 1\n",
      "2018-04-13T15:25:28.239271: step 5243, loss 0.00341807, acc 1\n",
      "2018-04-13T15:25:28.596524: step 5244, loss 0.00224886, acc 1\n",
      "2018-04-13T15:25:28.922754: step 5245, loss 0.000190387, acc 1\n",
      "2018-04-13T15:25:29.250486: step 5246, loss 0.0015536, acc 1\n",
      "2018-04-13T15:25:29.575214: step 5247, loss 0.000356457, acc 1\n",
      "2018-04-13T15:25:29.894441: step 5248, loss 0.060515, acc 0.984375\n",
      "2018-04-13T15:25:30.222672: step 5249, loss 0.00117971, acc 1\n",
      "2018-04-13T15:25:30.516379: step 5250, loss 0.000579397, acc 1\n",
      "2018-04-13T15:25:30.841108: step 5251, loss 0.000683816, acc 1\n",
      "2018-04-13T15:25:31.159333: step 5252, loss 0.0235997, acc 0.984375\n",
      "2018-04-13T15:25:31.531596: step 5253, loss 0.00113237, acc 1\n",
      "2018-04-13T15:25:31.846319: step 5254, loss 0.000428125, acc 1\n",
      "2018-04-13T15:25:32.172549: step 5255, loss 0.0138117, acc 0.984375\n",
      "2018-04-13T15:25:32.506784: step 5256, loss 0.000540067, acc 1\n",
      "2018-04-13T15:25:32.837017: step 5257, loss 0.000994352, acc 1\n",
      "2018-04-13T15:25:33.152741: step 5258, loss 0.000520027, acc 1\n",
      "2018-04-13T15:25:33.478971: step 5259, loss 0.00350666, acc 1\n",
      "2018-04-13T15:25:33.811205: step 5260, loss 0.025796, acc 0.984375\n",
      "2018-04-13T15:25:34.129431: step 5261, loss 0.000363542, acc 1\n",
      "2018-04-13T15:25:34.462165: step 5262, loss 0.00306915, acc 1\n",
      "2018-04-13T15:25:34.806909: step 5263, loss 0.00320589, acc 1\n",
      "2018-04-13T15:25:35.148656: step 5264, loss 0.00242375, acc 1\n",
      "2018-04-13T15:25:35.469376: step 5265, loss 0.000764611, acc 1\n",
      "2018-04-13T15:25:35.799109: step 5266, loss 0.000325499, acc 1\n",
      "2018-04-13T15:25:36.120336: step 5267, loss 0.000512075, acc 1\n",
      "2018-04-13T15:25:36.433057: step 5268, loss 0.000751021, acc 1\n",
      "2018-04-13T15:25:36.750281: step 5269, loss 0.00196739, acc 1\n",
      "2018-04-13T15:25:37.071508: step 5270, loss 0.00699906, acc 1\n",
      "2018-04-13T15:25:37.417252: step 5271, loss 0.000602683, acc 1\n",
      "2018-04-13T15:25:37.745494: step 5272, loss 0.00302989, acc 1\n",
      "2018-04-13T15:25:38.082721: step 5273, loss 0.00310192, acc 1\n",
      "2018-04-13T15:25:38.405950: step 5274, loss 0.00225194, acc 1\n",
      "2018-04-13T15:25:38.736683: step 5275, loss 0.000833591, acc 1\n",
      "2018-04-13T15:25:39.062913: step 5276, loss 0.00390328, acc 1\n",
      "2018-04-13T15:25:39.390145: step 5277, loss 0.00181746, acc 1\n",
      "2018-04-13T15:25:39.727384: step 5278, loss 0.00264092, acc 1\n",
      "2018-04-13T15:25:40.066622: step 5279, loss 0.000488248, acc 1\n",
      "2018-04-13T15:25:40.392354: step 5280, loss 0.0003443, acc 1\n",
      "2018-04-13T15:25:40.728590: step 5281, loss 0.00165961, acc 1\n",
      "2018-04-13T15:25:41.054320: step 5282, loss 0.00362574, acc 1\n",
      "2018-04-13T15:25:41.366040: step 5283, loss 0.00260986, acc 1\n",
      "2018-04-13T15:25:41.686266: step 5284, loss 0.000454038, acc 1\n",
      "2018-04-13T15:25:42.017000: step 5285, loss 0.00357132, acc 1\n",
      "2018-04-13T15:25:42.337726: step 5286, loss 0.00212297, acc 1\n",
      "2018-04-13T15:25:42.656452: step 5287, loss 0.00472121, acc 1\n",
      "2018-04-13T15:25:42.984683: step 5288, loss 0.000232279, acc 1\n",
      "2018-04-13T15:25:43.314416: step 5289, loss 0.000139578, acc 1\n",
      "2018-04-13T15:25:43.659660: step 5290, loss 0.00018819, acc 1\n",
      "2018-04-13T15:25:43.981387: step 5291, loss 0.00138105, acc 1\n",
      "2018-04-13T15:25:44.297610: step 5292, loss 0.000919651, acc 1\n",
      "2018-04-13T15:25:44.604827: step 5293, loss 0.000577201, acc 1\n",
      "2018-04-13T15:25:44.934560: step 5294, loss 0.000115081, acc 1\n",
      "2018-04-13T15:25:45.252285: step 5295, loss 0.00104267, acc 1\n",
      "2018-04-13T15:25:45.574011: step 5296, loss 0.000301927, acc 1\n",
      "2018-04-13T15:25:45.911250: step 5297, loss 0.00169796, acc 1\n",
      "2018-04-13T15:25:46.219968: step 5298, loss 0.000537887, acc 1\n",
      "2018-04-13T15:25:46.569716: step 5299, loss 0.000845375, acc 1\n",
      "2018-04-13T15:25:46.898947: step 5300, loss 0.0030846, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:25:48.051301: step 5300, loss 1.48448, acc 0.751407\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5300\n",
      "\n",
      "2018-04-13T15:25:49.660437: step 5301, loss 0.000953566, acc 1\n",
      "2018-04-13T15:25:49.982665: step 5302, loss 0.00212994, acc 1\n",
      "2018-04-13T15:25:50.310396: step 5303, loss 0.000304831, acc 1\n",
      "2018-04-13T15:25:50.624618: step 5304, loss 0.000460803, acc 1\n",
      "2018-04-13T15:25:50.947846: step 5305, loss 0.000555952, acc 1\n",
      "2018-04-13T15:25:51.263569: step 5306, loss 0.000408631, acc 1\n",
      "2018-04-13T15:25:51.584295: step 5307, loss 0.000616538, acc 1\n",
      "2018-04-13T15:25:51.904021: step 5308, loss 0.0553279, acc 0.984375\n",
      "2018-04-13T15:25:52.244762: step 5309, loss 0.000960861, acc 1\n",
      "2018-04-13T15:25:52.601013: step 5310, loss 0.000799092, acc 1\n",
      "2018-04-13T15:25:52.935749: step 5311, loss 0.000395014, acc 1\n",
      "2018-04-13T15:25:53.262981: step 5312, loss 0.00158467, acc 1\n",
      "2018-04-13T15:25:53.593803: step 5313, loss 0.00467161, acc 1\n",
      "2018-04-13T15:25:53.932543: step 5314, loss 0.00141064, acc 1\n",
      "2018-04-13T15:25:54.259774: step 5315, loss 0.00566862, acc 1\n",
      "2018-04-13T15:25:54.576497: step 5316, loss 0.00150163, acc 1\n",
      "2018-04-13T15:25:54.909232: step 5317, loss 0.00126459, acc 1\n",
      "2018-04-13T15:25:55.240967: step 5318, loss 0.00141635, acc 1\n",
      "2018-04-13T15:25:55.589713: step 5319, loss 0.000589109, acc 1\n",
      "2018-04-13T15:25:55.923010: step 5320, loss 0.0042711, acc 1\n",
      "2018-04-13T15:25:56.252242: step 5321, loss 0.00323238, acc 1\n",
      "2018-04-13T15:25:56.567965: step 5322, loss 0.00112845, acc 1\n",
      "2018-04-13T15:25:56.903702: step 5323, loss 0.00338538, acc 1\n",
      "2018-04-13T15:25:57.227431: step 5324, loss 0.00687314, acc 1\n",
      "2018-04-13T15:25:57.623214: step 5325, loss 0.00164418, acc 1\n",
      "2018-04-13T15:25:58.012441: step 5326, loss 0.0196011, acc 0.984375\n",
      "2018-04-13T15:25:58.355184: step 5327, loss 0.0164795, acc 0.984375\n",
      "2018-04-13T15:25:58.708932: step 5328, loss 0.0276058, acc 0.984375\n",
      "2018-04-13T15:25:59.038666: step 5329, loss 0.00255447, acc 1\n",
      "2018-04-13T15:25:59.363896: step 5330, loss 0.0179764, acc 0.984375\n",
      "2018-04-13T15:25:59.681620: step 5331, loss 0.00103325, acc 1\n",
      "2018-04-13T15:26:00.018859: step 5332, loss 0.000868392, acc 1\n",
      "2018-04-13T15:26:00.351093: step 5333, loss 0.00195582, acc 1\n",
      "2018-04-13T15:26:00.692334: step 5334, loss 0.00063364, acc 1\n",
      "2018-04-13T15:26:01.017062: step 5335, loss 0.000279992, acc 1\n",
      "2018-04-13T15:26:01.334787: step 5336, loss 9.42508e-05, acc 1\n",
      "2018-04-13T15:26:01.699545: step 5337, loss 0.0195188, acc 0.984375\n",
      "2018-04-13T15:26:02.027276: step 5338, loss 0.000578075, acc 1\n",
      "2018-04-13T15:26:02.341498: step 5339, loss 0.00134245, acc 1\n",
      "2018-04-13T15:26:02.676234: step 5340, loss 0.00274371, acc 1\n",
      "2018-04-13T15:26:03.000964: step 5341, loss 0.000353346, acc 1\n",
      "2018-04-13T15:26:03.319688: step 5342, loss 0.000713941, acc 1\n",
      "2018-04-13T15:26:03.631909: step 5343, loss 0.00229614, acc 1\n",
      "2018-04-13T15:26:03.961142: step 5344, loss 0.00157863, acc 1\n",
      "2018-04-13T15:26:04.273862: step 5345, loss 0.00296947, acc 1\n",
      "2018-04-13T15:26:04.636619: step 5346, loss 0.00852465, acc 1\n",
      "2018-04-13T15:26:04.970355: step 5347, loss 0.000756854, acc 1\n",
      "2018-04-13T15:26:05.289580: step 5348, loss 0.00299953, acc 1\n",
      "2018-04-13T15:26:05.614809: step 5349, loss 0.00516641, acc 1\n",
      "2018-04-13T15:26:05.937537: step 5350, loss 0.000555304, acc 1\n",
      "2018-04-13T15:26:06.264268: step 5351, loss 0.00340535, acc 1\n",
      "2018-04-13T15:26:06.583994: step 5352, loss 0.013602, acc 0.984375\n",
      "2018-04-13T15:26:06.910225: step 5353, loss 0.000458966, acc 1\n",
      "2018-04-13T15:26:07.231951: step 5354, loss 0.000736896, acc 1\n",
      "2018-04-13T15:26:07.581699: step 5355, loss 0.00158703, acc 1\n",
      "2018-04-13T15:26:07.918936: step 5356, loss 0.00438708, acc 1\n",
      "2018-04-13T15:26:08.235160: step 5357, loss 0.000744724, acc 1\n",
      "2018-04-13T15:26:08.544378: step 5358, loss 0.00123205, acc 1\n",
      "2018-04-13T15:26:08.883117: step 5359, loss 0.000211342, acc 1\n",
      "2018-04-13T15:26:09.204844: step 5360, loss 0.0051041, acc 1\n",
      "2018-04-13T15:26:09.523570: step 5361, loss 0.000239373, acc 1\n",
      "2018-04-13T15:26:09.868313: step 5362, loss 0.00369936, acc 1\n",
      "2018-04-13T15:26:10.208553: step 5363, loss 0.00618834, acc 1\n",
      "2018-04-13T15:26:10.560309: step 5364, loss 0.0391035, acc 0.96875\n",
      "2018-04-13T15:26:10.909555: step 5365, loss 0.0020961, acc 1\n",
      "2018-04-13T15:26:11.220775: step 5366, loss 0.00972552, acc 1\n",
      "2018-04-13T15:26:11.537498: step 5367, loss 0.000274114, acc 1\n",
      "2018-04-13T15:26:11.878744: step 5368, loss 0.000582146, acc 1\n",
      "2018-04-13T15:26:12.200467: step 5369, loss 0.00032824, acc 1\n",
      "2018-04-13T15:26:12.518191: step 5370, loss 0.00219933, acc 1\n",
      "2018-04-13T15:26:12.853928: step 5371, loss 0.0029401, acc 1\n",
      "2018-04-13T15:26:13.165148: step 5372, loss 0.00122523, acc 1\n",
      "2018-04-13T15:26:13.494882: step 5373, loss 0.00450562, acc 1\n",
      "2018-04-13T15:26:13.841626: step 5374, loss 0.0015099, acc 1\n",
      "2018-04-13T15:26:14.165354: step 5375, loss 0.00112654, acc 1\n",
      "2018-04-13T15:26:14.483079: step 5376, loss 0.000640368, acc 1\n",
      "2018-04-13T15:26:14.826321: step 5377, loss 0.000200791, acc 1\n",
      "2018-04-13T15:26:15.164560: step 5378, loss 0.00356873, acc 1\n",
      "2018-04-13T15:26:15.469775: step 5379, loss 0.000245365, acc 1\n",
      "2018-04-13T15:26:15.794005: step 5380, loss 0.00156028, acc 1\n",
      "2018-04-13T15:26:16.125238: step 5381, loss 0.00500765, acc 1\n",
      "2018-04-13T15:26:16.468481: step 5382, loss 0.00998991, acc 1\n",
      "2018-04-13T15:26:16.822230: step 5383, loss 0.0081949, acc 1\n",
      "2018-04-13T15:26:17.143457: step 5384, loss 0.00027792, acc 1\n",
      "2018-04-13T15:26:17.459682: step 5385, loss 0.00117496, acc 1\n",
      "2018-04-13T15:26:17.781408: step 5386, loss 0.00027068, acc 1\n",
      "2018-04-13T15:26:18.101634: step 5387, loss 0.00119434, acc 1\n",
      "2018-04-13T15:26:18.417857: step 5388, loss 0.000330132, acc 1\n",
      "2018-04-13T15:26:18.750093: step 5389, loss 0.0125321, acc 1\n",
      "2018-04-13T15:26:19.096836: step 5390, loss 0.00143416, acc 1\n",
      "2018-04-13T15:26:19.420065: step 5391, loss 0.0106103, acc 1\n",
      "2018-04-13T15:26:19.849868: step 5392, loss 0.00343827, acc 1\n",
      "2018-04-13T15:26:20.208122: step 5393, loss 0.00131741, acc 1\n",
      "2018-04-13T15:26:20.559369: step 5394, loss 0.000751756, acc 1\n",
      "2018-04-13T15:26:20.955149: step 5395, loss 0.00513928, acc 1\n",
      "2018-04-13T15:26:21.297891: step 5396, loss 0.00830511, acc 1\n",
      "2018-04-13T15:26:21.626623: step 5397, loss 0.000794547, acc 1\n",
      "2018-04-13T15:26:21.964862: step 5398, loss 0.00155226, acc 1\n",
      "2018-04-13T15:26:22.291592: step 5399, loss 0.00086643, acc 1\n",
      "2018-04-13T15:26:22.642341: step 5400, loss 0.000314236, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:26:23.801659: step 5400, loss 1.4802, acc 0.747655\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5400\n",
      "\n",
      "2018-04-13T15:26:25.677984: step 5401, loss 0.000121915, acc 1\n",
      "2018-04-13T15:26:26.009717: step 5402, loss 0.000703044, acc 1\n",
      "2018-04-13T15:26:26.327942: step 5403, loss 0.00190696, acc 1\n",
      "2018-04-13T15:26:26.642664: step 5404, loss 0.0127945, acc 1\n",
      "2018-04-13T15:26:26.977401: step 5405, loss 0.00176384, acc 1\n",
      "2018-04-13T15:26:27.298127: step 5406, loss 0.000520047, acc 1\n",
      "2018-04-13T15:26:27.625859: step 5407, loss 0.00743818, acc 1\n",
      "2018-04-13T15:26:27.954091: step 5408, loss 0.000251665, acc 1\n",
      "2018-04-13T15:26:28.269813: step 5409, loss 0.000122155, acc 1\n",
      "2018-04-13T15:26:28.615558: step 5410, loss 0.00338949, acc 1\n",
      "2018-04-13T15:26:28.957299: step 5411, loss 0.00179633, acc 1\n",
      "2018-04-13T15:26:29.272021: step 5412, loss 0.00085014, acc 1\n",
      "2018-04-13T15:26:29.596751: step 5413, loss 0.00288236, acc 1\n",
      "2018-04-13T15:26:29.922480: step 5414, loss 0.000254992, acc 1\n",
      "2018-04-13T15:26:30.245208: step 5415, loss 0.000140632, acc 1\n",
      "2018-04-13T15:26:30.565935: step 5416, loss 0.00600631, acc 1\n",
      "2018-04-13T15:26:30.890664: step 5417, loss 0.00139787, acc 1\n",
      "2018-04-13T15:26:31.216395: step 5418, loss 0.000267007, acc 1\n",
      "2018-04-13T15:26:31.546127: step 5419, loss 0.00226441, acc 1\n",
      "2018-04-13T15:26:31.896875: step 5420, loss 0.00165782, acc 1\n",
      "2018-04-13T15:26:32.211597: step 5421, loss 0.000400824, acc 1\n",
      "2018-04-13T15:26:32.535325: step 5422, loss 0.000177401, acc 1\n",
      "2018-04-13T15:26:32.873064: step 5423, loss 0.000379975, acc 1\n",
      "2018-04-13T15:26:33.205298: step 5424, loss 0.0397542, acc 0.984375\n",
      "2018-04-13T15:26:33.525524: step 5425, loss 0.000814999, acc 1\n",
      "2018-04-13T15:26:33.856761: step 5426, loss 6.04301e-05, acc 1\n",
      "2018-04-13T15:26:34.178986: step 5427, loss 0.000684438, acc 1\n",
      "2018-04-13T15:26:34.502715: step 5428, loss 0.000464286, acc 1\n",
      "2018-04-13T15:26:34.852462: step 5429, loss 0.000279863, acc 1\n",
      "2018-04-13T15:26:35.166183: step 5430, loss 0.00324663, acc 1\n",
      "2018-04-13T15:26:35.475902: step 5431, loss 0.00945644, acc 1\n",
      "2018-04-13T15:26:35.822647: step 5432, loss 0.00100108, acc 1\n",
      "2018-04-13T15:26:36.147876: step 5433, loss 9.42946e-05, acc 1\n",
      "2018-04-13T15:26:36.467602: step 5434, loss 0.00845241, acc 1\n",
      "2018-04-13T15:26:36.793332: step 5435, loss 0.00133324, acc 1\n",
      "2018-04-13T15:26:37.120063: step 5436, loss 0.00146574, acc 1\n",
      "2018-04-13T15:26:37.442291: step 5437, loss 0.000221906, acc 1\n",
      "2018-04-13T15:26:37.796540: step 5438, loss 0.0107659, acc 1\n",
      "2018-04-13T15:26:38.126273: step 5439, loss 0.00375941, acc 1\n",
      "2018-04-13T15:26:38.455006: step 5440, loss 0.00297274, acc 1\n",
      "2018-04-13T15:26:38.788741: step 5441, loss 0.000135425, acc 1\n",
      "2018-04-13T15:26:39.116973: step 5442, loss 0.00177381, acc 1\n",
      "2018-04-13T15:26:39.439701: step 5443, loss 0.00481443, acc 1\n",
      "2018-04-13T15:26:39.769434: step 5444, loss 0.00356596, acc 1\n",
      "2018-04-13T15:26:40.127186: step 5445, loss 0.00181829, acc 1\n",
      "2018-04-13T15:26:40.455419: step 5446, loss 0.00115191, acc 1\n",
      "2018-04-13T15:26:40.803164: step 5447, loss 0.00254933, acc 1\n",
      "2018-04-13T15:26:41.136899: step 5448, loss 0.00336637, acc 1\n",
      "2018-04-13T15:26:41.460128: step 5449, loss 0.000469413, acc 1\n",
      "2018-04-13T15:26:41.779854: step 5450, loss 0.00288789, acc 1\n",
      "2018-04-13T15:26:42.100079: step 5451, loss 0.00106638, acc 1\n",
      "2018-04-13T15:26:42.411299: step 5452, loss 0.000528342, acc 1\n",
      "2018-04-13T15:26:42.739531: step 5453, loss 0.0308494, acc 0.984375\n",
      "2018-04-13T15:26:43.058256: step 5454, loss 0.000578006, acc 1\n",
      "2018-04-13T15:26:43.371977: step 5455, loss 0.000683442, acc 1\n",
      "2018-04-13T15:26:43.731232: step 5456, loss 0.00583411, acc 1\n",
      "2018-04-13T15:26:44.050957: step 5457, loss 0.0034008, acc 1\n",
      "2018-04-13T15:26:44.377688: step 5458, loss 0.00263725, acc 1\n",
      "2018-04-13T15:26:44.706419: step 5459, loss 0.00580002, acc 1\n",
      "2018-04-13T15:26:45.029648: step 5460, loss 0.00506949, acc 1\n",
      "2018-04-13T15:26:45.343870: step 5461, loss 9.9898e-05, acc 1\n",
      "2018-04-13T15:26:45.669099: step 5462, loss 0.0050566, acc 1\n",
      "2018-04-13T15:26:45.999833: step 5463, loss 0.00268988, acc 1\n",
      "2018-04-13T15:26:46.313554: step 5464, loss 0.00276974, acc 1\n",
      "2018-04-13T15:26:46.653795: step 5465, loss 0.00889837, acc 1\n",
      "2018-04-13T15:26:47.000040: step 5466, loss 0.0138291, acc 0.984375\n",
      "2018-04-13T15:26:47.323267: step 5467, loss 0.000222431, acc 1\n",
      "2018-04-13T15:26:47.645495: step 5468, loss 0.00280655, acc 1\n",
      "2018-04-13T15:26:47.977229: step 5469, loss 0.000351839, acc 1\n",
      "2018-04-13T15:26:48.294453: step 5470, loss 0.00105592, acc 1\n",
      "2018-04-13T15:26:48.620183: step 5471, loss 0.000125354, acc 1\n",
      "2018-04-13T15:26:48.997950: step 5472, loss 0.00454607, acc 1\n",
      "2018-04-13T15:26:49.332687: step 5473, loss 0.000680752, acc 1\n",
      "2018-04-13T15:26:49.754484: step 5474, loss 0.000156318, acc 1\n",
      "2018-04-13T15:26:50.077712: step 5475, loss 0.00152324, acc 1\n",
      "2018-04-13T15:26:50.409947: step 5476, loss 0.00100714, acc 1\n",
      "2018-04-13T15:26:50.745183: step 5477, loss 0.000427551, acc 1\n",
      "2018-04-13T15:26:51.066411: step 5478, loss 6.42889e-05, acc 1\n",
      "2018-04-13T15:26:51.394142: step 5479, loss 0.00329923, acc 1\n",
      "2018-04-13T15:26:51.732882: step 5480, loss 0.000752268, acc 1\n",
      "2018-04-13T15:26:52.054611: step 5481, loss 0.00400228, acc 1\n",
      "2018-04-13T15:26:52.368331: step 5482, loss 0.00857453, acc 1\n",
      "2018-04-13T15:26:52.743595: step 5483, loss 0.0046744, acc 1\n",
      "2018-04-13T15:26:53.063821: step 5484, loss 0.000773826, acc 1\n",
      "2018-04-13T15:26:53.389051: step 5485, loss 0.00141153, acc 1\n",
      "2018-04-13T15:26:53.724288: step 5486, loss 0.00247507, acc 1\n",
      "2018-04-13T15:26:54.052519: step 5487, loss 0.004198, acc 1\n",
      "2018-04-13T15:26:54.371244: step 5488, loss 0.000551955, acc 1\n",
      "2018-04-13T15:26:54.706982: step 5489, loss 0.00286206, acc 1\n",
      "2018-04-13T15:26:55.033211: step 5490, loss 0.000412987, acc 1\n",
      "2018-04-13T15:26:55.343931: step 5491, loss 0.00125713, acc 1\n",
      "2018-04-13T15:26:55.688676: step 5492, loss 0.00273394, acc 1\n",
      "2018-04-13T15:26:56.037420: step 5493, loss 0.000560923, acc 1\n",
      "2018-04-13T15:26:56.375660: step 5494, loss 0.00182882, acc 1\n",
      "2018-04-13T15:26:56.692384: step 5495, loss 0.0122365, acc 0.984375\n",
      "2018-04-13T15:26:57.041629: step 5496, loss 0.000707951, acc 1\n",
      "2018-04-13T15:26:57.360355: step 5497, loss 0.0026617, acc 1\n",
      "2018-04-13T15:26:57.687086: step 5498, loss 0.00050787, acc 1\n",
      "2018-04-13T15:26:58.011815: step 5499, loss 0.000487606, acc 1\n",
      "2018-04-13T15:26:58.331543: step 5500, loss 7.12046e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:26:59.537392: step 5500, loss 1.48962, acc 0.744841\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5500\n",
      "\n",
      "2018-04-13T15:27:01.152032: step 5501, loss 0.000306051, acc 1\n",
      "2018-04-13T15:27:01.479265: step 5502, loss 0.000880807, acc 1\n",
      "2018-04-13T15:27:01.859031: step 5503, loss 0.00495701, acc 1\n",
      "2018-04-13T15:27:02.183260: step 5504, loss 0.000188375, acc 1\n",
      "2018-04-13T15:27:02.494981: step 5505, loss 0.00389982, acc 1\n",
      "2018-04-13T15:27:02.831218: step 5506, loss 8.3687e-05, acc 1\n",
      "2018-04-13T15:27:03.141438: step 5507, loss 0.00156558, acc 1\n",
      "2018-04-13T15:27:03.455659: step 5508, loss 0.00203087, acc 1\n",
      "2018-04-13T15:27:03.798401: step 5509, loss 0.0126386, acc 0.984375\n",
      "2018-04-13T15:27:04.121629: step 5510, loss 0.00497207, acc 1\n",
      "2018-04-13T15:27:04.444357: step 5511, loss 0.00138274, acc 1\n",
      "2018-04-13T15:27:04.811616: step 5512, loss 0.000307647, acc 1\n",
      "2018-04-13T15:27:05.130842: step 5513, loss 0.00388039, acc 1\n",
      "2018-04-13T15:27:05.445612: step 5514, loss 0.00339739, acc 1\n",
      "2018-04-13T15:27:05.795359: step 5515, loss 0.00212741, acc 1\n",
      "2018-04-13T15:27:06.114584: step 5516, loss 0.0252361, acc 0.984375\n",
      "2018-04-13T15:27:06.427305: step 5517, loss 0.00388076, acc 1\n",
      "2018-04-13T15:27:06.746530: step 5518, loss 0.021062, acc 0.984375\n",
      "2018-04-13T15:27:07.076764: step 5519, loss 0.0309394, acc 0.984375\n",
      "2018-04-13T15:27:07.389985: step 5520, loss 0.00995246, acc 1\n",
      "2018-04-13T15:27:07.747237: step 5521, loss 0.000191941, acc 1\n",
      "2018-04-13T15:27:08.090980: step 5522, loss 0.000801017, acc 1\n",
      "2018-04-13T15:27:08.410706: step 5523, loss 0.00174908, acc 1\n",
      "2018-04-13T15:27:08.740438: step 5524, loss 0.00021248, acc 1\n",
      "2018-04-13T15:27:09.058663: step 5525, loss 0.000531587, acc 1\n",
      "2018-04-13T15:27:09.382892: step 5526, loss 0.000167526, acc 1\n",
      "2018-04-13T15:27:09.715126: step 5527, loss 0.00244367, acc 1\n",
      "2018-04-13T15:27:10.024845: step 5528, loss 0.0405068, acc 0.984375\n",
      "2018-04-13T15:27:10.344571: step 5529, loss 0.00232528, acc 1\n",
      "2018-04-13T15:27:10.680808: step 5530, loss 0.00697362, acc 1\n",
      "2018-04-13T15:27:11.029555: step 5531, loss 0.00163738, acc 1\n",
      "2018-04-13T15:27:11.359288: step 5532, loss 0.0109593, acc 1\n",
      "2018-04-13T15:27:11.676011: step 5533, loss 0.00199573, acc 1\n",
      "2018-04-13T15:27:12.021755: step 5534, loss 0.00311095, acc 1\n",
      "2018-04-13T15:27:12.347485: step 5535, loss 0.000246973, acc 1\n",
      "2018-04-13T15:27:12.672215: step 5536, loss 0.00438704, acc 1\n",
      "2018-04-13T15:27:12.999946: step 5537, loss 0.00126749, acc 1\n",
      "2018-04-13T15:27:13.311666: step 5538, loss 0.00475439, acc 1\n",
      "2018-04-13T15:27:13.649405: step 5539, loss 0.00385254, acc 1\n",
      "2018-04-13T15:27:14.006656: step 5540, loss 0.00103458, acc 1\n",
      "2018-04-13T15:27:14.322880: step 5541, loss 0.00238369, acc 1\n",
      "2018-04-13T15:27:14.644607: step 5542, loss 0.0163261, acc 0.984375\n",
      "2018-04-13T15:27:14.977843: step 5543, loss 0.00904382, acc 1\n",
      "2018-04-13T15:27:15.294066: step 5544, loss 0.0002838, acc 1\n",
      "2018-04-13T15:27:15.614292: step 5545, loss 0.000323107, acc 1\n",
      "2018-04-13T15:27:15.952030: step 5546, loss 0.000909143, acc 1\n",
      "2018-04-13T15:27:16.259247: step 5547, loss 0.00657899, acc 1\n",
      "2018-04-13T15:27:16.588980: step 5548, loss 0.00137774, acc 1\n",
      "2018-04-13T15:27:16.953237: step 5549, loss 8.71836e-05, acc 1\n",
      "2018-04-13T15:27:17.257452: step 5550, loss 0.0640791, acc 0.983333\n",
      "2018-04-13T15:27:17.572174: step 5551, loss 0.000843399, acc 1\n",
      "2018-04-13T15:27:17.901407: step 5552, loss 0.0298591, acc 0.984375\n",
      "2018-04-13T15:27:18.231640: step 5553, loss 0.000235929, acc 1\n",
      "2018-04-13T15:27:18.540858: step 5554, loss 0.0138718, acc 0.984375\n",
      "2018-04-13T15:27:18.878096: step 5555, loss 0.000380177, acc 1\n",
      "2018-04-13T15:27:19.201325: step 5556, loss 0.00098525, acc 1\n",
      "2018-04-13T15:27:19.531558: step 5557, loss 0.000446576, acc 1\n",
      "2018-04-13T15:27:19.896816: step 5558, loss 0.0045517, acc 1\n",
      "2018-04-13T15:27:20.219043: step 5559, loss 0.00131302, acc 1\n",
      "2018-04-13T15:27:20.542773: step 5560, loss 0.000491249, acc 1\n",
      "2018-04-13T15:27:20.870003: step 5561, loss 0.000729953, acc 1\n",
      "2018-04-13T15:27:21.197734: step 5562, loss 0.00105, acc 1\n",
      "2018-04-13T15:27:21.517460: step 5563, loss 0.000227358, acc 1\n",
      "2018-04-13T15:27:21.838187: step 5564, loss 0.000638455, acc 1\n",
      "2018-04-13T15:27:22.147405: step 5565, loss 0.00950813, acc 1\n",
      "2018-04-13T15:27:22.465129: step 5566, loss 0.00017063, acc 1\n",
      "2018-04-13T15:27:22.814877: step 5567, loss 0.000310604, acc 1\n",
      "2018-04-13T15:27:23.145109: step 5568, loss 0.00113453, acc 1\n",
      "2018-04-13T15:27:23.455330: step 5569, loss 0.00130258, acc 1\n",
      "2018-04-13T15:27:23.797069: step 5570, loss 0.00258452, acc 1\n",
      "2018-04-13T15:27:24.126302: step 5571, loss 0.00020447, acc 1\n",
      "2018-04-13T15:27:24.434521: step 5572, loss 0.00617621, acc 1\n",
      "2018-04-13T15:27:24.775760: step 5573, loss 0.000370802, acc 1\n",
      "2018-04-13T15:27:25.088982: step 5574, loss 0.00235948, acc 1\n",
      "2018-04-13T15:27:25.410268: step 5575, loss 0.00154944, acc 1\n",
      "2018-04-13T15:27:25.756011: step 5576, loss 0.0010956, acc 1\n",
      "2018-04-13T15:27:26.092249: step 5577, loss 0.00135379, acc 1\n",
      "2018-04-13T15:27:26.409973: step 5578, loss 0.00440581, acc 1\n",
      "2018-04-13T15:27:26.739707: step 5579, loss 0.000859146, acc 1\n",
      "2018-04-13T15:27:27.062434: step 5580, loss 0.00132576, acc 1\n",
      "2018-04-13T15:27:27.391667: step 5581, loss 0.00558057, acc 1\n",
      "2018-04-13T15:27:27.726904: step 5582, loss 0.000929509, acc 1\n",
      "2018-04-13T15:27:28.040625: step 5583, loss 0.00190539, acc 1\n",
      "2018-04-13T15:27:28.366355: step 5584, loss 0.000412083, acc 1\n",
      "2018-04-13T15:27:28.719604: step 5585, loss 0.00169196, acc 1\n",
      "2018-04-13T15:27:29.059345: step 5586, loss 0.000398196, acc 1\n",
      "2018-04-13T15:27:29.384574: step 5587, loss 0.00206912, acc 1\n",
      "2018-04-13T15:27:29.697295: step 5588, loss 7.70195e-05, acc 1\n",
      "2018-04-13T15:27:30.017027: step 5589, loss 0.00050107, acc 1\n",
      "2018-04-13T15:27:30.332257: step 5590, loss 0.00484121, acc 1\n",
      "2018-04-13T15:27:30.662483: step 5591, loss 0.000451954, acc 1\n",
      "2018-04-13T15:27:31.010229: step 5592, loss 0.000429155, acc 1\n",
      "2018-04-13T15:27:31.329954: step 5593, loss 5.70809e-05, acc 1\n",
      "2018-04-13T15:27:31.646178: step 5594, loss 0.00322659, acc 1\n",
      "2018-04-13T15:27:32.003932: step 5595, loss 0.0150274, acc 0.984375\n",
      "2018-04-13T15:27:32.321654: step 5596, loss 0.0154899, acc 1\n",
      "2018-04-13T15:27:32.644883: step 5597, loss 0.00142285, acc 1\n",
      "2018-04-13T15:27:32.970112: step 5598, loss 0.000186706, acc 1\n",
      "2018-04-13T15:27:33.276829: step 5599, loss 0.00384909, acc 1\n",
      "2018-04-13T15:27:33.585047: step 5600, loss 0.000412648, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:27:34.724854: step 5600, loss 1.50582, acc 0.748593\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5600\n",
      "\n",
      "2018-04-13T15:27:36.551664: step 5601, loss 0.00140209, acc 1\n",
      "2018-04-13T15:27:36.891905: step 5602, loss 0.00688996, acc 1\n",
      "2018-04-13T15:27:37.213632: step 5603, loss 0.000616548, acc 1\n",
      "2018-04-13T15:27:37.525853: step 5604, loss 0.000577887, acc 1\n",
      "2018-04-13T15:27:37.878602: step 5605, loss 0.000209978, acc 1\n",
      "2018-04-13T15:27:38.201329: step 5606, loss 0.00166929, acc 1\n",
      "2018-04-13T15:27:38.519054: step 5607, loss 0.00287809, acc 1\n",
      "2018-04-13T15:27:38.860295: step 5608, loss 0.000209539, acc 1\n",
      "2018-04-13T15:27:39.177018: step 5609, loss 8.89601e-05, acc 1\n",
      "2018-04-13T15:27:39.486737: step 5610, loss 0.00105251, acc 1\n",
      "2018-04-13T15:27:39.813467: step 5611, loss 0.000786791, acc 1\n",
      "2018-04-13T15:27:40.148204: step 5612, loss 0.00255454, acc 1\n",
      "2018-04-13T15:27:40.464929: step 5613, loss 0.000455631, acc 1\n",
      "2018-04-13T15:27:40.820178: step 5614, loss 0.00106942, acc 1\n",
      "2018-04-13T15:27:41.151912: step 5615, loss 0.00150431, acc 1\n",
      "2018-04-13T15:27:41.468637: step 5616, loss 0.000421694, acc 1\n",
      "2018-04-13T15:27:41.792866: step 5617, loss 0.00102539, acc 1\n",
      "2018-04-13T15:27:42.122098: step 5618, loss 0.000158261, acc 1\n",
      "2018-04-13T15:27:42.428814: step 5619, loss 0.000270719, acc 1\n",
      "2018-04-13T15:27:42.755545: step 5620, loss 0.00223655, acc 1\n",
      "2018-04-13T15:27:43.090281: step 5621, loss 0.00136737, acc 1\n",
      "2018-04-13T15:27:43.420014: step 5622, loss 0.00756015, acc 1\n",
      "2018-04-13T15:27:43.761756: step 5623, loss 0.000529115, acc 1\n",
      "2018-04-13T15:27:44.128014: step 5624, loss 0.000749753, acc 1\n",
      "2018-04-13T15:27:44.453744: step 5625, loss 0.012968, acc 1\n",
      "2018-04-13T15:27:44.804992: step 5626, loss 0.00054366, acc 1\n",
      "2018-04-13T15:27:45.152738: step 5627, loss 0.000574865, acc 1\n",
      "2018-04-13T15:27:45.486973: step 5628, loss 0.00159236, acc 1\n",
      "2018-04-13T15:27:45.843225: step 5629, loss 0.000360057, acc 1\n",
      "2018-04-13T15:27:46.182966: step 5630, loss 0.00776039, acc 1\n",
      "2018-04-13T15:27:46.512698: step 5631, loss 0.000381682, acc 1\n",
      "2018-04-13T15:27:46.873953: step 5632, loss 0.000234293, acc 1\n",
      "2018-04-13T15:27:47.209690: step 5633, loss 0.0595934, acc 0.984375\n",
      "2018-04-13T15:27:47.542925: step 5634, loss 0.000479574, acc 1\n",
      "2018-04-13T15:27:47.861651: step 5635, loss 0.00248091, acc 1\n",
      "2018-04-13T15:27:48.186880: step 5636, loss 0.000765648, acc 1\n",
      "2018-04-13T15:27:48.503103: step 5637, loss 0.00520463, acc 1\n",
      "2018-04-13T15:27:48.841342: step 5638, loss 0.000318058, acc 1\n",
      "2018-04-13T15:27:49.166572: step 5639, loss 0.00189552, acc 1\n",
      "2018-04-13T15:27:49.484296: step 5640, loss 0.000271149, acc 1\n",
      "2018-04-13T15:27:49.850055: step 5641, loss 0.0084818, acc 1\n",
      "2018-04-13T15:27:50.177285: step 5642, loss 0.000495409, acc 1\n",
      "2018-04-13T15:27:50.492508: step 5643, loss 0.000478264, acc 1\n",
      "2018-04-13T15:27:50.820240: step 5644, loss 0.000260181, acc 1\n",
      "2018-04-13T15:27:51.145969: step 5645, loss 0.000565932, acc 1\n",
      "2018-04-13T15:27:51.464695: step 5646, loss 0.00198194, acc 1\n",
      "2018-04-13T15:27:51.794928: step 5647, loss 0.00159546, acc 1\n",
      "2018-04-13T15:27:52.112152: step 5648, loss 0.000659672, acc 1\n",
      "2018-04-13T15:27:52.414865: step 5649, loss 0.00833079, acc 1\n",
      "2018-04-13T15:27:52.752104: step 5650, loss 0.0467228, acc 0.984375\n",
      "2018-04-13T15:27:53.100349: step 5651, loss 0.000152336, acc 1\n",
      "2018-04-13T15:27:53.421577: step 5652, loss 0.000252141, acc 1\n",
      "2018-04-13T15:27:53.742803: step 5653, loss 0.00041248, acc 1\n",
      "2018-04-13T15:27:54.068534: step 5654, loss 0.000208437, acc 1\n",
      "2018-04-13T15:27:54.394263: step 5655, loss 0.0195461, acc 0.984375\n",
      "2018-04-13T15:27:54.726998: step 5656, loss 0.000915073, acc 1\n",
      "2018-04-13T15:27:55.034215: step 5657, loss 0.00295367, acc 1\n",
      "2018-04-13T15:27:55.343934: step 5658, loss 0.000165446, acc 1\n",
      "2018-04-13T15:27:55.665161: step 5659, loss 0.00149771, acc 1\n",
      "2018-04-13T15:27:56.027416: step 5660, loss 0.00036362, acc 1\n",
      "2018-04-13T15:27:56.343140: step 5661, loss 0.000563684, acc 1\n",
      "2018-04-13T15:27:56.664366: step 5662, loss 0.0178146, acc 0.984375\n",
      "2018-04-13T15:27:57.007108: step 5663, loss 0.000268989, acc 1\n",
      "2018-04-13T15:27:57.310823: step 5664, loss 0.0275847, acc 0.96875\n",
      "2018-04-13T15:27:57.624044: step 5665, loss 0.00282917, acc 1\n",
      "2018-04-13T15:27:57.947272: step 5666, loss 0.000901977, acc 1\n",
      "2018-04-13T15:27:58.261994: step 5667, loss 0.0024973, acc 1\n",
      "2018-04-13T15:27:58.582720: step 5668, loss 0.00179066, acc 1\n",
      "2018-04-13T15:27:58.939473: step 5669, loss 0.000495048, acc 1\n",
      "2018-04-13T15:27:59.258698: step 5670, loss 0.00753949, acc 1\n",
      "2018-04-13T15:27:59.588932: step 5671, loss 0.000181622, acc 1\n",
      "2018-04-13T15:27:59.919165: step 5672, loss 0.000293174, acc 1\n",
      "2018-04-13T15:28:00.249898: step 5673, loss 0.00121802, acc 1\n",
      "2018-04-13T15:28:00.579131: step 5674, loss 0.00107267, acc 1\n",
      "2018-04-13T15:28:00.902367: step 5675, loss 0.000556449, acc 1\n",
      "2018-04-13T15:28:01.231591: step 5676, loss 0.0749034, acc 0.984375\n",
      "2018-04-13T15:28:01.556821: step 5677, loss 0.000345775, acc 1\n",
      "2018-04-13T15:28:01.908569: step 5678, loss 0.000290472, acc 1\n",
      "2018-04-13T15:28:02.240804: step 5679, loss 0.000297874, acc 1\n",
      "2018-04-13T15:28:02.555526: step 5680, loss 0.000125159, acc 1\n",
      "2018-04-13T15:28:02.898769: step 5681, loss 0.00344206, acc 1\n",
      "2018-04-13T15:28:03.225499: step 5682, loss 0.000641889, acc 1\n",
      "2018-04-13T15:28:03.545224: step 5683, loss 0.00665812, acc 1\n",
      "2018-04-13T15:28:03.869453: step 5684, loss 0.00189334, acc 1\n",
      "2018-04-13T15:28:04.191182: step 5685, loss 0.0015157, acc 1\n",
      "2018-04-13T15:28:04.498899: step 5686, loss 0.00385224, acc 1\n",
      "2018-04-13T15:28:04.851648: step 5687, loss 0.000224956, acc 1\n",
      "2018-04-13T15:28:05.197392: step 5688, loss 0.000960311, acc 1\n",
      "2018-04-13T15:28:05.516617: step 5689, loss 0.00271041, acc 1\n",
      "2018-04-13T15:28:05.836852: step 5690, loss 0.00154389, acc 1\n",
      "2018-04-13T15:28:06.148571: step 5691, loss 0.0048201, acc 1\n",
      "2018-04-13T15:28:06.469798: step 5692, loss 0.00283523, acc 1\n",
      "2018-04-13T15:28:06.798041: step 5693, loss 0.000440633, acc 1\n",
      "2018-04-13T15:28:07.121259: step 5694, loss 0.000735068, acc 1\n",
      "2018-04-13T15:28:07.435480: step 5695, loss 0.00044926, acc 1\n",
      "2018-04-13T15:28:07.761210: step 5696, loss 0.000974938, acc 1\n",
      "2018-04-13T15:28:08.107955: step 5697, loss 0.0015275, acc 1\n",
      "2018-04-13T15:28:08.439689: step 5698, loss 0.00222494, acc 1\n",
      "2018-04-13T15:28:08.763418: step 5699, loss 0.000744609, acc 1\n",
      "2018-04-13T15:28:09.081643: step 5700, loss 0.0258977, acc 0.983333\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:28:10.233456: step 5700, loss 1.5639, acc 0.749531\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5700\n",
      "\n",
      "2018-04-13T15:28:11.826093: step 5701, loss 0.000339037, acc 1\n",
      "2018-04-13T15:28:12.150321: step 5702, loss 0.00380931, acc 1\n",
      "2018-04-13T15:28:12.473050: step 5703, loss 0.01049, acc 1\n",
      "2018-04-13T15:28:12.783769: step 5704, loss 0.000522629, acc 1\n",
      "2018-04-13T15:28:13.093488: step 5705, loss 0.00200383, acc 1\n",
      "2018-04-13T15:28:13.408211: step 5706, loss 0.00170577, acc 1\n",
      "2018-04-13T15:28:13.727435: step 5707, loss 0.00145195, acc 1\n",
      "2018-04-13T15:28:14.072178: step 5708, loss 0.010474, acc 1\n",
      "2018-04-13T15:28:14.397909: step 5709, loss 0.010205, acc 1\n",
      "2018-04-13T15:28:14.734646: step 5710, loss 0.0134956, acc 0.984375\n",
      "2018-04-13T15:28:15.053385: step 5711, loss 0.0310396, acc 0.984375\n",
      "2018-04-13T15:28:15.375111: step 5712, loss 0.000108904, acc 1\n",
      "2018-04-13T15:28:15.697839: step 5713, loss 0.000323626, acc 1\n",
      "2018-04-13T15:28:16.017565: step 5714, loss 0.00251102, acc 1\n",
      "2018-04-13T15:28:16.342794: step 5715, loss 0.0033447, acc 1\n",
      "2018-04-13T15:28:16.655515: step 5716, loss 0.000608848, acc 1\n",
      "2018-04-13T15:28:17.009765: step 5717, loss 0.00566842, acc 1\n",
      "2018-04-13T15:28:17.328491: step 5718, loss 0.000511, acc 1\n",
      "2018-04-13T15:28:17.660725: step 5719, loss 0.0619425, acc 0.984375\n",
      "2018-04-13T15:28:17.981952: step 5720, loss 0.00923975, acc 1\n",
      "2018-04-13T15:28:18.306682: step 5721, loss 0.000348214, acc 1\n",
      "2018-04-13T15:28:18.639917: step 5722, loss 0.000893381, acc 1\n",
      "2018-04-13T15:28:18.974152: step 5723, loss 0.00739775, acc 1\n",
      "2018-04-13T15:28:19.297899: step 5724, loss 0.00182211, acc 1\n",
      "2018-04-13T15:28:19.626131: step 5725, loss 0.00142693, acc 1\n",
      "2018-04-13T15:28:19.968373: step 5726, loss 0.0542364, acc 0.984375\n",
      "2018-04-13T15:28:20.300107: step 5727, loss 0.00150761, acc 1\n",
      "2018-04-13T15:28:20.620834: step 5728, loss 0.0014826, acc 1\n",
      "2018-04-13T15:28:20.945063: step 5729, loss 0.00126609, acc 1\n",
      "2018-04-13T15:28:21.260785: step 5730, loss 0.000350323, acc 1\n",
      "2018-04-13T15:28:21.571004: step 5731, loss 0.00105021, acc 1\n",
      "2018-04-13T15:28:21.913767: step 5732, loss 0.00894191, acc 1\n",
      "2018-04-13T15:28:22.245000: step 5733, loss 0.00138039, acc 1\n",
      "2018-04-13T15:28:22.573732: step 5734, loss 0.000692862, acc 1\n",
      "2018-04-13T15:28:22.923979: step 5735, loss 0.00265759, acc 1\n",
      "2018-04-13T15:28:23.263719: step 5736, loss 0.0022169, acc 1\n",
      "2018-04-13T15:28:23.575439: step 5737, loss 0.000476968, acc 1\n",
      "2018-04-13T15:28:23.910176: step 5738, loss 0.000341573, acc 1\n",
      "2018-04-13T15:28:24.228901: step 5739, loss 0.00785947, acc 1\n",
      "2018-04-13T15:28:24.541622: step 5740, loss 0.000291775, acc 1\n",
      "2018-04-13T15:28:24.879360: step 5741, loss 0.00144966, acc 1\n",
      "2018-04-13T15:28:25.195583: step 5742, loss 0.000792648, acc 1\n",
      "2018-04-13T15:28:25.509305: step 5743, loss 0.00452474, acc 1\n",
      "2018-04-13T15:28:25.848046: step 5744, loss 0.000650712, acc 1\n",
      "2018-04-13T15:28:26.200793: step 5745, loss 0.000161882, acc 1\n",
      "2018-04-13T15:28:26.510011: step 5746, loss 0.000987553, acc 1\n",
      "2018-04-13T15:28:26.837244: step 5747, loss 0.000272057, acc 1\n",
      "2018-04-13T15:28:27.161972: step 5748, loss 0.000433841, acc 1\n",
      "2018-04-13T15:28:27.476694: step 5749, loss 0.000419071, acc 1\n",
      "2018-04-13T15:28:27.803926: step 5750, loss 0.000932466, acc 1\n",
      "2018-04-13T15:28:28.115145: step 5751, loss 0.000187947, acc 1\n",
      "2018-04-13T15:28:28.426865: step 5752, loss 0.00100114, acc 1\n",
      "2018-04-13T15:28:28.754096: step 5753, loss 0.00500245, acc 1\n",
      "2018-04-13T15:28:29.116854: step 5754, loss 0.00401541, acc 1\n",
      "2018-04-13T15:28:29.431075: step 5755, loss 0.000718814, acc 1\n",
      "2018-04-13T15:28:29.760306: step 5756, loss 0.00103251, acc 1\n",
      "2018-04-13T15:28:30.085036: step 5757, loss 0.00235639, acc 1\n",
      "2018-04-13T15:28:30.401760: step 5758, loss 0.00221062, acc 1\n",
      "2018-04-13T15:28:30.727990: step 5759, loss 0.000878502, acc 1\n",
      "2018-04-13T15:28:31.044714: step 5760, loss 0.000459082, acc 1\n",
      "2018-04-13T15:28:31.394460: step 5761, loss 0.0121937, acc 1\n",
      "2018-04-13T15:28:31.734701: step 5762, loss 0.00173046, acc 1\n",
      "2018-04-13T15:28:32.084447: step 5763, loss 0.000309086, acc 1\n",
      "2018-04-13T15:28:32.406175: step 5764, loss 0.000229333, acc 1\n",
      "2018-04-13T15:28:32.731905: step 5765, loss 0.000396096, acc 1\n",
      "2018-04-13T15:28:33.048128: step 5766, loss 0.00163604, acc 1\n",
      "2018-04-13T15:28:33.367854: step 5767, loss 0.000676547, acc 1\n",
      "2018-04-13T15:28:33.698087: step 5768, loss 0.00887926, acc 1\n",
      "2018-04-13T15:28:34.019314: step 5769, loss 0.000228225, acc 1\n",
      "2018-04-13T15:28:34.332535: step 5770, loss 0.000929818, acc 1\n",
      "2018-04-13T15:28:34.648258: step 5771, loss 0.000482394, acc 1\n",
      "2018-04-13T15:28:34.997005: step 5772, loss 0.000570882, acc 1\n",
      "2018-04-13T15:28:35.331240: step 5773, loss 0.000668626, acc 1\n",
      "2018-04-13T15:28:35.654469: step 5774, loss 0.00038986, acc 1\n",
      "2018-04-13T15:28:35.986703: step 5775, loss 0.0016265, acc 1\n",
      "2018-04-13T15:28:36.305428: step 5776, loss 0.00114079, acc 1\n",
      "2018-04-13T15:28:36.628656: step 5777, loss 0.000868012, acc 1\n",
      "2018-04-13T15:28:36.956388: step 5778, loss 0.000209233, acc 1\n",
      "2018-04-13T15:28:37.270610: step 5779, loss 0.0138111, acc 0.984375\n",
      "2018-04-13T15:28:37.587333: step 5780, loss 0.00301176, acc 1\n",
      "2018-04-13T15:28:37.938581: step 5781, loss 0.00101052, acc 1\n",
      "2018-04-13T15:28:38.294332: step 5782, loss 0.000192752, acc 1\n",
      "2018-04-13T15:28:38.607554: step 5783, loss 0.00045425, acc 1\n",
      "2018-04-13T15:28:38.935786: step 5784, loss 0.0019556, acc 1\n",
      "2018-04-13T15:28:39.262016: step 5785, loss 0.00194494, acc 1\n",
      "2018-04-13T15:28:39.578239: step 5786, loss 0.00392683, acc 1\n",
      "2018-04-13T15:28:39.900467: step 5787, loss 0.00242955, acc 1\n",
      "2018-04-13T15:28:40.256718: step 5788, loss 0.00194923, acc 1\n",
      "2018-04-13T15:28:40.571941: step 5789, loss 0.00067733, acc 1\n",
      "2018-04-13T15:28:40.908178: step 5790, loss 0.00235093, acc 1\n",
      "2018-04-13T15:28:41.262429: step 5791, loss 4.49984e-05, acc 1\n",
      "2018-04-13T15:28:41.575149: step 5792, loss 0.00173844, acc 1\n",
      "2018-04-13T15:28:41.907383: step 5793, loss 0.00175678, acc 1\n",
      "2018-04-13T15:28:42.220104: step 5794, loss 0.00125612, acc 1\n",
      "2018-04-13T15:28:42.555342: step 5795, loss 0.000319657, acc 1\n",
      "2018-04-13T15:28:42.878069: step 5796, loss 0.00307516, acc 1\n",
      "2018-04-13T15:28:43.207802: step 5797, loss 6.48148e-05, acc 1\n",
      "2018-04-13T15:28:43.533532: step 5798, loss 0.00195628, acc 1\n",
      "2018-04-13T15:28:43.867768: step 5799, loss 0.00278344, acc 1\n",
      "2018-04-13T15:28:44.217515: step 5800, loss 0.00210215, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:28:45.375833: step 5800, loss 1.56428, acc 0.748593\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5800\n",
      "\n",
      "2018-04-13T15:28:47.086041: step 5801, loss 0.000679075, acc 1\n",
      "2018-04-13T15:28:47.417275: step 5802, loss 0.000139382, acc 1\n",
      "2018-04-13T15:28:47.753012: step 5803, loss 0.00024633, acc 1\n",
      "2018-04-13T15:28:48.084746: step 5804, loss 0.00149626, acc 1\n",
      "2018-04-13T15:28:48.412477: step 5805, loss 0.000371798, acc 1\n",
      "2018-04-13T15:28:48.740709: step 5806, loss 0.00234003, acc 1\n",
      "2018-04-13T15:28:49.065939: step 5807, loss 0.000638574, acc 1\n",
      "2018-04-13T15:28:49.383663: step 5808, loss 0.000818458, acc 1\n",
      "2018-04-13T15:28:49.763931: step 5809, loss 0.00271683, acc 1\n",
      "2018-04-13T15:28:50.101671: step 5810, loss 0.000210184, acc 1\n",
      "2018-04-13T15:28:50.417893: step 5811, loss 0.00154717, acc 1\n",
      "2018-04-13T15:28:50.756133: step 5812, loss 0.0015352, acc 1\n",
      "2018-04-13T15:28:51.078860: step 5813, loss 0.000706766, acc 1\n",
      "2018-04-13T15:28:51.411095: step 5814, loss 0.00163528, acc 1\n",
      "2018-04-13T15:28:51.731321: step 5815, loss 0.000177736, acc 1\n",
      "2018-04-13T15:28:52.056051: step 5816, loss 0.00054546, acc 1\n",
      "2018-04-13T15:28:52.370272: step 5817, loss 0.00271536, acc 1\n",
      "2018-04-13T15:28:52.697503: step 5818, loss 0.00243574, acc 1\n",
      "2018-04-13T15:28:53.027736: step 5819, loss 0.000748481, acc 1\n",
      "2018-04-13T15:28:53.359970: step 5820, loss 0.000223991, acc 1\n",
      "2018-04-13T15:28:53.703713: step 5821, loss 0.000271341, acc 1\n",
      "2018-04-13T15:28:54.018936: step 5822, loss 0.0049863, acc 1\n",
      "2018-04-13T15:28:54.328655: step 5823, loss 0.00120041, acc 1\n",
      "2018-04-13T15:28:54.642877: step 5824, loss 0.000936909, acc 1\n",
      "2018-04-13T15:28:54.977112: step 5825, loss 0.000709241, acc 1\n",
      "2018-04-13T15:28:55.300842: step 5826, loss 0.000294531, acc 1\n",
      "2018-04-13T15:28:55.627073: step 5827, loss 0.0028416, acc 1\n",
      "2018-04-13T15:28:55.972315: step 5828, loss 0.0182437, acc 0.984375\n",
      "2018-04-13T15:28:56.344579: step 5829, loss 0.000311457, acc 1\n",
      "2018-04-13T15:28:56.733857: step 5830, loss 0.00650075, acc 1\n",
      "2018-04-13T15:28:57.088008: step 5831, loss 0.00353885, acc 1\n",
      "2018-04-13T15:28:57.430250: step 5832, loss 0.00304003, acc 1\n",
      "2018-04-13T15:28:57.756480: step 5833, loss 0.00137168, acc 1\n",
      "2018-04-13T15:28:58.087714: step 5834, loss 0.000191398, acc 1\n",
      "2018-04-13T15:28:58.407939: step 5835, loss 0.000333101, acc 1\n",
      "2018-04-13T15:28:58.730668: step 5836, loss 0.000235412, acc 1\n",
      "2018-04-13T15:28:59.065904: step 5837, loss 0.000272528, acc 1\n",
      "2018-04-13T15:28:59.403643: step 5838, loss 0.000237057, acc 1\n",
      "2018-04-13T15:28:59.715862: step 5839, loss 0.000820025, acc 1\n",
      "2018-04-13T15:29:00.043594: step 5840, loss 0.00623048, acc 1\n",
      "2018-04-13T15:29:00.377330: step 5841, loss 0.0010849, acc 1\n",
      "2018-04-13T15:29:00.693554: step 5842, loss 0.000121006, acc 1\n",
      "2018-04-13T15:29:01.023787: step 5843, loss 0.000554714, acc 1\n",
      "2018-04-13T15:29:01.336507: step 5844, loss 0.00163576, acc 1\n",
      "2018-04-13T15:29:01.658734: step 5845, loss 0.00282762, acc 1\n",
      "2018-04-13T15:29:01.992471: step 5846, loss 0.00620767, acc 1\n",
      "2018-04-13T15:29:02.347721: step 5847, loss 0.0316577, acc 0.984375\n",
      "2018-04-13T15:29:02.659441: step 5848, loss 0.000711869, acc 1\n",
      "2018-04-13T15:29:02.993177: step 5849, loss 0.000497618, acc 1\n",
      "2018-04-13T15:29:03.292389: step 5850, loss 0.00175884, acc 1\n",
      "2018-04-13T15:29:03.604609: step 5851, loss 0.00115694, acc 1\n",
      "2018-04-13T15:29:03.930339: step 5852, loss 0.000348537, acc 1\n",
      "2018-04-13T15:29:04.241058: step 5853, loss 0.000339353, acc 1\n",
      "2018-04-13T15:29:04.561285: step 5854, loss 0.000479665, acc 1\n",
      "2018-04-13T15:29:04.892018: step 5855, loss 0.0018554, acc 1\n",
      "2018-04-13T15:29:05.245768: step 5856, loss 0.00151631, acc 1\n",
      "2018-04-13T15:29:05.568997: step 5857, loss 0.00471567, acc 1\n",
      "2018-04-13T15:29:05.897228: step 5858, loss 0.000219546, acc 1\n",
      "2018-04-13T15:29:06.212451: step 5859, loss 0.00451928, acc 1\n",
      "2018-04-13T15:29:06.530174: step 5860, loss 0.000370167, acc 1\n",
      "2018-04-13T15:29:06.866412: step 5861, loss 0.000292788, acc 1\n",
      "2018-04-13T15:29:07.175630: step 5862, loss 0.000231604, acc 1\n",
      "2018-04-13T15:29:07.496356: step 5863, loss 0.00406201, acc 1\n",
      "2018-04-13T15:29:07.825590: step 5864, loss 0.00105435, acc 1\n",
      "2018-04-13T15:29:08.160326: step 5865, loss 0.000302548, acc 1\n",
      "2018-04-13T15:29:08.476549: step 5866, loss 0.00165035, acc 1\n",
      "2018-04-13T15:29:08.798276: step 5867, loss 0.0248381, acc 0.984375\n",
      "2018-04-13T15:29:09.119504: step 5868, loss 0.000784014, acc 1\n",
      "2018-04-13T15:29:09.450737: step 5869, loss 0.00491859, acc 1\n",
      "2018-04-13T15:29:09.769962: step 5870, loss 0.00192843, acc 1\n",
      "2018-04-13T15:29:10.082683: step 5871, loss 0.000532014, acc 1\n",
      "2018-04-13T15:29:10.392402: step 5872, loss 0.00134488, acc 1\n",
      "2018-04-13T15:29:10.714129: step 5873, loss 0.000841329, acc 1\n",
      "2018-04-13T15:29:11.059873: step 5874, loss 0.0010593, acc 1\n",
      "2018-04-13T15:29:11.392608: step 5875, loss 0.000346966, acc 1\n",
      "2018-04-13T15:29:11.707830: step 5876, loss 0.000309024, acc 1\n",
      "2018-04-13T15:29:12.035062: step 5877, loss 0.000241485, acc 1\n",
      "2018-04-13T15:29:12.340778: step 5878, loss 0.00154426, acc 1\n",
      "2018-04-13T15:29:12.659503: step 5879, loss 0.00120272, acc 1\n",
      "2018-04-13T15:29:12.993239: step 5880, loss 0.0235728, acc 0.96875\n",
      "2018-04-13T15:29:13.315966: step 5881, loss 0.000848086, acc 1\n",
      "2018-04-13T15:29:13.630188: step 5882, loss 0.000443592, acc 1\n",
      "2018-04-13T15:29:13.960923: step 5883, loss 0.000757669, acc 1\n",
      "2018-04-13T15:29:14.327681: step 5884, loss 0.00016225, acc 1\n",
      "2018-04-13T15:29:14.647407: step 5885, loss 0.00193559, acc 1\n",
      "2018-04-13T15:29:14.977140: step 5886, loss 0.00176766, acc 1\n",
      "2018-04-13T15:29:15.294864: step 5887, loss 0.000465449, acc 1\n",
      "2018-04-13T15:29:15.610087: step 5888, loss 0.0121944, acc 0.984375\n",
      "2018-04-13T15:29:15.943821: step 5889, loss 0.00028309, acc 1\n",
      "2018-04-13T15:29:16.274055: step 5890, loss 0.0017918, acc 1\n",
      "2018-04-13T15:29:16.595282: step 5891, loss 0.0021021, acc 1\n",
      "2018-04-13T15:29:16.915008: step 5892, loss 0.000201426, acc 1\n",
      "2018-04-13T15:29:17.243239: step 5893, loss 0.000262296, acc 1\n",
      "2018-04-13T15:29:17.566468: step 5894, loss 0.0012453, acc 1\n",
      "2018-04-13T15:29:17.903706: step 5895, loss 0.00042045, acc 1\n",
      "2018-04-13T15:29:18.226933: step 5896, loss 0.00464466, acc 1\n",
      "2018-04-13T15:29:18.558168: step 5897, loss 0.000272711, acc 1\n",
      "2018-04-13T15:29:18.876393: step 5898, loss 0.00481305, acc 1\n",
      "2018-04-13T15:29:19.201622: step 5899, loss 0.000850532, acc 1\n",
      "2018-04-13T15:29:19.518846: step 5900, loss 0.000442662, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:29:20.703182: step 5900, loss 1.58204, acc 0.745779\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-5900\n",
      "\n",
      "2018-04-13T15:29:22.347343: step 5901, loss 0.000544978, acc 1\n",
      "2018-04-13T15:29:22.674580: step 5902, loss 0.00604056, acc 1\n",
      "2018-04-13T15:29:22.992305: step 5903, loss 0.000339714, acc 1\n",
      "2018-04-13T15:29:23.349057: step 5904, loss 0.00198995, acc 1\n",
      "2018-04-13T15:29:23.669784: step 5905, loss 0.0003596, acc 1\n",
      "2018-04-13T15:29:24.011024: step 5906, loss 0.000735648, acc 1\n",
      "2018-04-13T15:29:24.340757: step 5907, loss 0.000287618, acc 1\n",
      "2018-04-13T15:29:24.657981: step 5908, loss 0.00162966, acc 1\n",
      "2018-04-13T15:29:24.992218: step 5909, loss 0.00371922, acc 1\n",
      "2018-04-13T15:29:25.318447: step 5910, loss 0.00072422, acc 1\n",
      "2018-04-13T15:29:25.636672: step 5911, loss 0.00703412, acc 1\n",
      "2018-04-13T15:29:25.973910: step 5912, loss 0.000114498, acc 1\n",
      "2018-04-13T15:29:26.324157: step 5913, loss 0.000525513, acc 1\n",
      "2018-04-13T15:29:26.659395: step 5914, loss 0.00556347, acc 1\n",
      "2018-04-13T15:29:27.004638: step 5915, loss 0.00021723, acc 1\n",
      "2018-04-13T15:29:27.319860: step 5916, loss 0.000818568, acc 1\n",
      "2018-04-13T15:29:27.644590: step 5917, loss 0.00612569, acc 1\n",
      "2018-04-13T15:29:27.988833: step 5918, loss 0.00366953, acc 1\n",
      "2018-04-13T15:29:28.307058: step 5919, loss 0.000367311, acc 1\n",
      "2018-04-13T15:29:28.631787: step 5920, loss 0.00258868, acc 1\n",
      "2018-04-13T15:29:28.964522: step 5921, loss 0.000327251, acc 1\n",
      "2018-04-13T15:29:29.305263: step 5922, loss 0.00115685, acc 1\n",
      "2018-04-13T15:29:29.621486: step 5923, loss 0.00335493, acc 1\n",
      "2018-04-13T15:29:29.960726: step 5924, loss 0.00084548, acc 1\n",
      "2018-04-13T15:29:30.279951: step 5925, loss 0.00924863, acc 1\n",
      "2018-04-13T15:29:30.590170: step 5926, loss 0.000474259, acc 1\n",
      "2018-04-13T15:29:30.910397: step 5927, loss 0.00136498, acc 1\n",
      "2018-04-13T15:29:31.243633: step 5928, loss 0.000727787, acc 1\n",
      "2018-04-13T15:29:31.550348: step 5929, loss 0.0105871, acc 1\n",
      "2018-04-13T15:29:31.872075: step 5930, loss 0.000584347, acc 1\n",
      "2018-04-13T15:29:32.212316: step 5931, loss 0.00109023, acc 1\n",
      "2018-04-13T15:29:32.565064: step 5932, loss 0.00116217, acc 1\n",
      "2018-04-13T15:29:32.892796: step 5933, loss 0.000877891, acc 1\n",
      "2018-04-13T15:29:33.214023: step 5934, loss 0.00135966, acc 1\n",
      "2018-04-13T15:29:33.539753: step 5935, loss 0.000892357, acc 1\n",
      "2018-04-13T15:29:33.880493: step 5936, loss 0.000639041, acc 1\n",
      "2018-04-13T15:29:34.215230: step 5937, loss 0.000230854, acc 1\n",
      "2018-04-13T15:29:34.538458: step 5938, loss 0.00126037, acc 1\n",
      "2018-04-13T15:29:34.899713: step 5939, loss 0.000385359, acc 1\n",
      "2018-04-13T15:29:35.237952: step 5940, loss 0.00207556, acc 1\n",
      "2018-04-13T15:29:35.563181: step 5941, loss 0.000907457, acc 1\n",
      "2018-04-13T15:29:35.892914: step 5942, loss 0.0053125, acc 1\n",
      "2018-04-13T15:29:36.223147: step 5943, loss 0.000963171, acc 1\n",
      "2018-04-13T15:29:36.547876: step 5944, loss 0.000111577, acc 1\n",
      "2018-04-13T15:29:36.872606: step 5945, loss 0.00269659, acc 1\n",
      "2018-04-13T15:29:37.188835: step 5946, loss 0.00110226, acc 1\n",
      "2018-04-13T15:29:37.505554: step 5947, loss 0.000559356, acc 1\n",
      "2018-04-13T15:29:37.826779: step 5948, loss 0.0141937, acc 0.984375\n",
      "2018-04-13T15:29:38.163017: step 5949, loss 8.15823e-05, acc 1\n",
      "2018-04-13T15:29:38.500256: step 5950, loss 0.00231087, acc 1\n",
      "2018-04-13T15:29:38.838495: step 5951, loss 0.000385204, acc 1\n",
      "2018-04-13T15:29:39.168729: step 5952, loss 0.000706727, acc 1\n",
      "2018-04-13T15:29:39.491455: step 5953, loss 0.000977454, acc 1\n",
      "2018-04-13T15:29:39.807178: step 5954, loss 9.83909e-05, acc 1\n",
      "2018-04-13T15:29:40.122400: step 5955, loss 0.000258751, acc 1\n",
      "2018-04-13T15:29:40.435622: step 5956, loss 0.000360271, acc 1\n",
      "2018-04-13T15:29:40.764854: step 5957, loss 0.00649996, acc 1\n",
      "2018-04-13T15:29:41.084581: step 5958, loss 0.00033624, acc 1\n",
      "2018-04-13T15:29:41.429319: step 5959, loss 0.0031789, acc 1\n",
      "2018-04-13T15:29:41.769559: step 5960, loss 0.00021903, acc 1\n",
      "2018-04-13T15:29:42.091286: step 5961, loss 0.00184429, acc 1\n",
      "2018-04-13T15:29:42.411018: step 5962, loss 0.000265955, acc 1\n",
      "2018-04-13T15:29:42.744753: step 5963, loss 0.000688977, acc 1\n",
      "2018-04-13T15:29:43.083993: step 5964, loss 0.00103319, acc 1\n",
      "2018-04-13T15:29:43.408722: step 5965, loss 0.000418464, acc 1\n",
      "2018-04-13T15:29:43.745461: step 5966, loss 0.00457374, acc 1\n",
      "2018-04-13T15:29:44.068188: step 5967, loss 0.00206565, acc 1\n",
      "2018-04-13T15:29:44.419436: step 5968, loss 0.00491484, acc 1\n",
      "2018-04-13T15:29:44.748677: step 5969, loss 0.00103557, acc 1\n",
      "2018-04-13T15:29:45.070404: step 5970, loss 0.000593663, acc 1\n",
      "2018-04-13T15:29:45.383125: step 5971, loss 0.000922258, acc 1\n",
      "2018-04-13T15:29:45.700349: step 5972, loss 0.00109808, acc 1\n",
      "2018-04-13T15:29:46.030082: step 5973, loss 0.00120692, acc 1\n",
      "2018-04-13T15:29:46.346305: step 5974, loss 0.00258723, acc 1\n",
      "2018-04-13T15:29:46.674037: step 5975, loss 0.0113846, acc 1\n",
      "2018-04-13T15:29:47.002268: step 5976, loss 0.00450164, acc 1\n",
      "2018-04-13T15:29:47.357519: step 5977, loss 0.00331856, acc 1\n",
      "2018-04-13T15:29:47.677749: step 5978, loss 0.00121404, acc 1\n",
      "2018-04-13T15:29:48.004977: step 5979, loss 0.000837723, acc 1\n",
      "2018-04-13T15:29:48.322702: step 5980, loss 0.000555913, acc 1\n",
      "2018-04-13T15:29:48.656937: step 5981, loss 0.00270327, acc 1\n",
      "2018-04-13T15:29:48.991673: step 5982, loss 0.00319912, acc 1\n",
      "2018-04-13T15:29:49.310898: step 5983, loss 0.00536585, acc 1\n",
      "2018-04-13T15:29:49.625121: step 5984, loss 0.00143288, acc 1\n",
      "2018-04-13T15:29:49.958356: step 5985, loss 0.000605577, acc 1\n",
      "2018-04-13T15:29:50.288589: step 5986, loss 0.000214052, acc 1\n",
      "2018-04-13T15:29:50.612319: step 5987, loss 0.000514427, acc 1\n",
      "2018-04-13T15:29:50.960563: step 5988, loss 0.000582559, acc 1\n",
      "2018-04-13T15:29:51.283291: step 5989, loss 0.00722222, acc 1\n",
      "2018-04-13T15:29:51.589008: step 5990, loss 0.00159588, acc 1\n",
      "2018-04-13T15:29:51.921743: step 5991, loss 0.00758857, acc 1\n",
      "2018-04-13T15:29:52.249981: step 5992, loss 0.0598684, acc 0.984375\n",
      "2018-04-13T15:29:52.564203: step 5993, loss 0.00229341, acc 1\n",
      "2018-04-13T15:29:52.891435: step 5994, loss 0.0127924, acc 1\n",
      "2018-04-13T15:29:53.234676: step 5995, loss 0.00229425, acc 1\n",
      "2018-04-13T15:29:53.567420: step 5996, loss 0.0034264, acc 1\n",
      "2018-04-13T15:29:53.894651: step 5997, loss 0.000212636, acc 1\n",
      "2018-04-13T15:29:54.215377: step 5998, loss 0.00329403, acc 1\n",
      "2018-04-13T15:29:54.534603: step 5999, loss 0.00399461, acc 1\n",
      "2018-04-13T15:29:54.842820: step 6000, loss 0.00232952, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:29:55.989130: step 6000, loss 1.63291, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6000\n",
      "\n",
      "2018-04-13T15:29:57.798407: step 6001, loss 0.000379475, acc 1\n",
      "2018-04-13T15:29:58.117637: step 6002, loss 0.000357352, acc 1\n",
      "2018-04-13T15:29:58.439860: step 6003, loss 0.00188959, acc 1\n",
      "2018-04-13T15:29:58.762088: step 6004, loss 0.00166281, acc 1\n",
      "2018-04-13T15:29:59.082814: step 6005, loss 0.00172066, acc 1\n",
      "2018-04-13T15:29:59.447572: step 6006, loss 0.000681535, acc 1\n",
      "2018-04-13T15:29:59.776304: step 6007, loss 0.000173131, acc 1\n",
      "2018-04-13T15:30:00.116544: step 6008, loss 0.000855358, acc 1\n",
      "2018-04-13T15:30:00.438271: step 6009, loss 0.00227964, acc 1\n",
      "2018-04-13T15:30:00.765002: step 6010, loss 0.000741625, acc 1\n",
      "2018-04-13T15:30:01.084227: step 6011, loss 0.000556435, acc 1\n",
      "2018-04-13T15:30:01.397949: step 6012, loss 0.000218706, acc 1\n",
      "2018-04-13T15:30:01.723178: step 6013, loss 0.00812949, acc 1\n",
      "2018-04-13T15:30:02.055913: step 6014, loss 0.00358434, acc 1\n",
      "2018-04-13T15:30:02.408162: step 6015, loss 0.0256745, acc 0.984375\n",
      "2018-04-13T15:30:02.750404: step 6016, loss 0.00499583, acc 1\n",
      "2018-04-13T15:30:03.065627: step 6017, loss 0.0012154, acc 1\n",
      "2018-04-13T15:30:03.378347: step 6018, loss 0.000899295, acc 1\n",
      "2018-04-13T15:30:03.709081: step 6019, loss 0.000882737, acc 1\n",
      "2018-04-13T15:30:04.031808: step 6020, loss 0.000311691, acc 1\n",
      "2018-04-13T15:30:04.340526: step 6021, loss 0.000465532, acc 1\n",
      "2018-04-13T15:30:04.661252: step 6022, loss 0.000141579, acc 1\n",
      "2018-04-13T15:30:05.005496: step 6023, loss 0.00272108, acc 1\n",
      "2018-04-13T15:30:05.349739: step 6024, loss 0.0158926, acc 0.984375\n",
      "2018-04-13T15:30:05.664461: step 6025, loss 0.000157605, acc 1\n",
      "2018-04-13T15:30:05.995696: step 6026, loss 0.00475185, acc 1\n",
      "2018-04-13T15:30:06.310418: step 6027, loss 0.00170794, acc 1\n",
      "2018-04-13T15:30:06.622137: step 6028, loss 0.00135543, acc 1\n",
      "2018-04-13T15:30:06.945866: step 6029, loss 0.000734962, acc 1\n",
      "2018-04-13T15:30:07.282604: step 6030, loss 0.0290586, acc 0.984375\n",
      "2018-04-13T15:30:07.603831: step 6031, loss 0.000945356, acc 1\n",
      "2018-04-13T15:30:07.935064: step 6032, loss 0.000315856, acc 1\n",
      "2018-04-13T15:30:08.272303: step 6033, loss 0.000131348, acc 1\n",
      "2018-04-13T15:30:08.600534: step 6034, loss 0.000546924, acc 1\n",
      "2018-04-13T15:30:08.928266: step 6035, loss 0.000224555, acc 1\n",
      "2018-04-13T15:30:09.245490: step 6036, loss 0.00921731, acc 1\n",
      "2018-04-13T15:30:09.567718: step 6037, loss 0.00119339, acc 1\n",
      "2018-04-13T15:30:09.883441: step 6038, loss 0.000549713, acc 1\n",
      "2018-04-13T15:30:10.213173: step 6039, loss 0.00286918, acc 1\n",
      "2018-04-13T15:30:10.532398: step 6040, loss 0.00015629, acc 1\n",
      "2018-04-13T15:30:10.850123: step 6041, loss 0.00394838, acc 1\n",
      "2018-04-13T15:30:11.178855: step 6042, loss 0.00184501, acc 1\n",
      "2018-04-13T15:30:11.542612: step 6043, loss 0.000574983, acc 1\n",
      "2018-04-13T15:30:11.872346: step 6044, loss 0.000575938, acc 1\n",
      "2018-04-13T15:30:12.198074: step 6045, loss 0.000282521, acc 1\n",
      "2018-04-13T15:30:12.521303: step 6046, loss 0.000821228, acc 1\n",
      "2018-04-13T15:30:12.836026: step 6047, loss 0.00198151, acc 1\n",
      "2018-04-13T15:30:13.153750: step 6048, loss 0.00149739, acc 1\n",
      "2018-04-13T15:30:13.465470: step 6049, loss 0.0017951, acc 1\n",
      "2018-04-13T15:30:13.786196: step 6050, loss 0.000513725, acc 1\n",
      "2018-04-13T15:30:14.112427: step 6051, loss 0.00131512, acc 1\n",
      "2018-04-13T15:30:14.467178: step 6052, loss 0.000438245, acc 1\n",
      "2018-04-13T15:30:14.788408: step 6053, loss 0.000149803, acc 1\n",
      "2018-04-13T15:30:15.102131: step 6054, loss 0.000553025, acc 1\n",
      "2018-04-13T15:30:15.416352: step 6055, loss 0.0412561, acc 0.984375\n",
      "2018-04-13T15:30:15.738580: step 6056, loss 0.000131211, acc 1\n",
      "2018-04-13T15:30:16.059306: step 6057, loss 0.00174676, acc 1\n",
      "2018-04-13T15:30:16.383035: step 6058, loss 0.000307711, acc 1\n",
      "2018-04-13T15:30:16.705262: step 6059, loss 0.000616409, acc 1\n",
      "2018-04-13T15:30:17.020485: step 6060, loss 0.000369202, acc 1\n",
      "2018-04-13T15:30:17.361226: step 6061, loss 0.00493672, acc 1\n",
      "2018-04-13T15:30:17.682953: step 6062, loss 0.00157573, acc 1\n",
      "2018-04-13T15:30:18.010684: step 6063, loss 0.000123368, acc 1\n",
      "2018-04-13T15:30:18.332411: step 6064, loss 0.000427141, acc 1\n",
      "2018-04-13T15:30:18.653142: step 6065, loss 0.0259023, acc 0.984375\n",
      "2018-04-13T15:30:19.014393: step 6066, loss 0.00108652, acc 1\n",
      "2018-04-13T15:30:19.336121: step 6067, loss 0.00360266, acc 1\n",
      "2018-04-13T15:30:19.662851: step 6068, loss 0.000751621, acc 1\n",
      "2018-04-13T15:30:20.003091: step 6069, loss 0.000455699, acc 1\n",
      "2018-04-13T15:30:20.347835: step 6070, loss 0.00137448, acc 1\n",
      "2018-04-13T15:30:20.692078: step 6071, loss 0.00101966, acc 1\n",
      "2018-04-13T15:30:21.043326: step 6072, loss 0.041182, acc 0.984375\n",
      "2018-04-13T15:30:21.476632: step 6073, loss 0.00576958, acc 1\n",
      "2018-04-13T15:30:21.832383: step 6074, loss 0.0511418, acc 0.984375\n",
      "2018-04-13T15:30:22.163116: step 6075, loss 0.000491196, acc 1\n",
      "2018-04-13T15:30:22.481842: step 6076, loss 0.00431929, acc 1\n",
      "2018-04-13T15:30:22.810073: step 6077, loss 0.00409681, acc 1\n",
      "2018-04-13T15:30:23.133802: step 6078, loss 0.000399438, acc 1\n",
      "2018-04-13T15:30:23.480047: step 6079, loss 0.00309273, acc 1\n",
      "2018-04-13T15:30:23.811280: step 6080, loss 0.000153231, acc 1\n",
      "2018-04-13T15:30:24.137010: step 6081, loss 0.000390652, acc 1\n",
      "2018-04-13T15:30:24.457239: step 6082, loss 0.00962834, acc 1\n",
      "2018-04-13T15:30:24.804481: step 6083, loss 0.00097595, acc 1\n",
      "2018-04-13T15:30:25.142219: step 6084, loss 0.0298356, acc 0.984375\n",
      "2018-04-13T15:30:25.498471: step 6085, loss 0.012745, acc 0.984375\n",
      "2018-04-13T15:30:25.829706: step 6086, loss 0.000374484, acc 1\n",
      "2018-04-13T15:30:26.176450: step 6087, loss 0.000641843, acc 1\n",
      "2018-04-13T15:30:26.534703: step 6088, loss 0.0143903, acc 1\n",
      "2018-04-13T15:30:26.868939: step 6089, loss 0.00277442, acc 1\n",
      "2018-04-13T15:30:27.193172: step 6090, loss 0.00029262, acc 1\n",
      "2018-04-13T15:30:27.506893: step 6091, loss 0.000610112, acc 1\n",
      "2018-04-13T15:30:27.825118: step 6092, loss 0.000597461, acc 1\n",
      "2018-04-13T15:30:28.144343: step 6093, loss 0.000475851, acc 1\n",
      "2018-04-13T15:30:28.464569: step 6094, loss 0.0132382, acc 0.984375\n",
      "2018-04-13T15:30:28.795803: step 6095, loss 0.0013805, acc 1\n",
      "2018-04-13T15:30:29.120533: step 6096, loss 0.0150904, acc 0.984375\n",
      "2018-04-13T15:30:29.478285: step 6097, loss 0.00281867, acc 1\n",
      "2018-04-13T15:30:29.812521: step 6098, loss 0.000371705, acc 1\n",
      "2018-04-13T15:30:30.142254: step 6099, loss 0.00191865, acc 1\n",
      "2018-04-13T15:30:30.458978: step 6100, loss 0.000148756, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:30:31.595280: step 6100, loss 1.62802, acc 0.754221\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6100\n",
      "\n",
      "2018-04-13T15:30:33.208419: step 6101, loss 0.000521956, acc 1\n",
      "2018-04-13T15:30:33.539653: step 6102, loss 0.00104508, acc 1\n",
      "2018-04-13T15:30:33.868886: step 6103, loss 0.00513646, acc 1\n",
      "2018-04-13T15:30:34.197119: step 6104, loss 0.0198494, acc 0.984375\n",
      "2018-04-13T15:30:34.532855: step 6105, loss 0.00149444, acc 1\n",
      "2018-04-13T15:30:34.879100: step 6106, loss 0.000413281, acc 1\n",
      "2018-04-13T15:30:35.197323: step 6107, loss 1.36711e-05, acc 1\n",
      "2018-04-13T15:30:35.556077: step 6108, loss 0.0024507, acc 1\n",
      "2018-04-13T15:30:35.898819: step 6109, loss 9.04679e-05, acc 1\n",
      "2018-04-13T15:30:36.232554: step 6110, loss 0.000250726, acc 1\n",
      "2018-04-13T15:30:36.546276: step 6111, loss 0.075238, acc 0.984375\n",
      "2018-04-13T15:30:36.882514: step 6112, loss 0.00103646, acc 1\n",
      "2018-04-13T15:30:37.194735: step 6113, loss 0.00390182, acc 1\n",
      "2018-04-13T15:30:37.510457: step 6114, loss 0.000418478, acc 1\n",
      "2018-04-13T15:30:37.837188: step 6115, loss 0.000830011, acc 1\n",
      "2018-04-13T15:30:38.157914: step 6116, loss 0.000161009, acc 1\n",
      "2018-04-13T15:30:38.511166: step 6117, loss 0.00110119, acc 1\n",
      "2018-04-13T15:30:38.862411: step 6118, loss 0.000468137, acc 1\n",
      "2018-04-13T15:30:39.190643: step 6119, loss 0.00105166, acc 1\n",
      "2018-04-13T15:30:39.518876: step 6120, loss 0.000817539, acc 1\n",
      "2018-04-13T15:30:39.855613: step 6121, loss 0.0107353, acc 1\n",
      "2018-04-13T15:30:40.210864: step 6122, loss 0.000181379, acc 1\n",
      "2018-04-13T15:30:40.542598: step 6123, loss 0.00878693, acc 1\n",
      "2018-04-13T15:30:40.891845: step 6124, loss 0.00029673, acc 1\n",
      "2018-04-13T15:30:41.216574: step 6125, loss 0.0102827, acc 1\n",
      "2018-04-13T15:30:41.585835: step 6126, loss 0.0271628, acc 0.984375\n",
      "2018-04-13T15:30:41.948590: step 6127, loss 0.0057076, acc 1\n",
      "2018-04-13T15:30:42.290833: step 6128, loss 0.00718675, acc 1\n",
      "2018-04-13T15:30:42.622567: step 6129, loss 0.0129607, acc 1\n",
      "2018-04-13T15:30:42.965309: step 6130, loss 0.00523055, acc 1\n",
      "2018-04-13T15:30:43.292039: step 6131, loss 0.000835269, acc 1\n",
      "2018-04-13T15:30:43.614767: step 6132, loss 0.001055, acc 1\n",
      "2018-04-13T15:30:43.952506: step 6133, loss 0.00180208, acc 1\n",
      "2018-04-13T15:30:44.279737: step 6134, loss 0.000180699, acc 1\n",
      "2018-04-13T15:30:44.633486: step 6135, loss 0.00237225, acc 1\n",
      "2018-04-13T15:30:44.971726: step 6136, loss 0.0284481, acc 0.984375\n",
      "2018-04-13T15:30:45.284447: step 6137, loss 0.00138428, acc 1\n",
      "2018-04-13T15:30:45.601171: step 6138, loss 0.00082621, acc 1\n",
      "2018-04-13T15:30:45.940910: step 6139, loss 0.00320216, acc 1\n",
      "2018-04-13T15:30:46.264638: step 6140, loss 0.00951841, acc 1\n",
      "2018-04-13T15:30:46.591369: step 6141, loss 0.0234841, acc 0.984375\n",
      "2018-04-13T15:30:46.929108: step 6142, loss 0.00389131, acc 1\n",
      "2018-04-13T15:30:47.267346: step 6143, loss 0.00730172, acc 1\n",
      "2018-04-13T15:30:47.621096: step 6144, loss 0.00126787, acc 1\n",
      "2018-04-13T15:30:47.948828: step 6145, loss 0.000598477, acc 1\n",
      "2018-04-13T15:30:48.284065: step 6146, loss 0.000885991, acc 1\n",
      "2018-04-13T15:30:48.593784: step 6147, loss 0.0162686, acc 0.984375\n",
      "2018-04-13T15:30:48.926518: step 6148, loss 0.00938864, acc 1\n",
      "2018-04-13T15:30:49.247744: step 6149, loss 0.00149063, acc 1\n",
      "2018-04-13T15:30:49.556463: step 6150, loss 0.00014081, acc 1\n",
      "2018-04-13T15:30:49.946787: step 6151, loss 0.000942961, acc 1\n",
      "2018-04-13T15:30:50.279023: step 6152, loss 0.000609187, acc 1\n",
      "2018-04-13T15:30:50.634273: step 6153, loss 0.000978775, acc 1\n",
      "2018-04-13T15:30:50.967008: step 6154, loss 0.00845785, acc 1\n",
      "2018-04-13T15:30:51.280729: step 6155, loss 0.0117274, acc 0.984375\n",
      "2018-04-13T15:30:51.593951: step 6156, loss 0.000474137, acc 1\n",
      "2018-04-13T15:30:51.934191: step 6157, loss 0.00340781, acc 1\n",
      "2018-04-13T15:30:52.263924: step 6158, loss 0.00290957, acc 1\n",
      "2018-04-13T15:30:52.585150: step 6159, loss 0.00111694, acc 1\n",
      "2018-04-13T15:30:52.922389: step 6160, loss 0.000305224, acc 1\n",
      "2018-04-13T15:30:53.244116: step 6161, loss 0.00244567, acc 1\n",
      "2018-04-13T15:30:53.574349: step 6162, loss 0.000934544, acc 1\n",
      "2018-04-13T15:30:53.908585: step 6163, loss 9.93441e-05, acc 1\n",
      "2018-04-13T15:30:54.220805: step 6164, loss 0.000330022, acc 1\n",
      "2018-04-13T15:30:54.549537: step 6165, loss 0.000271716, acc 1\n",
      "2018-04-13T15:30:54.881772: step 6166, loss 0.000249395, acc 1\n",
      "2018-04-13T15:30:55.208002: step 6167, loss 0.00115968, acc 1\n",
      "2018-04-13T15:30:55.524726: step 6168, loss 0.000544049, acc 1\n",
      "2018-04-13T15:30:55.854959: step 6169, loss 0.0106533, acc 1\n",
      "2018-04-13T15:30:56.174184: step 6170, loss 0.00983096, acc 1\n",
      "2018-04-13T15:30:56.521430: step 6171, loss 0.00126843, acc 1\n",
      "2018-04-13T15:30:56.858669: step 6172, loss 0.00090763, acc 1\n",
      "2018-04-13T15:30:57.170889: step 6173, loss 0.000415115, acc 1\n",
      "2018-04-13T15:30:57.482608: step 6174, loss 0.000464499, acc 1\n",
      "2018-04-13T15:30:57.820847: step 6175, loss 0.0940939, acc 0.984375\n",
      "2018-04-13T15:30:58.145576: step 6176, loss 0.000828537, acc 1\n",
      "2018-04-13T15:30:58.458798: step 6177, loss 0.00692908, acc 1\n",
      "2018-04-13T15:30:58.780024: step 6178, loss 0.00089556, acc 1\n",
      "2018-04-13T15:30:59.107756: step 6179, loss 0.000386011, acc 1\n",
      "2018-04-13T15:30:59.428491: step 6180, loss 0.000634111, acc 1\n",
      "2018-04-13T15:30:59.794250: step 6181, loss 0.0115182, acc 1\n",
      "2018-04-13T15:31:00.132989: step 6182, loss 0.00551692, acc 1\n",
      "2018-04-13T15:31:00.459219: step 6183, loss 0.000601159, acc 1\n",
      "2018-04-13T15:31:00.776944: step 6184, loss 0.000553945, acc 1\n",
      "2018-04-13T15:31:01.090665: step 6185, loss 0.000395154, acc 1\n",
      "2018-04-13T15:31:01.409390: step 6186, loss 0.0013609, acc 1\n",
      "2018-04-13T15:31:01.738122: step 6187, loss 0.000199015, acc 1\n",
      "2018-04-13T15:31:02.076862: step 6188, loss 0.00638216, acc 1\n",
      "2018-04-13T15:31:02.419104: step 6189, loss 0.000651868, acc 1\n",
      "2018-04-13T15:31:02.775856: step 6190, loss 0.000734127, acc 1\n",
      "2018-04-13T15:31:03.094080: step 6191, loss 0.00543863, acc 1\n",
      "2018-04-13T15:31:03.408302: step 6192, loss 0.00116681, acc 1\n",
      "2018-04-13T15:31:03.734532: step 6193, loss 0.000215752, acc 1\n",
      "2018-04-13T15:31:04.055259: step 6194, loss 0.00158791, acc 1\n",
      "2018-04-13T15:31:04.390495: step 6195, loss 0.000768717, acc 1\n",
      "2018-04-13T15:31:04.709721: step 6196, loss 0.000720767, acc 1\n",
      "2018-04-13T15:31:05.019940: step 6197, loss 0.000469461, acc 1\n",
      "2018-04-13T15:31:05.333662: step 6198, loss 0.00137342, acc 1\n",
      "2018-04-13T15:31:05.703423: step 6199, loss 0.000364098, acc 1\n",
      "2018-04-13T15:31:06.020146: step 6200, loss 0.00179841, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:31:07.151946: step 6200, loss 1.69394, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6200\n",
      "\n",
      "2018-04-13T15:31:08.834643: step 6201, loss 0.00183318, acc 1\n",
      "2018-04-13T15:31:09.156872: step 6202, loss 0.000776371, acc 1\n",
      "2018-04-13T15:31:09.480099: step 6203, loss 0.0290135, acc 0.984375\n",
      "2018-04-13T15:31:09.827345: step 6204, loss 0.000176615, acc 1\n",
      "2018-04-13T15:31:10.146570: step 6205, loss 0.0122009, acc 0.984375\n",
      "2018-04-13T15:31:10.464294: step 6206, loss 0.00131355, acc 1\n",
      "2018-04-13T15:31:10.799531: step 6207, loss 0.000584661, acc 1\n",
      "2018-04-13T15:31:11.132266: step 6208, loss 5.98361e-05, acc 1\n",
      "2018-04-13T15:31:11.464001: step 6209, loss 0.000986236, acc 1\n",
      "2018-04-13T15:31:11.833261: step 6210, loss 0.00461741, acc 1\n",
      "2018-04-13T15:31:12.173502: step 6211, loss 0.000362666, acc 1\n",
      "2018-04-13T15:31:12.498731: step 6212, loss 0.00871369, acc 1\n",
      "2018-04-13T15:31:12.828464: step 6213, loss 0.000434655, acc 1\n",
      "2018-04-13T15:31:13.152192: step 6214, loss 0.00161556, acc 1\n",
      "2018-04-13T15:31:13.467415: step 6215, loss 0.00104806, acc 1\n",
      "2018-04-13T15:31:13.796648: step 6216, loss 0.0098108, acc 1\n",
      "2018-04-13T15:31:14.120877: step 6217, loss 0.000473511, acc 1\n",
      "2018-04-13T15:31:14.458115: step 6218, loss 0.000213303, acc 1\n",
      "2018-04-13T15:31:14.814365: step 6219, loss 0.00134922, acc 1\n",
      "2018-04-13T15:31:15.134092: step 6220, loss 0.00110651, acc 1\n",
      "2018-04-13T15:31:15.461323: step 6221, loss 0.000688915, acc 1\n",
      "2018-04-13T15:31:15.795559: step 6222, loss 0.00518227, acc 1\n",
      "2018-04-13T15:31:16.127293: step 6223, loss 0.00551802, acc 1\n",
      "2018-04-13T15:31:16.439014: step 6224, loss 0.000208022, acc 1\n",
      "2018-04-13T15:31:16.766244: step 6225, loss 0.0015857, acc 1\n",
      "2018-04-13T15:31:17.102982: step 6226, loss 0.00199657, acc 1\n",
      "2018-04-13T15:31:17.424709: step 6227, loss 0.00231717, acc 1\n",
      "2018-04-13T15:31:17.771954: step 6228, loss 0.00846915, acc 1\n",
      "2018-04-13T15:31:18.084675: step 6229, loss 0.000994943, acc 1\n",
      "2018-04-13T15:31:18.418912: step 6230, loss 0.000786941, acc 1\n",
      "2018-04-13T15:31:18.750146: step 6231, loss 9.77263e-05, acc 1\n",
      "2018-04-13T15:31:19.073374: step 6232, loss 0.0124574, acc 1\n",
      "2018-04-13T15:31:19.404607: step 6233, loss 0.105249, acc 0.984375\n",
      "2018-04-13T15:31:19.732338: step 6234, loss 0.000187994, acc 1\n",
      "2018-04-13T15:31:20.046560: step 6235, loss 0.0133526, acc 0.984375\n",
      "2018-04-13T15:31:20.354778: step 6236, loss 0.000576442, acc 1\n",
      "2018-04-13T15:31:20.706027: step 6237, loss 0.000796889, acc 1\n",
      "2018-04-13T15:31:21.032757: step 6238, loss 0.0232109, acc 0.984375\n",
      "2018-04-13T15:31:21.343977: step 6239, loss 0.000899091, acc 1\n",
      "2018-04-13T15:31:21.674209: step 6240, loss 0.0247104, acc 0.984375\n",
      "2018-04-13T15:31:22.013450: step 6241, loss 0.00167777, acc 1\n",
      "2018-04-13T15:31:22.336678: step 6242, loss 2.23894e-05, acc 1\n",
      "2018-04-13T15:31:22.654402: step 6243, loss 0.00286311, acc 1\n",
      "2018-04-13T15:31:22.990639: step 6244, loss 0.000271603, acc 1\n",
      "2018-04-13T15:31:23.311366: step 6245, loss 0.00597862, acc 1\n",
      "2018-04-13T15:31:23.649606: step 6246, loss 0.0012694, acc 1\n",
      "2018-04-13T15:31:23.990846: step 6247, loss 0.00289293, acc 1\n",
      "2018-04-13T15:31:24.312573: step 6248, loss 2.69405e-05, acc 1\n",
      "2018-04-13T15:31:24.633800: step 6249, loss 0.00133816, acc 1\n",
      "2018-04-13T15:31:24.973540: step 6250, loss 0.000124707, acc 1\n",
      "2018-04-13T15:31:25.291264: step 6251, loss 0.000326083, acc 1\n",
      "2018-04-13T15:31:25.615993: step 6252, loss 0.00179693, acc 1\n",
      "2018-04-13T15:31:25.937220: step 6253, loss 0.000362287, acc 1\n",
      "2018-04-13T15:31:26.255446: step 6254, loss 0.0129898, acc 0.984375\n",
      "2018-04-13T15:31:26.591682: step 6255, loss 0.00910547, acc 1\n",
      "2018-04-13T15:31:26.932923: step 6256, loss 0.00410499, acc 1\n",
      "2018-04-13T15:31:27.255151: step 6257, loss 0.000270407, acc 1\n",
      "2018-04-13T15:31:27.569873: step 6258, loss 0.00492644, acc 1\n",
      "2018-04-13T15:31:27.913615: step 6259, loss 0.000320074, acc 1\n",
      "2018-04-13T15:31:28.242863: step 6260, loss 0.000230406, acc 1\n",
      "2018-04-13T15:31:28.572590: step 6261, loss 0.001265, acc 1\n",
      "2018-04-13T15:31:28.905825: step 6262, loss 0.00189749, acc 1\n",
      "2018-04-13T15:31:29.219046: step 6263, loss 0.000897951, acc 1\n",
      "2018-04-13T15:31:29.534268: step 6264, loss 0.000803303, acc 1\n",
      "2018-04-13T15:31:29.884015: step 6265, loss 0.00225809, acc 1\n",
      "2018-04-13T15:31:30.203240: step 6266, loss 0.000229985, acc 1\n",
      "2018-04-13T15:31:30.522466: step 6267, loss 0.00347864, acc 1\n",
      "2018-04-13T15:31:30.859204: step 6268, loss 0.00168474, acc 1\n",
      "2018-04-13T15:31:31.178429: step 6269, loss 0.000588204, acc 1\n",
      "2018-04-13T15:31:31.493151: step 6270, loss 0.002416, acc 1\n",
      "2018-04-13T15:31:31.803871: step 6271, loss 0.000420319, acc 1\n",
      "2018-04-13T15:31:32.115591: step 6272, loss 0.00048779, acc 1\n",
      "2018-04-13T15:31:32.431314: step 6273, loss 0.000622661, acc 1\n",
      "2018-04-13T15:31:32.797573: step 6274, loss 0.0145421, acc 1\n",
      "2018-04-13T15:31:33.120300: step 6275, loss 0.000901855, acc 1\n",
      "2018-04-13T15:31:33.436025: step 6276, loss 0.00259222, acc 1\n",
      "2018-04-13T15:31:33.761753: step 6277, loss 0.00197617, acc 1\n",
      "2018-04-13T15:31:34.079478: step 6278, loss 0.000809885, acc 1\n",
      "2018-04-13T15:31:34.395701: step 6279, loss 0.000107395, acc 1\n",
      "2018-04-13T15:31:34.733439: step 6280, loss 0.000560132, acc 1\n",
      "2018-04-13T15:31:35.084187: step 6281, loss 0.00520154, acc 1\n",
      "2018-04-13T15:31:35.401410: step 6282, loss 0.0560764, acc 0.984375\n",
      "2018-04-13T15:31:35.774674: step 6283, loss 0.000611126, acc 1\n",
      "2018-04-13T15:31:36.102406: step 6284, loss 0.000121238, acc 1\n",
      "2018-04-13T15:31:36.412125: step 6285, loss 0.0324066, acc 0.984375\n",
      "2018-04-13T15:31:36.737355: step 6286, loss 0.00150661, acc 1\n",
      "2018-04-13T15:31:37.065092: step 6287, loss 0.000437083, acc 1\n",
      "2018-04-13T15:31:37.390322: step 6288, loss 0.000337799, acc 1\n",
      "2018-04-13T15:31:37.713551: step 6289, loss 0.00103398, acc 1\n",
      "2018-04-13T15:31:38.056793: step 6290, loss 0.00115028, acc 1\n",
      "2018-04-13T15:31:38.388527: step 6291, loss 0.000743162, acc 1\n",
      "2018-04-13T15:31:38.745779: step 6292, loss 0.000554489, acc 1\n",
      "2018-04-13T15:31:39.072510: step 6293, loss 0.000709685, acc 1\n",
      "2018-04-13T15:31:39.396238: step 6294, loss 0.0846477, acc 0.953125\n",
      "2018-04-13T15:31:39.723970: step 6295, loss 0.000583906, acc 1\n",
      "2018-04-13T15:31:40.043695: step 6296, loss 0.00843482, acc 1\n",
      "2018-04-13T15:31:40.361920: step 6297, loss 0.00341443, acc 1\n",
      "2018-04-13T15:31:40.700660: step 6298, loss 0.000277532, acc 1\n",
      "2018-04-13T15:31:41.024888: step 6299, loss 0.000399137, acc 1\n",
      "2018-04-13T15:31:41.326101: step 6300, loss 0.000413259, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:31:42.499430: step 6300, loss 1.6697, acc 0.757036\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6300\n",
      "\n",
      "2018-04-13T15:31:44.244687: step 6301, loss 0.00017589, acc 1\n",
      "2018-04-13T15:31:44.561907: step 6302, loss 0.000484464, acc 1\n",
      "2018-04-13T15:31:44.931166: step 6303, loss 0.00189926, acc 1\n",
      "2018-04-13T15:31:45.259398: step 6304, loss 0.00219171, acc 1\n",
      "2018-04-13T15:31:45.574621: step 6305, loss 0.00365666, acc 1\n",
      "2018-04-13T15:31:45.907356: step 6306, loss 0.00753644, acc 1\n",
      "2018-04-13T15:31:46.238090: step 6307, loss 9.38257e-05, acc 1\n",
      "2018-04-13T15:31:46.567322: step 6308, loss 0.000826368, acc 1\n",
      "2018-04-13T15:31:46.906562: step 6309, loss 0.00232903, acc 1\n",
      "2018-04-13T15:31:47.244800: step 6310, loss 0.00118425, acc 1\n",
      "2018-04-13T15:31:47.590046: step 6311, loss 0.00698701, acc 1\n",
      "2018-04-13T15:31:47.943794: step 6312, loss 0.00328749, acc 1\n",
      "2018-04-13T15:31:48.269028: step 6313, loss 0.00153896, acc 1\n",
      "2018-04-13T15:31:48.599257: step 6314, loss 0.000328275, acc 1\n",
      "2018-04-13T15:31:48.933994: step 6315, loss 0.00471707, acc 1\n",
      "2018-04-13T15:31:49.250717: step 6316, loss 0.000690007, acc 1\n",
      "2018-04-13T15:31:49.562937: step 6317, loss 0.00324944, acc 1\n",
      "2018-04-13T15:31:49.898174: step 6318, loss 0.000714542, acc 1\n",
      "2018-04-13T15:31:50.223404: step 6319, loss 0.0072787, acc 1\n",
      "2018-04-13T15:31:50.541128: step 6320, loss 0.00189122, acc 1\n",
      "2018-04-13T15:31:50.918895: step 6321, loss 0.0331569, acc 0.984375\n",
      "2018-04-13T15:31:51.255132: step 6322, loss 0.00238582, acc 1\n",
      "2018-04-13T15:31:51.569856: step 6323, loss 0.00323362, acc 1\n",
      "2018-04-13T15:31:51.896585: step 6324, loss 0.0312219, acc 0.984375\n",
      "2018-04-13T15:31:52.208305: step 6325, loss 0.00165024, acc 1\n",
      "2018-04-13T15:31:52.536036: step 6326, loss 0.000365541, acc 1\n",
      "2018-04-13T15:31:52.857264: step 6327, loss 0.000765976, acc 1\n",
      "2018-04-13T15:31:53.188998: step 6328, loss 0.00103765, acc 1\n",
      "2018-04-13T15:31:53.509225: step 6329, loss 0.000390451, acc 1\n",
      "2018-04-13T15:31:53.871480: step 6330, loss 0.000361162, acc 1\n",
      "2018-04-13T15:31:54.184202: step 6331, loss 0.00555977, acc 1\n",
      "2018-04-13T15:31:54.491417: step 6332, loss 0.000870838, acc 1\n",
      "2018-04-13T15:31:54.815647: step 6333, loss 0.00116151, acc 1\n",
      "2018-04-13T15:31:55.133871: step 6334, loss 0.0121432, acc 0.984375\n",
      "2018-04-13T15:31:55.459621: step 6335, loss 0.00239547, acc 1\n",
      "2018-04-13T15:31:55.783850: step 6336, loss 0.0339634, acc 0.984375\n",
      "2018-04-13T15:31:56.120087: step 6337, loss 0.000268184, acc 1\n",
      "2018-04-13T15:31:56.439312: step 6338, loss 0.0535108, acc 0.984375\n",
      "2018-04-13T15:31:56.807072: step 6339, loss 0.000115283, acc 1\n",
      "2018-04-13T15:31:57.141809: step 6340, loss 0.00175889, acc 1\n",
      "2018-04-13T15:31:57.499061: step 6341, loss 0.00102222, acc 1\n",
      "2018-04-13T15:31:57.821288: step 6342, loss 0.00860055, acc 1\n",
      "2018-04-13T15:31:58.138012: step 6343, loss 0.000934598, acc 1\n",
      "2018-04-13T15:31:58.466744: step 6344, loss 0.00121952, acc 1\n",
      "2018-04-13T15:31:58.783468: step 6345, loss 0.0092002, acc 1\n",
      "2018-04-13T15:31:59.118704: step 6346, loss 0.000285973, acc 1\n",
      "2018-04-13T15:31:59.439431: step 6347, loss 0.000662457, acc 1\n",
      "2018-04-13T15:31:59.783175: step 6348, loss 0.00645054, acc 1\n",
      "2018-04-13T15:32:00.114407: step 6349, loss 0.0160434, acc 0.984375\n",
      "2018-04-13T15:32:00.432632: step 6350, loss 2.87974e-05, acc 1\n",
      "2018-04-13T15:32:00.749361: step 6351, loss 0.00025865, acc 1\n",
      "2018-04-13T15:32:01.087100: step 6352, loss 0.000409953, acc 1\n",
      "2018-04-13T15:32:01.406325: step 6353, loss 0.00455273, acc 1\n",
      "2018-04-13T15:32:01.728553: step 6354, loss 0.00165559, acc 1\n",
      "2018-04-13T15:32:02.048779: step 6355, loss 0.00199566, acc 1\n",
      "2018-04-13T15:32:02.366504: step 6356, loss 0.000167297, acc 1\n",
      "2018-04-13T15:32:02.708247: step 6357, loss 0.0003616, acc 1\n",
      "2018-04-13T15:32:03.048986: step 6358, loss 0.00146645, acc 1\n",
      "2018-04-13T15:32:03.378218: step 6359, loss 0.0131108, acc 0.984375\n",
      "2018-04-13T15:32:03.722461: step 6360, loss 0.00242991, acc 1\n",
      "2018-04-13T15:32:04.043688: step 6361, loss 0.000567335, acc 1\n",
      "2018-04-13T15:32:04.366915: step 6362, loss 0.000403955, acc 1\n",
      "2018-04-13T15:32:04.680137: step 6363, loss 0.00202828, acc 1\n",
      "2018-04-13T15:32:05.002365: step 6364, loss 0.00666484, acc 1\n",
      "2018-04-13T15:32:05.318088: step 6365, loss 0.0133213, acc 0.984375\n",
      "2018-04-13T15:32:05.653324: step 6366, loss 0.0144428, acc 0.984375\n",
      "2018-04-13T15:32:06.022586: step 6367, loss 0.000781253, acc 1\n",
      "2018-04-13T15:32:06.339313: step 6368, loss 0.000402669, acc 1\n",
      "2018-04-13T15:32:06.662037: step 6369, loss 0.00778343, acc 1\n",
      "2018-04-13T15:32:06.989768: step 6370, loss 0.000312314, acc 1\n",
      "2018-04-13T15:32:07.306492: step 6371, loss 0.0134987, acc 1\n",
      "2018-04-13T15:32:07.637725: step 6372, loss 0.00265689, acc 1\n",
      "2018-04-13T15:32:07.970963: step 6373, loss 0.00412896, acc 1\n",
      "2018-04-13T15:32:08.284182: step 6374, loss 0.00574433, acc 1\n",
      "2018-04-13T15:32:08.588897: step 6375, loss 0.0122931, acc 0.984375\n",
      "2018-04-13T15:32:08.963161: step 6376, loss 0.00277832, acc 1\n",
      "2018-04-13T15:32:09.277383: step 6377, loss 0.00830511, acc 1\n",
      "2018-04-13T15:32:09.589604: step 6378, loss 0.00020768, acc 1\n",
      "2018-04-13T15:32:09.916335: step 6379, loss 0.000595755, acc 1\n",
      "2018-04-13T15:32:10.239563: step 6380, loss 0.000548766, acc 1\n",
      "2018-04-13T15:32:10.558288: step 6381, loss 0.00347026, acc 1\n",
      "2018-04-13T15:32:10.887019: step 6382, loss 0.00184867, acc 1\n",
      "2018-04-13T15:32:11.206746: step 6383, loss 0.00911912, acc 1\n",
      "2018-04-13T15:32:11.511461: step 6384, loss 0.00106167, acc 1\n",
      "2018-04-13T15:32:11.873717: step 6385, loss 0.00325311, acc 1\n",
      "2018-04-13T15:32:12.200947: step 6386, loss 0.00010988, acc 1\n",
      "2018-04-13T15:32:12.505663: step 6387, loss 0.000776538, acc 1\n",
      "2018-04-13T15:32:12.827899: step 6388, loss 0.0163884, acc 0.984375\n",
      "2018-04-13T15:32:13.152628: step 6389, loss 0.00529773, acc 1\n",
      "2018-04-13T15:32:13.483863: step 6390, loss 0.0026845, acc 1\n",
      "2018-04-13T15:32:13.820101: step 6391, loss 0.000524578, acc 1\n",
      "2018-04-13T15:32:14.141828: step 6392, loss 0.000463183, acc 1\n",
      "2018-04-13T15:32:14.454549: step 6393, loss 0.000333565, acc 1\n",
      "2018-04-13T15:32:14.777276: step 6394, loss 0.000285411, acc 1\n",
      "2018-04-13T15:32:15.121019: step 6395, loss 0.000302849, acc 1\n",
      "2018-04-13T15:32:15.446748: step 6396, loss 0.0191987, acc 0.984375\n",
      "2018-04-13T15:32:15.780484: step 6397, loss 0.0066704, acc 1\n",
      "2018-04-13T15:32:16.122225: step 6398, loss 0.000770721, acc 1\n",
      "2018-04-13T15:32:16.456462: step 6399, loss 0.020423, acc 0.984375\n",
      "2018-04-13T15:32:16.799705: step 6400, loss 0.00478511, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:32:17.963026: step 6400, loss 1.73179, acc 0.750469\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6400\n",
      "\n",
      "2018-04-13T15:32:20.326194: step 6401, loss 0.00349541, acc 1\n",
      "2018-04-13T15:32:20.648922: step 6402, loss 0.000554762, acc 1\n",
      "2018-04-13T15:32:21.009677: step 6403, loss 0.000459199, acc 1\n",
      "2018-04-13T15:32:21.331404: step 6404, loss 0.00934328, acc 1\n",
      "2018-04-13T15:32:21.655634: step 6405, loss 0.00185209, acc 1\n",
      "2018-04-13T15:32:21.987367: step 6406, loss 0.000998351, acc 1\n",
      "2018-04-13T15:32:22.307093: step 6407, loss 0.000398237, acc 1\n",
      "2018-04-13T15:32:22.624317: step 6408, loss 0.000745437, acc 1\n",
      "2018-04-13T15:32:22.959053: step 6409, loss 0.000316315, acc 1\n",
      "2018-04-13T15:32:23.268271: step 6410, loss 0.0284674, acc 0.984375\n",
      "2018-04-13T15:32:23.612514: step 6411, loss 0.00064542, acc 1\n",
      "2018-04-13T15:32:23.981775: step 6412, loss 0.00127046, acc 1\n",
      "2018-04-13T15:32:24.297008: step 6413, loss 0.00223858, acc 1\n",
      "2018-04-13T15:32:24.618235: step 6414, loss 0.000150188, acc 1\n",
      "2018-04-13T15:32:24.945466: step 6415, loss 0.00184514, acc 1\n",
      "2018-04-13T15:32:25.264692: step 6416, loss 0.000692935, acc 1\n",
      "2018-04-13T15:32:25.578913: step 6417, loss 0.000360792, acc 1\n",
      "2018-04-13T15:32:25.899640: step 6418, loss 0.00166376, acc 1\n",
      "2018-04-13T15:32:26.222868: step 6419, loss 0.0117423, acc 0.984375\n",
      "2018-04-13T15:32:26.542095: step 6420, loss 0.000190627, acc 1\n",
      "2018-04-13T15:32:26.896344: step 6421, loss 0.000816099, acc 1\n",
      "2018-04-13T15:32:27.229079: step 6422, loss 0.000231631, acc 1\n",
      "2018-04-13T15:32:27.543301: step 6423, loss 0.000286543, acc 1\n",
      "2018-04-13T15:32:27.882542: step 6424, loss 0.00429111, acc 1\n",
      "2018-04-13T15:32:28.209771: step 6425, loss 0.00113454, acc 1\n",
      "2018-04-13T15:32:28.533002: step 6426, loss 0.00141739, acc 1\n",
      "2018-04-13T15:32:28.879745: step 6427, loss 0.0253865, acc 0.984375\n",
      "2018-04-13T15:32:29.243005: step 6428, loss 6.08659e-05, acc 1\n",
      "2018-04-13T15:32:29.617989: step 6429, loss 0.000907966, acc 1\n",
      "2018-04-13T15:32:29.974741: step 6430, loss 0.00385793, acc 1\n",
      "2018-04-13T15:32:30.291965: step 6431, loss 0.00030022, acc 1\n",
      "2018-04-13T15:32:30.620197: step 6432, loss 0.000271577, acc 1\n",
      "2018-04-13T15:32:30.939423: step 6433, loss 0.0158288, acc 0.984375\n",
      "2018-04-13T15:32:31.277161: step 6434, loss 9.93633e-05, acc 1\n",
      "2018-04-13T15:32:31.591382: step 6435, loss 0.0115516, acc 0.984375\n",
      "2018-04-13T15:32:31.922616: step 6436, loss 0.00101725, acc 1\n",
      "2018-04-13T15:32:32.256853: step 6437, loss 0.00299249, acc 1\n",
      "2018-04-13T15:32:32.586585: step 6438, loss 0.0226671, acc 0.984375\n",
      "2018-04-13T15:32:32.940335: step 6439, loss 0.00137333, acc 1\n",
      "2018-04-13T15:32:33.271570: step 6440, loss 0.0100856, acc 1\n",
      "2018-04-13T15:32:33.615812: step 6441, loss 0.00039228, acc 1\n",
      "2018-04-13T15:32:33.947046: step 6442, loss 0.000312518, acc 1\n",
      "2018-04-13T15:32:34.256765: step 6443, loss 0.000775106, acc 1\n",
      "2018-04-13T15:32:34.585497: step 6444, loss 0.00174378, acc 1\n",
      "2018-04-13T15:32:34.912728: step 6445, loss 0.0252275, acc 0.984375\n",
      "2018-04-13T15:32:35.231453: step 6446, loss 0.000367331, acc 1\n",
      "2018-04-13T15:32:35.562686: step 6447, loss 0.00526477, acc 1\n",
      "2018-04-13T15:32:35.916436: step 6448, loss 0.00127962, acc 1\n",
      "2018-04-13T15:32:36.257678: step 6449, loss 0.000492226, acc 1\n",
      "2018-04-13T15:32:36.562892: step 6450, loss 0.00502847, acc 1\n",
      "2018-04-13T15:32:36.887622: step 6451, loss 0.000548477, acc 1\n",
      "2018-04-13T15:32:37.204846: step 6452, loss 0.00254714, acc 1\n",
      "2018-04-13T15:32:37.528575: step 6453, loss 0.000674193, acc 1\n",
      "2018-04-13T15:32:37.853304: step 6454, loss 0.000413468, acc 1\n",
      "2018-04-13T15:32:38.166525: step 6455, loss 0.002029, acc 1\n",
      "2018-04-13T15:32:38.498760: step 6456, loss 0.00017942, acc 1\n",
      "2018-04-13T15:32:38.844504: step 6457, loss 0.000367121, acc 1\n",
      "2018-04-13T15:32:39.186245: step 6458, loss 0.000139195, acc 1\n",
      "2018-04-13T15:32:39.521985: step 6459, loss 0.0028532, acc 1\n",
      "2018-04-13T15:32:39.856219: step 6460, loss 0.00122063, acc 1\n",
      "2018-04-13T15:32:40.193957: step 6461, loss 0.00167195, acc 1\n",
      "2018-04-13T15:32:40.513182: step 6462, loss 0.00358336, acc 1\n",
      "2018-04-13T15:32:40.841914: step 6463, loss 0.00336024, acc 1\n",
      "2018-04-13T15:32:41.188159: step 6464, loss 0.00054037, acc 1\n",
      "2018-04-13T15:32:41.517892: step 6465, loss 0.001282, acc 1\n",
      "2018-04-13T15:32:41.877646: step 6466, loss 0.00564006, acc 1\n",
      "2018-04-13T15:32:42.219887: step 6467, loss 0.00565696, acc 1\n",
      "2018-04-13T15:32:42.554624: step 6468, loss 0.014912, acc 0.984375\n",
      "2018-04-13T15:32:42.883356: step 6469, loss 0.000306334, acc 1\n",
      "2018-04-13T15:32:43.255118: step 6470, loss 0.000924673, acc 1\n",
      "2018-04-13T15:32:43.625380: step 6471, loss 0.000560391, acc 1\n",
      "2018-04-13T15:32:44.017158: step 6472, loss 0.000130559, acc 1\n",
      "2018-04-13T15:32:44.346890: step 6473, loss 0.00878612, acc 1\n",
      "2018-04-13T15:32:44.681625: step 6474, loss 0.000290451, acc 1\n",
      "2018-04-13T15:32:45.048385: step 6475, loss 0.00541153, acc 1\n",
      "2018-04-13T15:32:45.380619: step 6476, loss 0.00183431, acc 1\n",
      "2018-04-13T15:32:45.712353: step 6477, loss 0.00101104, acc 1\n",
      "2018-04-13T15:32:46.056597: step 6478, loss 0.000388514, acc 1\n",
      "2018-04-13T15:32:46.410847: step 6479, loss 0.00013911, acc 1\n",
      "2018-04-13T15:32:46.754089: step 6480, loss 0.00390765, acc 1\n",
      "2018-04-13T15:32:47.084322: step 6481, loss 0.00113657, acc 1\n",
      "2018-04-13T15:32:47.418558: step 6482, loss 0.000790308, acc 1\n",
      "2018-04-13T15:32:47.747795: step 6483, loss 0.00107679, acc 1\n",
      "2018-04-13T15:32:48.107044: step 6484, loss 0.0028109, acc 1\n",
      "2018-04-13T15:32:48.425269: step 6485, loss 0.000286601, acc 1\n",
      "2018-04-13T15:32:48.752499: step 6486, loss 0.0105678, acc 1\n",
      "2018-04-13T15:32:49.077229: step 6487, loss 0.00371734, acc 1\n",
      "2018-04-13T15:32:49.408964: step 6488, loss 0.000433494, acc 1\n",
      "2018-04-13T15:32:49.784241: step 6489, loss 0.00299004, acc 1\n",
      "2018-04-13T15:32:50.165510: step 6490, loss 6.50788e-05, acc 1\n",
      "2018-04-13T15:32:50.493243: step 6491, loss 0.000784294, acc 1\n",
      "2018-04-13T15:32:50.841989: step 6492, loss 0.00743908, acc 1\n",
      "2018-04-13T15:32:51.212751: step 6493, loss 0.0034438, acc 1\n",
      "2018-04-13T15:32:51.579010: step 6494, loss 0.00553951, acc 1\n",
      "2018-04-13T15:32:51.935260: step 6495, loss 0.000233729, acc 1\n",
      "2018-04-13T15:32:52.282005: step 6496, loss 0.000746586, acc 1\n",
      "2018-04-13T15:32:52.631253: step 6497, loss 0.00382666, acc 1\n",
      "2018-04-13T15:32:52.957484: step 6498, loss 0.00176225, acc 1\n",
      "2018-04-13T15:32:53.300725: step 6499, loss 0.00040424, acc 1\n",
      "2018-04-13T15:32:53.635961: step 6500, loss 0.000942498, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:32:54.916866: step 6500, loss 1.74175, acc 0.757974\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6500\n",
      "\n",
      "2018-04-13T15:32:56.635580: step 6501, loss 0.00157748, acc 1\n",
      "2018-04-13T15:32:57.042866: step 6502, loss 0.00829881, acc 1\n",
      "2018-04-13T15:32:57.387111: step 6503, loss 0.002102, acc 1\n",
      "2018-04-13T15:32:57.706336: step 6504, loss 0.00178158, acc 1\n",
      "2018-04-13T15:32:58.036068: step 6505, loss 7.95211e-05, acc 1\n",
      "2018-04-13T15:32:58.346288: step 6506, loss 0.000122708, acc 1\n",
      "2018-04-13T15:32:58.660009: step 6507, loss 0.0010681, acc 1\n",
      "2018-04-13T15:32:58.990242: step 6508, loss 0.0042031, acc 1\n",
      "2018-04-13T15:32:59.290454: step 6509, loss 0.00484064, acc 1\n",
      "2018-04-13T15:32:59.609679: step 6510, loss 0.000336212, acc 1\n",
      "2018-04-13T15:32:59.946918: step 6511, loss 0.00057447, acc 1\n",
      "2018-04-13T15:33:00.294163: step 6512, loss 0.000698845, acc 1\n",
      "2018-04-13T15:33:00.631401: step 6513, loss 0.0164669, acc 0.984375\n",
      "2018-04-13T15:33:00.982148: step 6514, loss 0.000127918, acc 1\n",
      "2018-04-13T15:33:01.297871: step 6515, loss 3.11203e-05, acc 1\n",
      "2018-04-13T15:33:01.668134: step 6516, loss 0.000136117, acc 1\n",
      "2018-04-13T15:33:02.037394: step 6517, loss 9.05576e-05, acc 1\n",
      "2018-04-13T15:33:02.364124: step 6518, loss 0.000529797, acc 1\n",
      "2018-04-13T15:33:02.689354: step 6519, loss 0.00135833, acc 1\n",
      "2018-04-13T15:33:03.036100: step 6520, loss 0.0153596, acc 0.984375\n",
      "2018-04-13T15:33:03.378341: step 6521, loss 0.0255965, acc 0.984375\n",
      "2018-04-13T15:33:03.693563: step 6522, loss 0.000535497, acc 1\n",
      "2018-04-13T15:33:04.012288: step 6523, loss 0.00106757, acc 1\n",
      "2018-04-13T15:33:04.334016: step 6524, loss 0.00023012, acc 1\n",
      "2018-04-13T15:33:04.652741: step 6525, loss 0.0009758, acc 1\n",
      "2018-04-13T15:33:04.971966: step 6526, loss 0.007936, acc 1\n",
      "2018-04-13T15:33:05.285187: step 6527, loss 0.00215723, acc 1\n",
      "2018-04-13T15:33:05.615421: step 6528, loss 0.000703701, acc 1\n",
      "2018-04-13T15:33:05.966668: step 6529, loss 0.00160656, acc 1\n",
      "2018-04-13T15:33:06.292398: step 6530, loss 0.000186808, acc 1\n",
      "2018-04-13T15:33:06.605119: step 6531, loss 0.000399997, acc 1\n",
      "2018-04-13T15:33:06.929348: step 6532, loss 0.000911026, acc 1\n",
      "2018-04-13T15:33:07.258581: step 6533, loss 0.00243718, acc 1\n",
      "2018-04-13T15:33:07.572802: step 6534, loss 0.00101526, acc 1\n",
      "2018-04-13T15:33:07.890527: step 6535, loss 0.000367927, acc 1\n",
      "2018-04-13T15:33:08.216257: step 6536, loss 9.54736e-05, acc 1\n",
      "2018-04-13T15:33:08.521472: step 6537, loss 0.00320286, acc 1\n",
      "2018-04-13T15:33:08.857209: step 6538, loss 0.000523249, acc 1\n",
      "2018-04-13T15:33:09.194948: step 6539, loss 0.000123191, acc 1\n",
      "2018-04-13T15:33:09.505166: step 6540, loss 0.00028022, acc 1\n",
      "2018-04-13T15:33:09.829396: step 6541, loss 0.000108669, acc 1\n",
      "2018-04-13T15:33:10.151623: step 6542, loss 0.00211287, acc 1\n",
      "2018-04-13T15:33:10.467346: step 6543, loss 0.000340424, acc 1\n",
      "2018-04-13T15:33:10.807587: step 6544, loss 0.000476254, acc 1\n",
      "2018-04-13T15:33:11.115804: step 6545, loss 0.00247259, acc 1\n",
      "2018-04-13T15:33:11.429526: step 6546, loss 0.00443839, acc 1\n",
      "2018-04-13T15:33:11.754254: step 6547, loss 0.00176133, acc 1\n",
      "2018-04-13T15:33:12.097997: step 6548, loss 0.000824037, acc 1\n",
      "2018-04-13T15:33:12.418724: step 6549, loss 0.00615298, acc 1\n",
      "2018-04-13T15:33:12.744954: step 6550, loss 0.00414267, acc 1\n",
      "2018-04-13T15:33:13.077189: step 6551, loss 0.000553497, acc 1\n",
      "2018-04-13T15:33:13.390411: step 6552, loss 0.000640876, acc 1\n",
      "2018-04-13T15:33:13.705132: step 6553, loss 0.00664285, acc 1\n",
      "2018-04-13T15:33:14.021856: step 6554, loss 0.00729542, acc 1\n",
      "2018-04-13T15:33:14.329073: step 6555, loss 0.00192644, acc 1\n",
      "2018-04-13T15:33:14.646297: step 6556, loss 0.00118993, acc 1\n",
      "2018-04-13T15:33:15.000047: step 6557, loss 0.00718744, acc 1\n",
      "2018-04-13T15:33:15.332781: step 6558, loss 0.00411585, acc 1\n",
      "2018-04-13T15:33:15.672022: step 6559, loss 0.00229707, acc 1\n",
      "2018-04-13T15:33:16.015764: step 6560, loss 0.00379568, acc 1\n",
      "2018-04-13T15:33:16.342495: step 6561, loss 0.000242395, acc 1\n",
      "2018-04-13T15:33:16.658718: step 6562, loss 0.0003689, acc 1\n",
      "2018-04-13T15:33:16.994955: step 6563, loss 0.000512762, acc 1\n",
      "2018-04-13T15:33:17.307676: step 6564, loss 0.000376721, acc 1\n",
      "2018-04-13T15:33:17.645915: step 6565, loss 0.000253551, acc 1\n",
      "2018-04-13T15:33:18.003668: step 6566, loss 0.000531024, acc 1\n",
      "2018-04-13T15:33:18.346410: step 6567, loss 0.00108571, acc 1\n",
      "2018-04-13T15:33:18.664635: step 6568, loss 0.000297051, acc 1\n",
      "2018-04-13T15:33:18.989364: step 6569, loss 0.000481555, acc 1\n",
      "2018-04-13T15:33:19.300083: step 6570, loss 0.00126362, acc 1\n",
      "2018-04-13T15:33:19.613304: step 6571, loss 0.00439048, acc 1\n",
      "2018-04-13T15:33:19.938534: step 6572, loss 0.00252532, acc 1\n",
      "2018-04-13T15:33:20.264765: step 6573, loss 0.000765821, acc 1\n",
      "2018-04-13T15:33:20.581489: step 6574, loss 0.000530098, acc 1\n",
      "2018-04-13T15:33:20.919727: step 6575, loss 0.00484767, acc 1\n",
      "2018-04-13T15:33:21.270474: step 6576, loss 0.000116709, acc 1\n",
      "2018-04-13T15:33:21.581203: step 6577, loss 0.00128536, acc 1\n",
      "2018-04-13T15:33:21.916440: step 6578, loss 0.000428282, acc 1\n",
      "2018-04-13T15:33:22.234164: step 6579, loss 0.000702442, acc 1\n",
      "2018-04-13T15:33:22.555891: step 6580, loss 0.00201637, acc 1\n",
      "2018-04-13T15:33:22.881121: step 6581, loss 0.00017977, acc 1\n",
      "2018-04-13T15:33:23.199345: step 6582, loss 0.000349952, acc 1\n",
      "2018-04-13T15:33:23.533581: step 6583, loss 0.000372839, acc 1\n",
      "2018-04-13T15:33:23.854308: step 6584, loss 0.00026124, acc 1\n",
      "2018-04-13T15:33:24.205557: step 6585, loss 0.00185669, acc 1\n",
      "2018-04-13T15:33:24.519787: step 6586, loss 0.00165907, acc 1\n",
      "2018-04-13T15:33:24.844517: step 6587, loss 0.0136435, acc 0.984375\n",
      "2018-04-13T15:33:25.165743: step 6588, loss 0.00218006, acc 1\n",
      "2018-04-13T15:33:25.494975: step 6589, loss 0.000195973, acc 1\n",
      "2018-04-13T15:33:25.838718: step 6590, loss 0.000165569, acc 1\n",
      "2018-04-13T15:33:26.162948: step 6591, loss 0.00190407, acc 1\n",
      "2018-04-13T15:33:26.482173: step 6592, loss 0.00059932, acc 1\n",
      "2018-04-13T15:33:26.805401: step 6593, loss 0.000591236, acc 1\n",
      "2018-04-13T15:33:27.174663: step 6594, loss 0.00655896, acc 1\n",
      "2018-04-13T15:33:27.492386: step 6595, loss 0.000986066, acc 1\n",
      "2018-04-13T15:33:27.814614: step 6596, loss 0.000194751, acc 1\n",
      "2018-04-13T15:33:28.126834: step 6597, loss 0.0179449, acc 0.984375\n",
      "2018-04-13T15:33:28.451064: step 6598, loss 0.00538903, acc 1\n",
      "2018-04-13T15:33:28.777294: step 6599, loss 0.000280679, acc 1\n",
      "2018-04-13T15:33:29.067999: step 6600, loss 0.000556219, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:33:30.236325: step 6600, loss 1.79171, acc 0.748593\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6600\n",
      "\n",
      "2018-04-13T15:33:31.978054: step 6601, loss 9.36796e-05, acc 1\n",
      "2018-04-13T15:33:32.292776: step 6602, loss 0.00191837, acc 1\n",
      "2018-04-13T15:33:32.608499: step 6603, loss 0.000961467, acc 1\n",
      "2018-04-13T15:33:32.939733: step 6604, loss 0.00688341, acc 1\n",
      "2018-04-13T15:33:33.284481: step 6605, loss 0.00230035, acc 1\n",
      "2018-04-13T15:33:33.607704: step 6606, loss 0.00549783, acc 1\n",
      "2018-04-13T15:33:33.944442: step 6607, loss 0.00027579, acc 1\n",
      "2018-04-13T15:33:34.336720: step 6608, loss 4.85864e-05, acc 1\n",
      "2018-04-13T15:33:34.691970: step 6609, loss 0.000178227, acc 1\n",
      "2018-04-13T15:33:35.010195: step 6610, loss 9.75074e-05, acc 1\n",
      "2018-04-13T15:33:35.342930: step 6611, loss 0.00268426, acc 1\n",
      "2018-04-13T15:33:35.662656: step 6612, loss 3.28978e-05, acc 1\n",
      "2018-04-13T15:33:36.017907: step 6613, loss 0.00245282, acc 1\n",
      "2018-04-13T15:33:36.360648: step 6614, loss 7.63365e-05, acc 1\n",
      "2018-04-13T15:33:36.687880: step 6615, loss 0.0508187, acc 0.984375\n",
      "2018-04-13T15:33:37.022616: step 6616, loss 0.00546199, acc 1\n",
      "2018-04-13T15:33:37.341341: step 6617, loss 0.00108878, acc 1\n",
      "2018-04-13T15:33:37.659565: step 6618, loss 0.0504803, acc 0.984375\n",
      "2018-04-13T15:33:37.983294: step 6619, loss 0.0101982, acc 1\n",
      "2018-04-13T15:33:38.295015: step 6620, loss 0.00825665, acc 1\n",
      "2018-04-13T15:33:38.608505: step 6621, loss 0.000682631, acc 1\n",
      "2018-04-13T15:33:38.955750: step 6622, loss 0.00113489, acc 1\n",
      "2018-04-13T15:33:39.325010: step 6623, loss 0.000702689, acc 1\n",
      "2018-04-13T15:33:39.675758: step 6624, loss 0.00145352, acc 1\n",
      "2018-04-13T15:33:40.009994: step 6625, loss 0.000852645, acc 1\n",
      "2018-04-13T15:33:40.325216: step 6626, loss 0.000852686, acc 1\n",
      "2018-04-13T15:33:40.644442: step 6627, loss 0.000410323, acc 1\n",
      "2018-04-13T15:33:40.992689: step 6628, loss 0.00128192, acc 1\n",
      "2018-04-13T15:33:41.301907: step 6629, loss 0.00184717, acc 1\n",
      "2018-04-13T15:33:41.616628: step 6630, loss 0.000146106, acc 1\n",
      "2018-04-13T15:33:41.946862: step 6631, loss 0.0046625, acc 1\n",
      "2018-04-13T15:33:42.307616: step 6632, loss 0.000279167, acc 1\n",
      "2018-04-13T15:33:42.624840: step 6633, loss 0.000743999, acc 1\n",
      "2018-04-13T15:33:42.943065: step 6634, loss 0.00051371, acc 1\n",
      "2018-04-13T15:33:43.276300: step 6635, loss 0.000175182, acc 1\n",
      "2018-04-13T15:33:43.599028: step 6636, loss 0.000669408, acc 1\n",
      "2018-04-13T15:33:43.919255: step 6637, loss 0.000506927, acc 1\n",
      "2018-04-13T15:33:44.248487: step 6638, loss 0.000694544, acc 1\n",
      "2018-04-13T15:33:44.590228: step 6639, loss 0.0169455, acc 0.984375\n",
      "2018-04-13T15:33:44.941476: step 6640, loss 7.72537e-05, acc 1\n",
      "2018-04-13T15:33:45.327249: step 6641, loss 9.8844e-05, acc 1\n",
      "2018-04-13T15:33:45.668989: step 6642, loss 0.000542024, acc 1\n",
      "2018-04-13T15:33:45.983212: step 6643, loss 0.00131074, acc 1\n",
      "2018-04-13T15:33:46.286426: step 6644, loss 0.000933735, acc 1\n",
      "2018-04-13T15:33:46.612155: step 6645, loss 0.000127115, acc 1\n",
      "2018-04-13T15:33:46.929880: step 6646, loss 0.0153521, acc 0.984375\n",
      "2018-04-13T15:33:47.239099: step 6647, loss 0.0114863, acc 1\n",
      "2018-04-13T15:33:47.571333: step 6648, loss 0.000434731, acc 1\n",
      "2018-04-13T15:33:47.895062: step 6649, loss 0.0241307, acc 0.984375\n",
      "2018-04-13T15:33:48.237303: step 6650, loss 0.0414104, acc 0.984375\n",
      "2018-04-13T15:33:48.557529: step 6651, loss 0.00278862, acc 1\n",
      "2018-04-13T15:33:48.885762: step 6652, loss 3.56137e-05, acc 1\n",
      "2018-04-13T15:33:49.203986: step 6653, loss 0.018424, acc 0.984375\n",
      "2018-04-13T15:33:49.526714: step 6654, loss 7.10418e-05, acc 1\n",
      "2018-04-13T15:33:49.859949: step 6655, loss 0.00409951, acc 1\n",
      "2018-04-13T15:33:50.190682: step 6656, loss 0.000165821, acc 1\n",
      "2018-04-13T15:33:50.495898: step 6657, loss 0.000437133, acc 1\n",
      "2018-04-13T15:33:50.829633: step 6658, loss 0.00108899, acc 1\n",
      "2018-04-13T15:33:51.180381: step 6659, loss 0.000460604, acc 1\n",
      "2018-04-13T15:33:51.496605: step 6660, loss 0.000311717, acc 1\n",
      "2018-04-13T15:33:51.815330: step 6661, loss 0.00118542, acc 1\n",
      "2018-04-13T15:33:52.130552: step 6662, loss 0.00778793, acc 1\n",
      "2018-04-13T15:33:52.451280: step 6663, loss 0.000285945, acc 1\n",
      "2018-04-13T15:33:52.772005: step 6664, loss 0.000635755, acc 1\n",
      "2018-04-13T15:33:53.092732: step 6665, loss 0.000101083, acc 1\n",
      "2018-04-13T15:33:53.401449: step 6666, loss 0.01532, acc 0.984375\n",
      "2018-04-13T15:33:53.724678: step 6667, loss 0.000516763, acc 1\n",
      "2018-04-13T15:33:54.059415: step 6668, loss 0.0074213, acc 1\n",
      "2018-04-13T15:33:54.399655: step 6669, loss 0.029069, acc 0.984375\n",
      "2018-04-13T15:33:54.718380: step 6670, loss 0.000335174, acc 1\n",
      "2018-04-13T15:33:55.043109: step 6671, loss 8.28736e-05, acc 1\n",
      "2018-04-13T15:33:55.357331: step 6672, loss 0.000326867, acc 1\n",
      "2018-04-13T15:33:55.677558: step 6673, loss 0.000276372, acc 1\n",
      "2018-04-13T15:33:55.995281: step 6674, loss 0.00133698, acc 1\n",
      "2018-04-13T15:33:56.328517: step 6675, loss 0.000356537, acc 1\n",
      "2018-04-13T15:33:56.646741: step 6676, loss 0.000834826, acc 1\n",
      "2018-04-13T15:33:56.982479: step 6677, loss 0.00328569, acc 1\n",
      "2018-04-13T15:33:57.317215: step 6678, loss 0.0059064, acc 1\n",
      "2018-04-13T15:33:57.647448: step 6679, loss 0.000606909, acc 1\n",
      "2018-04-13T15:33:57.970676: step 6680, loss 0.00210831, acc 1\n",
      "2018-04-13T15:33:58.289901: step 6681, loss 0.000176079, acc 1\n",
      "2018-04-13T15:33:58.615631: step 6682, loss 0.0003935, acc 1\n",
      "2018-04-13T15:33:58.942863: step 6683, loss 4.48957e-05, acc 1\n",
      "2018-04-13T15:33:59.248078: step 6684, loss 0.000122489, acc 1\n",
      "2018-04-13T15:33:59.565803: step 6685, loss 0.00176098, acc 1\n",
      "2018-04-13T15:33:59.900539: step 6686, loss 0.00298992, acc 1\n",
      "2018-04-13T15:34:00.340850: step 6687, loss 0.000277985, acc 1\n",
      "2018-04-13T15:34:00.691598: step 6688, loss 0.0162708, acc 0.984375\n",
      "2018-04-13T15:34:01.054353: step 6689, loss 0.00268074, acc 1\n",
      "2018-04-13T15:34:01.385087: step 6690, loss 2.19861e-05, acc 1\n",
      "2018-04-13T15:34:01.715320: step 6691, loss 0.00270469, acc 1\n",
      "2018-04-13T15:34:02.050556: step 6692, loss 0.00166585, acc 1\n",
      "2018-04-13T15:34:02.398804: step 6693, loss 7.75043e-05, acc 1\n",
      "2018-04-13T15:34:02.788579: step 6694, loss 0.00136003, acc 1\n",
      "2018-04-13T15:34:03.167346: step 6695, loss 0.000168431, acc 1\n",
      "2018-04-13T15:34:03.499080: step 6696, loss 0.00119409, acc 1\n",
      "2018-04-13T15:34:03.891361: step 6697, loss 0.000180033, acc 1\n",
      "2018-04-13T15:34:04.246107: step 6698, loss 0.00146726, acc 1\n",
      "2018-04-13T15:34:04.585847: step 6699, loss 0.00484958, acc 1\n",
      "2018-04-13T15:34:04.936113: step 6700, loss 0.000183599, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:34:06.359100: step 6700, loss 1.86101, acc 0.748593\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6700\n",
      "\n",
      "2018-04-13T15:34:08.267447: step 6701, loss 0.00985781, acc 1\n",
      "2018-04-13T15:34:08.645714: step 6702, loss 0.00047571, acc 1\n",
      "2018-04-13T15:34:09.100035: step 6703, loss 0.000385863, acc 1\n",
      "2018-04-13T15:34:09.468794: step 6704, loss 0.000463927, acc 1\n",
      "2018-04-13T15:34:09.786520: step 6705, loss 0.000144901, acc 1\n",
      "2018-04-13T15:34:10.115252: step 6706, loss 0.00265916, acc 1\n",
      "2018-04-13T15:34:10.432476: step 6707, loss 0.0021755, acc 1\n",
      "2018-04-13T15:34:10.756204: step 6708, loss 0.000659013, acc 1\n",
      "2018-04-13T15:34:11.083436: step 6709, loss 0.00148387, acc 1\n",
      "2018-04-13T15:34:11.400159: step 6710, loss 0.000231729, acc 1\n",
      "2018-04-13T15:34:11.726890: step 6711, loss 0.000152975, acc 1\n",
      "2018-04-13T15:34:12.052119: step 6712, loss 0.00133571, acc 1\n",
      "2018-04-13T15:34:12.381352: step 6713, loss 0.00022939, acc 1\n",
      "2018-04-13T15:34:12.743108: step 6714, loss 0.00187935, acc 1\n",
      "2018-04-13T15:34:13.077345: step 6715, loss 8.73603e-05, acc 1\n",
      "2018-04-13T15:34:13.391065: step 6716, loss 0.00275127, acc 1\n",
      "2018-04-13T15:34:13.714793: step 6717, loss 0.000806694, acc 1\n",
      "2018-04-13T15:34:14.038022: step 6718, loss 0.00144018, acc 1\n",
      "2018-04-13T15:34:14.366754: step 6719, loss 0.00164393, acc 1\n",
      "2018-04-13T15:34:14.731011: step 6720, loss 0.000744904, acc 1\n",
      "2018-04-13T15:34:15.053238: step 6721, loss 0.000529521, acc 1\n",
      "2018-04-13T15:34:15.381971: step 6722, loss 0.000110782, acc 1\n",
      "2018-04-13T15:34:15.701196: step 6723, loss 0.00182707, acc 1\n",
      "2018-04-13T15:34:16.020922: step 6724, loss 0.0024264, acc 1\n",
      "2018-04-13T15:34:16.346151: step 6725, loss 0.00772455, acc 1\n",
      "2018-04-13T15:34:16.668879: step 6726, loss 0.000557084, acc 1\n",
      "2018-04-13T15:34:16.997611: step 6727, loss 0.000142811, acc 1\n",
      "2018-04-13T15:34:17.316336: step 6728, loss 6.3218e-05, acc 1\n",
      "2018-04-13T15:34:17.714617: step 6729, loss 0.00488656, acc 1\n",
      "2018-04-13T15:34:18.066866: step 6730, loss 0.00027171, acc 1\n",
      "2018-04-13T15:34:18.386092: step 6731, loss 0.00475179, acc 1\n",
      "2018-04-13T15:34:18.828404: step 6732, loss 0.000380247, acc 1\n",
      "2018-04-13T15:34:19.154134: step 6733, loss 0.000250744, acc 1\n",
      "2018-04-13T15:34:19.514889: step 6734, loss 0.012804, acc 0.984375\n",
      "2018-04-13T15:34:19.858131: step 6735, loss 2.69239e-05, acc 1\n",
      "2018-04-13T15:34:20.183861: step 6736, loss 0.00155152, acc 1\n",
      "2018-04-13T15:34:20.577138: step 6737, loss 0.000183801, acc 1\n",
      "2018-04-13T15:34:20.987933: step 6738, loss 0.00464817, acc 1\n",
      "2018-04-13T15:34:21.375203: step 6739, loss 0.000239822, acc 1\n",
      "2018-04-13T15:34:21.753469: step 6740, loss 0.0188056, acc 0.984375\n",
      "2018-04-13T15:34:22.074196: step 6741, loss 0.000523554, acc 1\n",
      "2018-04-13T15:34:22.401427: step 6742, loss 0.000625671, acc 1\n",
      "2018-04-13T15:34:22.745670: step 6743, loss 0.000966744, acc 1\n",
      "2018-04-13T15:34:23.173972: step 6744, loss 0.000418188, acc 1\n",
      "2018-04-13T15:34:23.563748: step 6745, loss 0.00206295, acc 1\n",
      "2018-04-13T15:34:23.973037: step 6746, loss 0.000140368, acc 1\n",
      "2018-04-13T15:34:24.292762: step 6747, loss 0.00140762, acc 1\n",
      "2018-04-13T15:34:24.616991: step 6748, loss 0.0086107, acc 1\n",
      "2018-04-13T15:34:24.951227: step 6749, loss 0.000621667, acc 1\n",
      "2018-04-13T15:34:25.265950: step 6750, loss 0.000143706, acc 1\n",
      "2018-04-13T15:34:25.588677: step 6751, loss 0.0104762, acc 1\n",
      "2018-04-13T15:34:25.955936: step 6752, loss 0.000424922, acc 1\n",
      "2018-04-13T15:34:26.383239: step 6753, loss 0.000510381, acc 1\n",
      "2018-04-13T15:34:26.712971: step 6754, loss 0.00035671, acc 1\n",
      "2018-04-13T15:34:27.047709: step 6755, loss 0.00440145, acc 1\n",
      "2018-04-13T15:34:27.369435: step 6756, loss 0.00020051, acc 1\n",
      "2018-04-13T15:34:27.709174: step 6757, loss 0.00475769, acc 1\n",
      "2018-04-13T15:34:28.101452: step 6758, loss 0.00140541, acc 1\n",
      "2018-04-13T15:34:28.451699: step 6759, loss 0.0318915, acc 0.984375\n",
      "2018-04-13T15:34:28.782933: step 6760, loss 0.00105841, acc 1\n",
      "2018-04-13T15:34:29.106661: step 6761, loss 0.000200315, acc 1\n",
      "2018-04-13T15:34:29.423385: step 6762, loss 0.0132905, acc 0.984375\n",
      "2018-04-13T15:34:29.755620: step 6763, loss 0.00323321, acc 1\n",
      "2018-04-13T15:34:30.078348: step 6764, loss 0.00066105, acc 1\n",
      "2018-04-13T15:34:30.396573: step 6765, loss 0.000351502, acc 1\n",
      "2018-04-13T15:34:30.727306: step 6766, loss 0.00591039, acc 1\n",
      "2018-04-13T15:34:31.049033: step 6767, loss 2.73338e-05, acc 1\n",
      "2018-04-13T15:34:31.372761: step 6768, loss 2.59034e-05, acc 1\n",
      "2018-04-13T15:34:31.702496: step 6769, loss 0.0049016, acc 1\n",
      "2018-04-13T15:34:32.032227: step 6770, loss 0.00165204, acc 1\n",
      "2018-04-13T15:34:32.352454: step 6771, loss 0.000771518, acc 1\n",
      "2018-04-13T15:34:32.683688: step 6772, loss 0.0103885, acc 1\n",
      "2018-04-13T15:34:33.009430: step 6773, loss 0.00745051, acc 1\n",
      "2018-04-13T15:34:33.329155: step 6774, loss 0.00142625, acc 1\n",
      "2018-04-13T15:34:33.655886: step 6775, loss 0.0014721, acc 1\n",
      "2018-04-13T15:34:34.100701: step 6776, loss 0.014599, acc 0.984375\n",
      "2018-04-13T15:34:34.459954: step 6777, loss 0.000586527, acc 1\n",
      "2018-04-13T15:34:34.797192: step 6778, loss 0.00341827, acc 1\n",
      "2018-04-13T15:34:35.152944: step 6779, loss 0.0351679, acc 0.984375\n",
      "2018-04-13T15:34:35.478173: step 6780, loss 0.000669056, acc 1\n",
      "2018-04-13T15:34:35.800901: step 6781, loss 0.00198661, acc 1\n",
      "2018-04-13T15:34:36.121127: step 6782, loss 0.00163254, acc 1\n",
      "2018-04-13T15:34:36.484384: step 6783, loss 0.00021784, acc 1\n",
      "2018-04-13T15:34:36.820622: step 6784, loss 0.0480635, acc 0.984375\n",
      "2018-04-13T15:34:37.152855: step 6785, loss 0.000639133, acc 1\n",
      "2018-04-13T15:34:37.476584: step 6786, loss 0.00228385, acc 1\n",
      "2018-04-13T15:34:37.802815: step 6787, loss 0.00202783, acc 1\n",
      "2018-04-13T15:34:38.132548: step 6788, loss 0.000291511, acc 1\n",
      "2018-04-13T15:34:38.504810: step 6789, loss 0.000528073, acc 1\n",
      "2018-04-13T15:34:38.832041: step 6790, loss 0.0143785, acc 0.984375\n",
      "2018-04-13T15:34:39.179287: step 6791, loss 0.000542595, acc 1\n",
      "2018-04-13T15:34:39.529033: step 6792, loss 0.00104174, acc 1\n",
      "2018-04-13T15:34:39.878782: step 6793, loss 0.000452469, acc 1\n",
      "2018-04-13T15:34:40.234532: step 6794, loss 0.000214692, acc 1\n",
      "2018-04-13T15:34:40.577774: step 6795, loss 0.000195394, acc 1\n",
      "2018-04-13T15:34:40.920519: step 6796, loss 0.000578811, acc 1\n",
      "2018-04-13T15:34:41.269762: step 6797, loss 0.000346427, acc 1\n",
      "2018-04-13T15:34:41.601997: step 6798, loss 0.000143068, acc 1\n",
      "2018-04-13T15:34:41.929728: step 6799, loss 0.00286351, acc 1\n",
      "2018-04-13T15:34:42.245451: step 6800, loss 0.00164935, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:34:43.426786: step 6800, loss 1.87256, acc 0.752345\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6800\n",
      "\n",
      "2018-04-13T15:34:45.353146: step 6801, loss 3.2295e-05, acc 1\n",
      "2018-04-13T15:34:45.675874: step 6802, loss 0.000966268, acc 1\n",
      "2018-04-13T15:34:45.998601: step 6803, loss 0.0285856, acc 0.984375\n",
      "2018-04-13T15:34:46.310322: step 6804, loss 0.000324797, acc 1\n",
      "2018-04-13T15:34:46.632049: step 6805, loss 0.00892753, acc 1\n",
      "2018-04-13T15:34:46.965785: step 6806, loss 0.00491776, acc 1\n",
      "2018-04-13T15:34:47.285510: step 6807, loss 0.0210349, acc 0.984375\n",
      "2018-04-13T15:34:47.604235: step 6808, loss 0.000966473, acc 1\n",
      "2018-04-13T15:34:47.930465: step 6809, loss 8.45855e-05, acc 1\n",
      "2018-04-13T15:34:48.243687: step 6810, loss 0.00113581, acc 1\n",
      "2018-04-13T15:34:48.558410: step 6811, loss 0.00457896, acc 1\n",
      "2018-04-13T15:34:48.879636: step 6812, loss 0.000160421, acc 1\n",
      "2018-04-13T15:34:49.194358: step 6813, loss 0.0010624, acc 1\n",
      "2018-04-13T15:34:49.506078: step 6814, loss 0.00399814, acc 1\n",
      "2018-04-13T15:34:49.832809: step 6815, loss 0.000343447, acc 1\n",
      "2018-04-13T15:34:50.203071: step 6816, loss 0.0137811, acc 0.984375\n",
      "2018-04-13T15:34:50.524297: step 6817, loss 5.5904e-05, acc 1\n",
      "2018-04-13T15:34:50.854030: step 6818, loss 0.0115111, acc 1\n",
      "2018-04-13T15:34:51.178760: step 6819, loss 0.00371388, acc 1\n",
      "2018-04-13T15:34:51.507992: step 6820, loss 0.0352568, acc 0.984375\n",
      "2018-04-13T15:34:51.833221: step 6821, loss 0.000501911, acc 1\n",
      "2018-04-13T15:34:52.155451: step 6822, loss 0.0072913, acc 1\n",
      "2018-04-13T15:34:52.473674: step 6823, loss 0.000575692, acc 1\n",
      "2018-04-13T15:34:52.793400: step 6824, loss 0.0011875, acc 1\n",
      "2018-04-13T15:34:53.105621: step 6825, loss 0.0146777, acc 0.984375\n",
      "2018-04-13T15:34:53.429348: step 6826, loss 0.00503262, acc 1\n",
      "2018-04-13T15:34:53.755578: step 6827, loss 0.000511516, acc 1\n",
      "2018-04-13T15:34:54.087813: step 6828, loss 0.00389945, acc 1\n",
      "2018-04-13T15:34:54.405539: step 6829, loss 0.000455245, acc 1\n",
      "2018-04-13T15:34:54.728266: step 6830, loss 0.000125841, acc 1\n",
      "2018-04-13T15:34:55.045490: step 6831, loss 0.000799712, acc 1\n",
      "2018-04-13T15:34:55.358711: step 6832, loss 0.000591402, acc 1\n",
      "2018-04-13T15:34:55.683941: step 6833, loss 0.00135826, acc 1\n",
      "2018-04-13T15:34:56.008670: step 6834, loss 0.000422377, acc 1\n",
      "2018-04-13T15:34:56.338403: step 6835, loss 0.000222022, acc 1\n",
      "2018-04-13T15:34:56.656128: step 6836, loss 0.00708769, acc 1\n",
      "2018-04-13T15:34:56.980356: step 6837, loss 0.0407476, acc 0.984375\n",
      "2018-04-13T15:34:57.304084: step 6838, loss 0.000223076, acc 1\n",
      "2018-04-13T15:34:57.620809: step 6839, loss 0.00242526, acc 1\n",
      "2018-04-13T15:34:57.944037: step 6840, loss 0.000535522, acc 1\n",
      "2018-04-13T15:34:58.273269: step 6841, loss 0.00147389, acc 1\n",
      "2018-04-13T15:34:58.591493: step 6842, loss 0.00157126, acc 1\n",
      "2018-04-13T15:34:58.919725: step 6843, loss 0.00526295, acc 1\n",
      "2018-04-13T15:34:59.229444: step 6844, loss 0.0106331, acc 1\n",
      "2018-04-13T15:34:59.548669: step 6845, loss 2.30592e-05, acc 1\n",
      "2018-04-13T15:34:59.868896: step 6846, loss 0.000403453, acc 1\n",
      "2018-04-13T15:35:00.185620: step 6847, loss 0.000676561, acc 1\n",
      "2018-04-13T15:35:00.501842: step 6848, loss 0.00053629, acc 1\n",
      "2018-04-13T15:35:00.821068: step 6849, loss 0.00258269, acc 1\n",
      "2018-04-13T15:35:01.142294: step 6850, loss 0.000688709, acc 1\n",
      "2018-04-13T15:35:01.462021: step 6851, loss 0.0106264, acc 1\n",
      "2018-04-13T15:35:01.796256: step 6852, loss 3.87965e-05, acc 1\n",
      "2018-04-13T15:35:02.102473: step 6853, loss 0.00325881, acc 1\n",
      "2018-04-13T15:35:02.428202: step 6854, loss 0.000203655, acc 1\n",
      "2018-04-13T15:35:02.747428: step 6855, loss 0.000131473, acc 1\n",
      "2018-04-13T15:35:03.053144: step 6856, loss 0.00807206, acc 1\n",
      "2018-04-13T15:35:03.373370: step 6857, loss 0.0149017, acc 0.984375\n",
      "2018-04-13T15:35:03.709108: step 6858, loss 0.000768978, acc 1\n",
      "2018-04-13T15:35:04.035337: step 6859, loss 3.89449e-05, acc 1\n",
      "2018-04-13T15:35:04.353062: step 6860, loss 0.00143887, acc 1\n",
      "2018-04-13T15:35:04.665784: step 6861, loss 0.00056563, acc 1\n",
      "2018-04-13T15:35:04.986509: step 6862, loss 0.000168272, acc 1\n",
      "2018-04-13T15:35:05.306235: step 6863, loss 0.00263962, acc 1\n",
      "2018-04-13T15:35:05.629463: step 6864, loss 0.000835472, acc 1\n",
      "2018-04-13T15:35:05.957701: step 6865, loss 0.00061919, acc 1\n",
      "2018-04-13T15:35:06.286927: step 6866, loss 0.000546081, acc 1\n",
      "2018-04-13T15:35:06.595656: step 6867, loss 0.000543159, acc 1\n",
      "2018-04-13T15:35:06.921887: step 6868, loss 0.00945596, acc 1\n",
      "2018-04-13T15:35:07.254621: step 6869, loss 0.000354179, acc 1\n",
      "2018-04-13T15:35:07.577349: step 6870, loss 0.0070459, acc 1\n",
      "2018-04-13T15:35:07.911585: step 6871, loss 0.00140414, acc 1\n",
      "2018-04-13T15:35:08.239318: step 6872, loss 0.000170512, acc 1\n",
      "2018-04-13T15:35:08.567549: step 6873, loss 0.000743517, acc 1\n",
      "2018-04-13T15:35:08.892277: step 6874, loss 0.00373424, acc 1\n",
      "2018-04-13T15:35:09.211504: step 6875, loss 0.00557725, acc 1\n",
      "2018-04-13T15:35:09.523724: step 6876, loss 0.00346736, acc 1\n",
      "2018-04-13T15:35:09.842448: step 6877, loss 9.70296e-05, acc 1\n",
      "2018-04-13T15:35:10.158179: step 6878, loss 0.00286264, acc 1\n",
      "2018-04-13T15:35:10.480407: step 6879, loss 0.000655778, acc 1\n",
      "2018-04-13T15:35:10.804135: step 6880, loss 0.000253889, acc 1\n",
      "2018-04-13T15:35:11.138373: step 6881, loss 0.000469212, acc 1\n",
      "2018-04-13T15:35:11.455595: step 6882, loss 0.000461449, acc 1\n",
      "2018-04-13T15:35:11.784328: step 6883, loss 0.0449886, acc 0.96875\n",
      "2018-04-13T15:35:12.110558: step 6884, loss 0.000475609, acc 1\n",
      "2018-04-13T15:35:12.434787: step 6885, loss 0.000681445, acc 1\n",
      "2018-04-13T15:35:12.758516: step 6886, loss 0.00110929, acc 1\n",
      "2018-04-13T15:35:13.082745: step 6887, loss 0.00127273, acc 1\n",
      "2018-04-13T15:35:13.392965: step 6888, loss 0.0015245, acc 1\n",
      "2018-04-13T15:35:13.738709: step 6889, loss 0.000242708, acc 1\n",
      "2018-04-13T15:35:14.068941: step 6890, loss 0.00210307, acc 1\n",
      "2018-04-13T15:35:14.404178: step 6891, loss 0.000585002, acc 1\n",
      "2018-04-13T15:35:14.753925: step 6892, loss 3.54566e-05, acc 1\n",
      "2018-04-13T15:35:15.091663: step 6893, loss 0.00201845, acc 1\n",
      "2018-04-13T15:35:15.432404: step 6894, loss 0.00239941, acc 1\n",
      "2018-04-13T15:35:15.776647: step 6895, loss 0.000962515, acc 1\n",
      "2018-04-13T15:35:16.108881: step 6896, loss 0.00257982, acc 1\n",
      "2018-04-13T15:35:16.443618: step 6897, loss 0.00432272, acc 1\n",
      "2018-04-13T15:35:16.787861: step 6898, loss 0.000920411, acc 1\n",
      "2018-04-13T15:35:17.120596: step 6899, loss 0.000154792, acc 1\n",
      "2018-04-13T15:35:17.426312: step 6900, loss 0.000285737, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:35:18.565116: step 6900, loss 2.0446, acc 0.734522\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-6900\n",
      "\n",
      "2018-04-13T15:35:20.121715: step 6901, loss 0.00555404, acc 1\n",
      "2018-04-13T15:35:20.450447: step 6902, loss 0.000414856, acc 1\n",
      "2018-04-13T15:35:20.782181: step 6903, loss 2.65491e-05, acc 1\n",
      "2018-04-13T15:35:21.095903: step 6904, loss 0.000191253, acc 1\n",
      "2018-04-13T15:35:21.411125: step 6905, loss 9.34472e-05, acc 1\n",
      "2018-04-13T15:35:21.742860: step 6906, loss 6.04187e-05, acc 1\n",
      "2018-04-13T15:35:22.052579: step 6907, loss 0.000701182, acc 1\n",
      "2018-04-13T15:35:22.360796: step 6908, loss 0.0169324, acc 0.984375\n",
      "2018-04-13T15:35:22.683524: step 6909, loss 0.00135012, acc 1\n",
      "2018-04-13T15:35:23.005251: step 6910, loss 0.000162168, acc 1\n",
      "2018-04-13T15:35:23.318972: step 6911, loss 0.000401276, acc 1\n",
      "2018-04-13T15:35:23.638700: step 6912, loss 0.000650328, acc 1\n",
      "2018-04-13T15:35:23.965930: step 6913, loss 0.00129443, acc 1\n",
      "2018-04-13T15:35:24.287156: step 6914, loss 0.000404242, acc 1\n",
      "2018-04-13T15:35:24.606882: step 6915, loss 0.00116837, acc 1\n",
      "2018-04-13T15:35:24.939117: step 6916, loss 0.0350502, acc 0.984375\n",
      "2018-04-13T15:35:25.261845: step 6917, loss 0.000601897, acc 1\n",
      "2018-04-13T15:35:25.584073: step 6918, loss 0.000239308, acc 1\n",
      "2018-04-13T15:35:25.909302: step 6919, loss 9.31843e-05, acc 1\n",
      "2018-04-13T15:35:26.222922: step 6920, loss 0.000469686, acc 1\n",
      "2018-04-13T15:35:26.541648: step 6921, loss 0.000189879, acc 1\n",
      "2018-04-13T15:35:26.854368: step 6922, loss 8.47153e-05, acc 1\n",
      "2018-04-13T15:35:27.167589: step 6923, loss 0.000965752, acc 1\n",
      "2018-04-13T15:35:27.489818: step 6924, loss 6.72192e-05, acc 1\n",
      "2018-04-13T15:35:27.814047: step 6925, loss 0.000159131, acc 1\n",
      "2018-04-13T15:35:28.141278: step 6926, loss 0.00135756, acc 1\n",
      "2018-04-13T15:35:28.461004: step 6927, loss 0.000206995, acc 1\n",
      "2018-04-13T15:35:28.779228: step 6928, loss 0.00146787, acc 1\n",
      "2018-04-13T15:35:29.098953: step 6929, loss 0.000762723, acc 1\n",
      "2018-04-13T15:35:29.417683: step 6930, loss 0.00224949, acc 1\n",
      "2018-04-13T15:35:29.738405: step 6931, loss 0.00029077, acc 1\n",
      "2018-04-13T15:35:30.056630: step 6932, loss 0.00193796, acc 1\n",
      "2018-04-13T15:35:30.384862: step 6933, loss 0.000754115, acc 1\n",
      "2018-04-13T15:35:30.702587: step 6934, loss 7.4404e-05, acc 1\n",
      "2018-04-13T15:35:31.024313: step 6935, loss 0.00390299, acc 1\n",
      "2018-04-13T15:35:31.341036: step 6936, loss 0.000663893, acc 1\n",
      "2018-04-13T15:35:31.665766: step 6937, loss 0.000108222, acc 1\n",
      "2018-04-13T15:35:31.997501: step 6938, loss 0.00239836, acc 1\n",
      "2018-04-13T15:35:32.336740: step 6939, loss 0.00013044, acc 1\n",
      "2018-04-13T15:35:32.653964: step 6940, loss 0.00160336, acc 1\n",
      "2018-04-13T15:35:32.978693: step 6941, loss 0.000121912, acc 1\n",
      "2018-04-13T15:35:33.309427: step 6942, loss 0.00186715, acc 1\n",
      "2018-04-13T15:35:33.626151: step 6943, loss 0.000107029, acc 1\n",
      "2018-04-13T15:35:33.970393: step 6944, loss 0.000358676, acc 1\n",
      "2018-04-13T15:35:34.296624: step 6945, loss 0.00014207, acc 1\n",
      "2018-04-13T15:35:34.619352: step 6946, loss 0.000841788, acc 1\n",
      "2018-04-13T15:35:34.947082: step 6947, loss 0.00224275, acc 1\n",
      "2018-04-13T15:35:35.273314: step 6948, loss 0.000214602, acc 1\n",
      "2018-04-13T15:35:35.606549: step 6949, loss 0.00115691, acc 1\n",
      "2018-04-13T15:35:35.943287: step 6950, loss 0.000193605, acc 1\n",
      "2018-04-13T15:35:36.269016: step 6951, loss 0.000149205, acc 1\n",
      "2018-04-13T15:35:36.579235: step 6952, loss 8.00241e-05, acc 1\n",
      "2018-04-13T15:35:36.901463: step 6953, loss 0.00749841, acc 1\n",
      "2018-04-13T15:35:37.217686: step 6954, loss 0.00800472, acc 1\n",
      "2018-04-13T15:35:37.534910: step 6955, loss 0.0132012, acc 0.984375\n",
      "2018-04-13T15:35:37.862641: step 6956, loss 0.000237131, acc 1\n",
      "2018-04-13T15:35:38.173861: step 6957, loss 0.000467342, acc 1\n",
      "2018-04-13T15:35:38.489084: step 6958, loss 0.00030731, acc 1\n",
      "2018-04-13T15:35:38.813813: step 6959, loss 0.0399847, acc 0.984375\n",
      "2018-04-13T15:35:39.142545: step 6960, loss 0.0447023, acc 0.984375\n",
      "2018-04-13T15:35:39.467275: step 6961, loss 0.00238506, acc 1\n",
      "2018-04-13T15:35:39.794506: step 6962, loss 0.000208973, acc 1\n",
      "2018-04-13T15:35:40.117735: step 6963, loss 0.000735901, acc 1\n",
      "2018-04-13T15:35:40.434458: step 6964, loss 0.0560963, acc 0.984375\n",
      "2018-04-13T15:35:40.769194: step 6965, loss 0.000457134, acc 1\n",
      "2018-04-13T15:35:41.098427: step 6966, loss 0.00132627, acc 1\n",
      "2018-04-13T15:35:41.426158: step 6967, loss 8.46239e-05, acc 1\n",
      "2018-04-13T15:35:41.744884: step 6968, loss 0.00141668, acc 1\n",
      "2018-04-13T15:35:42.069113: step 6969, loss 0.009792, acc 1\n",
      "2018-04-13T15:35:42.378831: step 6970, loss 0.00738789, acc 1\n",
      "2018-04-13T15:35:42.682546: step 6971, loss 0.0019944, acc 1\n",
      "2018-04-13T15:35:43.010277: step 6972, loss 0.161757, acc 0.984375\n",
      "2018-04-13T15:35:43.331015: step 6973, loss 0.00148989, acc 1\n",
      "2018-04-13T15:35:43.659747: step 6974, loss 7.22998e-05, acc 1\n",
      "2018-04-13T15:35:43.985477: step 6975, loss 0.000825933, acc 1\n",
      "2018-04-13T15:35:44.313708: step 6976, loss 0.000559947, acc 1\n",
      "2018-04-13T15:35:44.635936: step 6977, loss 0.000125692, acc 1\n",
      "2018-04-13T15:35:44.955661: step 6978, loss 1.72298e-05, acc 1\n",
      "2018-04-13T15:35:45.274387: step 6979, loss 0.0160927, acc 0.984375\n",
      "2018-04-13T15:35:45.598115: step 6980, loss 0.000944566, acc 1\n",
      "2018-04-13T15:35:45.921344: step 6981, loss 0.000155234, acc 1\n",
      "2018-04-13T15:35:46.247073: step 6982, loss 0.000130547, acc 1\n",
      "2018-04-13T15:35:46.570301: step 6983, loss 0.000384323, acc 1\n",
      "2018-04-13T15:35:46.896032: step 6984, loss 0.0607255, acc 0.96875\n",
      "2018-04-13T15:35:47.213256: step 6985, loss 9.22622e-05, acc 1\n",
      "2018-04-13T15:35:47.525976: step 6986, loss 0.000813205, acc 1\n",
      "2018-04-13T15:35:47.844202: step 6987, loss 0.000143599, acc 1\n",
      "2018-04-13T15:35:48.153420: step 6988, loss 0.0172045, acc 0.984375\n",
      "2018-04-13T15:35:48.467641: step 6989, loss 0.0016259, acc 1\n",
      "2018-04-13T15:35:48.800377: step 6990, loss 0.000237796, acc 1\n",
      "2018-04-13T15:35:49.113598: step 6991, loss 0.00274691, acc 1\n",
      "2018-04-13T15:35:49.439328: step 6992, loss 0.000522605, acc 1\n",
      "2018-04-13T15:35:49.766558: step 6993, loss 0.00046247, acc 1\n",
      "2018-04-13T15:35:50.075325: step 6994, loss 0.0075112, acc 1\n",
      "2018-04-13T15:35:50.399053: step 6995, loss 0.000865094, acc 1\n",
      "2018-04-13T15:35:50.734290: step 6996, loss 0.00214746, acc 1\n",
      "2018-04-13T15:35:51.051513: step 6997, loss 0.00118282, acc 1\n",
      "2018-04-13T15:35:51.364235: step 6998, loss 0.090592, acc 0.96875\n",
      "2018-04-13T15:35:51.686962: step 6999, loss 0.0001781, acc 1\n",
      "2018-04-13T15:35:52.008189: step 7000, loss 0.000177651, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:35:53.139988: step 7000, loss 2.01201, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7000\n",
      "\n",
      "2018-04-13T15:35:54.854942: step 7001, loss 8.91302e-05, acc 1\n",
      "2018-04-13T15:35:55.163161: step 7002, loss 0.000597944, acc 1\n",
      "2018-04-13T15:35:55.470378: step 7003, loss 0.00494137, acc 1\n",
      "2018-04-13T15:35:55.797608: step 7004, loss 0.000175617, acc 1\n",
      "2018-04-13T15:35:56.114337: step 7005, loss 0.000474595, acc 1\n",
      "2018-04-13T15:35:56.423555: step 7006, loss 0.0016023, acc 1\n",
      "2018-04-13T15:35:56.758292: step 7007, loss 0.000735526, acc 1\n",
      "2018-04-13T15:35:57.080019: step 7008, loss 8.26734e-05, acc 1\n",
      "2018-04-13T15:35:57.408251: step 7009, loss 0.00895326, acc 1\n",
      "2018-04-13T15:35:57.741987: step 7010, loss 0.00049261, acc 1\n",
      "2018-04-13T15:35:58.064214: step 7011, loss 0.000262895, acc 1\n",
      "2018-04-13T15:35:58.373933: step 7012, loss 0.000510296, acc 1\n",
      "2018-04-13T15:35:58.687655: step 7013, loss 0.000121665, acc 1\n",
      "2018-04-13T15:35:59.009393: step 7014, loss 0.0253699, acc 0.984375\n",
      "2018-04-13T15:35:59.324115: step 7015, loss 0.00239852, acc 1\n",
      "2018-04-13T15:35:59.638837: step 7016, loss 0.0213121, acc 1\n",
      "2018-04-13T15:35:59.961065: step 7017, loss 0.004518, acc 1\n",
      "2018-04-13T15:36:00.301806: step 7018, loss 0.00229096, acc 1\n",
      "2018-04-13T15:36:00.619030: step 7019, loss 0.00418018, acc 1\n",
      "2018-04-13T15:36:00.945259: step 7020, loss 0.000492045, acc 1\n",
      "2018-04-13T15:36:01.262485: step 7021, loss 0.00554515, acc 1\n",
      "2018-04-13T15:36:01.591216: step 7022, loss 0.000274393, acc 1\n",
      "2018-04-13T15:36:01.937461: step 7023, loss 0.0121538, acc 0.984375\n",
      "2018-04-13T15:36:02.314727: step 7024, loss 0.000452361, acc 1\n",
      "2018-04-13T15:36:02.706003: step 7025, loss 0.000891097, acc 1\n",
      "2018-04-13T15:36:03.059753: step 7026, loss 0.0161341, acc 0.984375\n",
      "2018-04-13T15:36:03.467548: step 7027, loss 0.0022412, acc 1\n",
      "2018-04-13T15:36:03.903356: step 7028, loss 0.00326693, acc 1\n",
      "2018-04-13T15:36:04.270615: step 7029, loss 0.000218157, acc 1\n",
      "2018-04-13T15:36:04.606864: step 7030, loss 0.0831134, acc 0.984375\n",
      "2018-04-13T15:36:04.959614: step 7031, loss 0.00122231, acc 1\n",
      "2018-04-13T15:36:05.285343: step 7032, loss 0.00526456, acc 1\n",
      "2018-04-13T15:36:05.645599: step 7033, loss 0.00423629, acc 1\n",
      "2018-04-13T15:36:06.050884: step 7034, loss 0.00613107, acc 1\n",
      "2018-04-13T15:36:06.396635: step 7035, loss 0.0518352, acc 0.984375\n",
      "2018-04-13T15:36:06.749377: step 7036, loss 0.00326361, acc 1\n",
      "2018-04-13T15:36:07.114637: step 7037, loss 0.00415201, acc 1\n",
      "2018-04-13T15:36:07.515418: step 7038, loss 0.000599042, acc 1\n",
      "2018-04-13T15:36:07.885181: step 7039, loss 0.00407712, acc 1\n",
      "2018-04-13T15:36:08.291385: step 7040, loss 0.00274836, acc 1\n",
      "2018-04-13T15:36:08.656144: step 7041, loss 0.00102305, acc 1\n",
      "2018-04-13T15:36:09.022902: step 7042, loss 0.000497992, acc 1\n",
      "2018-04-13T15:36:09.357138: step 7043, loss 0.00177275, acc 1\n",
      "2018-04-13T15:36:09.678365: step 7044, loss 0.00396212, acc 1\n",
      "2018-04-13T15:36:10.009098: step 7045, loss 0.00888204, acc 1\n",
      "2018-04-13T15:36:10.338330: step 7046, loss 0.00933915, acc 1\n",
      "2018-04-13T15:36:10.688578: step 7047, loss 0.00179308, acc 1\n",
      "2018-04-13T15:36:11.032321: step 7048, loss 0.00541937, acc 1\n",
      "2018-04-13T15:36:11.354047: step 7049, loss 0.00135202, acc 1\n",
      "2018-04-13T15:36:11.654760: step 7050, loss 0.000941999, acc 1\n",
      "2018-04-13T15:36:11.998002: step 7051, loss 0.000230715, acc 1\n",
      "2018-04-13T15:36:12.308721: step 7052, loss 0.00178231, acc 1\n",
      "2018-04-13T15:36:12.631950: step 7053, loss 0.000100707, acc 1\n",
      "2018-04-13T15:36:12.952677: step 7054, loss 0.00403727, acc 1\n",
      "2018-04-13T15:36:13.286412: step 7055, loss 0.000924313, acc 1\n",
      "2018-04-13T15:36:13.624651: step 7056, loss 0.00123357, acc 1\n",
      "2018-04-13T15:36:13.952882: step 7057, loss 0.00294512, acc 1\n",
      "2018-04-13T15:36:14.268605: step 7058, loss 0.000478102, acc 1\n",
      "2018-04-13T15:36:14.581326: step 7059, loss 3.11088e-05, acc 1\n",
      "2018-04-13T15:36:14.897550: step 7060, loss 0.0020392, acc 1\n",
      "2018-04-13T15:36:15.211772: step 7061, loss 0.000887315, acc 1\n",
      "2018-04-13T15:36:15.532498: step 7062, loss 0.00155422, acc 1\n",
      "2018-04-13T15:36:15.861730: step 7063, loss 0.000506473, acc 1\n",
      "2018-04-13T15:36:16.177954: step 7064, loss 0.00298279, acc 1\n",
      "2018-04-13T15:36:16.528701: step 7065, loss 0.000476242, acc 1\n",
      "2018-04-13T15:36:16.855432: step 7066, loss 0.000326501, acc 1\n",
      "2018-04-13T15:36:17.177662: step 7067, loss 0.000448368, acc 1\n",
      "2018-04-13T15:36:17.499386: step 7068, loss 0.000162951, acc 1\n",
      "2018-04-13T15:36:17.821614: step 7069, loss 0.00277511, acc 1\n",
      "2018-04-13T15:36:18.139339: step 7070, loss 0.00735449, acc 1\n",
      "2018-04-13T15:36:18.457564: step 7071, loss 0.00304738, acc 1\n",
      "2018-04-13T15:36:18.778790: step 7072, loss 0.000931651, acc 1\n",
      "2018-04-13T15:36:19.099517: step 7073, loss 0.00134407, acc 1\n",
      "2018-04-13T15:36:19.429249: step 7074, loss 0.00536699, acc 1\n",
      "2018-04-13T15:36:19.750977: step 7075, loss 0.000552019, acc 1\n",
      "2018-04-13T15:36:20.085213: step 7076, loss 0.0026373, acc 1\n",
      "2018-04-13T15:36:20.423452: step 7077, loss 0.000665946, acc 1\n",
      "2018-04-13T15:36:20.753685: step 7078, loss 0.00574037, acc 1\n",
      "2018-04-13T15:36:21.083918: step 7079, loss 0.000165581, acc 1\n",
      "2018-04-13T15:36:21.427661: step 7080, loss 0.00136745, acc 1\n",
      "2018-04-13T15:36:21.762897: step 7081, loss 0.0103637, acc 1\n",
      "2018-04-13T15:36:22.095132: step 7082, loss 0.000289899, acc 1\n",
      "2018-04-13T15:36:22.454386: step 7083, loss 0.000278047, acc 1\n",
      "2018-04-13T15:36:22.807136: step 7084, loss 7.60551e-05, acc 1\n",
      "2018-04-13T15:36:23.140871: step 7085, loss 0.000493265, acc 1\n",
      "2018-04-13T15:36:23.495120: step 7086, loss 0.000741021, acc 1\n",
      "2018-04-13T15:36:23.815847: step 7087, loss 0.000212663, acc 1\n",
      "2018-04-13T15:36:24.132570: step 7088, loss 0.00131939, acc 1\n",
      "2018-04-13T15:36:24.446793: step 7089, loss 0.000877651, acc 1\n",
      "2018-04-13T15:36:24.772022: step 7090, loss 0.000817145, acc 1\n",
      "2018-04-13T15:36:25.102756: step 7091, loss 0.0399729, acc 0.984375\n",
      "2018-04-13T15:36:25.479021: step 7092, loss 0.000202051, acc 1\n",
      "2018-04-13T15:36:25.812757: step 7093, loss 0.00624028, acc 1\n",
      "2018-04-13T15:36:26.126480: step 7094, loss 5.69529e-06, acc 1\n",
      "2018-04-13T15:36:26.441701: step 7095, loss 0.00129864, acc 1\n",
      "2018-04-13T15:36:26.772435: step 7096, loss 9.78714e-05, acc 1\n",
      "2018-04-13T15:36:27.100174: step 7097, loss 0.00244494, acc 1\n",
      "2018-04-13T15:36:27.409894: step 7098, loss 0.000970471, acc 1\n",
      "2018-04-13T15:36:27.727617: step 7099, loss 0.00254778, acc 1\n",
      "2018-04-13T15:36:28.059352: step 7100, loss 0.00013352, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:36:29.264204: step 7100, loss 2.11155, acc 0.733584\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7100\n",
      "\n",
      "2018-04-13T15:36:31.018942: step 7101, loss 0.00151136, acc 1\n",
      "2018-04-13T15:36:31.338669: step 7102, loss 0.00124389, acc 1\n",
      "2018-04-13T15:36:31.689916: step 7103, loss 0.00471798, acc 1\n",
      "2018-04-13T15:36:32.009641: step 7104, loss 0.0545079, acc 0.984375\n",
      "2018-04-13T15:36:32.338874: step 7105, loss 0.00221163, acc 1\n",
      "2018-04-13T15:36:32.652096: step 7106, loss 0.00110487, acc 1\n",
      "2018-04-13T15:36:32.991335: step 7107, loss 8.99098e-05, acc 1\n",
      "2018-04-13T15:36:33.305056: step 7108, loss 7.99681e-05, acc 1\n",
      "2018-04-13T15:36:33.616277: step 7109, loss 0.00257803, acc 1\n",
      "2018-04-13T15:36:33.943006: step 7110, loss 8.56039e-05, acc 1\n",
      "2018-04-13T15:36:34.272239: step 7111, loss 0.000441134, acc 1\n",
      "2018-04-13T15:36:34.624988: step 7112, loss 0.000195499, acc 1\n",
      "2018-04-13T15:36:34.953220: step 7113, loss 0.00484105, acc 1\n",
      "2018-04-13T15:36:35.274947: step 7114, loss 7.23229e-05, acc 1\n",
      "2018-04-13T15:36:35.583165: step 7115, loss 0.00026287, acc 1\n",
      "2018-04-13T15:36:35.903891: step 7116, loss 0.00746713, acc 1\n",
      "2018-04-13T15:36:36.221616: step 7117, loss 0.000443664, acc 1\n",
      "2018-04-13T15:36:36.537338: step 7118, loss 7.03875e-05, acc 1\n",
      "2018-04-13T15:36:36.859566: step 7119, loss 0.0100041, acc 1\n",
      "2018-04-13T15:36:37.176290: step 7120, loss 0.000334075, acc 1\n",
      "2018-04-13T15:36:37.510526: step 7121, loss 0.00154, acc 1\n",
      "2018-04-13T15:36:37.844761: step 7122, loss 0.000822412, acc 1\n",
      "2018-04-13T15:36:38.166489: step 7123, loss 0.00245269, acc 1\n",
      "2018-04-13T15:36:38.486715: step 7124, loss 0.000263262, acc 1\n",
      "2018-04-13T15:36:38.815948: step 7125, loss 0.000779757, acc 1\n",
      "2018-04-13T15:36:39.132671: step 7126, loss 0.00142962, acc 1\n",
      "2018-04-13T15:36:39.448394: step 7127, loss 0.0161573, acc 1\n",
      "2018-04-13T15:36:39.784131: step 7128, loss 0.000160388, acc 1\n",
      "2018-04-13T15:36:40.108860: step 7129, loss 0.000336315, acc 1\n",
      "2018-04-13T15:36:40.415083: step 7130, loss 0.00268081, acc 1\n",
      "2018-04-13T15:36:40.762829: step 7131, loss 0.000652116, acc 1\n",
      "2018-04-13T15:36:41.075049: step 7132, loss 0.000169634, acc 1\n",
      "2018-04-13T15:36:41.386269: step 7133, loss 0.00621027, acc 1\n",
      "2018-04-13T15:36:41.709998: step 7134, loss 8.89352e-05, acc 1\n",
      "2018-04-13T15:36:42.034228: step 7135, loss 0.000322137, acc 1\n",
      "2018-04-13T15:36:42.355453: step 7136, loss 0.00048871, acc 1\n",
      "2018-04-13T15:36:42.673177: step 7137, loss 0.000513306, acc 1\n",
      "2018-04-13T15:36:43.001910: step 7138, loss 0.0012765, acc 1\n",
      "2018-04-13T15:36:43.320635: step 7139, loss 0.00992406, acc 1\n",
      "2018-04-13T15:36:43.664378: step 7140, loss 6.60858e-05, acc 1\n",
      "2018-04-13T15:36:43.981101: step 7141, loss 0.000370379, acc 1\n",
      "2018-04-13T15:36:44.306331: step 7142, loss 0.000890676, acc 1\n",
      "2018-04-13T15:36:44.628558: step 7143, loss 0.000658229, acc 1\n",
      "2018-04-13T15:36:44.947283: step 7144, loss 0.0134585, acc 1\n",
      "2018-04-13T15:36:45.281520: step 7145, loss 0.00078886, acc 1\n",
      "2018-04-13T15:36:45.596242: step 7146, loss 5.14679e-05, acc 1\n",
      "2018-04-13T15:36:45.928476: step 7147, loss 0.000119639, acc 1\n",
      "2018-04-13T15:36:46.243699: step 7148, loss 0.00105153, acc 1\n",
      "2018-04-13T15:36:46.574433: step 7149, loss 0.00206087, acc 1\n",
      "2018-04-13T15:36:46.900662: step 7150, loss 0.00293142, acc 1\n",
      "2018-04-13T15:36:47.233898: step 7151, loss 0.000428114, acc 1\n",
      "2018-04-13T15:36:47.561129: step 7152, loss 0.000156167, acc 1\n",
      "2018-04-13T15:36:47.893364: step 7153, loss 4.98794e-05, acc 1\n",
      "2018-04-13T15:36:48.215591: step 7154, loss 0.000931393, acc 1\n",
      "2018-04-13T15:36:48.539820: step 7155, loss 0.0498157, acc 0.984375\n",
      "2018-04-13T15:36:48.873055: step 7156, loss 0.000151913, acc 1\n",
      "2018-04-13T15:36:49.189780: step 7157, loss 0.000276396, acc 1\n",
      "2018-04-13T15:36:49.525016: step 7158, loss 0.00196425, acc 1\n",
      "2018-04-13T15:36:49.854749: step 7159, loss 0.000944475, acc 1\n",
      "2018-04-13T15:36:50.213002: step 7160, loss 0.000869776, acc 1\n",
      "2018-04-13T15:36:50.544267: step 7161, loss 0.00166764, acc 1\n",
      "2018-04-13T15:36:50.876003: step 7162, loss 0.000175659, acc 1\n",
      "2018-04-13T15:36:51.186722: step 7163, loss 0.00597099, acc 1\n",
      "2018-04-13T15:36:51.499443: step 7164, loss 0.000958393, acc 1\n",
      "2018-04-13T15:36:51.818174: step 7165, loss 0.00106464, acc 1\n",
      "2018-04-13T15:36:52.140395: step 7166, loss 0.000978484, acc 1\n",
      "2018-04-13T15:36:52.457119: step 7167, loss 0.00170514, acc 1\n",
      "2018-04-13T15:36:52.806866: step 7168, loss 0.000416172, acc 1\n",
      "2018-04-13T15:36:53.127592: step 7169, loss 0.00574898, acc 1\n",
      "2018-04-13T15:36:53.447318: step 7170, loss 0.00688022, acc 1\n",
      "2018-04-13T15:36:53.770546: step 7171, loss 0.0015072, acc 1\n",
      "2018-04-13T15:36:54.102280: step 7172, loss 0.00525144, acc 1\n",
      "2018-04-13T15:36:54.421505: step 7173, loss 6.56497e-05, acc 1\n",
      "2018-04-13T15:36:54.748737: step 7174, loss 0.000115787, acc 1\n",
      "2018-04-13T15:36:55.066461: step 7175, loss 0.000369888, acc 1\n",
      "2018-04-13T15:36:55.387688: step 7176, loss 0.00314157, acc 1\n",
      "2018-04-13T15:36:55.746441: step 7177, loss 0.000471425, acc 1\n",
      "2018-04-13T15:36:56.072671: step 7178, loss 0.0161631, acc 0.984375\n",
      "2018-04-13T15:36:56.393899: step 7179, loss 0.000435242, acc 1\n",
      "2018-04-13T15:36:56.717127: step 7180, loss 0.000810298, acc 1\n",
      "2018-04-13T15:36:57.026845: step 7181, loss 0.000311187, acc 1\n",
      "2018-04-13T15:36:57.341568: step 7182, loss 0.00637826, acc 1\n",
      "2018-04-13T15:36:57.659792: step 7183, loss 0.000176295, acc 1\n",
      "2018-04-13T15:36:57.991026: step 7184, loss 0.00061218, acc 1\n",
      "2018-04-13T15:36:58.311753: step 7185, loss 3.49845e-05, acc 1\n",
      "2018-04-13T15:36:58.726546: step 7186, loss 5.70432e-05, acc 1\n",
      "2018-04-13T15:36:59.050274: step 7187, loss 0.0039147, acc 1\n",
      "2018-04-13T15:36:59.375504: step 7188, loss 0.000453797, acc 1\n",
      "2018-04-13T15:36:59.694730: step 7189, loss 0.00171582, acc 1\n",
      "2018-04-13T15:37:00.015957: step 7190, loss 0.000384902, acc 1\n",
      "2018-04-13T15:37:00.335181: step 7191, loss 0.00134682, acc 1\n",
      "2018-04-13T15:37:00.655908: step 7192, loss 0.00125814, acc 1\n",
      "2018-04-13T15:37:00.980137: step 7193, loss 0.0178848, acc 0.984375\n",
      "2018-04-13T15:37:01.314373: step 7194, loss 0.0019712, acc 1\n",
      "2018-04-13T15:37:01.713655: step 7195, loss 0.00513012, acc 1\n",
      "2018-04-13T15:37:02.041887: step 7196, loss 0.000350537, acc 1\n",
      "2018-04-13T15:37:02.369117: step 7197, loss 0.00447144, acc 1\n",
      "2018-04-13T15:37:02.773404: step 7198, loss 0.000822509, acc 1\n",
      "2018-04-13T15:37:03.156674: step 7199, loss 0.00120028, acc 1\n",
      "2018-04-13T15:37:03.488908: step 7200, loss 0.00735805, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:37:04.811342: step 7200, loss 2.09444, acc 0.737336\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7200\n",
      "\n",
      "2018-04-13T15:37:06.857292: step 7201, loss 0.000742304, acc 1\n",
      "2018-04-13T15:37:07.174516: step 7202, loss 0.00331736, acc 1\n",
      "2018-04-13T15:37:07.533275: step 7203, loss 0.00119884, acc 1\n",
      "2018-04-13T15:37:07.904531: step 7204, loss 0.00140343, acc 1\n",
      "2018-04-13T15:37:08.218754: step 7205, loss 0.00111288, acc 1\n",
      "2018-04-13T15:37:08.540480: step 7206, loss 3.21603e-05, acc 1\n",
      "2018-04-13T15:37:08.863208: step 7207, loss 0.000742929, acc 1\n",
      "2018-04-13T15:37:09.181433: step 7208, loss 0.000673934, acc 1\n",
      "2018-04-13T15:37:09.491652: step 7209, loss 0.00121697, acc 1\n",
      "2018-04-13T15:37:09.821384: step 7210, loss 0.00127103, acc 1\n",
      "2018-04-13T15:37:10.146115: step 7211, loss 0.00223759, acc 1\n",
      "2018-04-13T15:37:10.485353: step 7212, loss 0.000706088, acc 1\n",
      "2018-04-13T15:37:10.852113: step 7213, loss 0.000166852, acc 1\n",
      "2018-04-13T15:37:11.173839: step 7214, loss 1.03004e-06, acc 1\n",
      "2018-04-13T15:37:11.515581: step 7215, loss 0.00228912, acc 1\n",
      "2018-04-13T15:37:11.838809: step 7216, loss 0.000984422, acc 1\n",
      "2018-04-13T15:37:12.176548: step 7217, loss 0.000104548, acc 1\n",
      "2018-04-13T15:37:12.490770: step 7218, loss 0.000168711, acc 1\n",
      "2018-04-13T15:37:12.811997: step 7219, loss 0.000233354, acc 1\n",
      "2018-04-13T15:37:13.152737: step 7220, loss 0.000301941, acc 1\n",
      "2018-04-13T15:37:13.491977: step 7221, loss 0.000486846, acc 1\n",
      "2018-04-13T15:37:13.850730: step 7222, loss 0.000523799, acc 1\n",
      "2018-04-13T15:37:14.189470: step 7223, loss 0.000123881, acc 1\n",
      "2018-04-13T15:37:14.504191: step 7224, loss 0.0201616, acc 0.984375\n",
      "2018-04-13T15:37:14.830422: step 7225, loss 0.00321835, acc 1\n",
      "2018-04-13T15:37:15.166159: step 7226, loss 0.000198954, acc 1\n",
      "2018-04-13T15:37:15.488387: step 7227, loss 0.000177487, acc 1\n",
      "2018-04-13T15:37:15.814116: step 7228, loss 0.000416634, acc 1\n",
      "2018-04-13T15:37:16.147852: step 7229, loss 0.000236666, acc 1\n",
      "2018-04-13T15:37:16.466078: step 7230, loss 0.000193708, acc 1\n",
      "2018-04-13T15:37:16.846845: step 7231, loss 0.000661117, acc 1\n",
      "2018-04-13T15:37:17.179081: step 7232, loss 0.000120387, acc 1\n",
      "2018-04-13T15:37:17.498306: step 7233, loss 0.000140122, acc 1\n",
      "2018-04-13T15:37:17.823535: step 7234, loss 9.25985e-05, acc 1\n",
      "2018-04-13T15:37:18.152267: step 7235, loss 0.00359658, acc 1\n",
      "2018-04-13T15:37:18.474997: step 7236, loss 7.33588e-05, acc 1\n",
      "2018-04-13T15:37:18.868273: step 7237, loss 0.000289718, acc 1\n",
      "2018-04-13T15:37:19.234532: step 7238, loss 0.000489851, acc 1\n",
      "2018-04-13T15:37:19.583278: step 7239, loss 0.00188314, acc 1\n",
      "2018-04-13T15:37:19.923518: step 7240, loss 0.000176852, acc 1\n",
      "2018-04-13T15:37:20.247247: step 7241, loss 0.0324547, acc 0.984375\n",
      "2018-04-13T15:37:20.574978: step 7242, loss 0.000292531, acc 1\n",
      "2018-04-13T15:37:20.907214: step 7243, loss 0.000421066, acc 1\n",
      "2018-04-13T15:37:21.233443: step 7244, loss 0.00279789, acc 1\n",
      "2018-04-13T15:37:21.566679: step 7245, loss 2.33697e-05, acc 1\n",
      "2018-04-13T15:37:21.918427: step 7246, loss 3.07125e-05, acc 1\n",
      "2018-04-13T15:37:22.251662: step 7247, loss 0.00194607, acc 1\n",
      "2018-04-13T15:37:22.586399: step 7248, loss 0.00472092, acc 1\n",
      "2018-04-13T15:37:22.921635: step 7249, loss 0.112305, acc 0.984375\n",
      "2018-04-13T15:37:23.252370: step 7250, loss 0.0128095, acc 1\n",
      "2018-04-13T15:37:23.565590: step 7251, loss 0.000151781, acc 1\n",
      "2018-04-13T15:37:23.886319: step 7252, loss 0.000119215, acc 1\n",
      "2018-04-13T15:37:24.202539: step 7253, loss 0.00123343, acc 1\n",
      "2018-04-13T15:37:24.519275: step 7254, loss 0.00177265, acc 1\n",
      "2018-04-13T15:37:24.849496: step 7255, loss 0.0105017, acc 1\n",
      "2018-04-13T15:37:25.173725: step 7256, loss 0.000114556, acc 1\n",
      "2018-04-13T15:37:25.491450: step 7257, loss 7.57165e-05, acc 1\n",
      "2018-04-13T15:37:25.843198: step 7258, loss 0.00223311, acc 1\n",
      "2018-04-13T15:37:26.154918: step 7259, loss 0.00031584, acc 1\n",
      "2018-04-13T15:37:26.485152: step 7260, loss 0.00270092, acc 1\n",
      "2018-04-13T15:37:26.819887: step 7261, loss 0.00100452, acc 1\n",
      "2018-04-13T15:37:27.143616: step 7262, loss 0.000378965, acc 1\n",
      "2018-04-13T15:37:27.476852: step 7263, loss 0.0411748, acc 0.984375\n",
      "2018-04-13T15:37:27.803082: step 7264, loss 0.0122884, acc 1\n",
      "2018-04-13T15:37:28.134815: step 7265, loss 0.0013413, acc 1\n",
      "2018-04-13T15:37:28.452540: step 7266, loss 0.000264264, acc 1\n",
      "2018-04-13T15:37:28.817798: step 7267, loss 0.000679537, acc 1\n",
      "2018-04-13T15:37:29.138525: step 7268, loss 0.000192073, acc 1\n",
      "2018-04-13T15:37:29.459251: step 7269, loss 0.00170624, acc 1\n",
      "2018-04-13T15:37:29.778477: step 7270, loss 0.0109517, acc 1\n",
      "2018-04-13T15:37:30.114214: step 7271, loss 0.00103406, acc 1\n",
      "2018-04-13T15:37:30.439444: step 7272, loss 1.82043e-05, acc 1\n",
      "2018-04-13T15:37:30.757168: step 7273, loss 0.00125999, acc 1\n",
      "2018-04-13T15:37:31.083898: step 7274, loss 0.00115323, acc 1\n",
      "2018-04-13T15:37:31.414132: step 7275, loss 0.00112267, acc 1\n",
      "2018-04-13T15:37:31.765381: step 7276, loss 0.00157311, acc 1\n",
      "2018-04-13T15:37:32.096114: step 7277, loss 0.0264483, acc 0.984375\n",
      "2018-04-13T15:37:32.416340: step 7278, loss 0.00666086, acc 1\n",
      "2018-04-13T15:37:32.751077: step 7279, loss 0.00382787, acc 1\n",
      "2018-04-13T15:37:33.070801: step 7280, loss 0.00102317, acc 1\n",
      "2018-04-13T15:37:33.394530: step 7281, loss 3.1459e-05, acc 1\n",
      "2018-04-13T15:37:33.697244: step 7282, loss 0.000244551, acc 1\n",
      "2018-04-13T15:37:34.011466: step 7283, loss 0.000638042, acc 1\n",
      "2018-04-13T15:37:34.333693: step 7284, loss 0.00139107, acc 1\n",
      "2018-04-13T15:37:34.662425: step 7285, loss 0.00594117, acc 1\n",
      "2018-04-13T15:37:35.001164: step 7286, loss 0.000624875, acc 1\n",
      "2018-04-13T15:37:35.318889: step 7287, loss 5.95758e-05, acc 1\n",
      "2018-04-13T15:37:35.639615: step 7288, loss 0.0019542, acc 1\n",
      "2018-04-13T15:37:35.973855: step 7289, loss 0.00335165, acc 1\n",
      "2018-04-13T15:37:36.298081: step 7290, loss 0.000296045, acc 1\n",
      "2018-04-13T15:37:36.632816: step 7291, loss 0.00184362, acc 1\n",
      "2018-04-13T15:37:36.961548: step 7292, loss 0.00411928, acc 1\n",
      "2018-04-13T15:37:37.280775: step 7293, loss 0.000145249, acc 1\n",
      "2018-04-13T15:37:37.604504: step 7294, loss 0.000241758, acc 1\n",
      "2018-04-13T15:37:37.956751: step 7295, loss 0.00389153, acc 1\n",
      "2018-04-13T15:37:38.282483: step 7296, loss 0.00227972, acc 1\n",
      "2018-04-13T15:37:38.610213: step 7297, loss 4.13429e-05, acc 1\n",
      "2018-04-13T15:37:38.929938: step 7298, loss 0.0264832, acc 0.984375\n",
      "2018-04-13T15:37:39.247663: step 7299, loss 0.00324426, acc 1\n",
      "2018-04-13T15:37:39.562886: step 7300, loss 0.00117884, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:37:40.731713: step 7300, loss 2.13014, acc 0.736398\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7300\n",
      "\n",
      "2018-04-13T15:37:42.298112: step 7301, loss 0.000194498, acc 1\n",
      "2018-04-13T15:37:42.613834: step 7302, loss 0.00034042, acc 1\n",
      "2018-04-13T15:37:42.948570: step 7303, loss 0.0207017, acc 0.984375\n",
      "2018-04-13T15:37:43.275802: step 7304, loss 0.0271945, acc 0.984375\n",
      "2018-04-13T15:37:43.607535: step 7305, loss 0.00520757, acc 1\n",
      "2018-04-13T15:37:43.962786: step 7306, loss 0.000564438, acc 1\n",
      "2018-04-13T15:37:44.282012: step 7307, loss 0.000221544, acc 1\n",
      "2018-04-13T15:37:44.597235: step 7308, loss 0.00012234, acc 1\n",
      "2018-04-13T15:37:44.921464: step 7309, loss 0.000830238, acc 1\n",
      "2018-04-13T15:37:45.254699: step 7310, loss 0.00045075, acc 1\n",
      "2018-04-13T15:37:45.588434: step 7311, loss 0.00263516, acc 1\n",
      "2018-04-13T15:37:45.933178: step 7312, loss 0.000136403, acc 1\n",
      "2018-04-13T15:37:46.250903: step 7313, loss 0.00015008, acc 1\n",
      "2018-04-13T15:37:46.572630: step 7314, loss 0.000289158, acc 1\n",
      "2018-04-13T15:37:46.925879: step 7315, loss 0.00114944, acc 1\n",
      "2018-04-13T15:37:47.251621: step 7316, loss 0.039146, acc 0.96875\n",
      "2018-04-13T15:37:47.582854: step 7317, loss 2.29325e-05, acc 1\n",
      "2018-04-13T15:37:47.916090: step 7318, loss 0.000197427, acc 1\n",
      "2018-04-13T15:37:48.248825: step 7319, loss 8.45863e-05, acc 1\n",
      "2018-04-13T15:37:48.557542: step 7320, loss 6.15571e-05, acc 1\n",
      "2018-04-13T15:37:48.887275: step 7321, loss 0.00122001, acc 1\n",
      "2018-04-13T15:37:49.202498: step 7322, loss 0.00882471, acc 1\n",
      "2018-04-13T15:37:49.516719: step 7323, loss 0.00180801, acc 1\n",
      "2018-04-13T15:37:49.901992: step 7324, loss 8.49551e-05, acc 1\n",
      "2018-04-13T15:37:50.242233: step 7325, loss 0.000328956, acc 1\n",
      "2018-04-13T15:37:50.556454: step 7326, loss 0.00029699, acc 1\n",
      "2018-04-13T15:37:50.915710: step 7327, loss 6.30943e-05, acc 1\n",
      "2018-04-13T15:37:51.261452: step 7328, loss 0.00143221, acc 1\n",
      "2018-04-13T15:37:51.590184: step 7329, loss 9.2509e-05, acc 1\n",
      "2018-04-13T15:37:51.912411: step 7330, loss 0.00408714, acc 1\n",
      "2018-04-13T15:37:52.231637: step 7331, loss 0.000482751, acc 1\n",
      "2018-04-13T15:37:52.558868: step 7332, loss 0.000151402, acc 1\n",
      "2018-04-13T15:37:52.946141: step 7333, loss 0.00183264, acc 1\n",
      "2018-04-13T15:37:53.282379: step 7334, loss 0.000117642, acc 1\n",
      "2018-04-13T15:37:53.604106: step 7335, loss 0.000174579, acc 1\n",
      "2018-04-13T15:37:53.945847: step 7336, loss 0.000445375, acc 1\n",
      "2018-04-13T15:37:54.259068: step 7337, loss 9.55485e-05, acc 1\n",
      "2018-04-13T15:37:54.585300: step 7338, loss 0.000260157, acc 1\n",
      "2018-04-13T15:37:54.912029: step 7339, loss 0.000537183, acc 1\n",
      "2018-04-13T15:37:55.241762: step 7340, loss 0.000494924, acc 1\n",
      "2018-04-13T15:37:55.567992: step 7341, loss 0.00253535, acc 1\n",
      "2018-04-13T15:37:55.927246: step 7342, loss 0.000964817, acc 1\n",
      "2018-04-13T15:37:56.250475: step 7343, loss 0.00233404, acc 1\n",
      "2018-04-13T15:37:56.579207: step 7344, loss 0.000800957, acc 1\n",
      "2018-04-13T15:37:56.916445: step 7345, loss 0.000220877, acc 1\n",
      "2018-04-13T15:37:57.242675: step 7346, loss 0.00284676, acc 1\n",
      "2018-04-13T15:37:57.563401: step 7347, loss 0.000110697, acc 1\n",
      "2018-04-13T15:37:57.891634: step 7348, loss 0.0254499, acc 0.984375\n",
      "2018-04-13T15:37:58.212360: step 7349, loss 0.00447649, acc 1\n",
      "2018-04-13T15:37:58.524581: step 7350, loss 0.00244883, acc 1\n",
      "2018-04-13T15:37:58.906350: step 7351, loss 0.000659805, acc 1\n",
      "2018-04-13T15:37:59.238084: step 7352, loss 8.26037e-05, acc 1\n",
      "2018-04-13T15:37:59.554808: step 7353, loss 0.0019423, acc 1\n",
      "2018-04-13T15:37:59.879537: step 7354, loss 0.00185918, acc 1\n",
      "2018-04-13T15:38:00.213273: step 7355, loss 0.000166815, acc 1\n",
      "2018-04-13T15:38:00.516487: step 7356, loss 0.00017283, acc 1\n",
      "2018-04-13T15:38:00.844718: step 7357, loss 0.00164883, acc 1\n",
      "2018-04-13T15:38:01.174952: step 7358, loss 0.000594579, acc 1\n",
      "2018-04-13T15:38:01.501182: step 7359, loss 2.0189e-05, acc 1\n",
      "2018-04-13T15:38:01.875947: step 7360, loss 0.000127056, acc 1\n",
      "2018-04-13T15:38:02.208681: step 7361, loss 0.0030834, acc 1\n",
      "2018-04-13T15:38:02.531910: step 7362, loss 0.00213922, acc 1\n",
      "2018-04-13T15:38:02.856640: step 7363, loss 0.00207528, acc 1\n",
      "2018-04-13T15:38:03.189875: step 7364, loss 0.00120416, acc 1\n",
      "2018-04-13T15:38:03.509600: step 7365, loss 0.00043778, acc 1\n",
      "2018-04-13T15:38:03.841334: step 7366, loss 0.0101395, acc 1\n",
      "2018-04-13T15:38:04.171568: step 7367, loss 0.00191674, acc 1\n",
      "2018-04-13T15:38:04.492794: step 7368, loss 0.00459574, acc 1\n",
      "2018-04-13T15:38:04.880069: step 7369, loss 0.000742652, acc 1\n",
      "2018-04-13T15:38:05.220308: step 7370, loss 0.000835421, acc 1\n",
      "2018-04-13T15:38:05.545037: step 7371, loss 0.00262419, acc 1\n",
      "2018-04-13T15:38:05.921303: step 7372, loss 0.00194206, acc 1\n",
      "2018-04-13T15:38:06.273552: step 7373, loss 0.000259019, acc 1\n",
      "2018-04-13T15:38:06.685844: step 7374, loss 0.000363905, acc 1\n",
      "2018-04-13T15:38:07.013574: step 7375, loss 0.00096017, acc 1\n",
      "2018-04-13T15:38:07.346310: step 7376, loss 0.000313132, acc 1\n",
      "2018-04-13T15:38:07.696557: step 7377, loss 2.26115e-05, acc 1\n",
      "2018-04-13T15:38:08.077326: step 7378, loss 0.00141338, acc 1\n",
      "2018-04-13T15:38:08.411562: step 7379, loss 0.000991755, acc 1\n",
      "2018-04-13T15:38:08.745797: step 7380, loss 0.043464, acc 0.984375\n",
      "2018-04-13T15:38:09.077532: step 7381, loss 0.00243982, acc 1\n",
      "2018-04-13T15:38:09.424277: step 7382, loss 0.00120106, acc 1\n",
      "2018-04-13T15:38:09.760014: step 7383, loss 0.000194352, acc 1\n",
      "2018-04-13T15:38:10.091748: step 7384, loss 0.0214433, acc 0.984375\n",
      "2018-04-13T15:38:10.437493: step 7385, loss 0.00118984, acc 1\n",
      "2018-04-13T15:38:10.787740: step 7386, loss 0.00210837, acc 1\n",
      "2018-04-13T15:38:11.130481: step 7387, loss 7.39047e-05, acc 1\n",
      "2018-04-13T15:38:11.463216: step 7388, loss 8.13671e-05, acc 1\n",
      "2018-04-13T15:38:11.789948: step 7389, loss 0.000427325, acc 1\n",
      "2018-04-13T15:38:12.147200: step 7390, loss 7.62019e-05, acc 1\n",
      "2018-04-13T15:38:12.456918: step 7391, loss 7.68863e-05, acc 1\n",
      "2018-04-13T15:38:12.782148: step 7392, loss 0.00135429, acc 1\n",
      "2018-04-13T15:38:13.108878: step 7393, loss 0.00075164, acc 1\n",
      "2018-04-13T15:38:13.471635: step 7394, loss 0.0126069, acc 1\n",
      "2018-04-13T15:38:13.807872: step 7395, loss 0.00170012, acc 1\n",
      "2018-04-13T15:38:14.133602: step 7396, loss 8.65859e-05, acc 1\n",
      "2018-04-13T15:38:14.469839: step 7397, loss 0.0247429, acc 0.984375\n",
      "2018-04-13T15:38:14.800073: step 7398, loss 0.0031976, acc 1\n",
      "2018-04-13T15:38:15.121299: step 7399, loss 0.000910479, acc 1\n",
      "2018-04-13T15:38:15.438523: step 7400, loss 0.000324369, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:38:16.585334: step 7400, loss 2.13579, acc 0.730769\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7400\n",
      "\n",
      "2018-04-13T15:38:18.364093: step 7401, loss 0.0128445, acc 0.984375\n",
      "2018-04-13T15:38:18.705330: step 7402, loss 0.000104484, acc 1\n",
      "2018-04-13T15:38:19.014048: step 7403, loss 0.000295373, acc 1\n",
      "2018-04-13T15:38:19.330272: step 7404, loss 0.00282484, acc 1\n",
      "2018-04-13T15:38:19.660515: step 7405, loss 0.00673428, acc 1\n",
      "2018-04-13T15:38:20.012764: step 7406, loss 7.20991e-05, acc 1\n",
      "2018-04-13T15:38:20.341996: step 7407, loss 0.000195594, acc 1\n",
      "2018-04-13T15:38:20.659220: step 7408, loss 0.000966808, acc 1\n",
      "2018-04-13T15:38:20.981948: step 7409, loss 0.00178789, acc 1\n",
      "2018-04-13T15:38:21.304677: step 7410, loss 9.69816e-05, acc 1\n",
      "2018-04-13T15:38:21.621900: step 7411, loss 0.00523681, acc 1\n",
      "2018-04-13T15:38:21.963641: step 7412, loss 0.000552513, acc 1\n",
      "2018-04-13T15:38:22.290872: step 7413, loss 0.00089595, acc 1\n",
      "2018-04-13T15:38:22.623607: step 7414, loss 0.00056331, acc 1\n",
      "2018-04-13T15:38:22.979858: step 7415, loss 0.00011846, acc 1\n",
      "2018-04-13T15:38:23.305088: step 7416, loss 0.000321184, acc 1\n",
      "2018-04-13T15:38:23.629817: step 7417, loss 0.00453294, acc 1\n",
      "2018-04-13T15:38:23.963052: step 7418, loss 0.000739605, acc 1\n",
      "2018-04-13T15:38:24.298289: step 7419, loss 0.000188695, acc 1\n",
      "2018-04-13T15:38:24.624523: step 7420, loss 0.000619887, acc 1\n",
      "2018-04-13T15:38:24.956254: step 7421, loss 0.000126279, acc 1\n",
      "2018-04-13T15:38:25.271476: step 7422, loss 0.000224309, acc 1\n",
      "2018-04-13T15:38:25.585699: step 7423, loss 7.49826e-05, acc 1\n",
      "2018-04-13T15:38:25.937446: step 7424, loss 0.00469704, acc 1\n",
      "2018-04-13T15:38:26.264678: step 7425, loss 0.000653804, acc 1\n",
      "2018-04-13T15:38:26.586405: step 7426, loss 5.52622e-06, acc 1\n",
      "2018-04-13T15:38:26.931149: step 7427, loss 0.00119343, acc 1\n",
      "2018-04-13T15:38:27.253376: step 7428, loss 2.22959e-05, acc 1\n",
      "2018-04-13T15:38:27.568598: step 7429, loss 0.000807142, acc 1\n",
      "2018-04-13T15:38:27.887824: step 7430, loss 0.000239598, acc 1\n",
      "2018-04-13T15:38:28.194040: step 7431, loss 2.30413e-05, acc 1\n",
      "2018-04-13T15:38:28.504760: step 7432, loss 0.000161292, acc 1\n",
      "2018-04-13T15:38:28.847069: step 7433, loss 0.00733011, acc 1\n",
      "2018-04-13T15:38:29.176301: step 7434, loss 0.00300778, acc 1\n",
      "2018-04-13T15:38:29.487521: step 7435, loss 0.000203161, acc 1\n",
      "2018-04-13T15:38:29.813752: step 7436, loss 0.00456669, acc 1\n",
      "2018-04-13T15:38:30.157495: step 7437, loss 0.000310392, acc 1\n",
      "2018-04-13T15:38:30.469715: step 7438, loss 0.000225172, acc 1\n",
      "2018-04-13T15:38:30.793944: step 7439, loss 0.00046221, acc 1\n",
      "2018-04-13T15:38:31.161703: step 7440, loss 0.000128323, acc 1\n",
      "2018-04-13T15:38:31.487433: step 7441, loss 0.00318949, acc 1\n",
      "2018-04-13T15:38:31.829675: step 7442, loss 0.0122178, acc 1\n",
      "2018-04-13T15:38:32.168414: step 7443, loss 0.00393842, acc 1\n",
      "2018-04-13T15:38:32.490641: step 7444, loss 0.00138211, acc 1\n",
      "2018-04-13T15:38:32.824879: step 7445, loss 0.00118097, acc 1\n",
      "2018-04-13T15:38:33.151108: step 7446, loss 0.00034094, acc 1\n",
      "2018-04-13T15:38:33.475337: step 7447, loss 0.00279965, acc 1\n",
      "2018-04-13T15:38:33.799566: step 7448, loss 0.00752857, acc 1\n",
      "2018-04-13T15:38:34.119793: step 7449, loss 5.77403e-06, acc 1\n",
      "2018-04-13T15:38:34.439018: step 7450, loss 0.000229526, acc 1\n",
      "2018-04-13T15:38:34.775755: step 7451, loss 0.00259303, acc 1\n",
      "2018-04-13T15:38:35.124001: step 7452, loss 0.00292139, acc 1\n",
      "2018-04-13T15:38:35.443227: step 7453, loss 0.000254264, acc 1\n",
      "2018-04-13T15:38:35.774460: step 7454, loss 0.000731514, acc 1\n",
      "2018-04-13T15:38:36.093686: step 7455, loss 0.000667742, acc 1\n",
      "2018-04-13T15:38:36.418415: step 7456, loss 0.000163412, acc 1\n",
      "2018-04-13T15:38:36.735140: step 7457, loss 0.000915132, acc 1\n",
      "2018-04-13T15:38:37.063871: step 7458, loss 0.000566886, acc 1\n",
      "2018-04-13T15:38:37.391602: step 7459, loss 0.00211245, acc 1\n",
      "2018-04-13T15:38:37.720335: step 7460, loss 0.000374001, acc 1\n",
      "2018-04-13T15:38:38.088094: step 7461, loss 0.000159138, acc 1\n",
      "2018-04-13T15:38:38.407321: step 7462, loss 0.00723033, acc 1\n",
      "2018-04-13T15:38:38.741556: step 7463, loss 6.86682e-05, acc 1\n",
      "2018-04-13T15:38:39.049273: step 7464, loss 6.39568e-05, acc 1\n",
      "2018-04-13T15:38:39.372001: step 7465, loss 0.00105924, acc 1\n",
      "2018-04-13T15:38:39.692727: step 7466, loss 0.000375691, acc 1\n",
      "2018-04-13T15:38:40.027464: step 7467, loss 0.0900958, acc 0.984375\n",
      "2018-04-13T15:38:40.353194: step 7468, loss 0.000185765, acc 1\n",
      "2018-04-13T15:38:40.671919: step 7469, loss 0.000605695, acc 1\n",
      "2018-04-13T15:38:41.048185: step 7470, loss 0.000829162, acc 1\n",
      "2018-04-13T15:38:41.367911: step 7471, loss 3.42047e-05, acc 1\n",
      "2018-04-13T15:38:41.708651: step 7472, loss 0.000663411, acc 1\n",
      "2018-04-13T15:38:42.035882: step 7473, loss 6.421e-05, acc 1\n",
      "2018-04-13T15:38:42.349103: step 7474, loss 0.000560954, acc 1\n",
      "2018-04-13T15:38:42.665327: step 7475, loss 0.000340294, acc 1\n",
      "2018-04-13T15:38:42.993558: step 7476, loss 5.14592e-05, acc 1\n",
      "2018-04-13T15:38:43.318788: step 7477, loss 0.00614298, acc 1\n",
      "2018-04-13T15:38:43.641517: step 7478, loss 4.48374e-05, acc 1\n",
      "2018-04-13T15:38:44.009275: step 7479, loss 0.00232876, acc 1\n",
      "2018-04-13T15:38:44.336006: step 7480, loss 0.0021584, acc 1\n",
      "2018-04-13T15:38:44.653230: step 7481, loss 0.000123478, acc 1\n",
      "2018-04-13T15:38:44.987466: step 7482, loss 0.0221699, acc 0.984375\n",
      "2018-04-13T15:38:45.313196: step 7483, loss 0.00145429, acc 1\n",
      "2018-04-13T15:38:45.633923: step 7484, loss 0.00015607, acc 1\n",
      "2018-04-13T15:38:45.965659: step 7485, loss 0.000260891, acc 1\n",
      "2018-04-13T15:38:46.291887: step 7486, loss 0.000218809, acc 1\n",
      "2018-04-13T15:38:46.622120: step 7487, loss 0.000119192, acc 1\n",
      "2018-04-13T15:38:46.979872: step 7488, loss 0.000834399, acc 1\n",
      "2018-04-13T15:38:47.306604: step 7489, loss 0.000735387, acc 1\n",
      "2018-04-13T15:38:47.625329: step 7490, loss 0.00350665, acc 1\n",
      "2018-04-13T15:38:47.952059: step 7491, loss 0.00374802, acc 1\n",
      "2018-04-13T15:38:48.267783: step 7492, loss 0.000932833, acc 1\n",
      "2018-04-13T15:38:48.582505: step 7493, loss 0.0148205, acc 0.984375\n",
      "2018-04-13T15:38:48.923245: step 7494, loss 0.00131677, acc 1\n",
      "2018-04-13T15:38:49.241970: step 7495, loss 3.10804e-05, acc 1\n",
      "2018-04-13T15:38:49.562709: step 7496, loss 0.00467388, acc 1\n",
      "2018-04-13T15:38:49.926467: step 7497, loss 0.00870826, acc 1\n",
      "2018-04-13T15:38:50.374783: step 7498, loss 8.15587e-05, acc 1\n",
      "2018-04-13T15:38:50.692507: step 7499, loss 0.000137768, acc 1\n",
      "2018-04-13T15:38:50.994220: step 7500, loss 0.000271825, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:38:52.158047: step 7500, loss 2.15079, acc 0.733584\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7500\n",
      "\n",
      "2018-04-13T15:38:54.347238: step 7501, loss 8.51566e-05, acc 1\n",
      "2018-04-13T15:38:54.661460: step 7502, loss 0.000208327, acc 1\n",
      "2018-04-13T15:38:54.985189: step 7503, loss 0.00165881, acc 1\n",
      "2018-04-13T15:38:55.310918: step 7504, loss 0.0022091, acc 1\n",
      "2018-04-13T15:38:55.639151: step 7505, loss 0.00468717, acc 1\n",
      "2018-04-13T15:38:55.986896: step 7506, loss 0.00340548, acc 1\n",
      "2018-04-13T15:38:56.323133: step 7507, loss 0.000994491, acc 1\n",
      "2018-04-13T15:38:56.639357: step 7508, loss 0.000369355, acc 1\n",
      "2018-04-13T15:38:56.965087: step 7509, loss 0.00547096, acc 1\n",
      "2018-04-13T15:38:57.301824: step 7510, loss 0.000349085, acc 1\n",
      "2018-04-13T15:38:57.638562: step 7511, loss 0.000760102, acc 1\n",
      "2018-04-13T15:38:57.972798: step 7512, loss 0.000185731, acc 1\n",
      "2018-04-13T15:38:58.298528: step 7513, loss 9.17319e-05, acc 1\n",
      "2018-04-13T15:38:58.636267: step 7514, loss 8.38653e-05, acc 1\n",
      "2018-04-13T15:38:58.991520: step 7515, loss 0.00139932, acc 1\n",
      "2018-04-13T15:38:59.321250: step 7516, loss 7.67716e-05, acc 1\n",
      "2018-04-13T15:38:59.634472: step 7517, loss 4.51969e-05, acc 1\n",
      "2018-04-13T15:38:59.949695: step 7518, loss 0.00184877, acc 1\n",
      "2018-04-13T15:39:00.286932: step 7519, loss 7.8392e-05, acc 1\n",
      "2018-04-13T15:39:00.600654: step 7520, loss 0.00230418, acc 1\n",
      "2018-04-13T15:39:00.931387: step 7521, loss 0.000183198, acc 1\n",
      "2018-04-13T15:39:01.255616: step 7522, loss 0.000244768, acc 1\n",
      "2018-04-13T15:39:01.569338: step 7523, loss 0.000770239, acc 1\n",
      "2018-04-13T15:39:01.917083: step 7524, loss 0.0255262, acc 0.984375\n",
      "2018-04-13T15:39:02.251319: step 7525, loss 0.01692, acc 0.984375\n",
      "2018-04-13T15:39:02.605570: step 7526, loss 0.000138496, acc 1\n",
      "2018-04-13T15:39:02.950314: step 7527, loss 0.00307953, acc 1\n",
      "2018-04-13T15:39:03.304064: step 7528, loss 0.00381785, acc 1\n",
      "2018-04-13T15:39:03.643302: step 7529, loss 0.00133674, acc 1\n",
      "2018-04-13T15:39:03.999554: step 7530, loss 9.522e-05, acc 1\n",
      "2018-04-13T15:39:04.394332: step 7531, loss 5.98649e-05, acc 1\n",
      "2018-04-13T15:39:04.713558: step 7532, loss 0.000178664, acc 1\n",
      "2018-04-13T15:39:05.051297: step 7533, loss 0.000859969, acc 1\n",
      "2018-04-13T15:39:05.381029: step 7534, loss 0.000114137, acc 1\n",
      "2018-04-13T15:39:05.705758: step 7535, loss 0.00276949, acc 1\n",
      "2018-04-13T15:39:06.030988: step 7536, loss 0.000680642, acc 1\n",
      "2018-04-13T15:39:06.362723: step 7537, loss 0.00229218, acc 1\n",
      "2018-04-13T15:39:06.698960: step 7538, loss 6.01701e-05, acc 1\n",
      "2018-04-13T15:39:07.017685: step 7539, loss 0.000190123, acc 1\n",
      "2018-04-13T15:39:07.338411: step 7540, loss 0.000608249, acc 1\n",
      "2018-04-13T15:39:07.661139: step 7541, loss 8.26933e-05, acc 1\n",
      "2018-04-13T15:39:07.997378: step 7542, loss 0.000830171, acc 1\n",
      "2018-04-13T15:39:08.337616: step 7543, loss 0.000119283, acc 1\n",
      "2018-04-13T15:39:08.662346: step 7544, loss 0.000425655, acc 1\n",
      "2018-04-13T15:39:08.997583: step 7545, loss 0.000159133, acc 1\n",
      "2018-04-13T15:39:09.308803: step 7546, loss 0.00137211, acc 1\n",
      "2018-04-13T15:39:09.635534: step 7547, loss 1.85461e-05, acc 1\n",
      "2018-04-13T15:39:09.953258: step 7548, loss 0.000296525, acc 1\n",
      "2018-04-13T15:39:10.281990: step 7549, loss 0.00536927, acc 1\n",
      "2018-04-13T15:39:10.616726: step 7550, loss 0.000132426, acc 1\n",
      "2018-04-13T15:39:10.949963: step 7551, loss 7.66115e-05, acc 1\n",
      "2018-04-13T15:39:11.283697: step 7552, loss 5.83287e-05, acc 1\n",
      "2018-04-13T15:39:11.614932: step 7553, loss 0.000318565, acc 1\n",
      "2018-04-13T15:39:11.951669: step 7554, loss 0.000876371, acc 1\n",
      "2018-04-13T15:39:12.267391: step 7555, loss 0.00400105, acc 1\n",
      "2018-04-13T15:39:12.586116: step 7556, loss 0.00011172, acc 1\n",
      "2018-04-13T15:39:12.911847: step 7557, loss 0.00104414, acc 1\n",
      "2018-04-13T15:39:13.229071: step 7558, loss 0.000213375, acc 1\n",
      "2018-04-13T15:39:13.560805: step 7559, loss 0.00413921, acc 1\n",
      "2018-04-13T15:39:13.903047: step 7560, loss 0.015478, acc 0.984375\n",
      "2018-04-13T15:39:14.255796: step 7561, loss 2.90668e-05, acc 1\n",
      "2018-04-13T15:39:14.579524: step 7562, loss 0.00848596, acc 1\n",
      "2018-04-13T15:39:14.913761: step 7563, loss 0.00457828, acc 1\n",
      "2018-04-13T15:39:15.237489: step 7564, loss 6.43653e-05, acc 1\n",
      "2018-04-13T15:39:15.570724: step 7565, loss 0.0109429, acc 1\n",
      "2018-04-13T15:39:15.902959: step 7566, loss 0.000621229, acc 1\n",
      "2018-04-13T15:39:16.226687: step 7567, loss 0.000191005, acc 1\n",
      "2018-04-13T15:39:16.550416: step 7568, loss 0.000164709, acc 1\n",
      "2018-04-13T15:39:16.874645: step 7569, loss 0.00182247, acc 1\n",
      "2018-04-13T15:39:17.225393: step 7570, loss 0.00149703, acc 1\n",
      "2018-04-13T15:39:17.541616: step 7571, loss 7.58069e-05, acc 1\n",
      "2018-04-13T15:39:17.870349: step 7572, loss 0.00154675, acc 1\n",
      "2018-04-13T15:39:18.196579: step 7573, loss 0.000191388, acc 1\n",
      "2018-04-13T15:39:18.515304: step 7574, loss 0.0005962, acc 1\n",
      "2018-04-13T15:39:18.840033: step 7575, loss 0.000372394, acc 1\n",
      "2018-04-13T15:39:19.161260: step 7576, loss 0.000727884, acc 1\n",
      "2018-04-13T15:39:19.477483: step 7577, loss 0.00118052, acc 1\n",
      "2018-04-13T15:39:19.807715: step 7578, loss 0.00337359, acc 1\n",
      "2018-04-13T15:39:20.164968: step 7579, loss 0.000250244, acc 1\n",
      "2018-04-13T15:39:20.495201: step 7580, loss 0.000251492, acc 1\n",
      "2018-04-13T15:39:20.829939: step 7581, loss 0.000312742, acc 1\n",
      "2018-04-13T15:39:21.160672: step 7582, loss 0.000137046, acc 1\n",
      "2018-04-13T15:39:21.495408: step 7583, loss 0.00169113, acc 1\n",
      "2018-04-13T15:39:21.826641: step 7584, loss 0.000452915, acc 1\n",
      "2018-04-13T15:39:22.152371: step 7585, loss 9.25305e-05, acc 1\n",
      "2018-04-13T15:39:22.473598: step 7586, loss 5.43412e-05, acc 1\n",
      "2018-04-13T15:39:22.794825: step 7587, loss 0.00250053, acc 1\n",
      "2018-04-13T15:39:23.147074: step 7588, loss 0.000586963, acc 1\n",
      "2018-04-13T15:39:23.477307: step 7589, loss 0.00165824, acc 1\n",
      "2018-04-13T15:39:23.799534: step 7590, loss 0.000174013, acc 1\n",
      "2018-04-13T15:39:24.130268: step 7591, loss 7.74425e-05, acc 1\n",
      "2018-04-13T15:39:24.452997: step 7592, loss 0.000290986, acc 1\n",
      "2018-04-13T15:39:24.778726: step 7593, loss 7.53295e-05, acc 1\n",
      "2018-04-13T15:39:25.105957: step 7594, loss 0.0034052, acc 1\n",
      "2018-04-13T15:39:25.429186: step 7595, loss 7.40809e-05, acc 1\n",
      "2018-04-13T15:39:25.754916: step 7596, loss 6.34612e-05, acc 1\n",
      "2018-04-13T15:39:26.116673: step 7597, loss 0.0154908, acc 0.984375\n",
      "2018-04-13T15:39:26.447905: step 7598, loss 0.000526828, acc 1\n",
      "2018-04-13T15:39:26.774635: step 7599, loss 0.000448933, acc 1\n",
      "2018-04-13T15:39:27.084354: step 7600, loss 0.000595074, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:39:28.253680: step 7600, loss 2.15435, acc 0.741088\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7600\n",
      "\n",
      "2018-04-13T15:39:30.114494: step 7601, loss 0.000454675, acc 1\n",
      "2018-04-13T15:39:30.440224: step 7602, loss 0.000313122, acc 1\n",
      "2018-04-13T15:39:30.768455: step 7603, loss 0.000238175, acc 1\n",
      "2018-04-13T15:39:31.092684: step 7604, loss 0.00271078, acc 1\n",
      "2018-04-13T15:39:31.412410: step 7605, loss 0.000114303, acc 1\n",
      "2018-04-13T15:39:31.734137: step 7606, loss 0.00204369, acc 1\n",
      "2018-04-13T15:39:32.086887: step 7607, loss 0.00259832, acc 1\n",
      "2018-04-13T15:39:32.421123: step 7608, loss 0.0428767, acc 0.984375\n",
      "2018-04-13T15:39:32.745852: step 7609, loss 0.000594147, acc 1\n",
      "2018-04-13T15:39:33.074584: step 7610, loss 0.000510421, acc 1\n",
      "2018-04-13T15:39:33.407319: step 7611, loss 0.000379494, acc 1\n",
      "2018-04-13T15:39:33.733549: step 7612, loss 0.000986237, acc 1\n",
      "2018-04-13T15:39:34.068286: step 7613, loss 0.00213404, acc 1\n",
      "2018-04-13T15:39:34.387511: step 7614, loss 0.00028638, acc 1\n",
      "2018-04-13T15:39:34.751769: step 7615, loss 0.00155848, acc 1\n",
      "2018-04-13T15:39:35.102516: step 7616, loss 0.000159042, acc 1\n",
      "2018-04-13T15:39:35.436760: step 7617, loss 5.26342e-06, acc 1\n",
      "2018-04-13T15:39:35.759479: step 7618, loss 0.00178419, acc 1\n",
      "2018-04-13T15:39:36.084710: step 7619, loss 4.50524e-05, acc 1\n",
      "2018-04-13T15:39:36.405436: step 7620, loss 0.00413198, acc 1\n",
      "2018-04-13T15:39:36.732166: step 7621, loss 0.000910601, acc 1\n",
      "2018-04-13T15:39:37.066403: step 7622, loss 0.00244585, acc 1\n",
      "2018-04-13T15:39:37.385127: step 7623, loss 0.00154683, acc 1\n",
      "2018-04-13T15:39:37.690343: step 7624, loss 0.00469549, acc 1\n",
      "2018-04-13T15:39:38.027082: step 7625, loss 0.00150141, acc 1\n",
      "2018-04-13T15:39:38.376328: step 7626, loss 0.000772373, acc 1\n",
      "2018-04-13T15:39:38.704559: step 7627, loss 0.000167086, acc 1\n",
      "2018-04-13T15:39:39.044800: step 7628, loss 0.000429127, acc 1\n",
      "2018-04-13T15:39:39.373031: step 7629, loss 0.000102737, acc 1\n",
      "2018-04-13T15:39:39.684752: step 7630, loss 0.000219837, acc 1\n",
      "2018-04-13T15:39:40.011982: step 7631, loss 3.66211e-05, acc 1\n",
      "2018-04-13T15:39:40.323703: step 7632, loss 0.000858701, acc 1\n",
      "2018-04-13T15:39:40.643429: step 7633, loss 0.000194937, acc 1\n",
      "2018-04-13T15:39:40.971660: step 7634, loss 0.000453214, acc 1\n",
      "2018-04-13T15:39:41.339420: step 7635, loss 0.00102777, acc 1\n",
      "2018-04-13T15:39:41.659146: step 7636, loss 0.00101742, acc 1\n",
      "2018-04-13T15:39:41.982874: step 7637, loss 0.0177945, acc 0.984375\n",
      "2018-04-13T15:39:42.311106: step 7638, loss 7.44028e-05, acc 1\n",
      "2018-04-13T15:39:42.630832: step 7639, loss 0.000995204, acc 1\n",
      "2018-04-13T15:39:42.953560: step 7640, loss 6.39644e-05, acc 1\n",
      "2018-04-13T15:39:43.277789: step 7641, loss 0.000146021, acc 1\n",
      "2018-04-13T15:39:43.597014: step 7642, loss 0.000393038, acc 1\n",
      "2018-04-13T15:39:43.910735: step 7643, loss 0.00095951, acc 1\n",
      "2018-04-13T15:39:44.282998: step 7644, loss 0.0109772, acc 1\n",
      "2018-04-13T15:39:44.591216: step 7645, loss 0.00171686, acc 1\n",
      "2018-04-13T15:39:44.922450: step 7646, loss 0.00514828, acc 1\n",
      "2018-04-13T15:39:45.246679: step 7647, loss 7.60945e-05, acc 1\n",
      "2018-04-13T15:39:45.565904: step 7648, loss 0.0016096, acc 1\n",
      "2018-04-13T15:39:45.900140: step 7649, loss 0.00942861, acc 1\n",
      "2018-04-13T15:39:46.218365: step 7650, loss 0.00224651, acc 1\n",
      "2018-04-13T15:39:46.586125: step 7651, loss 0.000135322, acc 1\n",
      "2018-04-13T15:39:46.925866: step 7652, loss 3.64414e-05, acc 1\n",
      "2018-04-13T15:39:47.294125: step 7653, loss 0.000645855, acc 1\n",
      "2018-04-13T15:39:47.616852: step 7654, loss 1.71888e-05, acc 1\n",
      "2018-04-13T15:39:47.952590: step 7655, loss 3.6019e-05, acc 1\n",
      "2018-04-13T15:39:48.275317: step 7656, loss 6.665e-05, acc 1\n",
      "2018-04-13T15:39:48.597044: step 7657, loss 0.000901547, acc 1\n",
      "2018-04-13T15:39:48.930280: step 7658, loss 0.00614497, acc 1\n",
      "2018-04-13T15:39:49.264016: step 7659, loss 5.4806e-05, acc 1\n",
      "2018-04-13T15:39:49.584243: step 7660, loss 2.55354e-05, acc 1\n",
      "2018-04-13T15:39:49.914474: step 7661, loss 0.00136202, acc 1\n",
      "2018-04-13T15:39:50.269225: step 7662, loss 0.00027186, acc 1\n",
      "2018-04-13T15:39:50.597457: step 7663, loss 0.000651791, acc 1\n",
      "2018-04-13T15:39:50.928692: step 7664, loss 5.76771e-05, acc 1\n",
      "2018-04-13T15:39:51.261926: step 7665, loss 0.000141429, acc 1\n",
      "2018-04-13T15:39:51.582152: step 7666, loss 0.000340658, acc 1\n",
      "2018-04-13T15:39:51.913386: step 7667, loss 0.00145798, acc 1\n",
      "2018-04-13T15:39:52.235614: step 7668, loss 0.00464471, acc 1\n",
      "2018-04-13T15:39:52.551336: step 7669, loss 0.00556837, acc 1\n",
      "2018-04-13T15:39:52.887074: step 7670, loss 9.82558e-05, acc 1\n",
      "2018-04-13T15:39:53.221310: step 7671, loss 0.0010412, acc 1\n",
      "2018-04-13T15:39:53.557547: step 7672, loss 0.000405174, acc 1\n",
      "2018-04-13T15:39:53.885287: step 7673, loss 0.000422087, acc 1\n",
      "2018-04-13T15:39:54.205504: step 7674, loss 0.00308715, acc 1\n",
      "2018-04-13T15:39:54.528233: step 7675, loss 0.000339554, acc 1\n",
      "2018-04-13T15:39:54.858466: step 7676, loss 9.70696e-05, acc 1\n",
      "2018-04-13T15:39:55.179193: step 7677, loss 0.000421449, acc 1\n",
      "2018-04-13T15:39:55.502421: step 7678, loss 1.62087e-05, acc 1\n",
      "2018-04-13T15:39:55.824148: step 7679, loss 2.99954e-05, acc 1\n",
      "2018-04-13T15:39:56.151879: step 7680, loss 0.00100951, acc 1\n",
      "2018-04-13T15:39:56.496622: step 7681, loss 0.000117046, acc 1\n",
      "2018-04-13T15:39:56.826355: step 7682, loss 0.000839952, acc 1\n",
      "2018-04-13T15:39:57.154587: step 7683, loss 0.000143195, acc 1\n",
      "2018-04-13T15:39:57.473813: step 7684, loss 0.00349472, acc 1\n",
      "2018-04-13T15:39:57.801544: step 7685, loss 0.0023091, acc 1\n",
      "2018-04-13T15:39:58.118268: step 7686, loss 6.81366e-05, acc 1\n",
      "2018-04-13T15:39:58.434991: step 7687, loss 0.0320714, acc 0.984375\n",
      "2018-04-13T15:39:58.756718: step 7688, loss 0.00658618, acc 1\n",
      "2018-04-13T15:39:59.077445: step 7689, loss 3.99345e-05, acc 1\n",
      "2018-04-13T15:39:59.421188: step 7690, loss 0.000231136, acc 1\n",
      "2018-04-13T15:39:59.742415: step 7691, loss 0.000497601, acc 1\n",
      "2018-04-13T15:40:00.084656: step 7692, loss 0.001505, acc 1\n",
      "2018-04-13T15:40:00.410386: step 7693, loss 0.000440867, acc 1\n",
      "2018-04-13T15:40:00.746123: step 7694, loss 0.000298612, acc 1\n",
      "2018-04-13T15:40:01.070352: step 7695, loss 0.00137764, acc 1\n",
      "2018-04-13T15:40:01.391078: step 7696, loss 0.000842239, acc 1\n",
      "2018-04-13T15:40:01.704300: step 7697, loss 0.000141011, acc 1\n",
      "2018-04-13T15:40:02.024526: step 7698, loss 0.000727011, acc 1\n",
      "2018-04-13T15:40:02.377275: step 7699, loss 0.000123782, acc 1\n",
      "2018-04-13T15:40:02.708008: step 7700, loss 0.000335903, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:40:03.876834: step 7700, loss 2.17357, acc 0.745779\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7700\n",
      "\n",
      "2018-04-13T15:40:05.485491: step 7701, loss 0.00779177, acc 1\n",
      "2018-04-13T15:40:05.821228: step 7702, loss 0.0018794, acc 1\n",
      "2018-04-13T15:40:06.137952: step 7703, loss 0.000204911, acc 1\n",
      "2018-04-13T15:40:06.491703: step 7704, loss 0.000246223, acc 1\n",
      "2018-04-13T15:40:06.898489: step 7705, loss 0.00110678, acc 1\n",
      "2018-04-13T15:40:07.232225: step 7706, loss 0.00021657, acc 1\n",
      "2018-04-13T15:40:07.569963: step 7707, loss 0.00293435, acc 1\n",
      "2018-04-13T15:40:07.906201: step 7708, loss 0.000427751, acc 1\n",
      "2018-04-13T15:40:08.265955: step 7709, loss 3.47409e-05, acc 1\n",
      "2018-04-13T15:40:08.599690: step 7710, loss 0.000538642, acc 1\n",
      "2018-04-13T15:40:08.949437: step 7711, loss 0.000383013, acc 1\n",
      "2018-04-13T15:40:09.274666: step 7712, loss 0.00054718, acc 1\n",
      "2018-04-13T15:40:09.622412: step 7713, loss 0.000864811, acc 1\n",
      "2018-04-13T15:40:09.972159: step 7714, loss 0.00080129, acc 1\n",
      "2018-04-13T15:40:10.287382: step 7715, loss 0.000464175, acc 1\n",
      "2018-04-13T15:40:10.604605: step 7716, loss 0.00338148, acc 1\n",
      "2018-04-13T15:40:10.936340: step 7717, loss 0.00240918, acc 1\n",
      "2018-04-13T15:40:11.295094: step 7718, loss 0.00443989, acc 1\n",
      "2018-04-13T15:40:11.686370: step 7719, loss 1.19733e-05, acc 1\n",
      "2018-04-13T15:40:12.074144: step 7720, loss 0.000255039, acc 1\n",
      "2018-04-13T15:40:12.420888: step 7721, loss 0.00031821, acc 1\n",
      "2018-04-13T15:40:12.771636: step 7722, loss 0.00174636, acc 1\n",
      "2018-04-13T15:40:13.109874: step 7723, loss 8.53474e-05, acc 1\n",
      "2018-04-13T15:40:13.482643: step 7724, loss 0.000211052, acc 1\n",
      "2018-04-13T15:40:13.844894: step 7725, loss 0.00103969, acc 1\n",
      "2018-04-13T15:40:14.212654: step 7726, loss 0.000308135, acc 1\n",
      "2018-04-13T15:40:14.572408: step 7727, loss 8.59486e-05, acc 1\n",
      "2018-04-13T15:40:14.920654: step 7728, loss 0.000630109, acc 1\n",
      "2018-04-13T15:40:15.286412: step 7729, loss 0.00281903, acc 1\n",
      "2018-04-13T15:40:15.614143: step 7730, loss 0.00372699, acc 1\n",
      "2018-04-13T15:40:15.950380: step 7731, loss 5.71342e-05, acc 1\n",
      "2018-04-13T15:40:16.269606: step 7732, loss 9.35132e-05, acc 1\n",
      "2018-04-13T15:40:16.586330: step 7733, loss 0.000990342, acc 1\n",
      "2018-04-13T15:40:16.932574: step 7734, loss 7.28384e-05, acc 1\n",
      "2018-04-13T15:40:17.278321: step 7735, loss 0.00023517, acc 1\n",
      "2018-04-13T15:40:17.601046: step 7736, loss 0.000977344, acc 1\n",
      "2018-04-13T15:40:17.920772: step 7737, loss 9.03675e-05, acc 1\n",
      "2018-04-13T15:40:18.247503: step 7738, loss 0.0012828, acc 1\n",
      "2018-04-13T15:40:18.578736: step 7739, loss 6.16231e-05, acc 1\n",
      "2018-04-13T15:40:18.926988: step 7740, loss 0.00203635, acc 1\n",
      "2018-04-13T15:40:19.259218: step 7741, loss 0.000125808, acc 1\n",
      "2018-04-13T15:40:19.588950: step 7742, loss 0.00236122, acc 1\n",
      "2018-04-13T15:40:20.036266: step 7743, loss 0.0174963, acc 0.984375\n",
      "2018-04-13T15:40:20.467070: step 7744, loss 0.00217833, acc 1\n",
      "2018-04-13T15:40:20.839333: step 7745, loss 0.00256618, acc 1\n",
      "2018-04-13T15:40:21.207593: step 7746, loss 0.000801818, acc 1\n",
      "2018-04-13T15:40:21.581857: step 7747, loss 0.00266204, acc 1\n",
      "2018-04-13T15:40:21.961125: step 7748, loss 0.00020404, acc 1\n",
      "2018-04-13T15:40:22.348900: step 7749, loss 0.000478344, acc 1\n",
      "2018-04-13T15:40:22.716659: step 7750, loss 0.0461317, acc 0.984375\n",
      "2018-04-13T15:40:23.091423: step 7751, loss 0.00016789, acc 1\n",
      "2018-04-13T15:40:23.511719: step 7752, loss 2.62705e-05, acc 1\n",
      "2018-04-13T15:40:23.911001: step 7753, loss 2.98074e-05, acc 1\n",
      "2018-04-13T15:40:24.263751: step 7754, loss 0.000134122, acc 1\n",
      "2018-04-13T15:40:24.602490: step 7755, loss 0.000988206, acc 1\n",
      "2018-04-13T15:40:24.955739: step 7756, loss 0.000213266, acc 1\n",
      "2018-04-13T15:40:25.287477: step 7757, loss 2.0676e-05, acc 1\n",
      "2018-04-13T15:40:25.644726: step 7758, loss 0.00231028, acc 1\n",
      "2018-04-13T15:40:25.973458: step 7759, loss 0.00129922, acc 1\n",
      "2018-04-13T15:40:26.317200: step 7760, loss 0.000547175, acc 1\n",
      "2018-04-13T15:40:26.650936: step 7761, loss 0.000392879, acc 1\n",
      "2018-04-13T15:40:26.999183: step 7762, loss 0.057667, acc 0.984375\n",
      "2018-04-13T15:40:27.331917: step 7763, loss 0.000282698, acc 1\n",
      "2018-04-13T15:40:27.644639: step 7764, loss 0.00803656, acc 1\n",
      "2018-04-13T15:40:27.977873: step 7765, loss 3.16694e-05, acc 1\n",
      "2018-04-13T15:40:28.298600: step 7766, loss 0.00169044, acc 1\n",
      "2018-04-13T15:40:28.624330: step 7767, loss 0.00205182, acc 1\n",
      "2018-04-13T15:40:28.968573: step 7768, loss 0.000104848, acc 1\n",
      "2018-04-13T15:40:29.311316: step 7769, loss 0.00201515, acc 1\n",
      "2018-04-13T15:40:29.645551: step 7770, loss 0.000497802, acc 1\n",
      "2018-04-13T15:40:29.980787: step 7771, loss 0.000589449, acc 1\n",
      "2018-04-13T15:40:30.321528: step 7772, loss 0.00362602, acc 1\n",
      "2018-04-13T15:40:30.651761: step 7773, loss 0.000474411, acc 1\n",
      "2018-04-13T15:40:30.998008: step 7774, loss 0.0106681, acc 1\n",
      "2018-04-13T15:40:31.311727: step 7775, loss 0.0102113, acc 1\n",
      "2018-04-13T15:40:31.641961: step 7776, loss 0.000279549, acc 1\n",
      "2018-04-13T15:40:31.966189: step 7777, loss 0.000345962, acc 1\n",
      "2018-04-13T15:40:32.309932: step 7778, loss 0.000736284, acc 1\n",
      "2018-04-13T15:40:32.649172: step 7779, loss 0.000265348, acc 1\n",
      "2018-04-13T15:40:32.989912: step 7780, loss 0.000203417, acc 1\n",
      "2018-04-13T15:40:33.332154: step 7781, loss 0.00510063, acc 1\n",
      "2018-04-13T15:40:33.653380: step 7782, loss 0.000289387, acc 1\n",
      "2018-04-13T15:40:33.994122: step 7783, loss 0.000198333, acc 1\n",
      "2018-04-13T15:40:34.311845: step 7784, loss 4.10704e-05, acc 1\n",
      "2018-04-13T15:40:34.638077: step 7785, loss 0.00054722, acc 1\n",
      "2018-04-13T15:40:34.967809: step 7786, loss 0.0137606, acc 0.984375\n",
      "2018-04-13T15:40:35.313053: step 7787, loss 3.04526e-05, acc 1\n",
      "2018-04-13T15:40:35.656795: step 7788, loss 0.0137725, acc 0.984375\n",
      "2018-04-13T15:40:36.005542: step 7789, loss 0.000109262, acc 1\n",
      "2018-04-13T15:40:36.349285: step 7790, loss 0.000849088, acc 1\n",
      "2018-04-13T15:40:36.681019: step 7791, loss 0.00175293, acc 1\n",
      "2018-04-13T15:40:37.006748: step 7792, loss 0.00146094, acc 1\n",
      "2018-04-13T15:40:37.323974: step 7793, loss 0.00033752, acc 1\n",
      "2018-04-13T15:40:37.641197: step 7794, loss 0.000190222, acc 1\n",
      "2018-04-13T15:40:37.967427: step 7795, loss 2.80549e-05, acc 1\n",
      "2018-04-13T15:40:38.315172: step 7796, loss 0.000416552, acc 1\n",
      "2018-04-13T15:40:38.647407: step 7797, loss 0.00426364, acc 1\n",
      "2018-04-13T15:40:38.976639: step 7798, loss 0.000754649, acc 1\n",
      "2018-04-13T15:40:39.332391: step 7799, loss 0.0055036, acc 1\n",
      "2018-04-13T15:40:39.663124: step 7800, loss 0.00450078, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:40:40.881985: step 7800, loss 2.24372, acc 0.736398\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7800\n",
      "\n",
      "2018-04-13T15:40:42.597197: step 7801, loss 1.33186e-05, acc 1\n",
      "2018-04-13T15:40:42.914420: step 7802, loss 0.00157557, acc 1\n",
      "2018-04-13T15:40:43.230644: step 7803, loss 0.00017651, acc 1\n",
      "2018-04-13T15:40:43.556874: step 7804, loss 6.81505e-05, acc 1\n",
      "2018-04-13T15:40:43.879602: step 7805, loss 0.000153789, acc 1\n",
      "2018-04-13T15:40:44.208835: step 7806, loss 0.00422743, acc 1\n",
      "2018-04-13T15:40:44.555578: step 7807, loss 0.000161535, acc 1\n",
      "2018-04-13T15:40:44.863297: step 7808, loss 4.07468e-05, acc 1\n",
      "2018-04-13T15:40:45.176517: step 7809, loss 0.00151483, acc 1\n",
      "2018-04-13T15:40:45.493741: step 7810, loss 0.00217592, acc 1\n",
      "2018-04-13T15:40:45.838485: step 7811, loss 0.000387438, acc 1\n",
      "2018-04-13T15:40:46.171220: step 7812, loss 0.00728361, acc 1\n",
      "2018-04-13T15:40:46.501954: step 7813, loss 0.00551483, acc 1\n",
      "2018-04-13T15:40:46.827684: step 7814, loss 0.000107017, acc 1\n",
      "2018-04-13T15:40:47.149911: step 7815, loss 0.00347649, acc 1\n",
      "2018-04-13T15:40:47.502160: step 7816, loss 7.72379e-05, acc 1\n",
      "2018-04-13T15:40:47.824388: step 7817, loss 0.000525108, acc 1\n",
      "2018-04-13T15:40:48.140611: step 7818, loss 0.000631716, acc 1\n",
      "2018-04-13T15:40:48.458836: step 7819, loss 0.000163445, acc 1\n",
      "2018-04-13T15:40:48.784565: step 7820, loss 0.000407892, acc 1\n",
      "2018-04-13T15:40:49.104791: step 7821, loss 1.71174e-05, acc 1\n",
      "2018-04-13T15:40:49.450035: step 7822, loss 2.98679e-05, acc 1\n",
      "2018-04-13T15:40:49.773263: step 7823, loss 0.000219676, acc 1\n",
      "2018-04-13T15:40:50.101495: step 7824, loss 0.000684785, acc 1\n",
      "2018-04-13T15:40:50.508783: step 7825, loss 0.00938637, acc 1\n",
      "2018-04-13T15:40:50.839516: step 7826, loss 0.000348143, acc 1\n",
      "2018-04-13T15:40:51.160743: step 7827, loss 0.000120181, acc 1\n",
      "2018-04-13T15:40:51.483471: step 7828, loss 0.00138539, acc 1\n",
      "2018-04-13T15:40:51.811703: step 7829, loss 0.00016312, acc 1\n",
      "2018-04-13T15:40:52.127926: step 7830, loss 0.00015143, acc 1\n",
      "2018-04-13T15:40:52.462162: step 7831, loss 0.00338831, acc 1\n",
      "2018-04-13T15:40:52.793396: step 7832, loss 0.000117702, acc 1\n",
      "2018-04-13T15:40:53.112621: step 7833, loss 6.39796e-06, acc 1\n",
      "2018-04-13T15:40:53.449359: step 7834, loss 0.000158522, acc 1\n",
      "2018-04-13T15:40:53.783595: step 7835, loss 7.20804e-05, acc 1\n",
      "2018-04-13T15:40:54.084308: step 7836, loss 0.000163784, acc 1\n",
      "2018-04-13T15:40:54.397529: step 7837, loss 0.0177417, acc 0.984375\n",
      "2018-04-13T15:40:54.724259: step 7838, loss 0.000198496, acc 1\n",
      "2018-04-13T15:40:55.049989: step 7839, loss 0.00100031, acc 1\n",
      "2018-04-13T15:40:55.376219: step 7840, loss 1.59756e-05, acc 1\n",
      "2018-04-13T15:40:55.716460: step 7841, loss 0.00014749, acc 1\n",
      "2018-04-13T15:40:56.038688: step 7842, loss 0.00242538, acc 1\n",
      "2018-04-13T15:40:56.380429: step 7843, loss 0.000867176, acc 1\n",
      "2018-04-13T15:40:56.726673: step 7844, loss 3.89171e-05, acc 1\n",
      "2018-04-13T15:40:57.043397: step 7845, loss 0.000266359, acc 1\n",
      "2018-04-13T15:40:57.361121: step 7846, loss 0.00031422, acc 1\n",
      "2018-04-13T15:40:57.684350: step 7847, loss 3.02922e-05, acc 1\n",
      "2018-04-13T15:40:58.008579: step 7848, loss 0.0534552, acc 0.984375\n",
      "2018-04-13T15:40:58.313793: step 7849, loss 0.00310561, acc 1\n",
      "2018-04-13T15:40:58.651032: step 7850, loss 7.23382e-05, acc 1\n",
      "2018-04-13T15:40:58.976262: step 7851, loss 2.76277e-05, acc 1\n",
      "2018-04-13T15:40:59.294487: step 7852, loss 0.000108708, acc 1\n",
      "2018-04-13T15:40:59.654740: step 7853, loss 0.00130608, acc 1\n",
      "2018-04-13T15:40:59.980471: step 7854, loss 0.000692454, acc 1\n",
      "2018-04-13T15:41:00.315217: step 7855, loss 0.00205616, acc 1\n",
      "2018-04-13T15:41:00.633442: step 7856, loss 0.000123955, acc 1\n",
      "2018-04-13T15:41:00.968178: step 7857, loss 0.00113383, acc 1\n",
      "2018-04-13T15:41:01.300418: step 7858, loss 0.00104718, acc 1\n",
      "2018-04-13T15:41:01.642655: step 7859, loss 0.000478676, acc 1\n",
      "2018-04-13T15:41:01.963381: step 7860, loss 0.00013164, acc 1\n",
      "2018-04-13T15:41:02.280606: step 7861, loss 8.8777e-05, acc 1\n",
      "2018-04-13T15:41:02.637357: step 7862, loss 0.0163601, acc 0.984375\n",
      "2018-04-13T15:41:02.976596: step 7863, loss 0.0680762, acc 0.984375\n",
      "2018-04-13T15:41:03.366872: step 7864, loss 0.0035337, acc 1\n",
      "2018-04-13T15:41:03.706112: step 7865, loss 0.00216561, acc 1\n",
      "2018-04-13T15:41:04.067867: step 7866, loss 0.000127342, acc 1\n",
      "2018-04-13T15:41:04.408607: step 7867, loss 0.00122904, acc 1\n",
      "2018-04-13T15:41:04.775366: step 7868, loss 0.00346469, acc 1\n",
      "2018-04-13T15:41:05.122111: step 7869, loss 9.67447e-05, acc 1\n",
      "2018-04-13T15:41:05.458849: step 7870, loss 3.04026e-05, acc 1\n",
      "2018-04-13T15:41:05.778577: step 7871, loss 0.000361677, acc 1\n",
      "2018-04-13T15:41:06.087293: step 7872, loss 0.00185308, acc 1\n",
      "2018-04-13T15:41:06.408019: step 7873, loss 0.00134593, acc 1\n",
      "2018-04-13T15:41:06.728246: step 7874, loss 0.000669606, acc 1\n",
      "2018-04-13T15:41:07.038465: step 7875, loss 0.000852172, acc 1\n",
      "2018-04-13T15:41:07.350185: step 7876, loss 0.000976926, acc 1\n",
      "2018-04-13T15:41:07.674914: step 7877, loss 0.000145252, acc 1\n",
      "2018-04-13T15:41:08.005146: step 7878, loss 2.93925e-05, acc 1\n",
      "2018-04-13T15:41:08.322372: step 7879, loss 0.00516819, acc 1\n",
      "2018-04-13T15:41:08.677122: step 7880, loss 0.0020099, acc 1\n",
      "2018-04-13T15:41:09.010857: step 7881, loss 0.0887787, acc 0.984375\n",
      "2018-04-13T15:41:09.331083: step 7882, loss 0.00252598, acc 1\n",
      "2018-04-13T15:41:09.645305: step 7883, loss 0.000220981, acc 1\n",
      "2018-04-13T15:41:09.971035: step 7884, loss 0.0270178, acc 0.984375\n",
      "2018-04-13T15:41:10.286758: step 7885, loss 0.000310729, acc 1\n",
      "2018-04-13T15:41:10.608486: step 7886, loss 0.000365515, acc 1\n",
      "2018-04-13T15:41:10.941221: step 7887, loss 0.000105479, acc 1\n",
      "2018-04-13T15:41:11.261446: step 7888, loss 1.71264e-05, acc 1\n",
      "2018-04-13T15:41:11.626704: step 7889, loss 0.00246536, acc 1\n",
      "2018-04-13T15:41:11.969946: step 7890, loss 7.06857e-05, acc 1\n",
      "2018-04-13T15:41:12.280666: step 7891, loss 0.000481241, acc 1\n",
      "2018-04-13T15:41:12.605896: step 7892, loss 0.00649672, acc 1\n",
      "2018-04-13T15:41:12.930125: step 7893, loss 0.0423515, acc 0.984375\n",
      "2018-04-13T15:41:13.243346: step 7894, loss 9.33097e-05, acc 1\n",
      "2018-04-13T15:41:13.563071: step 7895, loss 0.00103388, acc 1\n",
      "2018-04-13T15:41:13.914820: step 7896, loss 0.000202323, acc 1\n",
      "2018-04-13T15:41:14.226540: step 7897, loss 0.000130053, acc 1\n",
      "2018-04-13T15:41:14.574285: step 7898, loss 0.000203083, acc 1\n",
      "2018-04-13T15:41:14.917027: step 7899, loss 0.000720794, acc 1\n",
      "2018-04-13T15:41:15.242257: step 7900, loss 0.000181611, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:41:16.375557: step 7900, loss 2.49643, acc 0.725141\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-7900\n",
      "\n",
      "2018-04-13T15:41:18.090270: step 7901, loss 0.0196593, acc 0.984375\n",
      "2018-04-13T15:41:18.418500: step 7902, loss 0.000272151, acc 1\n",
      "2018-04-13T15:41:18.738226: step 7903, loss 0.0104424, acc 1\n",
      "2018-04-13T15:41:19.055950: step 7904, loss 0.0114312, acc 1\n",
      "2018-04-13T15:41:19.372674: step 7905, loss 0.0090521, acc 1\n",
      "2018-04-13T15:41:19.695902: step 7906, loss 0.000196189, acc 1\n",
      "2018-04-13T15:41:20.014627: step 7907, loss 0.000465787, acc 1\n",
      "2018-04-13T15:41:20.336855: step 7908, loss 0.000653398, acc 1\n",
      "2018-04-13T15:41:20.695608: step 7909, loss 0.000306039, acc 1\n",
      "2018-04-13T15:41:21.021338: step 7910, loss 0.000405366, acc 1\n",
      "2018-04-13T15:41:21.345567: step 7911, loss 0.00111193, acc 1\n",
      "2018-04-13T15:41:21.667795: step 7912, loss 9.35083e-05, acc 1\n",
      "2018-04-13T15:41:21.991523: step 7913, loss 0.0036539, acc 1\n",
      "2018-04-13T15:41:22.305745: step 7914, loss 0.00141046, acc 1\n",
      "2018-04-13T15:41:22.626471: step 7915, loss 0.0391769, acc 0.984375\n",
      "2018-04-13T15:41:22.950700: step 7916, loss 0.000160472, acc 1\n",
      "2018-04-13T15:41:23.266423: step 7917, loss 0.000814093, acc 1\n",
      "2018-04-13T15:41:23.636685: step 7918, loss 0.00247775, acc 1\n",
      "2018-04-13T15:41:23.978927: step 7919, loss 0.0025396, acc 1\n",
      "2018-04-13T15:41:24.309160: step 7920, loss 0.00366483, acc 1\n",
      "2018-04-13T15:41:24.630387: step 7921, loss 0.00163132, acc 1\n",
      "2018-04-13T15:41:24.957117: step 7922, loss 0.000274724, acc 1\n",
      "2018-04-13T15:41:25.281846: step 7923, loss 0.000315865, acc 1\n",
      "2018-04-13T15:41:25.602073: step 7924, loss 0.00106532, acc 1\n",
      "2018-04-13T15:41:25.929804: step 7925, loss 0.000100687, acc 1\n",
      "2018-04-13T15:41:26.244526: step 7926, loss 0.00101671, acc 1\n",
      "2018-04-13T15:41:26.577763: step 7927, loss 0.00244871, acc 1\n",
      "2018-04-13T15:41:26.904492: step 7928, loss 0.000192768, acc 1\n",
      "2018-04-13T15:41:27.245733: step 7929, loss 0.000489732, acc 1\n",
      "2018-04-13T15:41:27.569962: step 7930, loss 0.000534074, acc 1\n",
      "2018-04-13T15:41:27.895191: step 7931, loss 0.00020561, acc 1\n",
      "2018-04-13T15:41:28.217419: step 7932, loss 0.00485163, acc 1\n",
      "2018-04-13T15:41:28.535644: step 7933, loss 0.00950808, acc 1\n",
      "2018-04-13T15:41:28.865877: step 7934, loss 0.00155792, acc 1\n",
      "2018-04-13T15:41:29.173097: step 7935, loss 0.000111612, acc 1\n",
      "2018-04-13T15:41:29.500325: step 7936, loss 0.000171974, acc 1\n",
      "2018-04-13T15:41:29.846574: step 7937, loss 0.0233183, acc 0.984375\n",
      "2018-04-13T15:41:30.185809: step 7938, loss 0.000839339, acc 1\n",
      "2018-04-13T15:41:30.510538: step 7939, loss 0.0197469, acc 0.984375\n",
      "2018-04-13T15:41:30.833767: step 7940, loss 0.000746256, acc 1\n",
      "2018-04-13T15:41:31.149490: step 7941, loss 0.0331395, acc 0.984375\n",
      "2018-04-13T15:41:31.467213: step 7942, loss 0.00211995, acc 1\n",
      "2018-04-13T15:41:31.782436: step 7943, loss 3.4053e-05, acc 1\n",
      "2018-04-13T15:41:32.098661: step 7944, loss 0.000159682, acc 1\n",
      "2018-04-13T15:41:32.428393: step 7945, loss 0.000882959, acc 1\n",
      "2018-04-13T15:41:32.761128: step 7946, loss 1.09607e-05, acc 1\n",
      "2018-04-13T15:41:33.093862: step 7947, loss 0.0111345, acc 1\n",
      "2018-04-13T15:41:33.424096: step 7948, loss 0.000300571, acc 1\n",
      "2018-04-13T15:41:33.746324: step 7949, loss 0.000113497, acc 1\n",
      "2018-04-13T15:41:34.055041: step 7950, loss 0.000548559, acc 1\n",
      "2018-04-13T15:41:34.372766: step 7951, loss 0.0138563, acc 0.984375\n",
      "2018-04-13T15:41:34.699997: step 7952, loss 8.97768e-05, acc 1\n",
      "2018-04-13T15:41:35.011217: step 7953, loss 0.000656977, acc 1\n",
      "2018-04-13T15:41:35.321436: step 7954, loss 0.125135, acc 0.984375\n",
      "2018-04-13T15:41:35.659674: step 7955, loss 2.18557e-05, acc 1\n",
      "2018-04-13T15:41:36.002416: step 7956, loss 7.80323e-05, acc 1\n",
      "2018-04-13T15:41:36.341156: step 7957, loss 0.0010715, acc 1\n",
      "2018-04-13T15:41:36.658380: step 7958, loss 0.000545624, acc 1\n",
      "2018-04-13T15:41:37.003122: step 7959, loss 0.00206216, acc 1\n",
      "2018-04-13T15:41:37.322849: step 7960, loss 0.00261034, acc 1\n",
      "2018-04-13T15:41:37.646077: step 7961, loss 0.00945684, acc 1\n",
      "2018-04-13T15:41:37.968805: step 7962, loss 0.000948161, acc 1\n",
      "2018-04-13T15:41:38.281526: step 7963, loss 0.00557887, acc 1\n",
      "2018-04-13T15:41:38.613260: step 7964, loss 0.0165253, acc 0.984375\n",
      "2018-04-13T15:41:38.966009: step 7965, loss 0.000406435, acc 1\n",
      "2018-04-13T15:41:39.286735: step 7966, loss 0.000143233, acc 1\n",
      "2018-04-13T15:41:39.596955: step 7967, loss 0.000984214, acc 1\n",
      "2018-04-13T15:41:39.917681: step 7968, loss 0.00201292, acc 1\n",
      "2018-04-13T15:41:40.230902: step 7969, loss 0.00127688, acc 1\n",
      "2018-04-13T15:41:40.557133: step 7970, loss 0.00121211, acc 1\n",
      "2018-04-13T15:41:40.885364: step 7971, loss 0.0024756, acc 1\n",
      "2018-04-13T15:41:41.207091: step 7972, loss 0.0121189, acc 1\n",
      "2018-04-13T15:41:41.569348: step 7973, loss 0.000175516, acc 1\n",
      "2018-04-13T15:41:41.918595: step 7974, loss 0.0287616, acc 0.984375\n",
      "2018-04-13T15:41:42.246325: step 7975, loss 0.000576976, acc 1\n",
      "2018-04-13T15:41:42.562048: step 7976, loss 0.00212396, acc 1\n",
      "2018-04-13T15:41:42.889279: step 7977, loss 0.000105846, acc 1\n",
      "2018-04-13T15:41:43.200499: step 7978, loss 0.00281389, acc 1\n",
      "2018-04-13T15:41:43.522727: step 7979, loss 0.000139188, acc 1\n",
      "2018-04-13T15:41:43.843452: step 7980, loss 0.00156817, acc 1\n",
      "2018-04-13T15:41:44.168183: step 7981, loss 2.22581e-06, acc 1\n",
      "2018-04-13T15:41:44.483404: step 7982, loss 1.90988e-05, acc 1\n",
      "2018-04-13T15:41:44.831151: step 7983, loss 0.0102658, acc 1\n",
      "2018-04-13T15:41:45.158397: step 7984, loss 0.0304974, acc 0.984375\n",
      "2018-04-13T15:41:45.501639: step 7985, loss 0.0465475, acc 0.984375\n",
      "2018-04-13T15:41:45.829869: step 7986, loss 0.000168067, acc 1\n",
      "2018-04-13T15:41:46.136085: step 7987, loss 0.09748, acc 0.984375\n",
      "2018-04-13T15:41:46.459815: step 7988, loss 0.0596137, acc 0.984375\n",
      "2018-04-13T15:41:46.787046: step 7989, loss 0.000224602, acc 1\n",
      "2018-04-13T15:41:47.111275: step 7990, loss 0.000271789, acc 1\n",
      "2018-04-13T15:41:47.424996: step 7991, loss 0.000762761, acc 1\n",
      "2018-04-13T15:41:47.806265: step 7992, loss 2.29529e-05, acc 1\n",
      "2018-04-13T15:41:48.138000: step 7993, loss 0.0378137, acc 0.984375\n",
      "2018-04-13T15:41:48.495253: step 7994, loss 1.11297e-05, acc 1\n",
      "2018-04-13T15:41:48.826987: step 7995, loss 0.00216212, acc 1\n",
      "2018-04-13T15:41:49.142709: step 7996, loss 0.000147732, acc 1\n",
      "2018-04-13T15:41:49.460433: step 7997, loss 0.000278638, acc 1\n",
      "2018-04-13T15:41:49.772153: step 7998, loss 8.11192e-05, acc 1\n",
      "2018-04-13T15:41:50.086376: step 7999, loss 0.000616978, acc 1\n",
      "2018-04-13T15:41:50.407603: step 8000, loss 2.01607e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:41:51.611453: step 8000, loss 2.35087, acc 0.737336\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8000\n",
      "\n",
      "2018-04-13T15:41:53.575345: step 8001, loss 0.0211482, acc 0.984375\n",
      "2018-04-13T15:41:53.927594: step 8002, loss 0.00379128, acc 1\n",
      "2018-04-13T15:41:54.261829: step 8003, loss 0.000330297, acc 1\n",
      "2018-04-13T15:41:54.599068: step 8004, loss 0.000180448, acc 1\n",
      "2018-04-13T15:41:54.937807: step 8005, loss 0.000212513, acc 1\n",
      "2018-04-13T15:41:55.281550: step 8006, loss 0.00162278, acc 1\n",
      "2018-04-13T15:41:55.604778: step 8007, loss 0.000874811, acc 1\n",
      "2018-04-13T15:41:55.935011: step 8008, loss 0.00271562, acc 1\n",
      "2018-04-13T15:41:56.264244: step 8009, loss 0.000115376, acc 1\n",
      "2018-04-13T15:41:56.624998: step 8010, loss 0.00112461, acc 1\n",
      "2018-04-13T15:41:56.964237: step 8011, loss 0.000207779, acc 1\n",
      "2018-04-13T15:41:57.285465: step 8012, loss 0.000232035, acc 1\n",
      "2018-04-13T15:41:57.594683: step 8013, loss 0.0100397, acc 1\n",
      "2018-04-13T15:41:57.925417: step 8014, loss 0.00093726, acc 1\n",
      "2018-04-13T15:41:58.240138: step 8015, loss 0.0010111, acc 1\n",
      "2018-04-13T15:41:58.570372: step 8016, loss 0.000831117, acc 1\n",
      "2018-04-13T15:41:58.888597: step 8017, loss 0.00369922, acc 1\n",
      "2018-04-13T15:41:59.217829: step 8018, loss 0.0425843, acc 0.96875\n",
      "2018-04-13T15:41:59.594095: step 8019, loss 2.83076e-05, acc 1\n",
      "2018-04-13T15:41:59.954349: step 8020, loss 0.000388899, acc 1\n",
      "2018-04-13T15:42:00.279078: step 8021, loss 0.000153686, acc 1\n",
      "2018-04-13T15:42:00.599805: step 8022, loss 8.47717e-05, acc 1\n",
      "2018-04-13T15:42:00.916528: step 8023, loss 0.0076823, acc 1\n",
      "2018-04-13T15:42:01.245260: step 8024, loss 2.23624e-05, acc 1\n",
      "2018-04-13T15:42:01.561984: step 8025, loss 0.00193773, acc 1\n",
      "2018-04-13T15:42:01.884212: step 8026, loss 0.000456993, acc 1\n",
      "2018-04-13T15:42:02.217948: step 8027, loss 0.000392655, acc 1\n",
      "2018-04-13T15:42:02.561190: step 8028, loss 0.00177641, acc 1\n",
      "2018-04-13T15:42:02.932452: step 8029, loss 0.0232924, acc 0.984375\n",
      "2018-04-13T15:42:03.250677: step 8030, loss 0.012298, acc 0.984375\n",
      "2018-04-13T15:42:03.567400: step 8031, loss 0.000426992, acc 1\n",
      "2018-04-13T15:42:03.885624: step 8032, loss 0.0244789, acc 0.984375\n",
      "2018-04-13T15:42:04.201849: step 8033, loss 0.00295228, acc 1\n",
      "2018-04-13T15:42:04.515070: step 8034, loss 0.000320536, acc 1\n",
      "2018-04-13T15:42:04.847304: step 8035, loss 5.51105e-05, acc 1\n",
      "2018-04-13T15:42:05.180539: step 8036, loss 0.000453929, acc 1\n",
      "2018-04-13T15:42:05.523782: step 8037, loss 0.00323379, acc 1\n",
      "2018-04-13T15:42:05.882035: step 8038, loss 0.000309578, acc 1\n",
      "2018-04-13T15:42:06.211267: step 8039, loss 0.0034862, acc 1\n",
      "2018-04-13T15:42:06.536998: step 8040, loss 0.000730504, acc 1\n",
      "2018-04-13T15:42:06.852720: step 8041, loss 0.00170609, acc 1\n",
      "2018-04-13T15:42:07.175448: step 8042, loss 0.000160183, acc 1\n",
      "2018-04-13T15:42:07.491170: step 8043, loss 1.65099e-05, acc 1\n",
      "2018-04-13T15:42:07.813899: step 8044, loss 0.000322192, acc 1\n",
      "2018-04-13T15:42:08.125119: step 8045, loss 8.82458e-05, acc 1\n",
      "2018-04-13T15:42:08.450348: step 8046, loss 0.00317289, acc 1\n",
      "2018-04-13T15:42:08.825113: step 8047, loss 0.000396422, acc 1\n",
      "2018-04-13T15:42:09.141336: step 8048, loss 0.0241501, acc 0.984375\n",
      "2018-04-13T15:42:09.478074: step 8049, loss 0.0150661, acc 0.984375\n",
      "2018-04-13T15:42:09.800301: step 8050, loss 0.000808049, acc 1\n",
      "2018-04-13T15:42:10.124030: step 8051, loss 0.000395529, acc 1\n",
      "2018-04-13T15:42:10.446758: step 8052, loss 0.00167982, acc 1\n",
      "2018-04-13T15:42:10.769486: step 8053, loss 2.21135e-05, acc 1\n",
      "2018-04-13T15:42:11.076702: step 8054, loss 0.000146695, acc 1\n",
      "2018-04-13T15:42:11.404435: step 8055, loss 0.0070204, acc 1\n",
      "2018-04-13T15:42:11.774195: step 8056, loss 0.0018938, acc 1\n",
      "2018-04-13T15:42:12.099425: step 8057, loss 0.0135909, acc 0.984375\n",
      "2018-04-13T15:42:12.421652: step 8058, loss 0.000261191, acc 1\n",
      "2018-04-13T15:42:12.743879: step 8059, loss 0.00230841, acc 1\n",
      "2018-04-13T15:42:13.073612: step 8060, loss 0.000241953, acc 1\n",
      "2018-04-13T15:42:13.396841: step 8061, loss 0.000337523, acc 1\n",
      "2018-04-13T15:42:13.717569: step 8062, loss 0.0225266, acc 0.984375\n",
      "2018-04-13T15:42:14.041297: step 8063, loss 0.00502292, acc 1\n",
      "2018-04-13T15:42:14.353517: step 8064, loss 0.000299428, acc 1\n",
      "2018-04-13T15:42:14.718774: step 8065, loss 0.00212783, acc 1\n",
      "2018-04-13T15:42:15.055512: step 8066, loss 4.3226e-05, acc 1\n",
      "2018-04-13T15:42:15.376739: step 8067, loss 0.0167653, acc 0.984375\n",
      "2018-04-13T15:42:15.699467: step 8068, loss 0.00222983, acc 1\n",
      "2018-04-13T15:42:16.018192: step 8069, loss 2.36629e-05, acc 1\n",
      "2018-04-13T15:42:16.331413: step 8070, loss 0.00205948, acc 1\n",
      "2018-04-13T15:42:16.651640: step 8071, loss 0.00927437, acc 1\n",
      "2018-04-13T15:42:16.991380: step 8072, loss 0.00127856, acc 1\n",
      "2018-04-13T15:42:17.316109: step 8073, loss 0.00342764, acc 1\n",
      "2018-04-13T15:42:17.653346: step 8074, loss 0.0118538, acc 0.984375\n",
      "2018-04-13T15:42:17.985581: step 8075, loss 0.000325587, acc 1\n",
      "2018-04-13T15:42:18.300303: step 8076, loss 0.000263476, acc 1\n",
      "2018-04-13T15:42:18.634039: step 8077, loss 8.12764e-05, acc 1\n",
      "2018-04-13T15:42:18.973779: step 8078, loss 0.000191911, acc 1\n",
      "2018-04-13T15:42:19.310016: step 8079, loss 0.000337407, acc 1\n",
      "2018-04-13T15:42:19.643752: step 8080, loss 0.000579257, acc 1\n",
      "2018-04-13T15:42:19.983992: step 8081, loss 7.03185e-05, acc 1\n",
      "2018-04-13T15:42:20.323232: step 8082, loss 0.039673, acc 0.96875\n",
      "2018-04-13T15:42:20.671478: step 8083, loss 0.00127653, acc 1\n",
      "2018-04-13T15:42:21.072261: step 8084, loss 0.00333415, acc 1\n",
      "2018-04-13T15:42:21.434516: step 8085, loss 0.000262004, acc 1\n",
      "2018-04-13T15:42:21.779760: step 8086, loss 0.000148423, acc 1\n",
      "2018-04-13T15:42:22.106491: step 8087, loss 0.000556909, acc 1\n",
      "2018-04-13T15:42:22.449733: step 8088, loss 7.2977e-05, acc 1\n",
      "2018-04-13T15:42:22.769459: step 8089, loss 8.66702e-05, acc 1\n",
      "2018-04-13T15:42:23.086683: step 8090, loss 0.00136096, acc 1\n",
      "2018-04-13T15:42:23.417917: step 8091, loss 0.00012468, acc 1\n",
      "2018-04-13T15:42:23.754154: step 8092, loss 0.00156147, acc 1\n",
      "2018-04-13T15:42:24.104401: step 8093, loss 0.000300013, acc 1\n",
      "2018-04-13T15:42:24.432134: step 8094, loss 0.00581887, acc 1\n",
      "2018-04-13T15:42:24.763367: step 8095, loss 5.44252e-05, acc 1\n",
      "2018-04-13T15:42:25.078089: step 8096, loss 0.000128075, acc 1\n",
      "2018-04-13T15:42:25.399817: step 8097, loss 0.000375384, acc 1\n",
      "2018-04-13T15:42:25.728049: step 8098, loss 0.00536788, acc 1\n",
      "2018-04-13T15:42:26.054278: step 8099, loss 0.000440535, acc 1\n",
      "2018-04-13T15:42:26.357994: step 8100, loss 0.000744538, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:42:27.546833: step 8100, loss 2.38314, acc 0.737336\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8100\n",
      "\n",
      "2018-04-13T15:42:29.224543: step 8101, loss 8.28715e-05, acc 1\n",
      "2018-04-13T15:42:29.546271: step 8102, loss 0.000551318, acc 1\n",
      "2018-04-13T15:42:29.898519: step 8103, loss 0.000310124, acc 1\n",
      "2018-04-13T15:42:30.216744: step 8104, loss 0.00134748, acc 1\n",
      "2018-04-13T15:42:30.538471: step 8105, loss 0.000139456, acc 1\n",
      "2018-04-13T15:42:30.861199: step 8106, loss 0.000226772, acc 1\n",
      "2018-04-13T15:42:31.169417: step 8107, loss 0.000244804, acc 1\n",
      "2018-04-13T15:42:31.494147: step 8108, loss 0.0103204, acc 1\n",
      "2018-04-13T15:42:31.824886: step 8109, loss 0.000274063, acc 1\n",
      "2018-04-13T15:42:32.140603: step 8110, loss 0.00434309, acc 1\n",
      "2018-04-13T15:42:32.465332: step 8111, loss 0.000863225, acc 1\n",
      "2018-04-13T15:42:32.798568: step 8112, loss 0.000430238, acc 1\n",
      "2018-04-13T15:42:33.140308: step 8113, loss 0.000301209, acc 1\n",
      "2018-04-13T15:42:33.462536: step 8114, loss 3.31729e-05, acc 1\n",
      "2018-04-13T15:42:33.791769: step 8115, loss 3.78323e-05, acc 1\n",
      "2018-04-13T15:42:34.108492: step 8116, loss 0.000104961, acc 1\n",
      "2018-04-13T15:42:34.425716: step 8117, loss 3.95023e-05, acc 1\n",
      "2018-04-13T15:42:34.756950: step 8118, loss 0.000975568, acc 1\n",
      "2018-04-13T15:42:35.084683: step 8119, loss 0.000362921, acc 1\n",
      "2018-04-13T15:42:35.404407: step 8120, loss 0.000124759, acc 1\n",
      "2018-04-13T15:42:35.740644: step 8121, loss 0.000329845, acc 1\n",
      "2018-04-13T15:42:36.085888: step 8122, loss 0.00272448, acc 1\n",
      "2018-04-13T15:42:36.407115: step 8123, loss 0.000124232, acc 1\n",
      "2018-04-13T15:42:36.730844: step 8124, loss 0.000363311, acc 1\n",
      "2018-04-13T15:42:37.065581: step 8125, loss 0.000608988, acc 1\n",
      "2018-04-13T15:42:37.386808: step 8126, loss 0.000227214, acc 1\n",
      "2018-04-13T15:42:37.741057: step 8127, loss 0.00418703, acc 1\n",
      "2018-04-13T15:42:38.061784: step 8128, loss 6.46285e-05, acc 1\n",
      "2018-04-13T15:42:38.370002: step 8129, loss 0.00012588, acc 1\n",
      "2018-04-13T15:42:38.726755: step 8130, loss 0.000707426, acc 1\n",
      "2018-04-13T15:42:39.102019: step 8131, loss 0.000126238, acc 1\n",
      "2018-04-13T15:42:39.433752: step 8132, loss 4.97125e-06, acc 1\n",
      "2018-04-13T15:42:39.749475: step 8133, loss 0.00158154, acc 1\n",
      "2018-04-13T15:42:40.092217: step 8134, loss 0.00815908, acc 1\n",
      "2018-04-13T15:42:40.432458: step 8135, loss 0.000284168, acc 1\n",
      "2018-04-13T15:42:40.788710: step 8136, loss 0.0112441, acc 1\n",
      "2018-04-13T15:42:41.164975: step 8137, loss 0.00253314, acc 1\n",
      "2018-04-13T15:42:41.562755: step 8138, loss 0.00496388, acc 1\n",
      "2018-04-13T15:42:41.976548: step 8139, loss 0.000257014, acc 1\n",
      "2018-04-13T15:42:42.312286: step 8140, loss 7.93317e-05, acc 1\n",
      "2018-04-13T15:42:42.675042: step 8141, loss 0.0103647, acc 1\n",
      "2018-04-13T15:42:43.049806: step 8142, loss 3.79579e-05, acc 1\n",
      "2018-04-13T15:42:43.424070: step 8143, loss 0.00011775, acc 1\n",
      "2018-04-13T15:42:43.758306: step 8144, loss 5.63393e-05, acc 1\n",
      "2018-04-13T15:42:44.128068: step 8145, loss 0.000744162, acc 1\n",
      "2018-04-13T15:42:44.521846: step 8146, loss 3.86065e-05, acc 1\n",
      "2018-04-13T15:42:44.932135: step 8147, loss 5.70504e-06, acc 1\n",
      "2018-04-13T15:42:45.255863: step 8148, loss 0.000144728, acc 1\n",
      "2018-04-13T15:42:45.629127: step 8149, loss 0.00029838, acc 1\n",
      "2018-04-13T15:42:45.986379: step 8150, loss 0.0159606, acc 0.984375\n",
      "2018-04-13T15:42:46.337127: step 8151, loss 3.25114e-05, acc 1\n",
      "2018-04-13T15:42:46.666360: step 8152, loss 0.00385508, acc 1\n",
      "2018-04-13T15:42:47.030116: step 8153, loss 0.0194999, acc 0.984375\n",
      "2018-04-13T15:42:47.353845: step 8154, loss 0.0279329, acc 0.984375\n",
      "2018-04-13T15:42:47.667067: step 8155, loss 0.0286871, acc 0.984375\n",
      "2018-04-13T15:42:48.018815: step 8156, loss 0.000209881, acc 1\n",
      "2018-04-13T15:42:48.348047: step 8157, loss 0.000194575, acc 1\n",
      "2018-04-13T15:42:48.671276: step 8158, loss 0.000990893, acc 1\n",
      "2018-04-13T15:42:49.015018: step 8159, loss 0.00069655, acc 1\n",
      "2018-04-13T15:42:49.364766: step 8160, loss 0.0030986, acc 1\n",
      "2018-04-13T15:42:49.723518: step 8161, loss 2.72564e-05, acc 1\n",
      "2018-04-13T15:42:50.061757: step 8162, loss 0.0005178, acc 1\n",
      "2018-04-13T15:42:50.403499: step 8163, loss 0.00036582, acc 1\n",
      "2018-04-13T15:42:50.809286: step 8164, loss 0.00067603, acc 1\n",
      "2018-04-13T15:42:51.179546: step 8165, loss 0.00333703, acc 1\n",
      "2018-04-13T15:42:51.507287: step 8166, loss 3.26093e-05, acc 1\n",
      "2018-04-13T15:42:51.841023: step 8167, loss 0.0441024, acc 0.984375\n",
      "2018-04-13T15:42:52.181764: step 8168, loss 0.000398279, acc 1\n",
      "2018-04-13T15:42:52.522505: step 8169, loss 4.67967e-05, acc 1\n",
      "2018-04-13T15:42:52.856741: step 8170, loss 0.00261969, acc 1\n",
      "2018-04-13T15:42:53.172968: step 8171, loss 0.00033498, acc 1\n",
      "2018-04-13T15:42:53.493694: step 8172, loss 9.12309e-05, acc 1\n",
      "2018-04-13T15:42:53.813420: step 8173, loss 2.30217e-06, acc 1\n",
      "2018-04-13T15:42:54.180179: step 8174, loss 0.00019642, acc 1\n",
      "2018-04-13T15:42:54.515416: step 8175, loss 0.00026959, acc 1\n",
      "2018-04-13T15:42:54.863661: step 8176, loss 0.000118365, acc 1\n",
      "2018-04-13T15:42:55.206903: step 8177, loss 1.78184e-05, acc 1\n",
      "2018-04-13T15:42:55.527130: step 8178, loss 0.00752645, acc 1\n",
      "2018-04-13T15:42:55.896892: step 8179, loss 0.000592186, acc 1\n",
      "2018-04-13T15:42:56.226138: step 8180, loss 0.0241615, acc 0.984375\n",
      "2018-04-13T15:42:56.582389: step 8181, loss 0.0548847, acc 0.984375\n",
      "2018-04-13T15:42:56.959655: step 8182, loss 0.00380682, acc 1\n",
      "2018-04-13T15:42:57.339423: step 8183, loss 5.73438e-05, acc 1\n",
      "2018-04-13T15:42:57.708685: step 8184, loss 0.000358848, acc 1\n",
      "2018-04-13T15:42:58.061433: step 8185, loss 0.000149491, acc 1\n",
      "2018-04-13T15:42:58.384161: step 8186, loss 0.000680171, acc 1\n",
      "2018-04-13T15:42:58.715395: step 8187, loss 0.00114273, acc 1\n",
      "2018-04-13T15:42:59.242767: step 8188, loss 0.000126988, acc 1\n",
      "2018-04-13T15:42:59.694587: step 8189, loss 0.00169439, acc 1\n",
      "2018-04-13T15:43:00.047337: step 8190, loss 0.00395921, acc 1\n",
      "2018-04-13T15:43:00.565201: step 8191, loss 7.12299e-05, acc 1\n",
      "2018-04-13T15:43:01.093074: step 8192, loss 0.00093523, acc 1\n",
      "2018-04-13T15:43:01.668980: step 8193, loss 0.00125422, acc 1\n",
      "2018-04-13T15:43:02.116297: step 8194, loss 0.000290712, acc 1\n",
      "2018-04-13T15:43:02.639166: step 8195, loss 0.000770308, acc 1\n",
      "2018-04-13T15:43:03.101492: step 8196, loss 0.000404401, acc 1\n",
      "2018-04-13T15:43:03.541803: step 8197, loss 0.00415916, acc 1\n",
      "2018-04-13T15:43:04.013636: step 8198, loss 0.000222478, acc 1\n",
      "2018-04-13T15:43:04.454037: step 8199, loss 0.00131045, acc 1\n",
      "2018-04-13T15:43:04.813290: step 8200, loss 0.0299569, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:43:06.343871: step 8200, loss 2.4846, acc 0.73546\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8200\n",
      "\n",
      "2018-04-13T15:43:08.555850: step 8201, loss 1.26762e-05, acc 1\n",
      "2018-04-13T15:43:08.879078: step 8202, loss 0.000494803, acc 1\n",
      "2018-04-13T15:43:09.232828: step 8203, loss 0.000271556, acc 1\n",
      "2018-04-13T15:43:09.567064: step 8204, loss 0.00518889, acc 1\n",
      "2018-04-13T15:43:09.924817: step 8205, loss 0.00100887, acc 1\n",
      "2018-04-13T15:43:10.256052: step 8206, loss 0.0103021, acc 1\n",
      "2018-04-13T15:43:10.613304: step 8207, loss 0.0121142, acc 0.984375\n",
      "2018-04-13T15:43:11.016088: step 8208, loss 0.00116175, acc 1\n",
      "2018-04-13T15:43:11.366335: step 8209, loss 0.000333979, acc 1\n",
      "2018-04-13T15:43:11.832167: step 8210, loss 6.65822e-05, acc 1\n",
      "2018-04-13T15:43:12.287489: step 8211, loss 0.00340599, acc 1\n",
      "2018-04-13T15:43:12.644134: step 8212, loss 0.000346697, acc 1\n",
      "2018-04-13T15:43:13.032909: step 8213, loss 0.00170574, acc 1\n",
      "2018-04-13T15:43:13.436695: step 8214, loss 0.0010733, acc 1\n",
      "2018-04-13T15:43:13.796948: step 8215, loss 0.00453987, acc 1\n",
      "2018-04-13T15:43:14.124680: step 8216, loss 0.00499422, acc 1\n",
      "2018-04-13T15:43:14.449909: step 8217, loss 4.04608e-05, acc 1\n",
      "2018-04-13T15:43:14.797155: step 8218, loss 0.00776169, acc 1\n",
      "2018-04-13T15:43:15.122385: step 8219, loss 0.00212921, acc 1\n",
      "2018-04-13T15:43:15.490144: step 8220, loss 0.000569075, acc 1\n",
      "2018-04-13T15:43:16.010511: step 8221, loss 0.000422516, acc 1\n",
      "2018-04-13T15:43:16.436813: step 8222, loss 0.0017361, acc 1\n",
      "2018-04-13T15:43:16.899640: step 8223, loss 0.000224565, acc 1\n",
      "2018-04-13T15:43:17.413002: step 8224, loss 0.0182878, acc 0.984375\n",
      "2018-04-13T15:43:17.962897: step 8225, loss 0.000190495, acc 1\n",
      "2018-04-13T15:43:18.531122: step 8226, loss 0.000394696, acc 1\n",
      "2018-04-13T15:43:19.075006: step 8227, loss 0.00133424, acc 1\n",
      "2018-04-13T15:43:19.497804: step 8228, loss 6.5653e-05, acc 1\n",
      "2018-04-13T15:43:19.994155: step 8229, loss 9.82233e-05, acc 1\n",
      "2018-04-13T15:43:20.450477: step 8230, loss 0.000335623, acc 1\n",
      "2018-04-13T15:43:20.871274: step 8231, loss 0.000939444, acc 1\n",
      "2018-04-13T15:43:21.314586: step 8232, loss 0.00340466, acc 1\n",
      "2018-04-13T15:43:21.711867: step 8233, loss 0.0148052, acc 1\n",
      "2018-04-13T15:43:22.165190: step 8234, loss 0.000717087, acc 1\n",
      "2018-04-13T15:43:22.602009: step 8235, loss 0.00136236, acc 1\n",
      "2018-04-13T15:43:23.048325: step 8236, loss 0.00945271, acc 1\n",
      "2018-04-13T15:43:23.421588: step 8237, loss 5.86382e-05, acc 1\n",
      "2018-04-13T15:43:23.777840: step 8238, loss 0.000725932, acc 1\n",
      "2018-04-13T15:43:24.177623: step 8239, loss 0.0304995, acc 0.984375\n",
      "2018-04-13T15:43:24.534373: step 8240, loss 4.0765e-05, acc 1\n",
      "2018-04-13T15:43:24.859104: step 8241, loss 0.00835341, acc 1\n",
      "2018-04-13T15:43:25.216355: step 8242, loss 0.000348508, acc 1\n",
      "2018-04-13T15:43:25.550092: step 8243, loss 5.91739e-06, acc 1\n",
      "2018-04-13T15:43:25.871318: step 8244, loss 0.000178274, acc 1\n",
      "2018-04-13T15:43:26.206054: step 8245, loss 0.0633607, acc 0.984375\n",
      "2018-04-13T15:43:26.534786: step 8246, loss 0.000212649, acc 1\n",
      "2018-04-13T15:43:26.862018: step 8247, loss 0.000877115, acc 1\n",
      "2018-04-13T15:43:27.179241: step 8248, loss 0.000204766, acc 1\n",
      "2018-04-13T15:43:27.500968: step 8249, loss 0.000127731, acc 1\n",
      "2018-04-13T15:43:27.821695: step 8250, loss 0.00107854, acc 1\n",
      "2018-04-13T15:43:28.160934: step 8251, loss 2.96029e-05, acc 1\n",
      "2018-04-13T15:43:28.477658: step 8252, loss 0.0015864, acc 1\n",
      "2018-04-13T15:43:28.805389: step 8253, loss 0.000694631, acc 1\n",
      "2018-04-13T15:43:29.199168: step 8254, loss 0.279822, acc 0.96875\n",
      "2018-04-13T15:43:29.559424: step 8255, loss 0.000100835, acc 1\n",
      "2018-04-13T15:43:29.916675: step 8256, loss 0.000246867, acc 1\n",
      "2018-04-13T15:43:30.290439: step 8257, loss 0.00322348, acc 1\n",
      "2018-04-13T15:43:30.654195: step 8258, loss 0.00188459, acc 1\n",
      "2018-04-13T15:43:31.036465: step 8259, loss 0.0185487, acc 0.984375\n",
      "2018-04-13T15:43:31.408228: step 8260, loss 0.000496954, acc 1\n",
      "2018-04-13T15:43:31.752471: step 8261, loss 7.73092e-05, acc 1\n",
      "2018-04-13T15:43:32.114226: step 8262, loss 0.000306361, acc 1\n",
      "2018-04-13T15:43:32.479984: step 8263, loss 0.000764277, acc 1\n",
      "2018-04-13T15:43:32.834234: step 8264, loss 8.08072e-05, acc 1\n",
      "2018-04-13T15:43:33.226512: step 8265, loss 0.000193402, acc 1\n",
      "2018-04-13T15:43:33.580261: step 8266, loss 0.00077395, acc 1\n",
      "2018-04-13T15:43:33.948521: step 8267, loss 0.000139097, acc 1\n",
      "2018-04-13T15:43:34.320284: step 8268, loss 0.000224339, acc 1\n",
      "2018-04-13T15:43:34.743582: step 8269, loss 0.00033264, acc 1\n",
      "2018-04-13T15:43:35.093330: step 8270, loss 0.000313648, acc 1\n",
      "2018-04-13T15:43:35.419560: step 8271, loss 6.11093e-05, acc 1\n",
      "2018-04-13T15:43:35.754796: step 8272, loss 0.0116618, acc 1\n",
      "2018-04-13T15:43:36.126063: step 8273, loss 0.00239388, acc 1\n",
      "2018-04-13T15:43:36.476806: step 8274, loss 0.000313301, acc 1\n",
      "2018-04-13T15:43:36.793531: step 8275, loss 0.000193004, acc 1\n",
      "2018-04-13T15:43:37.159288: step 8276, loss 0.00194295, acc 1\n",
      "2018-04-13T15:43:37.560572: step 8277, loss 8.79277e-05, acc 1\n",
      "2018-04-13T15:43:37.870291: step 8278, loss 0.000278915, acc 1\n",
      "2018-04-13T15:43:38.213533: step 8279, loss 0.00105636, acc 1\n",
      "2018-04-13T15:43:38.536261: step 8280, loss 0.00016429, acc 1\n",
      "2018-04-13T15:43:38.868496: step 8281, loss 0.000538524, acc 1\n",
      "2018-04-13T15:43:39.206233: step 8282, loss 0.000145869, acc 1\n",
      "2018-04-13T15:43:39.519958: step 8283, loss 0.00115187, acc 1\n",
      "2018-04-13T15:43:39.861696: step 8284, loss 0.0349321, acc 0.96875\n",
      "2018-04-13T15:43:40.208943: step 8285, loss 3.60046e-05, acc 1\n",
      "2018-04-13T15:43:40.582205: step 8286, loss 0.0527632, acc 0.984375\n",
      "2018-04-13T15:43:40.907435: step 8287, loss 0.00359467, acc 1\n",
      "2018-04-13T15:43:41.236667: step 8288, loss 0.00324738, acc 1\n",
      "2018-04-13T15:43:41.555393: step 8289, loss 0.00155382, acc 1\n",
      "2018-04-13T15:43:41.882624: step 8290, loss 0.000324192, acc 1\n",
      "2018-04-13T15:43:42.215358: step 8291, loss 0.000344423, acc 1\n",
      "2018-04-13T15:43:42.546592: step 8292, loss 0.00632804, acc 1\n",
      "2018-04-13T15:43:42.873824: step 8293, loss 0.0683244, acc 0.984375\n",
      "2018-04-13T15:43:43.232076: step 8294, loss 0.0398436, acc 0.984375\n",
      "2018-04-13T15:43:43.618350: step 8295, loss 0.0176504, acc 0.984375\n",
      "2018-04-13T15:43:43.951084: step 8296, loss 8.93565e-05, acc 1\n",
      "2018-04-13T15:43:44.294327: step 8297, loss 0.0100406, acc 1\n",
      "2018-04-13T15:43:44.621558: step 8298, loss 0.000196765, acc 1\n",
      "2018-04-13T15:43:44.947288: step 8299, loss 6.54727e-05, acc 1\n",
      "2018-04-13T15:43:45.279522: step 8300, loss 0.0277877, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:43:46.485921: step 8300, loss 2.49148, acc 0.734522\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8300\n",
      "\n",
      "2018-04-13T15:43:48.178569: step 8301, loss 0.0565161, acc 0.984375\n",
      "2018-04-13T15:43:48.488788: step 8302, loss 0.00307178, acc 1\n",
      "2018-04-13T15:43:48.820530: step 8303, loss 0.00307078, acc 1\n",
      "2018-04-13T15:43:49.145759: step 8304, loss 0.00395256, acc 1\n",
      "2018-04-13T15:43:49.499015: step 8305, loss 0.00543921, acc 1\n",
      "2018-04-13T15:43:49.823244: step 8306, loss 0.0125132, acc 0.984375\n",
      "2018-04-13T15:43:50.143970: step 8307, loss 0.00107357, acc 1\n",
      "2018-04-13T15:43:50.464197: step 8308, loss 5.84997e-05, acc 1\n",
      "2018-04-13T15:43:50.796934: step 8309, loss 4.96546e-05, acc 1\n",
      "2018-04-13T15:43:51.138673: step 8310, loss 0.00132219, acc 1\n",
      "2018-04-13T15:43:51.454396: step 8311, loss 0.000187143, acc 1\n",
      "2018-04-13T15:43:51.775623: step 8312, loss 0.00185906, acc 1\n",
      "2018-04-13T15:43:52.103855: step 8313, loss 0.00107701, acc 1\n",
      "2018-04-13T15:43:52.455102: step 8314, loss 1.71705e-05, acc 1\n",
      "2018-04-13T15:43:52.778831: step 8315, loss 0.000734274, acc 1\n",
      "2018-04-13T15:43:53.108063: step 8316, loss 0.00252193, acc 1\n",
      "2018-04-13T15:43:53.433293: step 8317, loss 0.000323394, acc 1\n",
      "2018-04-13T15:43:53.763526: step 8318, loss 0.000188905, acc 1\n",
      "2018-04-13T15:43:54.099765: step 8319, loss 6.17449e-05, acc 1\n",
      "2018-04-13T15:43:54.423492: step 8320, loss 0.00648176, acc 1\n",
      "2018-04-13T15:43:54.757229: step 8321, loss 0.00021737, acc 1\n",
      "2018-04-13T15:43:55.076954: step 8322, loss 0.000145509, acc 1\n",
      "2018-04-13T15:43:55.411691: step 8323, loss 0.0331533, acc 0.984375\n",
      "2018-04-13T15:43:55.762437: step 8324, loss 0.0231561, acc 0.984375\n",
      "2018-04-13T15:43:56.096675: step 8325, loss 0.000436434, acc 1\n",
      "2018-04-13T15:43:56.418401: step 8326, loss 0.0031052, acc 1\n",
      "2018-04-13T15:43:56.742631: step 8327, loss 1.29525e-05, acc 1\n",
      "2018-04-13T15:43:57.076866: step 8328, loss 2.99544e-05, acc 1\n",
      "2018-04-13T15:43:57.412603: step 8329, loss 0.000910694, acc 1\n",
      "2018-04-13T15:43:57.738834: step 8330, loss 0.000922864, acc 1\n",
      "2018-04-13T15:43:58.074070: step 8331, loss 0.000890061, acc 1\n",
      "2018-04-13T15:43:58.418814: step 8332, loss 0.00016772, acc 1\n",
      "2018-04-13T15:43:58.759554: step 8333, loss 0.000164836, acc 1\n",
      "2018-04-13T15:43:59.081782: step 8334, loss 1.60263e-05, acc 1\n",
      "2018-04-13T15:43:59.398505: step 8335, loss 0.00242396, acc 1\n",
      "2018-04-13T15:43:59.721233: step 8336, loss 3.11066e-05, acc 1\n",
      "2018-04-13T15:44:00.042461: step 8337, loss 0.00013777, acc 1\n",
      "2018-04-13T15:44:00.361686: step 8338, loss 0.000265104, acc 1\n",
      "2018-04-13T15:44:00.677909: step 8339, loss 2.6744e-05, acc 1\n",
      "2018-04-13T15:44:01.012145: step 8340, loss 0.00282756, acc 1\n",
      "2018-04-13T15:44:01.349384: step 8341, loss 5.35983e-05, acc 1\n",
      "2018-04-13T15:44:01.689123: step 8342, loss 0.00015432, acc 1\n",
      "2018-04-13T15:44:02.010849: step 8343, loss 0.000480342, acc 1\n",
      "2018-04-13T15:44:02.335082: step 8344, loss 0.000310514, acc 1\n",
      "2018-04-13T15:44:02.672818: step 8345, loss 0.00344532, acc 1\n",
      "2018-04-13T15:44:03.002050: step 8346, loss 0.000494554, acc 1\n",
      "2018-04-13T15:44:03.333284: step 8347, loss 0.0407088, acc 0.984375\n",
      "2018-04-13T15:44:03.649007: step 8348, loss 0.00175341, acc 1\n",
      "2018-04-13T15:44:03.986746: step 8349, loss 0.000116593, acc 1\n",
      "2018-04-13T15:44:04.322983: step 8350, loss 4.07645e-05, acc 1\n",
      "2018-04-13T15:44:04.660721: step 8351, loss 0.000148069, acc 1\n",
      "2018-04-13T15:44:04.982448: step 8352, loss 0.000149693, acc 1\n",
      "2018-04-13T15:44:05.313682: step 8353, loss 0.000378054, acc 1\n",
      "2018-04-13T15:44:05.632407: step 8354, loss 0.000500629, acc 1\n",
      "2018-04-13T15:44:05.940625: step 8355, loss 0.000168887, acc 1\n",
      "2018-04-13T15:44:06.267356: step 8356, loss 0.00240994, acc 1\n",
      "2018-04-13T15:44:06.583078: step 8357, loss 0.000306776, acc 1\n",
      "2018-04-13T15:44:06.897802: step 8358, loss 0.000231119, acc 1\n",
      "2018-04-13T15:44:07.236540: step 8359, loss 0.00448395, acc 1\n",
      "2018-04-13T15:44:07.585786: step 8360, loss 0.0205771, acc 0.984375\n",
      "2018-04-13T15:44:07.912017: step 8361, loss 9.50182e-06, acc 1\n",
      "2018-04-13T15:44:08.228741: step 8362, loss 0.0358856, acc 0.984375\n",
      "2018-04-13T15:44:08.547966: step 8363, loss 0.000381441, acc 1\n",
      "2018-04-13T15:44:08.854683: step 8364, loss 0.000112251, acc 1\n",
      "2018-04-13T15:44:09.169905: step 8365, loss 0.00148027, acc 1\n",
      "2018-04-13T15:44:09.497637: step 8366, loss 0.00750711, acc 1\n",
      "2018-04-13T15:44:09.819864: step 8367, loss 0.00376945, acc 1\n",
      "2018-04-13T15:44:10.166609: step 8368, loss 0.08837, acc 0.984375\n",
      "2018-04-13T15:44:10.499848: step 8369, loss 0.000100386, acc 1\n",
      "2018-04-13T15:44:10.840084: step 8370, loss 0.00592272, acc 1\n",
      "2018-04-13T15:44:11.170828: step 8371, loss 0.000121792, acc 1\n",
      "2018-04-13T15:44:11.483048: step 8372, loss 0.000647281, acc 1\n",
      "2018-04-13T15:44:11.802774: step 8373, loss 0.00104645, acc 1\n",
      "2018-04-13T15:44:12.146016: step 8374, loss 0.000140126, acc 1\n",
      "2018-04-13T15:44:12.449730: step 8375, loss 0.0010253, acc 1\n",
      "2018-04-13T15:44:12.775961: step 8376, loss 9.01386e-05, acc 1\n",
      "2018-04-13T15:44:13.102692: step 8377, loss 0.000338939, acc 1\n",
      "2018-04-13T15:44:13.439930: step 8378, loss 3.11167e-05, acc 1\n",
      "2018-04-13T15:44:13.785673: step 8379, loss 0.000438189, acc 1\n",
      "2018-04-13T15:44:14.124413: step 8380, loss 0.000260265, acc 1\n",
      "2018-04-13T15:44:14.449643: step 8381, loss 0.129881, acc 0.984375\n",
      "2018-04-13T15:44:14.768868: step 8382, loss 0.000251376, acc 1\n",
      "2018-04-13T15:44:15.098601: step 8383, loss 0.0135523, acc 1\n",
      "2018-04-13T15:44:15.424331: step 8384, loss 0.000197152, acc 1\n",
      "2018-04-13T15:44:15.751563: step 8385, loss 0.00157265, acc 1\n",
      "2018-04-13T15:44:16.073790: step 8386, loss 0.0036552, acc 1\n",
      "2018-04-13T15:44:16.406024: step 8387, loss 0.000643847, acc 1\n",
      "2018-04-13T15:44:16.755771: step 8388, loss 0.007848, acc 1\n",
      "2018-04-13T15:44:17.105518: step 8389, loss 0.00232197, acc 1\n",
      "2018-04-13T15:44:17.443758: step 8390, loss 0.00072498, acc 1\n",
      "2018-04-13T15:44:17.770988: step 8391, loss 0.000558616, acc 1\n",
      "2018-04-13T15:44:18.095217: step 8392, loss 0.000537813, acc 1\n",
      "2018-04-13T15:44:18.422948: step 8393, loss 0.000623231, acc 1\n",
      "2018-04-13T15:44:18.733168: step 8394, loss 0.00866211, acc 1\n",
      "2018-04-13T15:44:19.067403: step 8395, loss 0.0149563, acc 0.984375\n",
      "2018-04-13T15:44:19.419152: step 8396, loss 0.00323267, acc 1\n",
      "2018-04-13T15:44:19.757891: step 8397, loss 0.000471395, acc 1\n",
      "2018-04-13T15:44:20.095630: step 8398, loss 0.000840615, acc 1\n",
      "2018-04-13T15:44:20.458386: step 8399, loss 0.000182511, acc 1\n",
      "2018-04-13T15:44:20.778111: step 8400, loss 0.000270786, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:44:21.934928: step 8400, loss 2.49589, acc 0.738274\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8400\n",
      "\n",
      "2018-04-13T15:44:23.742705: step 8401, loss 1.84298e-05, acc 1\n",
      "2018-04-13T15:44:24.065433: step 8402, loss 0.00109158, acc 1\n",
      "2018-04-13T15:44:24.379655: step 8403, loss 0.00126481, acc 1\n",
      "2018-04-13T15:44:24.702382: step 8404, loss 0.00544211, acc 1\n",
      "2018-04-13T15:44:25.027612: step 8405, loss 0.000145178, acc 1\n",
      "2018-04-13T15:44:25.362849: step 8406, loss 0.0179948, acc 0.984375\n",
      "2018-04-13T15:44:25.724604: step 8407, loss 1.0915e-06, acc 1\n",
      "2018-04-13T15:44:26.038326: step 8408, loss 0.000362079, acc 1\n",
      "2018-04-13T15:44:26.361553: step 8409, loss 1.32188e-05, acc 1\n",
      "2018-04-13T15:44:26.688785: step 8410, loss 0.000818635, acc 1\n",
      "2018-04-13T15:44:27.010013: step 8411, loss 0.000334746, acc 1\n",
      "2018-04-13T15:44:27.337243: step 8412, loss 6.02081e-05, acc 1\n",
      "2018-04-13T15:44:27.656468: step 8413, loss 6.2766e-05, acc 1\n",
      "2018-04-13T15:44:27.984700: step 8414, loss 2.15607e-05, acc 1\n",
      "2018-04-13T15:44:28.303425: step 8415, loss 0.000217312, acc 1\n",
      "2018-04-13T15:44:28.685195: step 8416, loss 0.000172259, acc 1\n",
      "2018-04-13T15:44:29.012426: step 8417, loss 0.00035375, acc 1\n",
      "2018-04-13T15:44:29.352666: step 8418, loss 0.000686876, acc 1\n",
      "2018-04-13T15:44:29.687402: step 8419, loss 0.000514604, acc 1\n",
      "2018-04-13T15:44:30.016134: step 8420, loss 0.000962947, acc 1\n",
      "2018-04-13T15:44:30.373893: step 8421, loss 0.00107696, acc 1\n",
      "2018-04-13T15:44:30.706127: step 8422, loss 3.77677e-05, acc 1\n",
      "2018-04-13T15:44:31.031873: step 8423, loss 0.0131756, acc 1\n",
      "2018-04-13T15:44:31.359604: step 8424, loss 0.00156717, acc 1\n",
      "2018-04-13T15:44:31.723862: step 8425, loss 0.00241629, acc 1\n",
      "2018-04-13T15:44:32.063601: step 8426, loss 6.7233e-06, acc 1\n",
      "2018-04-13T15:44:32.379324: step 8427, loss 7.94476e-05, acc 1\n",
      "2018-04-13T15:44:32.712059: step 8428, loss 0.000108909, acc 1\n",
      "2018-04-13T15:44:33.035788: step 8429, loss 0.00128014, acc 1\n",
      "2018-04-13T15:44:33.373526: step 8430, loss 4.41706e-05, acc 1\n",
      "2018-04-13T15:44:33.703767: step 8431, loss 0.00157084, acc 1\n",
      "2018-04-13T15:44:34.038996: step 8432, loss 0.00685697, acc 1\n",
      "2018-04-13T15:44:34.363725: step 8433, loss 0.00029358, acc 1\n",
      "2018-04-13T15:44:34.713973: step 8434, loss 0.00140964, acc 1\n",
      "2018-04-13T15:44:35.040203: step 8435, loss 1.61404e-05, acc 1\n",
      "2018-04-13T15:44:35.386448: step 8436, loss 0.000109082, acc 1\n",
      "2018-04-13T15:44:35.706673: step 8437, loss 0.0070789, acc 1\n",
      "2018-04-13T15:44:36.034909: step 8438, loss 0.000705411, acc 1\n",
      "2018-04-13T15:44:36.356132: step 8439, loss 0.000851837, acc 1\n",
      "2018-04-13T15:44:36.677359: step 8440, loss 0.000179265, acc 1\n",
      "2018-04-13T15:44:37.011595: step 8441, loss 0.00133568, acc 1\n",
      "2018-04-13T15:44:37.341328: step 8442, loss 9.00328e-05, acc 1\n",
      "2018-04-13T15:44:37.705585: step 8443, loss 0.000279036, acc 1\n",
      "2018-04-13T15:44:38.024311: step 8444, loss 0.000130007, acc 1\n",
      "2018-04-13T15:44:38.348039: step 8445, loss 0.000246216, acc 1\n",
      "2018-04-13T15:44:38.689780: step 8446, loss 0.00156948, acc 1\n",
      "2018-04-13T15:44:39.006003: step 8447, loss 0.000216087, acc 1\n",
      "2018-04-13T15:44:39.334236: step 8448, loss 0.00315629, acc 1\n",
      "2018-04-13T15:44:39.656463: step 8449, loss 0.000172517, acc 1\n",
      "2018-04-13T15:44:39.989212: step 8450, loss 5.98939e-05, acc 1\n",
      "2018-04-13T15:44:40.324935: step 8451, loss 0.000257379, acc 1\n",
      "2018-04-13T15:44:40.682687: step 8452, loss 0.00335242, acc 1\n",
      "2018-04-13T15:44:41.003914: step 8453, loss 5.41861e-05, acc 1\n",
      "2018-04-13T15:44:41.324140: step 8454, loss 0.000529058, acc 1\n",
      "2018-04-13T15:44:41.646869: step 8455, loss 0.00177817, acc 1\n",
      "2018-04-13T15:44:41.992112: step 8456, loss 4.80165e-05, acc 1\n",
      "2018-04-13T15:44:42.314840: step 8457, loss 9.07734e-05, acc 1\n",
      "2018-04-13T15:44:42.633565: step 8458, loss 0.000152726, acc 1\n",
      "2018-04-13T15:44:42.968802: step 8459, loss 0.0323175, acc 0.984375\n",
      "2018-04-13T15:44:43.312544: step 8460, loss 0.000638707, acc 1\n",
      "2018-04-13T15:44:43.662291: step 8461, loss 0.00138197, acc 1\n",
      "2018-04-13T15:44:44.001531: step 8462, loss 0.00215031, acc 1\n",
      "2018-04-13T15:44:44.335766: step 8463, loss 0.000155736, acc 1\n",
      "2018-04-13T15:44:44.651990: step 8464, loss 8.80373e-05, acc 1\n",
      "2018-04-13T15:44:44.974719: step 8465, loss 0.000794013, acc 1\n",
      "2018-04-13T15:44:45.313456: step 8466, loss 0.0034682, acc 1\n",
      "2018-04-13T15:44:45.627178: step 8467, loss 0.000442677, acc 1\n",
      "2018-04-13T15:44:45.948406: step 8468, loss 0.000499421, acc 1\n",
      "2018-04-13T15:44:46.284643: step 8469, loss 0.00426205, acc 1\n",
      "2018-04-13T15:44:46.625383: step 8470, loss 0.000262195, acc 1\n",
      "2018-04-13T15:44:46.963122: step 8471, loss 0.0583506, acc 0.984375\n",
      "2018-04-13T15:44:47.300360: step 8472, loss 2.21556e-05, acc 1\n",
      "2018-04-13T15:44:47.626590: step 8473, loss 0.00147244, acc 1\n",
      "2018-04-13T15:44:47.949819: step 8474, loss 3.83277e-05, acc 1\n",
      "2018-04-13T15:44:48.279051: step 8475, loss 0.0022496, acc 1\n",
      "2018-04-13T15:44:48.617791: step 8476, loss 0.000109495, acc 1\n",
      "2018-04-13T15:44:48.938523: step 8477, loss 0.00216531, acc 1\n",
      "2018-04-13T15:44:49.264747: step 8478, loss 0.00138891, acc 1\n",
      "2018-04-13T15:44:49.591478: step 8479, loss 0.000648636, acc 1\n",
      "2018-04-13T15:44:49.923712: step 8480, loss 0.000423165, acc 1\n",
      "2018-04-13T15:44:50.251445: step 8481, loss 0.000119699, acc 1\n",
      "2018-04-13T15:44:50.569168: step 8482, loss 0.000252063, acc 1\n",
      "2018-04-13T15:44:50.946935: step 8483, loss 2.20469e-05, acc 1\n",
      "2018-04-13T15:44:51.265660: step 8484, loss 1.97619e-05, acc 1\n",
      "2018-04-13T15:44:51.603899: step 8485, loss 0.0260731, acc 0.984375\n",
      "2018-04-13T15:44:51.955147: step 8486, loss 0.00131488, acc 1\n",
      "2018-04-13T15:44:52.295966: step 8487, loss 0.000688617, acc 1\n",
      "2018-04-13T15:44:52.635205: step 8488, loss 0.000111421, acc 1\n",
      "2018-04-13T15:44:52.963937: step 8489, loss 0.000409635, acc 1\n",
      "2018-04-13T15:44:53.293169: step 8490, loss 0.0408193, acc 0.984375\n",
      "2018-04-13T15:44:53.620901: step 8491, loss 0.000372242, acc 1\n",
      "2018-04-13T15:44:53.968647: step 8492, loss 0.00173788, acc 1\n",
      "2018-04-13T15:44:54.325399: step 8493, loss 0.000113864, acc 1\n",
      "2018-04-13T15:44:54.667641: step 8494, loss 0.00536082, acc 1\n",
      "2018-04-13T15:44:55.012386: step 8495, loss 0.00143243, acc 1\n",
      "2018-04-13T15:44:55.364132: step 8496, loss 0.000882982, acc 1\n",
      "2018-04-13T15:44:55.703872: step 8497, loss 0.0226002, acc 0.984375\n",
      "2018-04-13T15:44:56.028601: step 8498, loss 4.15464e-05, acc 1\n",
      "2018-04-13T15:44:56.354331: step 8499, loss 0.00187827, acc 1\n",
      "2018-04-13T15:44:56.697573: step 8500, loss 4.60914e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:44:57.850389: step 8500, loss 2.65024, acc 0.722326\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8500\n",
      "\n",
      "2018-04-13T15:44:59.474034: step 8501, loss 0.00545406, acc 1\n",
      "2018-04-13T15:44:59.785754: step 8502, loss 0.00056825, acc 1\n",
      "2018-04-13T15:45:00.158016: step 8503, loss 0.0255967, acc 0.984375\n",
      "2018-04-13T15:45:00.488250: step 8504, loss 0.000278983, acc 1\n",
      "2018-04-13T15:45:00.837497: step 8505, loss 0.00111168, acc 1\n",
      "2018-04-13T15:45:01.214263: step 8506, loss 0.00141904, acc 1\n",
      "2018-04-13T15:45:01.554002: step 8507, loss 3.94689e-05, acc 1\n",
      "2018-04-13T15:45:01.896245: step 8508, loss 0.000174816, acc 1\n",
      "2018-04-13T15:45:02.225477: step 8509, loss 0.0104684, acc 1\n",
      "2018-04-13T15:45:02.558712: step 8510, loss 0.0418082, acc 0.984375\n",
      "2018-04-13T15:45:02.885943: step 8511, loss 4.72547e-05, acc 1\n",
      "2018-04-13T15:45:03.222180: step 8512, loss 0.000159573, acc 1\n",
      "2018-04-13T15:45:03.563422: step 8513, loss 0.00163478, acc 1\n",
      "2018-04-13T15:45:03.882646: step 8514, loss 0.00114164, acc 1\n",
      "2018-04-13T15:45:04.215382: step 8515, loss 4.55949e-05, acc 1\n",
      "2018-04-13T15:45:04.534107: step 8516, loss 9.93982e-05, acc 1\n",
      "2018-04-13T15:45:04.873847: step 8517, loss 0.00011835, acc 1\n",
      "2018-04-13T15:45:05.200577: step 8518, loss 6.37635e-05, acc 1\n",
      "2018-04-13T15:45:05.516801: step 8519, loss 0.000164815, acc 1\n",
      "2018-04-13T15:45:05.839028: step 8520, loss 2.52698e-05, acc 1\n",
      "2018-04-13T15:45:06.175765: step 8521, loss 0.00151819, acc 1\n",
      "2018-04-13T15:45:06.497494: step 8522, loss 9.40946e-05, acc 1\n",
      "2018-04-13T15:45:06.820723: step 8523, loss 6.44607e-05, acc 1\n",
      "2018-04-13T15:45:07.145952: step 8524, loss 0.029791, acc 0.96875\n",
      "2018-04-13T15:45:07.477686: step 8525, loss 0.000628007, acc 1\n",
      "2018-04-13T15:45:07.829434: step 8526, loss 0.000122896, acc 1\n",
      "2018-04-13T15:45:08.156665: step 8527, loss 0.0005803, acc 1\n",
      "2018-04-13T15:45:08.482395: step 8528, loss 0.000453366, acc 1\n",
      "2018-04-13T15:45:08.799619: step 8529, loss 0.00139211, acc 1\n",
      "2018-04-13T15:45:09.127351: step 8530, loss 0.00229172, acc 1\n",
      "2018-04-13T15:45:09.453581: step 8531, loss 0.000553355, acc 1\n",
      "2018-04-13T15:45:09.789317: step 8532, loss 0.0022028, acc 1\n",
      "2018-04-13T15:45:10.127556: step 8533, loss 0.000912763, acc 1\n",
      "2018-04-13T15:45:10.448283: step 8534, loss 0.00513293, acc 1\n",
      "2018-04-13T15:45:10.813041: step 8535, loss 0.000159454, acc 1\n",
      "2018-04-13T15:45:11.140272: step 8536, loss 0.000263967, acc 1\n",
      "2018-04-13T15:45:11.473008: step 8537, loss 4.51862e-05, acc 1\n",
      "2018-04-13T15:45:11.790231: step 8538, loss 0.000325442, acc 1\n",
      "2018-04-13T15:45:12.123967: step 8539, loss 0.000223652, acc 1\n",
      "2018-04-13T15:45:12.436187: step 8540, loss 0.00282954, acc 1\n",
      "2018-04-13T15:45:12.749909: step 8541, loss 0.00299444, acc 1\n",
      "2018-04-13T15:45:13.089148: step 8542, loss 6.46393e-05, acc 1\n",
      "2018-04-13T15:45:13.425886: step 8543, loss 0.000182958, acc 1\n",
      "2018-04-13T15:45:13.790643: step 8544, loss 2.6604e-05, acc 1\n",
      "2018-04-13T15:45:14.114371: step 8545, loss 0.00015391, acc 1\n",
      "2018-04-13T15:45:14.427593: step 8546, loss 0.000352193, acc 1\n",
      "2018-04-13T15:45:14.746319: step 8547, loss 6.2369e-05, acc 1\n",
      "2018-04-13T15:45:15.079054: step 8548, loss 1.58859e-05, acc 1\n",
      "2018-04-13T15:45:15.389772: step 8549, loss 5.53794e-05, acc 1\n",
      "2018-04-13T15:45:15.692487: step 8550, loss 4.09923e-05, acc 1\n",
      "2018-04-13T15:45:16.017215: step 8551, loss 0.00426476, acc 1\n",
      "2018-04-13T15:45:16.338942: step 8552, loss 0.0106234, acc 1\n",
      "2018-04-13T15:45:16.708203: step 8553, loss 0.00020763, acc 1\n",
      "2018-04-13T15:45:17.021425: step 8554, loss 0.000251333, acc 1\n",
      "2018-04-13T15:45:17.351158: step 8555, loss 0.000233453, acc 1\n",
      "2018-04-13T15:45:17.678889: step 8556, loss 6.54369e-05, acc 1\n",
      "2018-04-13T15:45:17.995112: step 8557, loss 0.0123455, acc 0.984375\n",
      "2018-04-13T15:45:18.326346: step 8558, loss 8.32182e-05, acc 1\n",
      "2018-04-13T15:45:18.635064: step 8559, loss 1.19409e-05, acc 1\n",
      "2018-04-13T15:45:18.961795: step 8560, loss 0.000674435, acc 1\n",
      "2018-04-13T15:45:19.281019: step 8561, loss 0.000298735, acc 1\n",
      "2018-04-13T15:45:19.632768: step 8562, loss 0.000709304, acc 1\n",
      "2018-04-13T15:45:19.969507: step 8563, loss 0.000349785, acc 1\n",
      "2018-04-13T15:45:20.286230: step 8564, loss 0.000302001, acc 1\n",
      "2018-04-13T15:45:20.606956: step 8565, loss 0.00375949, acc 1\n",
      "2018-04-13T15:45:20.929684: step 8566, loss 0.000379312, acc 1\n",
      "2018-04-13T15:45:21.256916: step 8567, loss 0.000102414, acc 1\n",
      "2018-04-13T15:45:21.566634: step 8568, loss 0.00107836, acc 1\n",
      "2018-04-13T15:45:21.889362: step 8569, loss 2.22479e-05, acc 1\n",
      "2018-04-13T15:45:22.211590: step 8570, loss 0.000756613, acc 1\n",
      "2018-04-13T15:45:22.533817: step 8571, loss 0.000663244, acc 1\n",
      "2018-04-13T15:45:22.898074: step 8572, loss 0.00900998, acc 1\n",
      "2018-04-13T15:45:23.222803: step 8573, loss 0.000146144, acc 1\n",
      "2018-04-13T15:45:23.568048: step 8574, loss 5.15371e-06, acc 1\n",
      "2018-04-13T15:45:23.889274: step 8575, loss 0.000589654, acc 1\n",
      "2018-04-13T15:45:24.225511: step 8576, loss 1.63767e-05, acc 1\n",
      "2018-04-13T15:45:24.537732: step 8577, loss 0.000111996, acc 1\n",
      "2018-04-13T15:45:24.854956: step 8578, loss 0.000293974, acc 1\n",
      "2018-04-13T15:45:25.182688: step 8579, loss 1.89531e-05, acc 1\n",
      "2018-04-13T15:45:25.492907: step 8580, loss 0.00180059, acc 1\n",
      "2018-04-13T15:45:25.849157: step 8581, loss 0.00269536, acc 1\n",
      "2018-04-13T15:45:26.187897: step 8582, loss 0.000707711, acc 1\n",
      "2018-04-13T15:45:26.525636: step 8583, loss 0.0012281, acc 1\n",
      "2018-04-13T15:45:26.855869: step 8584, loss 3.39278e-05, acc 1\n",
      "2018-04-13T15:45:27.191606: step 8585, loss 5.86908e-05, acc 1\n",
      "2018-04-13T15:45:27.500324: step 8586, loss 0.00250774, acc 1\n",
      "2018-04-13T15:45:27.820050: step 8587, loss 0.000893503, acc 1\n",
      "2018-04-13T15:45:28.147781: step 8588, loss 0.000678395, acc 1\n",
      "2018-04-13T15:45:28.459001: step 8589, loss 0.0628855, acc 0.984375\n",
      "2018-04-13T15:45:28.823759: step 8590, loss 0.00211025, acc 1\n",
      "2018-04-13T15:45:29.150489: step 8591, loss 0.00247947, acc 1\n",
      "2018-04-13T15:45:29.482724: step 8592, loss 0.00276491, acc 1\n",
      "2018-04-13T15:45:29.804451: step 8593, loss 0.000290152, acc 1\n",
      "2018-04-13T15:45:30.144691: step 8594, loss 6.9209e-06, acc 1\n",
      "2018-04-13T15:45:30.461415: step 8595, loss 0.0101636, acc 1\n",
      "2018-04-13T15:45:30.788646: step 8596, loss 3.91927e-05, acc 1\n",
      "2018-04-13T15:45:31.120380: step 8597, loss 0.0017985, acc 1\n",
      "2018-04-13T15:45:31.436103: step 8598, loss 0.000133193, acc 1\n",
      "2018-04-13T15:45:31.777845: step 8599, loss 6.71532e-05, acc 1\n",
      "2018-04-13T15:45:32.104074: step 8600, loss 0.00151473, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:45:33.269398: step 8600, loss 2.68295, acc 0.72045\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8600\n",
      "\n",
      "2018-04-13T15:45:35.050154: step 8601, loss 8.51683e-05, acc 1\n",
      "2018-04-13T15:45:35.370381: step 8602, loss 0.00017065, acc 1\n",
      "2018-04-13T15:45:35.686604: step 8603, loss 2.10681e-05, acc 1\n",
      "2018-04-13T15:45:36.006330: step 8604, loss 0.000393555, acc 1\n",
      "2018-04-13T15:45:36.339065: step 8605, loss 0.00752126, acc 1\n",
      "2018-04-13T15:45:36.690814: step 8606, loss 0.000104971, acc 1\n",
      "2018-04-13T15:45:37.022047: step 8607, loss 5.23415e-05, acc 1\n",
      "2018-04-13T15:45:37.351280: step 8608, loss 0.000596302, acc 1\n",
      "2018-04-13T15:45:37.670005: step 8609, loss 9.70319e-05, acc 1\n",
      "2018-04-13T15:45:38.017751: step 8610, loss 0.000223049, acc 1\n",
      "2018-04-13T15:45:38.356490: step 8611, loss 0.00156778, acc 1\n",
      "2018-04-13T15:45:38.683220: step 8612, loss 0.000199681, acc 1\n",
      "2018-04-13T15:45:39.005948: step 8613, loss 0.010766, acc 1\n",
      "2018-04-13T15:45:39.340185: step 8614, loss 3.33002e-05, acc 1\n",
      "2018-04-13T15:45:39.645399: step 8615, loss 2.53985e-05, acc 1\n",
      "2018-04-13T15:45:39.961122: step 8616, loss 0.000257333, acc 1\n",
      "2018-04-13T15:45:40.285853: step 8617, loss 0.000170153, acc 1\n",
      "2018-04-13T15:45:40.613583: step 8618, loss 7.14805e-05, acc 1\n",
      "2018-04-13T15:45:40.953323: step 8619, loss 0.0316714, acc 0.984375\n",
      "2018-04-13T15:45:41.308574: step 8620, loss 0.000272455, acc 1\n",
      "2018-04-13T15:45:41.639307: step 8621, loss 0.000186704, acc 1\n",
      "2018-04-13T15:45:41.958033: step 8622, loss 0.000328108, acc 1\n",
      "2018-04-13T15:45:42.293769: step 8623, loss 0.00495928, acc 1\n",
      "2018-04-13T15:45:42.612995: step 8624, loss 0.000109322, acc 1\n",
      "2018-04-13T15:45:42.937224: step 8625, loss 0.00171973, acc 1\n",
      "2018-04-13T15:45:43.264955: step 8626, loss 0.00437134, acc 1\n",
      "2018-04-13T15:45:43.576676: step 8627, loss 0.000770683, acc 1\n",
      "2018-04-13T15:45:43.916918: step 8628, loss 0.000300931, acc 1\n",
      "2018-04-13T15:45:44.240645: step 8629, loss 0.000138107, acc 1\n",
      "2018-04-13T15:45:44.550363: step 8630, loss 9.62396e-05, acc 1\n",
      "2018-04-13T15:45:44.883098: step 8631, loss 1.13052e-05, acc 1\n",
      "2018-04-13T15:45:45.207827: step 8632, loss 0.000312002, acc 1\n",
      "2018-04-13T15:45:45.527553: step 8633, loss 5.22443e-05, acc 1\n",
      "2018-04-13T15:45:45.842275: step 8634, loss 0.00774094, acc 1\n",
      "2018-04-13T15:45:46.172508: step 8635, loss 0.000232393, acc 1\n",
      "2018-04-13T15:45:46.490733: step 8636, loss 0.000138403, acc 1\n",
      "2018-04-13T15:45:46.831474: step 8637, loss 4.96006e-06, acc 1\n",
      "2018-04-13T15:45:47.159707: step 8638, loss 0.016739, acc 0.984375\n",
      "2018-04-13T15:45:47.480932: step 8639, loss 0.000311714, acc 1\n",
      "2018-04-13T15:45:47.803661: step 8640, loss 0.0219663, acc 0.984375\n",
      "2018-04-13T15:45:48.135895: step 8641, loss 0.00299594, acc 1\n",
      "2018-04-13T15:45:48.449616: step 8642, loss 0.000401338, acc 1\n",
      "2018-04-13T15:45:48.770343: step 8643, loss 0.0003282, acc 1\n",
      "2018-04-13T15:45:49.102078: step 8644, loss 3.26694e-06, acc 1\n",
      "2018-04-13T15:45:49.436313: step 8645, loss 7.40872e-05, acc 1\n",
      "2018-04-13T15:45:49.768048: step 8646, loss 0.00023133, acc 1\n",
      "2018-04-13T15:45:50.113792: step 8647, loss 0.00231212, acc 1\n",
      "2018-04-13T15:45:50.441023: step 8648, loss 0.00020704, acc 1\n",
      "2018-04-13T15:45:50.749241: step 8649, loss 0.00016126, acc 1\n",
      "2018-04-13T15:45:51.074470: step 8650, loss 0.000184886, acc 1\n",
      "2018-04-13T15:45:51.406205: step 8651, loss 2.22762e-06, acc 1\n",
      "2018-04-13T15:45:51.747445: step 8652, loss 0.0022303, acc 1\n",
      "2018-04-13T15:45:52.080180: step 8653, loss 0.000144885, acc 1\n",
      "2018-04-13T15:45:52.400405: step 8654, loss 0.00130414, acc 1\n",
      "2018-04-13T15:45:52.748152: step 8655, loss 0.00902686, acc 1\n",
      "2018-04-13T15:45:53.079886: step 8656, loss 0.0779155, acc 0.984375\n",
      "2018-04-13T15:45:53.414622: step 8657, loss 3.48859e-06, acc 1\n",
      "2018-04-13T15:45:53.727844: step 8658, loss 4.16188e-05, acc 1\n",
      "2018-04-13T15:45:54.050572: step 8659, loss 0.0114179, acc 1\n",
      "2018-04-13T15:45:54.376302: step 8660, loss 0.000231336, acc 1\n",
      "2018-04-13T15:45:54.699529: step 8661, loss 2.14816e-05, acc 1\n",
      "2018-04-13T15:45:55.046274: step 8662, loss 0.00010056, acc 1\n",
      "2018-04-13T15:45:55.367001: step 8663, loss 2.12282e-05, acc 1\n",
      "2018-04-13T15:45:55.694232: step 8664, loss 8.08918e-05, acc 1\n",
      "2018-04-13T15:45:56.035973: step 8665, loss 2.61402e-05, acc 1\n",
      "2018-04-13T15:45:56.365707: step 8666, loss 0.00120694, acc 1\n",
      "2018-04-13T15:45:56.692437: step 8667, loss 2.0576e-05, acc 1\n",
      "2018-04-13T15:45:57.016665: step 8668, loss 3.34724e-05, acc 1\n",
      "2018-04-13T15:45:57.364911: step 8669, loss 0.00240852, acc 1\n",
      "2018-04-13T15:45:57.694644: step 8670, loss 7.65493e-06, acc 1\n",
      "2018-04-13T15:45:58.033885: step 8671, loss 0.000644055, acc 1\n",
      "2018-04-13T15:45:58.384132: step 8672, loss 0.00148538, acc 1\n",
      "2018-04-13T15:45:58.728375: step 8673, loss 0.000209246, acc 1\n",
      "2018-04-13T15:45:59.071116: step 8674, loss 0.000859581, acc 1\n",
      "2018-04-13T15:45:59.404852: step 8675, loss 0.000240217, acc 1\n",
      "2018-04-13T15:45:59.753600: step 8676, loss 0.000291578, acc 1\n",
      "2018-04-13T15:46:00.147878: step 8677, loss 0.00350294, acc 1\n",
      "2018-04-13T15:46:00.486630: step 8678, loss 0.0120143, acc 0.984375\n",
      "2018-04-13T15:46:00.844383: step 8679, loss 0.000559464, acc 1\n",
      "2018-04-13T15:46:01.232659: step 8680, loss 0.000167593, acc 1\n",
      "2018-04-13T15:46:01.552382: step 8681, loss 7.73594e-05, acc 1\n",
      "2018-04-13T15:46:01.920643: step 8682, loss 2.56845e-06, acc 1\n",
      "2018-04-13T15:46:02.299410: step 8683, loss 9.91622e-05, acc 1\n",
      "2018-04-13T15:46:02.680180: step 8684, loss 2.5053e-05, acc 1\n",
      "2018-04-13T15:46:03.020419: step 8685, loss 0.000430648, acc 1\n",
      "2018-04-13T15:46:03.354154: step 8686, loss 0.0447207, acc 0.984375\n",
      "2018-04-13T15:46:03.719913: step 8687, loss 0.000684455, acc 1\n",
      "2018-04-13T15:46:04.093177: step 8688, loss 0.000337023, acc 1\n",
      "2018-04-13T15:46:04.408399: step 8689, loss 4.00327e-05, acc 1\n",
      "2018-04-13T15:46:04.747138: step 8690, loss 0.00631873, acc 1\n",
      "2018-04-13T15:46:05.125406: step 8691, loss 0.000102947, acc 1\n",
      "2018-04-13T15:46:05.471652: step 8692, loss 9.7053e-06, acc 1\n",
      "2018-04-13T15:46:05.805386: step 8693, loss 0.00337304, acc 1\n",
      "2018-04-13T15:46:06.141122: step 8694, loss 1.4359e-05, acc 1\n",
      "2018-04-13T15:46:06.469855: step 8695, loss 2.62316e-05, acc 1\n",
      "2018-04-13T15:46:06.790581: step 8696, loss 0.0131632, acc 0.984375\n",
      "2018-04-13T15:46:07.113810: step 8697, loss 9.30228e-05, acc 1\n",
      "2018-04-13T15:46:07.424529: step 8698, loss 1.29194e-05, acc 1\n",
      "2018-04-13T15:46:07.763269: step 8699, loss 0.0267679, acc 0.984375\n",
      "2018-04-13T15:46:08.089499: step 8700, loss 0.00333461, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:46:09.371904: step 8700, loss 2.68191, acc 0.727017\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8700\n",
      "\n",
      "2018-04-13T15:46:11.126643: step 8701, loss 0.000213724, acc 1\n",
      "2018-04-13T15:46:11.509914: step 8702, loss 0.0338298, acc 0.984375\n",
      "2018-04-13T15:46:11.864664: step 8703, loss 0.000198389, acc 1\n",
      "2018-04-13T15:46:12.224418: step 8704, loss 0.000655995, acc 1\n",
      "2018-04-13T15:46:12.563657: step 8705, loss 0.0012504, acc 1\n",
      "2018-04-13T15:46:12.925913: step 8706, loss 0.00038999, acc 1\n",
      "2018-04-13T15:46:13.272659: step 8707, loss 0.000474291, acc 1\n",
      "2018-04-13T15:46:13.639418: step 8708, loss 0.00105826, acc 1\n",
      "2018-04-13T15:46:14.040201: step 8709, loss 0.00026564, acc 1\n",
      "2018-04-13T15:46:14.385950: step 8710, loss 4.25659e-05, acc 1\n",
      "2018-04-13T15:46:14.730188: step 8711, loss 0.00134175, acc 1\n",
      "2018-04-13T15:46:15.075431: step 8712, loss 0.000399126, acc 1\n",
      "2018-04-13T15:46:15.412169: step 8713, loss 0.000197134, acc 1\n",
      "2018-04-13T15:46:15.738399: step 8714, loss 9.33256e-06, acc 1\n",
      "2018-04-13T15:46:16.101656: step 8715, loss 0.00351934, acc 1\n",
      "2018-04-13T15:46:16.447900: step 8716, loss 0.000610636, acc 1\n",
      "2018-04-13T15:46:16.808155: step 8717, loss 0.0121729, acc 0.984375\n",
      "2018-04-13T15:46:17.175414: step 8718, loss 0.00278989, acc 1\n",
      "2018-04-13T15:46:17.525162: step 8719, loss 0.000945619, acc 1\n",
      "2018-04-13T15:46:17.875409: step 8720, loss 4.87199e-05, acc 1\n",
      "2018-04-13T15:46:18.229659: step 8721, loss 1.27311e-05, acc 1\n",
      "2018-04-13T15:46:18.552900: step 8722, loss 0.000301376, acc 1\n",
      "2018-04-13T15:46:18.911153: step 8723, loss 0.00195886, acc 1\n",
      "2018-04-13T15:46:19.254895: step 8724, loss 0.000270385, acc 1\n",
      "2018-04-13T15:46:19.581126: step 8725, loss 0.000110377, acc 1\n",
      "2018-04-13T15:46:19.942881: step 8726, loss 0.0136665, acc 0.984375\n",
      "2018-04-13T15:46:20.280120: step 8727, loss 2.99599e-05, acc 1\n",
      "2018-04-13T15:46:20.605349: step 8728, loss 2.40464e-06, acc 1\n",
      "2018-04-13T15:46:20.910565: step 8729, loss 0.00932469, acc 1\n",
      "2018-04-13T15:46:21.247803: step 8730, loss 0.00453212, acc 1\n",
      "2018-04-13T15:46:21.573033: step 8731, loss 0.000552241, acc 1\n",
      "2018-04-13T15:46:21.897762: step 8732, loss 8.13813e-05, acc 1\n",
      "2018-04-13T15:46:22.230003: step 8733, loss 0.00019528, acc 1\n",
      "2018-04-13T15:46:22.570737: step 8734, loss 0.0151517, acc 0.984375\n",
      "2018-04-13T15:46:22.926989: step 8735, loss 0.000613297, acc 1\n",
      "2018-04-13T15:46:23.247714: step 8736, loss 0.000122394, acc 1\n",
      "2018-04-13T15:46:23.572945: step 8737, loss 5.51505e-05, acc 1\n",
      "2018-04-13T15:46:23.889668: step 8738, loss 0.000878402, acc 1\n",
      "2018-04-13T15:46:24.223404: step 8739, loss 0.000249272, acc 1\n",
      "2018-04-13T15:46:24.536625: step 8740, loss 0.000360533, acc 1\n",
      "2018-04-13T15:46:24.858853: step 8741, loss 0.000209516, acc 1\n",
      "2018-04-13T15:46:25.201095: step 8742, loss 0.0244231, acc 0.984375\n",
      "2018-04-13T15:46:25.524823: step 8743, loss 0.0614796, acc 0.984375\n",
      "2018-04-13T15:46:25.874069: step 8744, loss 0.000266927, acc 1\n",
      "2018-04-13T15:46:26.204804: step 8745, loss 0.0189878, acc 0.984375\n",
      "2018-04-13T15:46:26.535037: step 8746, loss 2.04744e-05, acc 1\n",
      "2018-04-13T15:46:26.847257: step 8747, loss 0.0204552, acc 0.984375\n",
      "2018-04-13T15:46:27.190999: step 8748, loss 0.00198494, acc 1\n",
      "2018-04-13T15:46:27.507223: step 8749, loss 0.000694727, acc 1\n",
      "2018-04-13T15:46:27.819943: step 8750, loss 0.00314384, acc 1\n",
      "2018-04-13T15:46:28.152178: step 8751, loss 0.000261733, acc 1\n",
      "2018-04-13T15:46:28.480910: step 8752, loss 0.0187503, acc 0.984375\n",
      "2018-04-13T15:46:28.825655: step 8753, loss 0.00453901, acc 1\n",
      "2018-04-13T15:46:29.176401: step 8754, loss 8.84491e-05, acc 1\n",
      "2018-04-13T15:46:29.514641: step 8755, loss 0.000839364, acc 1\n",
      "2018-04-13T15:46:29.832865: step 8756, loss 0.00627957, acc 1\n",
      "2018-04-13T15:46:30.169605: step 8757, loss 4.1608e-05, acc 1\n",
      "2018-04-13T15:46:30.494832: step 8758, loss 3.55376e-05, acc 1\n",
      "2018-04-13T15:46:30.814558: step 8759, loss 0.00172512, acc 1\n",
      "2018-04-13T15:46:31.156800: step 8760, loss 0.000301097, acc 1\n",
      "2018-04-13T15:46:31.468020: step 8761, loss 1.9825e-05, acc 1\n",
      "2018-04-13T15:46:31.797752: step 8762, loss 0.000667092, acc 1\n",
      "2018-04-13T15:46:32.152503: step 8763, loss 1.56802e-05, acc 1\n",
      "2018-04-13T15:46:32.483738: step 8764, loss 0.000728237, acc 1\n",
      "2018-04-13T15:46:32.816972: step 8765, loss 0.000207944, acc 1\n",
      "2018-04-13T15:46:33.148706: step 8766, loss 0.00490718, acc 1\n",
      "2018-04-13T15:46:33.466431: step 8767, loss 0.00109117, acc 1\n",
      "2018-04-13T15:46:33.784655: step 8768, loss 2.35931e-05, acc 1\n",
      "2018-04-13T15:46:34.113888: step 8769, loss 0.0126285, acc 0.984375\n",
      "2018-04-13T15:46:34.427109: step 8770, loss 0.00162132, acc 1\n",
      "2018-04-13T15:46:34.754340: step 8771, loss 0.0446204, acc 0.984375\n",
      "2018-04-13T15:46:35.115095: step 8772, loss 0.00272639, acc 1\n",
      "2018-04-13T15:46:35.436822: step 8773, loss 0.000200174, acc 1\n",
      "2018-04-13T15:46:35.756048: step 8774, loss 0.000143337, acc 1\n",
      "2018-04-13T15:46:36.101292: step 8775, loss 0.00011513, acc 1\n",
      "2018-04-13T15:46:36.424018: step 8776, loss 0.000520083, acc 1\n",
      "2018-04-13T15:46:36.748250: step 8777, loss 0.00298362, acc 1\n",
      "2018-04-13T15:46:37.076981: step 8778, loss 0.00212541, acc 1\n",
      "2018-04-13T15:46:37.415719: step 8779, loss 2.75136e-05, acc 1\n",
      "2018-04-13T15:46:37.742450: step 8780, loss 0.000610758, acc 1\n",
      "2018-04-13T15:46:38.112711: step 8781, loss 0.00212935, acc 1\n",
      "2018-04-13T15:46:38.473967: step 8782, loss 0.00589533, acc 1\n",
      "2018-04-13T15:46:38.812209: step 8783, loss 0.00287566, acc 1\n",
      "2018-04-13T15:46:39.150445: step 8784, loss 0.00104659, acc 1\n",
      "2018-04-13T15:46:39.498190: step 8785, loss 0.000372947, acc 1\n",
      "2018-04-13T15:46:39.820918: step 8786, loss 0.000212219, acc 1\n",
      "2018-04-13T15:46:40.176679: step 8787, loss 0.000372127, acc 1\n",
      "2018-04-13T15:46:40.491892: step 8788, loss 0.0888213, acc 0.984375\n",
      "2018-04-13T15:46:40.827630: step 8789, loss 0.000436764, acc 1\n",
      "2018-04-13T15:46:41.181378: step 8790, loss 0.00640784, acc 1\n",
      "2018-04-13T15:46:41.528123: step 8791, loss 1.6951e-05, acc 1\n",
      "2018-04-13T15:46:41.882874: step 8792, loss 0.000425168, acc 1\n",
      "2018-04-13T15:46:42.226116: step 8793, loss 0.000538857, acc 1\n",
      "2018-04-13T15:46:42.594376: step 8794, loss 0.000345913, acc 1\n",
      "2018-04-13T15:46:42.908097: step 8795, loss 0.000423852, acc 1\n",
      "2018-04-13T15:46:43.280861: step 8796, loss 4.97705e-05, acc 1\n",
      "2018-04-13T15:46:43.640616: step 8797, loss 1.81308e-05, acc 1\n",
      "2018-04-13T15:46:43.989362: step 8798, loss 3.37949e-05, acc 1\n",
      "2018-04-13T15:46:44.360623: step 8799, loss 0.00055985, acc 1\n",
      "2018-04-13T15:46:44.680850: step 8800, loss 0.000454656, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:46:45.887706: step 8800, loss 2.59665, acc 0.737336\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8800\n",
      "\n",
      "2018-04-13T15:46:47.886160: step 8801, loss 7.45315e-05, acc 1\n",
      "2018-04-13T15:46:48.240410: step 8802, loss 8.35972e-05, acc 1\n",
      "2018-04-13T15:46:48.559636: step 8803, loss 0.00024998, acc 1\n",
      "2018-04-13T15:46:48.874858: step 8804, loss 0.000102976, acc 1\n",
      "2018-04-13T15:46:49.212596: step 8805, loss 0.000277668, acc 1\n",
      "2018-04-13T15:46:49.524816: step 8806, loss 0.0509437, acc 0.984375\n",
      "2018-04-13T15:46:49.859053: step 8807, loss 0.000308348, acc 1\n",
      "2018-04-13T15:46:50.217806: step 8808, loss 0.000100017, acc 1\n",
      "2018-04-13T15:46:50.542536: step 8809, loss 9.21394e-06, acc 1\n",
      "2018-04-13T15:46:50.856757: step 8810, loss 0.000364775, acc 1\n",
      "2018-04-13T15:46:51.223516: step 8811, loss 0.001038, acc 1\n",
      "2018-04-13T15:46:51.559754: step 8812, loss 0.000414784, acc 1\n",
      "2018-04-13T15:46:51.877978: step 8813, loss 0.00128751, acc 1\n",
      "2018-04-13T15:46:52.217719: step 8814, loss 9.64502e-05, acc 1\n",
      "2018-04-13T15:46:52.547951: step 8815, loss 7.41896e-05, acc 1\n",
      "2018-04-13T15:46:52.890193: step 8816, loss 0.0458737, acc 0.984375\n",
      "2018-04-13T15:46:53.254450: step 8817, loss 2.48755e-05, acc 1\n",
      "2018-04-13T15:46:53.573676: step 8818, loss 0.000422106, acc 1\n",
      "2018-04-13T15:46:53.893902: step 8819, loss 0.00219196, acc 1\n",
      "2018-04-13T15:46:54.227159: step 8820, loss 0.000286677, acc 1\n",
      "2018-04-13T15:46:54.546385: step 8821, loss 0.00935047, acc 1\n",
      "2018-04-13T15:46:54.888629: step 8822, loss 0.00624336, acc 1\n",
      "2018-04-13T15:46:55.224864: step 8823, loss 0.00158662, acc 1\n",
      "2018-04-13T15:46:55.544089: step 8824, loss 0.000137258, acc 1\n",
      "2018-04-13T15:46:55.898340: step 8825, loss 4.16096e-05, acc 1\n",
      "2018-04-13T15:46:56.245585: step 8826, loss 8.84191e-05, acc 1\n",
      "2018-04-13T15:46:56.574317: step 8827, loss 0.000405702, acc 1\n",
      "2018-04-13T15:46:56.889040: step 8828, loss 0.000227134, acc 1\n",
      "2018-04-13T15:46:57.217771: step 8829, loss 0.00704347, acc 1\n",
      "2018-04-13T15:46:57.539999: step 8830, loss 0.00258245, acc 1\n",
      "2018-04-13T15:46:57.857724: step 8831, loss 4.53212e-05, acc 1\n",
      "2018-04-13T15:46:58.201466: step 8832, loss 0.000617685, acc 1\n",
      "2018-04-13T15:46:58.521692: step 8833, loss 0.000124064, acc 1\n",
      "2018-04-13T15:46:58.852926: step 8834, loss 0.00021161, acc 1\n",
      "2018-04-13T15:46:59.230192: step 8835, loss 0.00238775, acc 1\n",
      "2018-04-13T15:46:59.560426: step 8836, loss 0.024927, acc 0.984375\n",
      "2018-04-13T15:46:59.879150: step 8837, loss 0.000317516, acc 1\n",
      "2018-04-13T15:47:00.225896: step 8838, loss 0.000163362, acc 1\n",
      "2018-04-13T15:47:00.549624: step 8839, loss 6.17103e-05, acc 1\n",
      "2018-04-13T15:47:00.915882: step 8840, loss 0.000999971, acc 1\n",
      "2018-04-13T15:47:01.247617: step 8841, loss 1.80195e-05, acc 1\n",
      "2018-04-13T15:47:01.558837: step 8842, loss 0.000899823, acc 1\n",
      "2018-04-13T15:47:01.912586: step 8843, loss 3.7375e-05, acc 1\n",
      "2018-04-13T15:47:02.266359: step 8844, loss 0.000296015, acc 1\n",
      "2018-04-13T15:47:02.591088: step 8845, loss 0.000176874, acc 1\n",
      "2018-04-13T15:47:02.904809: step 8846, loss 0.000109412, acc 1\n",
      "2018-04-13T15:47:03.226537: step 8847, loss 0.000873091, acc 1\n",
      "2018-04-13T15:47:03.536255: step 8848, loss 0.000602623, acc 1\n",
      "2018-04-13T15:47:03.857982: step 8849, loss 2.52812e-05, acc 1\n",
      "2018-04-13T15:47:04.170203: step 8850, loss 8.06749e-05, acc 1\n",
      "2018-04-13T15:47:04.487927: step 8851, loss 1.34322e-05, acc 1\n",
      "2018-04-13T15:47:04.806153: step 8852, loss 0.000787544, acc 1\n",
      "2018-04-13T15:47:05.182918: step 8853, loss 0.000160236, acc 1\n",
      "2018-04-13T15:47:05.502143: step 8854, loss 0.00198698, acc 1\n",
      "2018-04-13T15:47:05.819867: step 8855, loss 5.89762e-05, acc 1\n",
      "2018-04-13T15:47:06.142095: step 8856, loss 0.00681496, acc 1\n",
      "2018-04-13T15:47:06.460320: step 8857, loss 5.1818e-05, acc 1\n",
      "2018-04-13T15:47:06.796057: step 8858, loss 0.000213558, acc 1\n",
      "2018-04-13T15:47:07.130794: step 8859, loss 2.85165e-06, acc 1\n",
      "2018-04-13T15:47:07.450519: step 8860, loss 0.000123442, acc 1\n",
      "2018-04-13T15:47:07.776751: step 8861, loss 7.05125e-06, acc 1\n",
      "2018-04-13T15:47:08.142508: step 8862, loss 4.72701e-06, acc 1\n",
      "2018-04-13T15:47:08.460808: step 8863, loss 0.000712539, acc 1\n",
      "2018-04-13T15:47:08.788540: step 8864, loss 0.000195623, acc 1\n",
      "2018-04-13T15:47:09.138286: step 8865, loss 4.41655e-05, acc 1\n",
      "2018-04-13T15:47:09.464016: step 8866, loss 4.77963e-05, acc 1\n",
      "2018-04-13T15:47:09.802755: step 8867, loss 0.00023813, acc 1\n",
      "2018-04-13T15:47:10.146998: step 8868, loss 0.0180285, acc 0.984375\n",
      "2018-04-13T15:47:10.467225: step 8869, loss 3.00665e-05, acc 1\n",
      "2018-04-13T15:47:10.780947: step 8870, loss 7.94693e-05, acc 1\n",
      "2018-04-13T15:47:11.143702: step 8871, loss 0.000585945, acc 1\n",
      "2018-04-13T15:47:11.468932: step 8872, loss 0.000662451, acc 1\n",
      "2018-04-13T15:47:11.792661: step 8873, loss 3.38597e-05, acc 1\n",
      "2018-04-13T15:47:12.111385: step 8874, loss 8.75044e-05, acc 1\n",
      "2018-04-13T15:47:12.439618: step 8875, loss 0.00119912, acc 1\n",
      "2018-04-13T15:47:12.806376: step 8876, loss 0.00178951, acc 1\n",
      "2018-04-13T15:47:13.144615: step 8877, loss 0.000175401, acc 1\n",
      "2018-04-13T15:47:13.463840: step 8878, loss 0.0200451, acc 0.984375\n",
      "2018-04-13T15:47:13.785567: step 8879, loss 6.05892e-05, acc 1\n",
      "2018-04-13T15:47:14.140818: step 8880, loss 0.00149664, acc 1\n",
      "2018-04-13T15:47:14.469051: step 8881, loss 0.000239171, acc 1\n",
      "2018-04-13T15:47:14.796282: step 8882, loss 9.56335e-05, acc 1\n",
      "2018-04-13T15:47:15.130017: step 8883, loss 0.00018414, acc 1\n",
      "2018-04-13T15:47:15.462752: step 8884, loss 0.00513291, acc 1\n",
      "2018-04-13T15:47:15.793486: step 8885, loss 3.37185e-05, acc 1\n",
      "2018-04-13T15:47:16.136728: step 8886, loss 0.00018553, acc 1\n",
      "2018-04-13T15:47:16.454452: step 8887, loss 0.00304844, acc 1\n",
      "2018-04-13T15:47:16.786186: step 8888, loss 0.00114617, acc 1\n",
      "2018-04-13T15:47:17.144440: step 8889, loss 0.00229367, acc 1\n",
      "2018-04-13T15:47:17.466667: step 8890, loss 1.76369e-05, acc 1\n",
      "2018-04-13T15:47:17.786393: step 8891, loss 0.000156844, acc 1\n",
      "2018-04-13T15:47:18.114124: step 8892, loss 9.3015e-05, acc 1\n",
      "2018-04-13T15:47:18.442356: step 8893, loss 8.42685e-05, acc 1\n",
      "2018-04-13T15:47:18.767085: step 8894, loss 5.90157e-05, acc 1\n",
      "2018-04-13T15:47:19.106325: step 8895, loss 0.000606441, acc 1\n",
      "2018-04-13T15:47:19.431054: step 8896, loss 0.000106129, acc 1\n",
      "2018-04-13T15:47:19.750280: step 8897, loss 0.000786743, acc 1\n",
      "2018-04-13T15:47:20.086017: step 8898, loss 0.00518964, acc 1\n",
      "2018-04-13T15:47:20.417751: step 8899, loss 8.61082e-05, acc 1\n",
      "2018-04-13T15:47:20.733474: step 8900, loss 0.0199018, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:47:21.880784: step 8900, loss 2.57222, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-8900\n",
      "\n",
      "2018-04-13T15:47:23.529448: step 8901, loss 0.000225217, acc 1\n",
      "2018-04-13T15:47:23.844671: step 8902, loss 9.14059e-06, acc 1\n",
      "2018-04-13T15:47:24.172902: step 8903, loss 0.00711388, acc 1\n",
      "2018-04-13T15:47:24.531656: step 8904, loss 4.53428e-05, acc 1\n",
      "2018-04-13T15:47:24.854884: step 8905, loss 0.000190398, acc 1\n",
      "2018-04-13T15:47:25.190120: step 8906, loss 0.000108402, acc 1\n",
      "2018-04-13T15:47:25.508846: step 8907, loss 0.000882999, acc 1\n",
      "2018-04-13T15:47:25.824568: step 8908, loss 4.14311e-05, acc 1\n",
      "2018-04-13T15:47:26.187826: step 8909, loss 0.00561058, acc 1\n",
      "2018-04-13T15:47:26.510553: step 8910, loss 0.00131085, acc 1\n",
      "2018-04-13T15:47:26.839786: step 8911, loss 0.000117684, acc 1\n",
      "2018-04-13T15:47:27.210047: step 8912, loss 9.63546e-05, acc 1\n",
      "2018-04-13T15:47:27.561295: step 8913, loss 0.000551781, acc 1\n",
      "2018-04-13T15:47:27.888026: step 8914, loss 0.000112596, acc 1\n",
      "2018-04-13T15:47:28.225764: step 8915, loss 0.000891354, acc 1\n",
      "2018-04-13T15:47:28.558999: step 8916, loss 0.000493448, acc 1\n",
      "2018-04-13T15:47:28.887732: step 8917, loss 0.000255635, acc 1\n",
      "2018-04-13T15:47:29.243483: step 8918, loss 2.15876e-06, acc 1\n",
      "2018-04-13T15:47:29.564209: step 8919, loss 0.000636092, acc 1\n",
      "2018-04-13T15:47:29.898946: step 8920, loss 6.251e-05, acc 1\n",
      "2018-04-13T15:47:30.220173: step 8921, loss 2.89042e-05, acc 1\n",
      "2018-04-13T15:47:30.526389: step 8922, loss 0.0187533, acc 0.984375\n",
      "2018-04-13T15:47:30.850117: step 8923, loss 4.34631e-05, acc 1\n",
      "2018-04-13T15:47:31.173346: step 8924, loss 0.000111383, acc 1\n",
      "2018-04-13T15:47:31.485066: step 8925, loss 1.31013e-05, acc 1\n",
      "2018-04-13T15:47:31.814800: step 8926, loss 0.000521786, acc 1\n",
      "2018-04-13T15:47:32.194066: step 8927, loss 2.26684e-05, acc 1\n",
      "2018-04-13T15:47:32.512791: step 8928, loss 1.57958e-05, acc 1\n",
      "2018-04-13T15:47:32.822510: step 8929, loss 1.12263e-05, acc 1\n",
      "2018-04-13T15:47:33.158747: step 8930, loss 0.00112676, acc 1\n",
      "2018-04-13T15:47:33.480475: step 8931, loss 0.000541851, acc 1\n",
      "2018-04-13T15:47:33.798699: step 8932, loss 2.20733e-05, acc 1\n",
      "2018-04-13T15:47:34.128933: step 8933, loss 0.00655231, acc 1\n",
      "2018-04-13T15:47:34.447157: step 8934, loss 0.0417782, acc 0.984375\n",
      "2018-04-13T15:47:34.765382: step 8935, loss 0.000402643, acc 1\n",
      "2018-04-13T15:47:35.156159: step 8936, loss 4.85896e-05, acc 1\n",
      "2018-04-13T15:47:35.493896: step 8937, loss 0.0011482, acc 1\n",
      "2018-04-13T15:47:35.807117: step 8938, loss 0.000349553, acc 1\n",
      "2018-04-13T15:47:36.139352: step 8939, loss 0.00119966, acc 1\n",
      "2018-04-13T15:47:36.453581: step 8940, loss 1.76371e-05, acc 1\n",
      "2018-04-13T15:47:36.769297: step 8941, loss 0.000814763, acc 1\n",
      "2018-04-13T15:47:37.091024: step 8942, loss 8.80675e-05, acc 1\n",
      "2018-04-13T15:47:37.410249: step 8943, loss 0.000210493, acc 1\n",
      "2018-04-13T15:47:37.727473: step 8944, loss 0.00131884, acc 1\n",
      "2018-04-13T15:47:38.077721: step 8945, loss 0.000855095, acc 1\n",
      "2018-04-13T15:47:38.413458: step 8946, loss 0.000443317, acc 1\n",
      "2018-04-13T15:47:38.745692: step 8947, loss 0.0462406, acc 0.984375\n",
      "2018-04-13T15:47:39.079929: step 8948, loss 2.46908e-05, acc 1\n",
      "2018-04-13T15:47:39.399655: step 8949, loss 9.27707e-06, acc 1\n",
      "2018-04-13T15:47:39.707872: step 8950, loss 0.000380215, acc 1\n",
      "2018-04-13T15:47:40.028098: step 8951, loss 0.000731334, acc 1\n",
      "2018-04-13T15:47:40.355330: step 8952, loss 0.000601902, acc 1\n",
      "2018-04-13T15:47:40.662046: step 8953, loss 0.0144399, acc 0.984375\n",
      "2018-04-13T15:47:41.010792: step 8954, loss 0.000184926, acc 1\n",
      "2018-04-13T15:47:41.353033: step 8955, loss 0.000498632, acc 1\n",
      "2018-04-13T15:47:41.662252: step 8956, loss 0.000200771, acc 1\n",
      "2018-04-13T15:47:41.978475: step 8957, loss 4.1386e-05, acc 1\n",
      "2018-04-13T15:47:42.323218: step 8958, loss 0.000116875, acc 1\n",
      "2018-04-13T15:47:42.643945: step 8959, loss 0.000194772, acc 1\n",
      "2018-04-13T15:47:42.963704: step 8960, loss 0.00624434, acc 1\n",
      "2018-04-13T15:47:43.287933: step 8961, loss 0.0173501, acc 0.984375\n",
      "2018-04-13T15:47:43.603156: step 8962, loss 0.00303003, acc 1\n",
      "2018-04-13T15:47:43.930387: step 8963, loss 0.00523819, acc 1\n",
      "2018-04-13T15:47:44.311657: step 8964, loss 0.00069828, acc 1\n",
      "2018-04-13T15:47:44.635385: step 8965, loss 0.00222039, acc 1\n",
      "2018-04-13T15:47:44.949607: step 8966, loss 7.07573e-05, acc 1\n",
      "2018-04-13T15:47:45.266831: step 8967, loss 0.00423004, acc 1\n",
      "2018-04-13T15:47:45.612074: step 8968, loss 7.1238e-05, acc 1\n",
      "2018-04-13T15:47:45.974831: step 8969, loss 0.0169941, acc 0.984375\n",
      "2018-04-13T15:47:46.297559: step 8970, loss 0.000177997, acc 1\n",
      "2018-04-13T15:47:46.630294: step 8971, loss 0.00720113, acc 1\n",
      "2018-04-13T15:47:46.982043: step 8972, loss 0.0321469, acc 0.984375\n",
      "2018-04-13T15:47:47.343297: step 8973, loss 0.0012931, acc 1\n",
      "2018-04-13T15:47:47.680034: step 8974, loss 1.15696e-05, acc 1\n",
      "2018-04-13T15:47:48.019274: step 8975, loss 0.000631187, acc 1\n",
      "2018-04-13T15:47:48.382530: step 8976, loss 8.29931e-05, acc 1\n",
      "2018-04-13T15:47:48.720770: step 8977, loss 5.04593e-05, acc 1\n",
      "2018-04-13T15:47:49.047500: step 8978, loss 6.64971e-05, acc 1\n",
      "2018-04-13T15:47:49.383739: step 8979, loss 0.0016194, acc 1\n",
      "2018-04-13T15:47:49.717473: step 8980, loss 0.000711051, acc 1\n",
      "2018-04-13T15:47:50.050709: step 8981, loss 0.0133621, acc 0.984375\n",
      "2018-04-13T15:47:50.387447: step 8982, loss 0.000531074, acc 1\n",
      "2018-04-13T15:47:50.709174: step 8983, loss 0.00144068, acc 1\n",
      "2018-04-13T15:47:51.027398: step 8984, loss 0.000484306, acc 1\n",
      "2018-04-13T15:47:51.350627: step 8985, loss 0.000194476, acc 1\n",
      "2018-04-13T15:47:51.665349: step 8986, loss 0.000244496, acc 1\n",
      "2018-04-13T15:47:51.992580: step 8987, loss 0.000672371, acc 1\n",
      "2018-04-13T15:47:52.323695: step 8988, loss 9.85568e-05, acc 1\n",
      "2018-04-13T15:47:52.647924: step 8989, loss 0.00363584, acc 1\n",
      "2018-04-13T15:47:53.006677: step 8990, loss 0.0011285, acc 1\n",
      "2018-04-13T15:47:53.346917: step 8991, loss 0.000174453, acc 1\n",
      "2018-04-13T15:47:53.665142: step 8992, loss 0.000562563, acc 1\n",
      "2018-04-13T15:47:53.987370: step 8993, loss 0.00149076, acc 1\n",
      "2018-04-13T15:47:54.321606: step 8994, loss 8.27758e-06, acc 1\n",
      "2018-04-13T15:47:54.638830: step 8995, loss 0.000595383, acc 1\n",
      "2018-04-13T15:47:54.971065: step 8996, loss 3.93985e-05, acc 1\n",
      "2018-04-13T15:47:55.305800: step 8997, loss 1.96459e-05, acc 1\n",
      "2018-04-13T15:47:55.617021: step 8998, loss 0.000231076, acc 1\n",
      "2018-04-13T15:47:55.937747: step 8999, loss 1.99831e-05, acc 1\n",
      "2018-04-13T15:47:56.306007: step 9000, loss 0.00672873, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:47:57.461323: step 9000, loss 2.67696, acc 0.737336\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9000\n",
      "\n",
      "2018-04-13T15:47:59.224174: step 9001, loss 0.000120475, acc 1\n",
      "2018-04-13T15:47:59.547401: step 9002, loss 0.00109387, acc 1\n",
      "2018-04-13T15:47:59.874133: step 9003, loss 2.05899e-05, acc 1\n",
      "2018-04-13T15:48:00.222379: step 9004, loss 0.000177064, acc 1\n",
      "2018-04-13T15:48:00.548108: step 9005, loss 2.97339e-05, acc 1\n",
      "2018-04-13T15:48:00.864332: step 9006, loss 0.0189957, acc 0.984375\n",
      "2018-04-13T15:48:01.198569: step 9007, loss 7.42661e-05, acc 1\n",
      "2018-04-13T15:48:01.530803: step 9008, loss 0.000186186, acc 1\n",
      "2018-04-13T15:48:01.853029: step 9009, loss 1.61895e-05, acc 1\n",
      "2018-04-13T15:48:02.207280: step 9010, loss 1.52101e-05, acc 1\n",
      "2018-04-13T15:48:02.529007: step 9011, loss 0.000354795, acc 1\n",
      "2018-04-13T15:48:02.855738: step 9012, loss 4.63849e-05, acc 1\n",
      "2018-04-13T15:48:03.176464: step 9013, loss 0.000398004, acc 1\n",
      "2018-04-13T15:48:03.491187: step 9014, loss 6.09615e-05, acc 1\n",
      "2018-04-13T15:48:03.802907: step 9015, loss 0.00014321, acc 1\n",
      "2018-04-13T15:48:04.132139: step 9016, loss 0.000522622, acc 1\n",
      "2018-04-13T15:48:04.449863: step 9017, loss 0.000116534, acc 1\n",
      "2018-04-13T15:48:04.769589: step 9018, loss 7.36942e-06, acc 1\n",
      "2018-04-13T15:48:05.117334: step 9019, loss 0.00244419, acc 1\n",
      "2018-04-13T15:48:05.464580: step 9020, loss 0.000111484, acc 1\n",
      "2018-04-13T15:48:05.784806: step 9021, loss 4.65651e-06, acc 1\n",
      "2018-04-13T15:48:06.109536: step 9022, loss 0.0028915, acc 1\n",
      "2018-04-13T15:48:06.431771: step 9023, loss 0.000339898, acc 1\n",
      "2018-04-13T15:48:06.742504: step 9024, loss 0.000296785, acc 1\n",
      "2018-04-13T15:48:07.066745: step 9025, loss 0.000920424, acc 1\n",
      "2018-04-13T15:48:07.398482: step 9026, loss 0.000623214, acc 1\n",
      "2018-04-13T15:48:07.763254: step 9027, loss 0.00062599, acc 1\n",
      "2018-04-13T15:48:08.136017: step 9028, loss 0.000420664, acc 1\n",
      "2018-04-13T15:48:08.455256: step 9029, loss 0.000508723, acc 1\n",
      "2018-04-13T15:48:08.790505: step 9030, loss 5.05132e-06, acc 1\n",
      "2018-04-13T15:48:09.116751: step 9031, loss 3.59405e-05, acc 1\n",
      "2018-04-13T15:48:09.445498: step 9032, loss 8.13479e-05, acc 1\n",
      "2018-04-13T15:48:09.769246: step 9033, loss 0.00283017, acc 1\n",
      "2018-04-13T15:48:10.104492: step 9034, loss 0.000412052, acc 1\n",
      "2018-04-13T15:48:10.455252: step 9035, loss 2.10217e-05, acc 1\n",
      "2018-04-13T15:48:10.845554: step 9036, loss 2.55893e-05, acc 1\n",
      "2018-04-13T15:48:11.256844: step 9037, loss 0.000524962, acc 1\n",
      "2018-04-13T15:48:11.585099: step 9038, loss 0.000105876, acc 1\n",
      "2018-04-13T15:48:11.901823: step 9039, loss 0.00193434, acc 1\n",
      "2018-04-13T15:48:12.242587: step 9040, loss 6.42968e-05, acc 1\n",
      "2018-04-13T15:48:12.572330: step 9041, loss 0.000171353, acc 1\n",
      "2018-04-13T15:48:12.902092: step 9042, loss 0.000117617, acc 1\n",
      "2018-04-13T15:48:13.234836: step 9043, loss 0.000306153, acc 1\n",
      "2018-04-13T15:48:13.550574: step 9044, loss 0.030168, acc 0.984375\n",
      "2018-04-13T15:48:13.870815: step 9045, loss 0.00473791, acc 1\n",
      "2018-04-13T15:48:14.242592: step 9046, loss 0.000240271, acc 1\n",
      "2018-04-13T15:48:14.563834: step 9047, loss 8.91114e-05, acc 1\n",
      "2018-04-13T15:48:14.893684: step 9048, loss 2.62397e-05, acc 1\n",
      "2018-04-13T15:48:15.233939: step 9049, loss 0.00198775, acc 1\n",
      "2018-04-13T15:48:15.564208: step 9050, loss 0.00527472, acc 1\n",
      "2018-04-13T15:48:15.995549: step 9051, loss 4.48135e-05, acc 1\n",
      "2018-04-13T15:48:16.390839: step 9052, loss 0.000541211, acc 1\n",
      "2018-04-13T15:48:16.712077: step 9053, loss 7.13426e-05, acc 1\n",
      "2018-04-13T15:48:17.134888: step 9054, loss 0.000113858, acc 1\n",
      "2018-04-13T15:48:17.515159: step 9055, loss 6.70291e-05, acc 1\n",
      "2018-04-13T15:48:17.848912: step 9056, loss 3.23361e-05, acc 1\n",
      "2018-04-13T15:48:18.200184: step 9057, loss 6.46336e-07, acc 1\n",
      "2018-04-13T15:48:18.566426: step 9058, loss 0.02936, acc 0.984375\n",
      "2018-04-13T15:48:18.932684: step 9059, loss 2.94846e-06, acc 1\n",
      "2018-04-13T15:48:19.267420: step 9060, loss 0.00123447, acc 1\n",
      "2018-04-13T15:48:19.585645: step 9061, loss 0.00036812, acc 1\n",
      "2018-04-13T15:48:19.937893: step 9062, loss 0.000492544, acc 1\n",
      "2018-04-13T15:48:20.316160: step 9063, loss 0.00013513, acc 1\n",
      "2018-04-13T15:48:20.648896: step 9064, loss 0.00043713, acc 1\n",
      "2018-04-13T15:48:20.985132: step 9065, loss 0.000105043, acc 1\n",
      "2018-04-13T15:48:21.311363: step 9066, loss 4.04362e-05, acc 1\n",
      "2018-04-13T15:48:21.639595: step 9067, loss 7.02792e-05, acc 1\n",
      "2018-04-13T15:48:21.976834: step 9068, loss 1.83026e-05, acc 1\n",
      "2018-04-13T15:48:22.295559: step 9069, loss 0.00102378, acc 1\n",
      "2018-04-13T15:48:22.610781: step 9070, loss 2.33012e-05, acc 1\n",
      "2018-04-13T15:48:22.932008: step 9071, loss 0.000271301, acc 1\n",
      "2018-04-13T15:48:23.305550: step 9072, loss 2.59135e-05, acc 1\n",
      "2018-04-13T15:48:23.656019: step 9073, loss 6.24402e-05, acc 1\n",
      "2018-04-13T15:48:23.991256: step 9074, loss 0.00366956, acc 1\n",
      "2018-04-13T15:48:24.394541: step 9075, loss 0.000329269, acc 1\n",
      "2018-04-13T15:48:24.752293: step 9076, loss 0.000334614, acc 1\n",
      "2018-04-13T15:48:25.160582: step 9077, loss 0.000276735, acc 1\n",
      "2018-04-13T15:48:25.598891: step 9078, loss 0.000288454, acc 1\n",
      "2018-04-13T15:48:25.940132: step 9079, loss 1.26498e-05, acc 1\n",
      "2018-04-13T15:48:26.388451: step 9080, loss 0.00474315, acc 1\n",
      "2018-04-13T15:48:26.798238: step 9081, loss 1.62046e-06, acc 1\n",
      "2018-04-13T15:48:27.145985: step 9082, loss 0.0074913, acc 1\n",
      "2018-04-13T15:48:27.579790: step 9083, loss 0.000414506, acc 1\n",
      "2018-04-13T15:48:27.915526: step 9084, loss 0.000800519, acc 1\n",
      "2018-04-13T15:48:28.320312: step 9085, loss 0.000616413, acc 1\n",
      "2018-04-13T15:48:28.698079: step 9086, loss 0.0089815, acc 1\n",
      "2018-04-13T15:48:29.084852: step 9087, loss 8.07126e-05, acc 1\n",
      "2018-04-13T15:48:29.453613: step 9088, loss 1.44365e-05, acc 1\n",
      "2018-04-13T15:48:29.809364: step 9089, loss 0.00299248, acc 1\n",
      "2018-04-13T15:48:30.217653: step 9090, loss 0.00121105, acc 1\n",
      "2018-04-13T15:48:30.575405: step 9091, loss 0.000367532, acc 1\n",
      "2018-04-13T15:48:31.003371: step 9092, loss 0.000591319, acc 1\n",
      "2018-04-13T15:48:31.432173: step 9093, loss 5.48386e-05, acc 1\n",
      "2018-04-13T15:48:31.810941: step 9094, loss 0.000228159, acc 1\n",
      "2018-04-13T15:48:32.307791: step 9095, loss 0.000460607, acc 1\n",
      "2018-04-13T15:48:32.724586: step 9096, loss 0.00486722, acc 1\n",
      "2018-04-13T15:48:33.115361: step 9097, loss 0.00023454, acc 1\n",
      "2018-04-13T15:48:33.521148: step 9098, loss 5.08992e-05, acc 1\n",
      "2018-04-13T15:48:33.940444: step 9099, loss 7.60178e-05, acc 1\n",
      "2018-04-13T15:48:34.308204: step 9100, loss 4.85941e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:48:35.542575: step 9100, loss 2.71575, acc 0.729831\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9100\n",
      "\n",
      "2018-04-13T15:48:37.340358: step 9101, loss 0.000231536, acc 1\n",
      "2018-04-13T15:48:37.728632: step 9102, loss 0.000898518, acc 1\n",
      "2018-04-13T15:48:38.072375: step 9103, loss 7.53472e-05, acc 1\n",
      "2018-04-13T15:48:38.481664: step 9104, loss 0.000513055, acc 1\n",
      "2018-04-13T15:48:38.899959: step 9105, loss 0.000274067, acc 1\n",
      "2018-04-13T15:48:39.295239: step 9106, loss 0.0114353, acc 0.984375\n",
      "2018-04-13T15:48:39.704527: step 9107, loss 0.00108989, acc 1\n",
      "2018-04-13T15:48:40.086297: step 9108, loss 0.00768755, acc 1\n",
      "2018-04-13T15:48:40.433542: step 9109, loss 0.000130397, acc 1\n",
      "2018-04-13T15:48:40.780788: step 9110, loss 0.000146695, acc 1\n",
      "2018-04-13T15:48:41.117025: step 9111, loss 2.74091e-05, acc 1\n",
      "2018-04-13T15:48:41.454263: step 9112, loss 3.62256e-05, acc 1\n",
      "2018-04-13T15:48:41.797505: step 9113, loss 0.00049411, acc 1\n",
      "2018-04-13T15:48:42.197788: step 9114, loss 4.44825e-05, acc 1\n",
      "2018-04-13T15:48:42.539529: step 9115, loss 0.000262739, acc 1\n",
      "2018-04-13T15:48:42.882272: step 9116, loss 5.30603e-05, acc 1\n",
      "2018-04-13T15:48:43.213505: step 9117, loss 0.0369599, acc 0.984375\n",
      "2018-04-13T15:48:43.539235: step 9118, loss 6.57424e-05, acc 1\n",
      "2018-04-13T15:48:43.876473: step 9119, loss 4.18599e-05, acc 1\n",
      "2018-04-13T15:48:44.198701: step 9120, loss 2.99897e-05, acc 1\n",
      "2018-04-13T15:48:44.518928: step 9121, loss 0.000744461, acc 1\n",
      "2018-04-13T15:48:44.847159: step 9122, loss 3.89983e-05, acc 1\n",
      "2018-04-13T15:48:45.192403: step 9123, loss 0.000233339, acc 1\n",
      "2018-04-13T15:48:45.507625: step 9124, loss 0.00389311, acc 1\n",
      "2018-04-13T15:48:45.894399: step 9125, loss 0.000178855, acc 1\n",
      "2018-04-13T15:48:46.223131: step 9126, loss 0.00850828, acc 1\n",
      "2018-04-13T15:48:46.567874: step 9127, loss 0.00682805, acc 1\n",
      "2018-04-13T15:48:46.900609: step 9128, loss 0.00151099, acc 1\n",
      "2018-04-13T15:48:47.215340: step 9129, loss 0.00316301, acc 1\n",
      "2018-04-13T15:48:47.535557: step 9130, loss 2.18531e-05, acc 1\n",
      "2018-04-13T15:48:47.867291: step 9131, loss 1.18393e-05, acc 1\n",
      "2018-04-13T15:48:48.209032: step 9132, loss 3.63577e-05, acc 1\n",
      "2018-04-13T15:48:48.533763: step 9133, loss 0.00074006, acc 1\n",
      "2018-04-13T15:48:48.854989: step 9134, loss 0.00118824, acc 1\n",
      "2018-04-13T15:48:49.176215: step 9135, loss 0.00100683, acc 1\n",
      "2018-04-13T15:48:49.503947: step 9136, loss 0.000430778, acc 1\n",
      "2018-04-13T15:48:49.845700: step 9137, loss 1.39e-05, acc 1\n",
      "2018-04-13T15:48:50.162412: step 9138, loss 5.87639e-05, acc 1\n",
      "2018-04-13T15:48:50.473131: step 9139, loss 0.000756884, acc 1\n",
      "2018-04-13T15:48:50.794858: step 9140, loss 1.84763e-05, acc 1\n",
      "2018-04-13T15:48:51.164120: step 9141, loss 6.20283e-05, acc 1\n",
      "2018-04-13T15:48:51.516368: step 9142, loss 7.43321e-05, acc 1\n",
      "2018-04-13T15:48:51.841597: step 9143, loss 3.04423e-05, acc 1\n",
      "2018-04-13T15:48:52.164325: step 9144, loss 5.89027e-05, acc 1\n",
      "2018-04-13T15:48:52.481550: step 9145, loss 0.00723291, acc 1\n",
      "2018-04-13T15:48:52.822791: step 9146, loss 0.000177662, acc 1\n",
      "2018-04-13T15:48:53.138514: step 9147, loss 0.000409693, acc 1\n",
      "2018-04-13T15:48:53.482758: step 9148, loss 0.0010283, acc 1\n",
      "2018-04-13T15:48:53.820495: step 9149, loss 0.000100787, acc 1\n",
      "2018-04-13T15:48:54.158734: step 9150, loss 0.000357955, acc 1\n",
      "2018-04-13T15:48:54.472956: step 9151, loss 0.0012365, acc 1\n",
      "2018-04-13T15:48:54.806191: step 9152, loss 4.07337e-05, acc 1\n",
      "2018-04-13T15:48:55.128418: step 9153, loss 0.000623634, acc 1\n",
      "2018-04-13T15:48:55.451146: step 9154, loss 0.00047986, acc 1\n",
      "2018-04-13T15:48:55.784381: step 9155, loss 0.0142799, acc 0.984375\n",
      "2018-04-13T15:48:56.104608: step 9156, loss 3.31013e-05, acc 1\n",
      "2018-04-13T15:48:56.418329: step 9157, loss 0.000292738, acc 1\n",
      "2018-04-13T15:48:56.743559: step 9158, loss 0.000616764, acc 1\n",
      "2018-04-13T15:48:57.130332: step 9159, loss 7.68864e-05, acc 1\n",
      "2018-04-13T15:48:57.458564: step 9160, loss 0.000172036, acc 1\n",
      "2018-04-13T15:48:57.804808: step 9161, loss 0.000368392, acc 1\n",
      "2018-04-13T15:48:58.139545: step 9162, loss 0.00613639, acc 1\n",
      "2018-04-13T15:48:58.482286: step 9163, loss 0.00131474, acc 1\n",
      "2018-04-13T15:48:58.833534: step 9164, loss 2.81156e-05, acc 1\n",
      "2018-04-13T15:48:59.169273: step 9165, loss 0.000238361, acc 1\n",
      "2018-04-13T15:48:59.495002: step 9166, loss 9.57265e-06, acc 1\n",
      "2018-04-13T15:48:59.831740: step 9167, loss 6.112e-05, acc 1\n",
      "2018-04-13T15:49:00.195997: step 9168, loss 0.000727024, acc 1\n",
      "2018-04-13T15:49:00.532235: step 9169, loss 5.63608e-05, acc 1\n",
      "2018-04-13T15:49:00.896992: step 9170, loss 0.00024235, acc 1\n",
      "2018-04-13T15:49:01.230728: step 9171, loss 8.65725e-05, acc 1\n",
      "2018-04-13T15:49:01.562462: step 9172, loss 5.74952e-05, acc 1\n",
      "2018-04-13T15:49:01.895697: step 9173, loss 2.77384e-05, acc 1\n",
      "2018-04-13T15:49:02.244443: step 9174, loss 0.000139358, acc 1\n",
      "2018-04-13T15:49:02.598194: step 9175, loss 0.00038267, acc 1\n",
      "2018-04-13T15:49:02.954445: step 9176, loss 0.00441862, acc 1\n",
      "2018-04-13T15:49:03.293184: step 9177, loss 0.000177042, acc 1\n",
      "2018-04-13T15:49:03.609908: step 9178, loss 2.93915e-06, acc 1\n",
      "2018-04-13T15:49:03.943643: step 9179, loss 0.021116, acc 0.984375\n",
      "2018-04-13T15:49:04.289888: step 9180, loss 0.00114716, acc 1\n",
      "2018-04-13T15:49:04.623624: step 9181, loss 0.00836573, acc 1\n",
      "2018-04-13T15:49:04.952356: step 9182, loss 0.000210071, acc 1\n",
      "2018-04-13T15:49:05.279086: step 9183, loss 6.64187e-06, acc 1\n",
      "2018-04-13T15:49:05.589304: step 9184, loss 0.000304073, acc 1\n",
      "2018-04-13T15:49:05.910031: step 9185, loss 0.000102914, acc 1\n",
      "2018-04-13T15:49:06.260780: step 9186, loss 0.000739216, acc 1\n",
      "2018-04-13T15:49:06.614029: step 9187, loss 6.04481e-05, acc 1\n",
      "2018-04-13T15:49:06.952268: step 9188, loss 0.0017364, acc 1\n",
      "2018-04-13T15:49:07.322529: step 9189, loss 0.000180626, acc 1\n",
      "2018-04-13T15:49:07.659767: step 9190, loss 0.000265405, acc 1\n",
      "2018-04-13T15:49:08.009514: step 9191, loss 0.019792, acc 0.984375\n",
      "2018-04-13T15:49:08.338246: step 9192, loss 1.51268e-05, acc 1\n",
      "2018-04-13T15:49:08.664477: step 9193, loss 3.02102e-05, acc 1\n",
      "2018-04-13T15:49:09.007719: step 9194, loss 6.47975e-05, acc 1\n",
      "2018-04-13T15:49:09.345458: step 9195, loss 0.000225429, acc 1\n",
      "2018-04-13T15:49:09.667184: step 9196, loss 7.89101e-05, acc 1\n",
      "2018-04-13T15:49:10.012428: step 9197, loss 0.000819058, acc 1\n",
      "2018-04-13T15:49:10.345163: step 9198, loss 2.11849e-05, acc 1\n",
      "2018-04-13T15:49:10.692909: step 9199, loss 1.19381e-05, acc 1\n",
      "2018-04-13T15:49:11.009133: step 9200, loss 5.77322e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:49:12.171453: step 9200, loss 2.72745, acc 0.736398\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9200\n",
      "\n",
      "2018-04-13T15:49:14.128335: step 9201, loss 0.000347103, acc 1\n",
      "2018-04-13T15:49:14.446559: step 9202, loss 0.000165504, acc 1\n",
      "2018-04-13T15:49:14.781297: step 9203, loss 7.52396e-05, acc 1\n",
      "2018-04-13T15:49:15.103023: step 9204, loss 0.000473412, acc 1\n",
      "2018-04-13T15:49:15.441262: step 9205, loss 2.79984e-05, acc 1\n",
      "2018-04-13T15:49:15.764991: step 9206, loss 1.76269e-05, acc 1\n",
      "2018-04-13T15:49:16.080714: step 9207, loss 0.00171837, acc 1\n",
      "2018-04-13T15:49:16.399439: step 9208, loss 0.00129542, acc 1\n",
      "2018-04-13T15:49:16.722667: step 9209, loss 5.17636e-05, acc 1\n",
      "2018-04-13T15:49:17.048897: step 9210, loss 0.000336901, acc 1\n",
      "2018-04-13T15:49:17.379130: step 9211, loss 0.000375757, acc 1\n",
      "2018-04-13T15:49:17.696354: step 9212, loss 0.0024212, acc 1\n",
      "2018-04-13T15:49:18.029600: step 9213, loss 2.70995e-05, acc 1\n",
      "2018-04-13T15:49:18.359833: step 9214, loss 0.00049141, acc 1\n",
      "2018-04-13T15:49:18.680559: step 9215, loss 4.57627e-06, acc 1\n",
      "2018-04-13T15:49:18.999785: step 9216, loss 0.000313943, acc 1\n",
      "2018-04-13T15:49:19.314007: step 9217, loss 9.24341e-06, acc 1\n",
      "2018-04-13T15:49:19.630229: step 9218, loss 0.00429242, acc 1\n",
      "2018-04-13T15:49:19.958962: step 9219, loss 6.21517e-06, acc 1\n",
      "2018-04-13T15:49:20.268680: step 9220, loss 0.00193791, acc 1\n",
      "2018-04-13T15:49:20.590407: step 9221, loss 0.000376751, acc 1\n",
      "2018-04-13T15:49:20.924143: step 9222, loss 0.000356338, acc 1\n",
      "2018-04-13T15:49:21.265384: step 9223, loss 4.66459e-05, acc 1\n",
      "2018-04-13T15:49:21.581608: step 9224, loss 0.0295652, acc 0.984375\n",
      "2018-04-13T15:49:21.898831: step 9225, loss 1.54258e-05, acc 1\n",
      "2018-04-13T15:49:22.221559: step 9226, loss 0.0019865, acc 1\n",
      "2018-04-13T15:49:22.549291: step 9227, loss 1.22047e-05, acc 1\n",
      "2018-04-13T15:49:22.874020: step 9228, loss 0.00768908, acc 1\n",
      "2018-04-13T15:49:23.204754: step 9229, loss 0.00226299, acc 1\n",
      "2018-04-13T15:49:23.521978: step 9230, loss 0.000193896, acc 1\n",
      "2018-04-13T15:49:23.856213: step 9231, loss 5.83453e-05, acc 1\n",
      "2018-04-13T15:49:24.233981: step 9232, loss 3.9511e-05, acc 1\n",
      "2018-04-13T15:49:24.571219: step 9233, loss 0.0851052, acc 0.984375\n",
      "2018-04-13T15:49:24.901451: step 9234, loss 0.00172567, acc 1\n",
      "2018-04-13T15:49:25.221177: step 9235, loss 0.000455727, acc 1\n",
      "2018-04-13T15:49:25.534398: step 9236, loss 0.00496734, acc 1\n",
      "2018-04-13T15:49:25.874139: step 9237, loss 0.00130511, acc 1\n",
      "2018-04-13T15:49:26.216880: step 9238, loss 2.94469e-06, acc 1\n",
      "2018-04-13T15:49:26.535606: step 9239, loss 0.00014603, acc 1\n",
      "2018-04-13T15:49:26.857833: step 9240, loss 9.30667e-05, acc 1\n",
      "2018-04-13T15:49:27.199074: step 9241, loss 0.000126755, acc 1\n",
      "2018-04-13T15:49:27.519801: step 9242, loss 0.00171282, acc 1\n",
      "2018-04-13T15:49:27.860541: step 9243, loss 0.00959167, acc 1\n",
      "2018-04-13T15:49:28.182768: step 9244, loss 0.00011723, acc 1\n",
      "2018-04-13T15:49:28.496490: step 9245, loss 0.000153728, acc 1\n",
      "2018-04-13T15:49:28.831227: step 9246, loss 0.00130565, acc 1\n",
      "2018-04-13T15:49:29.151953: step 9247, loss 3.36563e-06, acc 1\n",
      "2018-04-13T15:49:29.466675: step 9248, loss 0.0099488, acc 1\n",
      "2018-04-13T15:49:29.795407: step 9249, loss 0.00777981, acc 1\n",
      "2018-04-13T15:49:30.126642: step 9250, loss 0.000431381, acc 1\n",
      "2018-04-13T15:49:30.483894: step 9251, loss 1.33808e-05, acc 1\n",
      "2018-04-13T15:49:30.805121: step 9252, loss 0.000930976, acc 1\n",
      "2018-04-13T15:49:31.139857: step 9253, loss 0.000412925, acc 1\n",
      "2018-04-13T15:49:31.510119: step 9254, loss 8.73652e-05, acc 1\n",
      "2018-04-13T15:49:31.845355: step 9255, loss 3.62052e-05, acc 1\n",
      "2018-04-13T15:49:32.176589: step 9256, loss 2.78736e-05, acc 1\n",
      "2018-04-13T15:49:32.497816: step 9257, loss 1.73277e-05, acc 1\n",
      "2018-04-13T15:49:32.828549: step 9258, loss 7.99926e-05, acc 1\n",
      "2018-04-13T15:49:33.162785: step 9259, loss 0.00540645, acc 1\n",
      "2018-04-13T15:49:33.502029: step 9260, loss 1.14417e-05, acc 1\n",
      "2018-04-13T15:49:33.835260: step 9261, loss 3.30611e-06, acc 1\n",
      "2018-04-13T15:49:34.169996: step 9262, loss 0.000650965, acc 1\n",
      "2018-04-13T15:49:34.492224: step 9263, loss 0.00038611, acc 1\n",
      "2018-04-13T15:49:34.834466: step 9264, loss 0.000279338, acc 1\n",
      "2018-04-13T15:49:35.153692: step 9265, loss 0.000262931, acc 1\n",
      "2018-04-13T15:49:35.467413: step 9266, loss 0.00214037, acc 1\n",
      "2018-04-13T15:49:35.803650: step 9267, loss 1.50025e-05, acc 1\n",
      "2018-04-13T15:49:36.174912: step 9268, loss 0.000111144, acc 1\n",
      "2018-04-13T15:49:36.520156: step 9269, loss 9.90576e-05, acc 1\n",
      "2018-04-13T15:49:36.845886: step 9270, loss 2.75799e-05, acc 1\n",
      "2018-04-13T15:49:37.163610: step 9271, loss 0.000138353, acc 1\n",
      "2018-04-13T15:49:37.479834: step 9272, loss 0.0046996, acc 1\n",
      "2018-04-13T15:49:37.828080: step 9273, loss 0.000136439, acc 1\n",
      "2018-04-13T15:49:38.148806: step 9274, loss 0.00361331, acc 1\n",
      "2018-04-13T15:49:38.479540: step 9275, loss 0.00295194, acc 1\n",
      "2018-04-13T15:49:38.819779: step 9276, loss 0.00464441, acc 1\n",
      "2018-04-13T15:49:39.159520: step 9277, loss 1.61843e-05, acc 1\n",
      "2018-04-13T15:49:39.506264: step 9278, loss 0.000549013, acc 1\n",
      "2018-04-13T15:49:39.832495: step 9279, loss 0.000831483, acc 1\n",
      "2018-04-13T15:49:40.157724: step 9280, loss 0.00419772, acc 1\n",
      "2018-04-13T15:49:40.479952: step 9281, loss 0.00190061, acc 1\n",
      "2018-04-13T15:49:40.827698: step 9282, loss 0.000292726, acc 1\n",
      "2018-04-13T15:49:41.154428: step 9283, loss 8.59851e-05, acc 1\n",
      "2018-04-13T15:49:41.465648: step 9284, loss 0.00047515, acc 1\n",
      "2018-04-13T15:49:41.791879: step 9285, loss 0.000339742, acc 1\n",
      "2018-04-13T15:49:42.122111: step 9286, loss 0.000146078, acc 1\n",
      "2018-04-13T15:49:42.483866: step 9287, loss 1.2759e-05, acc 1\n",
      "2018-04-13T15:49:42.813099: step 9288, loss 7.17869e-05, acc 1\n",
      "2018-04-13T15:49:43.146335: step 9289, loss 0.000135496, acc 1\n",
      "2018-04-13T15:49:43.468062: step 9290, loss 0.000582532, acc 1\n",
      "2018-04-13T15:49:43.792291: step 9291, loss 7.62417e-05, acc 1\n",
      "2018-04-13T15:49:44.116019: step 9292, loss 0.000136579, acc 1\n",
      "2018-04-13T15:49:44.427739: step 9293, loss 0.00094597, acc 1\n",
      "2018-04-13T15:49:44.740961: step 9294, loss 7.95955e-05, acc 1\n",
      "2018-04-13T15:49:45.070193: step 9295, loss 5.25588e-06, acc 1\n",
      "2018-04-13T15:49:45.420941: step 9296, loss 0.00211965, acc 1\n",
      "2018-04-13T15:49:45.752175: step 9297, loss 0.028671, acc 0.984375\n",
      "2018-04-13T15:49:46.088912: step 9298, loss 0.000167688, acc 1\n",
      "2018-04-13T15:49:46.432655: step 9299, loss 5.49237e-06, acc 1\n",
      "2018-04-13T15:49:46.742874: step 9300, loss 0.00102505, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:49:47.872172: step 9300, loss 2.74971, acc 0.738274\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9300\n",
      "\n",
      "2018-04-13T15:49:49.402752: step 9301, loss 0.000102249, acc 1\n",
      "2018-04-13T15:49:49.722478: step 9302, loss 0.000283959, acc 1\n",
      "2018-04-13T15:49:50.065721: step 9303, loss 4.77368e-06, acc 1\n",
      "2018-04-13T15:49:50.385947: step 9304, loss 0.00119848, acc 1\n",
      "2018-04-13T15:49:50.709174: step 9305, loss 7.67461e-05, acc 1\n",
      "2018-04-13T15:49:51.032903: step 9306, loss 0.000104395, acc 1\n",
      "2018-04-13T15:49:51.375145: step 9307, loss 0.0713806, acc 0.984375\n",
      "2018-04-13T15:49:51.697873: step 9308, loss 0.000543811, acc 1\n",
      "2018-04-13T15:49:52.028106: step 9309, loss 4.09842e-05, acc 1\n",
      "2018-04-13T15:49:52.348833: step 9310, loss 0.00156296, acc 1\n",
      "2018-04-13T15:49:52.676564: step 9311, loss 0.0402062, acc 0.984375\n",
      "2018-04-13T15:49:53.008298: step 9312, loss 0.00141382, acc 1\n",
      "2018-04-13T15:49:53.326023: step 9313, loss 0.00251975, acc 1\n",
      "2018-04-13T15:49:53.659759: step 9314, loss 0.000615073, acc 1\n",
      "2018-04-13T15:49:53.994495: step 9315, loss 2.78644e-06, acc 1\n",
      "2018-04-13T15:49:54.318223: step 9316, loss 3.64138e-06, acc 1\n",
      "2018-04-13T15:49:54.632964: step 9317, loss 0.000110092, acc 1\n",
      "2018-04-13T15:49:54.963699: step 9318, loss 1.69326e-05, acc 1\n",
      "2018-04-13T15:49:55.276418: step 9319, loss 4.95854e-05, acc 1\n",
      "2018-04-13T15:49:55.605651: step 9320, loss 0.000486377, acc 1\n",
      "2018-04-13T15:49:55.955398: step 9321, loss 0.0330656, acc 0.984375\n",
      "2018-04-13T15:49:56.273623: step 9322, loss 2.5649e-05, acc 1\n",
      "2018-04-13T15:49:56.589346: step 9323, loss 0.00269857, acc 1\n",
      "2018-04-13T15:49:56.923581: step 9324, loss 3.15896e-06, acc 1\n",
      "2018-04-13T15:49:57.250813: step 9325, loss 0.000114481, acc 1\n",
      "2018-04-13T15:49:57.571039: step 9326, loss 0.000911932, acc 1\n",
      "2018-04-13T15:49:57.897269: step 9327, loss 0.000108773, acc 1\n",
      "2018-04-13T15:49:58.209489: step 9328, loss 8.05731e-05, acc 1\n",
      "2018-04-13T15:49:58.531717: step 9329, loss 9.45391e-05, acc 1\n",
      "2018-04-13T15:49:58.859450: step 9330, loss 0.000163351, acc 1\n",
      "2018-04-13T15:49:59.186182: step 9331, loss 0.0136228, acc 0.984375\n",
      "2018-04-13T15:49:59.510909: step 9332, loss 0.000121057, acc 1\n",
      "2018-04-13T15:49:59.831636: step 9333, loss 5.90863e-05, acc 1\n",
      "2018-04-13T15:50:00.156865: step 9334, loss 0.000102743, acc 1\n",
      "2018-04-13T15:50:00.500608: step 9335, loss 5.54411e-05, acc 1\n",
      "2018-04-13T15:50:00.856359: step 9336, loss 0.000298948, acc 1\n",
      "2018-04-13T15:50:01.193097: step 9337, loss 0.000235957, acc 1\n",
      "2018-04-13T15:50:01.523330: step 9338, loss 8.87599e-05, acc 1\n",
      "2018-04-13T15:50:01.852562: step 9339, loss 1.35656e-05, acc 1\n",
      "2018-04-13T15:50:02.194803: step 9340, loss 7.21861e-05, acc 1\n",
      "2018-04-13T15:50:02.519033: step 9341, loss 0.000226819, acc 1\n",
      "2018-04-13T15:50:02.873783: step 9342, loss 1.51132e-05, acc 1\n",
      "2018-04-13T15:50:03.201515: step 9343, loss 0.000475836, acc 1\n",
      "2018-04-13T15:50:03.540754: step 9344, loss 0.0011155, acc 1\n",
      "2018-04-13T15:50:03.876992: step 9345, loss 0.000592814, acc 1\n",
      "2018-04-13T15:50:04.195716: step 9346, loss 2.01646e-05, acc 1\n",
      "2018-04-13T15:50:04.505936: step 9347, loss 4.22105e-05, acc 1\n",
      "2018-04-13T15:50:04.834168: step 9348, loss 0.0868649, acc 0.984375\n",
      "2018-04-13T15:50:05.161398: step 9349, loss 1.58717e-05, acc 1\n",
      "2018-04-13T15:50:05.480124: step 9350, loss 4.49778e-06, acc 1\n",
      "2018-04-13T15:50:05.797348: step 9351, loss 2.69051e-05, acc 1\n",
      "2018-04-13T15:50:06.132085: step 9352, loss 3.42718e-06, acc 1\n",
      "2018-04-13T15:50:06.496842: step 9353, loss 0.000213204, acc 1\n",
      "2018-04-13T15:50:06.842586: step 9354, loss 1.91981e-05, acc 1\n",
      "2018-04-13T15:50:07.193834: step 9355, loss 3.80528e-06, acc 1\n",
      "2018-04-13T15:50:07.512558: step 9356, loss 0.000244284, acc 1\n",
      "2018-04-13T15:50:07.848797: step 9357, loss 0.00543839, acc 1\n",
      "2018-04-13T15:50:08.180530: step 9358, loss 0.000138926, acc 1\n",
      "2018-04-13T15:50:08.510764: step 9359, loss 0.000635885, acc 1\n",
      "2018-04-13T15:50:08.841498: step 9360, loss 0.000982161, acc 1\n",
      "2018-04-13T15:50:09.193246: step 9361, loss 0.00147847, acc 1\n",
      "2018-04-13T15:50:09.555501: step 9362, loss 0.00618575, acc 1\n",
      "2018-04-13T15:50:09.898744: step 9363, loss 0.000205326, acc 1\n",
      "2018-04-13T15:50:10.248491: step 9364, loss 0.000305036, acc 1\n",
      "2018-04-13T15:50:10.571218: step 9365, loss 6.74008e-06, acc 1\n",
      "2018-04-13T15:50:10.891445: step 9366, loss 9.2209e-06, acc 1\n",
      "2018-04-13T15:50:11.202164: step 9367, loss 0.00284108, acc 1\n",
      "2018-04-13T15:50:11.526893: step 9368, loss 0.000182878, acc 1\n",
      "2018-04-13T15:50:11.876140: step 9369, loss 1.88154e-05, acc 1\n",
      "2018-04-13T15:50:12.228388: step 9370, loss 0.000283698, acc 1\n",
      "2018-04-13T15:50:12.594647: step 9371, loss 2.73985e-06, acc 1\n",
      "2018-04-13T15:50:12.932386: step 9372, loss 0.000185252, acc 1\n",
      "2018-04-13T15:50:13.262128: step 9373, loss 1.1588e-05, acc 1\n",
      "2018-04-13T15:50:13.602359: step 9374, loss 6.42215e-06, acc 1\n",
      "2018-04-13T15:50:13.939098: step 9375, loss 7.80477e-05, acc 1\n",
      "2018-04-13T15:50:14.261324: step 9376, loss 0.000149942, acc 1\n",
      "2018-04-13T15:50:14.592058: step 9377, loss 0.000108177, acc 1\n",
      "2018-04-13T15:50:14.909282: step 9378, loss 0.000924204, acc 1\n",
      "2018-04-13T15:50:15.249522: step 9379, loss 0.00365599, acc 1\n",
      "2018-04-13T15:50:15.606274: step 9380, loss 0.00581706, acc 1\n",
      "2018-04-13T15:50:15.936007: step 9381, loss 0.00024702, acc 1\n",
      "2018-04-13T15:50:16.262237: step 9382, loss 0.0020459, acc 1\n",
      "2018-04-13T15:50:16.585973: step 9383, loss 0.00058403, acc 1\n",
      "2018-04-13T15:50:16.918208: step 9384, loss 0.00242129, acc 1\n",
      "2018-04-13T15:50:17.239935: step 9385, loss 0.000827036, acc 1\n",
      "2018-04-13T15:50:17.579675: step 9386, loss 6.67067e-05, acc 1\n",
      "2018-04-13T15:50:17.939429: step 9387, loss 2.80786e-05, acc 1\n",
      "2018-04-13T15:50:18.273665: step 9388, loss 9.42036e-06, acc 1\n",
      "2018-04-13T15:50:18.610903: step 9389, loss 0.000142404, acc 1\n",
      "2018-04-13T15:50:18.931629: step 9390, loss 0.00232358, acc 1\n",
      "2018-04-13T15:50:19.265366: step 9391, loss 0.00020562, acc 1\n",
      "2018-04-13T15:50:19.591096: step 9392, loss 0.000139402, acc 1\n",
      "2018-04-13T15:50:19.926832: step 9393, loss 4.06052e-05, acc 1\n",
      "2018-04-13T15:50:20.261574: step 9394, loss 0.00405755, acc 1\n",
      "2018-04-13T15:50:20.570789: step 9395, loss 0.000118469, acc 1\n",
      "2018-04-13T15:50:20.890013: step 9396, loss 6.53477e-05, acc 1\n",
      "2018-04-13T15:50:21.209739: step 9397, loss 0.00355846, acc 1\n",
      "2018-04-13T15:50:21.576998: step 9398, loss 0.000121809, acc 1\n",
      "2018-04-13T15:50:21.906230: step 9399, loss 0.00922425, acc 1\n",
      "2018-04-13T15:50:22.227957: step 9400, loss 4.87331e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:50:23.396783: step 9400, loss 2.81169, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9400\n",
      "\n",
      "2018-04-13T15:50:25.196553: step 9401, loss 0.000441358, acc 1\n",
      "2018-04-13T15:50:25.524785: step 9402, loss 2.45489e-05, acc 1\n",
      "2018-04-13T15:50:25.844511: step 9403, loss 0.000164821, acc 1\n",
      "2018-04-13T15:50:26.169241: step 9404, loss 2.97463e-05, acc 1\n",
      "2018-04-13T15:50:26.503976: step 9405, loss 0.000153308, acc 1\n",
      "2018-04-13T15:50:26.837213: step 9406, loss 0.000603187, acc 1\n",
      "2018-04-13T15:50:27.171448: step 9407, loss 0.00373154, acc 1\n",
      "2018-04-13T15:50:27.514191: step 9408, loss 0.000234899, acc 1\n",
      "2018-04-13T15:50:27.834916: step 9409, loss 0.000499762, acc 1\n",
      "2018-04-13T15:50:28.156143: step 9410, loss 1.48146e-05, acc 1\n",
      "2018-04-13T15:50:28.466362: step 9411, loss 6.40452e-06, acc 1\n",
      "2018-04-13T15:50:28.785587: step 9412, loss 3.65728e-05, acc 1\n",
      "2018-04-13T15:50:29.110817: step 9413, loss 0.000492153, acc 1\n",
      "2018-04-13T15:50:29.444052: step 9414, loss 5.00511e-05, acc 1\n",
      "2018-04-13T15:50:29.769783: step 9415, loss 0.00207875, acc 1\n",
      "2018-04-13T15:50:30.097014: step 9416, loss 0.00017339, acc 1\n",
      "2018-04-13T15:50:30.453765: step 9417, loss 0.000184901, acc 1\n",
      "2018-04-13T15:50:30.790003: step 9418, loss 1.50205e-05, acc 1\n",
      "2018-04-13T15:50:31.100222: step 9419, loss 1.68553e-05, acc 1\n",
      "2018-04-13T15:50:31.419947: step 9420, loss 8.49058e-05, acc 1\n",
      "2018-04-13T15:50:31.738673: step 9421, loss 0.0226381, acc 0.984375\n",
      "2018-04-13T15:50:32.079413: step 9422, loss 0.00651524, acc 1\n",
      "2018-04-13T15:50:32.394136: step 9423, loss 1.94815e-05, acc 1\n",
      "2018-04-13T15:50:32.700853: step 9424, loss 0.00106089, acc 1\n",
      "2018-04-13T15:50:33.038091: step 9425, loss 0.000443573, acc 1\n",
      "2018-04-13T15:50:33.378331: step 9426, loss 3.69715e-06, acc 1\n",
      "2018-04-13T15:50:33.709565: step 9427, loss 0.000266811, acc 1\n",
      "2018-04-13T15:50:34.049806: step 9428, loss 5.65745e-05, acc 1\n",
      "2018-04-13T15:50:34.365027: step 9429, loss 3.7843e-05, acc 1\n",
      "2018-04-13T15:50:34.687255: step 9430, loss 0.00159714, acc 1\n",
      "2018-04-13T15:50:35.015987: step 9431, loss 9.61596e-05, acc 1\n",
      "2018-04-13T15:50:35.333210: step 9432, loss 0.000237182, acc 1\n",
      "2018-04-13T15:50:35.666947: step 9433, loss 0.0249837, acc 0.96875\n",
      "2018-04-13T15:50:35.986672: step 9434, loss 9.22808e-05, acc 1\n",
      "2018-04-13T15:50:36.314404: step 9435, loss 0.000680223, acc 1\n",
      "2018-04-13T15:50:36.643648: step 9436, loss 8.65189e-05, acc 1\n",
      "2018-04-13T15:50:36.958370: step 9437, loss 0.000252278, acc 1\n",
      "2018-04-13T15:50:37.267088: step 9438, loss 5.84288e-06, acc 1\n",
      "2018-04-13T15:50:37.581310: step 9439, loss 9.53969e-05, acc 1\n",
      "2018-04-13T15:50:37.912044: step 9440, loss 0.000219465, acc 1\n",
      "2018-04-13T15:50:38.234772: step 9441, loss 6.96232e-06, acc 1\n",
      "2018-04-13T15:50:38.548493: step 9442, loss 0.000453527, acc 1\n",
      "2018-04-13T15:50:38.871722: step 9443, loss 8.94414e-05, acc 1\n",
      "2018-04-13T15:50:39.184442: step 9444, loss 0.000786362, acc 1\n",
      "2018-04-13T15:50:39.527685: step 9445, loss 0.00104065, acc 1\n",
      "2018-04-13T15:50:39.844909: step 9446, loss 3.18696e-05, acc 1\n",
      "2018-04-13T15:50:40.188151: step 9447, loss 0.00163026, acc 1\n",
      "2018-04-13T15:50:40.511880: step 9448, loss 0.0117085, acc 1\n",
      "2018-04-13T15:50:40.837109: step 9449, loss 0.00179573, acc 1\n",
      "2018-04-13T15:50:41.158836: step 9450, loss 0.00175154, acc 1\n",
      "2018-04-13T15:50:41.500077: step 9451, loss 1.16776e-05, acc 1\n",
      "2018-04-13T15:50:41.822805: step 9452, loss 2.18429e-05, acc 1\n",
      "2018-04-13T15:50:42.138528: step 9453, loss 0.00012242, acc 1\n",
      "2018-04-13T15:50:42.470262: step 9454, loss 0.000100998, acc 1\n",
      "2018-04-13T15:50:42.785484: step 9455, loss 0.000214991, acc 1\n",
      "2018-04-13T15:50:43.097705: step 9456, loss 0.000179973, acc 1\n",
      "2018-04-13T15:50:43.400920: step 9457, loss 0.000136707, acc 1\n",
      "2018-04-13T15:50:43.705635: step 9458, loss 0.000636262, acc 1\n",
      "2018-04-13T15:50:44.011851: step 9459, loss 0.000282471, acc 1\n",
      "2018-04-13T15:50:44.324571: step 9460, loss 3.72824e-05, acc 1\n",
      "2018-04-13T15:50:44.635291: step 9461, loss 7.60388e-05, acc 1\n",
      "2018-04-13T15:50:44.970027: step 9462, loss 0.00269934, acc 1\n",
      "2018-04-13T15:50:45.302762: step 9463, loss 5.73009e-05, acc 1\n",
      "2018-04-13T15:50:45.638000: step 9464, loss 0.000125876, acc 1\n",
      "2018-04-13T15:50:45.958725: step 9465, loss 0.00249599, acc 1\n",
      "2018-04-13T15:50:46.277951: step 9466, loss 3.19608e-05, acc 1\n",
      "2018-04-13T15:50:46.594675: step 9467, loss 7.44807e-05, acc 1\n",
      "2018-04-13T15:50:46.916901: step 9468, loss 2.57037e-05, acc 1\n",
      "2018-04-13T15:50:47.247137: step 9469, loss 0.000142616, acc 1\n",
      "2018-04-13T15:50:47.565359: step 9470, loss 4.5501e-05, acc 1\n",
      "2018-04-13T15:50:47.882584: step 9471, loss 0.00165509, acc 1\n",
      "2018-04-13T15:50:48.196806: step 9472, loss 4.23727e-05, acc 1\n",
      "2018-04-13T15:50:48.539548: step 9473, loss 0.0120067, acc 0.984375\n",
      "2018-04-13T15:50:48.887293: step 9474, loss 0.000937683, acc 1\n",
      "2018-04-13T15:50:49.202016: step 9475, loss 0.000199888, acc 1\n",
      "2018-04-13T15:50:49.527745: step 9476, loss 1.43261e-05, acc 1\n",
      "2018-04-13T15:50:49.846471: step 9477, loss 0.000256665, acc 1\n",
      "2018-04-13T15:50:50.183209: step 9478, loss 0.00180535, acc 1\n",
      "2018-04-13T15:50:50.506937: step 9479, loss 0.000992531, acc 1\n",
      "2018-04-13T15:50:50.833167: step 9480, loss 0.000900715, acc 1\n",
      "2018-04-13T15:50:51.154894: step 9481, loss 3.73701e-05, acc 1\n",
      "2018-04-13T15:50:51.484127: step 9482, loss 0.000873652, acc 1\n",
      "2018-04-13T15:50:51.874903: step 9483, loss 0.000281788, acc 1\n",
      "2018-04-13T15:50:52.191627: step 9484, loss 0.000364635, acc 1\n",
      "2018-04-13T15:50:52.507349: step 9485, loss 6.49826e-05, acc 1\n",
      "2018-04-13T15:50:52.833580: step 9486, loss 0.000495158, acc 1\n",
      "2018-04-13T15:50:53.164313: step 9487, loss 5.27106e-05, acc 1\n",
      "2018-04-13T15:50:53.483539: step 9488, loss 7.56226e-07, acc 1\n",
      "2018-04-13T15:50:53.800262: step 9489, loss 0.000266596, acc 1\n",
      "2018-04-13T15:50:54.117486: step 9490, loss 0.000175263, acc 1\n",
      "2018-04-13T15:50:54.450722: step 9491, loss 6.86712e-06, acc 1\n",
      "2018-04-13T15:50:54.781455: step 9492, loss 0.000159906, acc 1\n",
      "2018-04-13T15:50:55.103683: step 9493, loss 7.83637e-05, acc 1\n",
      "2018-04-13T15:50:55.413902: step 9494, loss 0.000125527, acc 1\n",
      "2018-04-13T15:50:55.724621: step 9495, loss 0.000197619, acc 1\n",
      "2018-04-13T15:50:56.059858: step 9496, loss 0.001314, acc 1\n",
      "2018-04-13T15:50:56.392092: step 9497, loss 0.00048588, acc 1\n",
      "2018-04-13T15:50:56.707816: step 9498, loss 1.75777e-05, acc 1\n",
      "2018-04-13T15:50:57.039050: step 9499, loss 0.024932, acc 0.984375\n",
      "2018-04-13T15:50:57.386294: step 9500, loss 5.42238e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:50:58.520096: step 9500, loss 2.82346, acc 0.73546\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9500\n",
      "\n",
      "2018-04-13T15:51:00.218295: step 9501, loss 2.69143e-06, acc 1\n",
      "2018-04-13T15:51:00.568042: step 9502, loss 8.91504e-05, acc 1\n",
      "2018-04-13T15:51:00.886266: step 9503, loss 0.000307141, acc 1\n",
      "2018-04-13T15:51:01.218500: step 9504, loss 0.0223222, acc 0.984375\n",
      "2018-04-13T15:51:01.543731: step 9505, loss 0.00253885, acc 1\n",
      "2018-04-13T15:51:01.884971: step 9506, loss 4.84447e-05, acc 1\n",
      "2018-04-13T15:51:02.209701: step 9507, loss 0.00219641, acc 1\n",
      "2018-04-13T15:51:02.537932: step 9508, loss 0.000100502, acc 1\n",
      "2018-04-13T15:51:02.859660: step 9509, loss 0.00295253, acc 1\n",
      "2018-04-13T15:51:03.183888: step 9510, loss 4.31463e-05, acc 1\n",
      "2018-04-13T15:51:03.540640: step 9511, loss 0.000267764, acc 1\n",
      "2018-04-13T15:51:03.870874: step 9512, loss 1.46626e-05, acc 1\n",
      "2018-04-13T15:51:04.188130: step 9513, loss 0.000855244, acc 1\n",
      "2018-04-13T15:51:04.499349: step 9514, loss 0.000102564, acc 1\n",
      "2018-04-13T15:51:04.816573: step 9515, loss 0.000609194, acc 1\n",
      "2018-04-13T15:51:05.137801: step 9516, loss 0.0001999, acc 1\n",
      "2018-04-13T15:51:05.477040: step 9517, loss 5.48138e-06, acc 1\n",
      "2018-04-13T15:51:05.810275: step 9518, loss 0.00479395, acc 1\n",
      "2018-04-13T15:51:06.139508: step 9519, loss 6.83056e-05, acc 1\n",
      "2018-04-13T15:51:06.479750: step 9520, loss 0.000678232, acc 1\n",
      "2018-04-13T15:51:06.805978: step 9521, loss 1.55308e-05, acc 1\n",
      "2018-04-13T15:51:07.133210: step 9522, loss 0.000246285, acc 1\n",
      "2018-04-13T15:51:07.446931: step 9523, loss 3.89995e-05, acc 1\n",
      "2018-04-13T15:51:07.766658: step 9524, loss 0.000115131, acc 1\n",
      "2018-04-13T15:51:08.084881: step 9525, loss 0.00315633, acc 1\n",
      "2018-04-13T15:51:08.400605: step 9526, loss 0.00981586, acc 1\n",
      "2018-04-13T15:51:08.720331: step 9527, loss 0.0229582, acc 0.984375\n",
      "2018-04-13T15:51:09.046060: step 9528, loss 0.000106809, acc 1\n",
      "2018-04-13T15:51:09.374295: step 9529, loss 0.00207705, acc 1\n",
      "2018-04-13T15:51:09.711030: step 9530, loss 0.00359574, acc 1\n",
      "2018-04-13T15:51:10.039762: step 9531, loss 2.03956e-06, acc 1\n",
      "2018-04-13T15:51:10.356485: step 9532, loss 9.49108e-05, acc 1\n",
      "2018-04-13T15:51:10.680214: step 9533, loss 0.000324362, acc 1\n",
      "2018-04-13T15:51:11.001441: step 9534, loss 0.0045417, acc 1\n",
      "2018-04-13T15:51:11.326671: step 9535, loss 0.000316718, acc 1\n",
      "2018-04-13T15:51:11.636893: step 9536, loss 0.000133719, acc 1\n",
      "2018-04-13T15:51:11.960618: step 9537, loss 1.55404e-05, acc 1\n",
      "2018-04-13T15:51:12.277842: step 9538, loss 2.4918e-05, acc 1\n",
      "2018-04-13T15:51:12.632593: step 9539, loss 0.000182918, acc 1\n",
      "2018-04-13T15:51:12.969331: step 9540, loss 8.31628e-05, acc 1\n",
      "2018-04-13T15:51:13.290557: step 9541, loss 0.00153776, acc 1\n",
      "2018-04-13T15:51:13.609283: step 9542, loss 6.8951e-06, acc 1\n",
      "2018-04-13T15:51:13.929509: step 9543, loss 0.0046644, acc 1\n",
      "2018-04-13T15:51:14.261243: step 9544, loss 0.00192113, acc 1\n",
      "2018-04-13T15:51:14.579968: step 9545, loss 0.000203732, acc 1\n",
      "2018-04-13T15:51:14.910201: step 9546, loss 0.0299279, acc 0.984375\n",
      "2018-04-13T15:51:15.235430: step 9547, loss 0.0122688, acc 0.984375\n",
      "2018-04-13T15:51:15.585678: step 9548, loss 4.90544e-05, acc 1\n",
      "2018-04-13T15:51:15.903903: step 9549, loss 0.000253545, acc 1\n",
      "2018-04-13T15:51:16.221627: step 9550, loss 0.00106464, acc 1\n",
      "2018-04-13T15:51:16.551861: step 9551, loss 0.00964615, acc 1\n",
      "2018-04-13T15:51:16.879593: step 9552, loss 0.000484866, acc 1\n",
      "2018-04-13T15:51:17.198817: step 9553, loss 0.000311284, acc 1\n",
      "2018-04-13T15:51:17.524547: step 9554, loss 0.000325079, acc 1\n",
      "2018-04-13T15:51:17.847275: step 9555, loss 0.00124795, acc 1\n",
      "2018-04-13T15:51:18.169503: step 9556, loss 0.0252328, acc 0.984375\n",
      "2018-04-13T15:51:18.516247: step 9557, loss 0.000687113, acc 1\n",
      "2018-04-13T15:51:18.840977: step 9558, loss 0.045399, acc 0.96875\n",
      "2018-04-13T15:51:19.170710: step 9559, loss 0.000146129, acc 1\n",
      "2018-04-13T15:51:19.488434: step 9560, loss 4.88249e-05, acc 1\n",
      "2018-04-13T15:51:19.807159: step 9561, loss 0.00019221, acc 1\n",
      "2018-04-13T15:51:20.142395: step 9562, loss 0.000153428, acc 1\n",
      "2018-04-13T15:51:20.487139: step 9563, loss 0.000272891, acc 1\n",
      "2018-04-13T15:51:20.808366: step 9564, loss 2.02638e-05, acc 1\n",
      "2018-04-13T15:51:21.123588: step 9565, loss 2.36822e-05, acc 1\n",
      "2018-04-13T15:51:21.463328: step 9566, loss 0.000247346, acc 1\n",
      "2018-04-13T15:51:21.801567: step 9567, loss 8.28276e-06, acc 1\n",
      "2018-04-13T15:51:22.108283: step 9568, loss 0.000345896, acc 1\n",
      "2018-04-13T15:51:22.432012: step 9569, loss 9.83467e-05, acc 1\n",
      "2018-04-13T15:51:22.773253: step 9570, loss 0.000501074, acc 1\n",
      "2018-04-13T15:51:23.103486: step 9571, loss 0.000484978, acc 1\n",
      "2018-04-13T15:51:23.487758: step 9572, loss 0.000675076, acc 1\n",
      "2018-04-13T15:51:23.821494: step 9573, loss 0.00227913, acc 1\n",
      "2018-04-13T15:51:24.149224: step 9574, loss 1.09336e-06, acc 1\n",
      "2018-04-13T15:51:24.479458: step 9575, loss 3.24971e-05, acc 1\n",
      "2018-04-13T15:51:24.828204: step 9576, loss 0.000151689, acc 1\n",
      "2018-04-13T15:51:25.149431: step 9577, loss 5.24509e-05, acc 1\n",
      "2018-04-13T15:51:25.469156: step 9578, loss 0.000170269, acc 1\n",
      "2018-04-13T15:51:25.794387: step 9579, loss 0.000108711, acc 1\n",
      "2018-04-13T15:51:26.115113: step 9580, loss 0.0158573, acc 0.984375\n",
      "2018-04-13T15:51:26.441844: step 9581, loss 0.000197023, acc 1\n",
      "2018-04-13T15:51:26.770075: step 9582, loss 7.54304e-06, acc 1\n",
      "2018-04-13T15:51:27.093804: step 9583, loss 0.000233882, acc 1\n",
      "2018-04-13T15:51:27.433545: step 9584, loss 0.000220809, acc 1\n",
      "2018-04-13T15:51:27.794799: step 9585, loss 0.000357366, acc 1\n",
      "2018-04-13T15:51:28.118028: step 9586, loss 0.000154852, acc 1\n",
      "2018-04-13T15:51:28.436252: step 9587, loss 0.000234299, acc 1\n",
      "2018-04-13T15:51:28.753476: step 9588, loss 6.82859e-05, acc 1\n",
      "2018-04-13T15:51:29.076204: step 9589, loss 2.08692e-05, acc 1\n",
      "2018-04-13T15:51:29.399932: step 9590, loss 0.00034825, acc 1\n",
      "2018-04-13T15:51:29.718158: step 9591, loss 4.72995e-05, acc 1\n",
      "2018-04-13T15:51:30.027375: step 9592, loss 0.000975029, acc 1\n",
      "2018-04-13T15:51:30.356609: step 9593, loss 0.00226686, acc 1\n",
      "2018-04-13T15:51:30.693346: step 9594, loss 0.000186254, acc 1\n",
      "2018-04-13T15:51:31.021078: step 9595, loss 0.00173148, acc 1\n",
      "2018-04-13T15:51:31.359820: step 9596, loss 0.00602458, acc 1\n",
      "2018-04-13T15:51:31.677040: step 9597, loss 0.000741802, acc 1\n",
      "2018-04-13T15:51:32.001269: step 9598, loss 0.000386145, acc 1\n",
      "2018-04-13T15:51:32.323503: step 9599, loss 0.00227641, acc 1\n",
      "2018-04-13T15:51:32.639726: step 9600, loss 0.00207119, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:51:33.815556: step 9600, loss 2.91349, acc 0.731707\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9600\n",
      "\n",
      "2018-04-13T15:51:35.663361: step 9601, loss 3.27065e-06, acc 1\n",
      "2018-04-13T15:51:35.981086: step 9602, loss 3.01731e-06, acc 1\n",
      "2018-04-13T15:51:36.291805: step 9603, loss 5.57439e-05, acc 1\n",
      "2018-04-13T15:51:36.651566: step 9604, loss 3.5632e-05, acc 1\n",
      "2018-04-13T15:51:36.964279: step 9605, loss 0.000390109, acc 1\n",
      "2018-04-13T15:51:37.283505: step 9606, loss 0.000353174, acc 1\n",
      "2018-04-13T15:51:37.596727: step 9607, loss 1.94821e-06, acc 1\n",
      "2018-04-13T15:51:37.942470: step 9608, loss 0.000127978, acc 1\n",
      "2018-04-13T15:51:38.270202: step 9609, loss 0.000329107, acc 1\n",
      "2018-04-13T15:51:38.590427: step 9610, loss 3.60339e-05, acc 1\n",
      "2018-04-13T15:51:38.919660: step 9611, loss 8.64268e-05, acc 1\n",
      "2018-04-13T15:51:39.239886: step 9612, loss 0.0022382, acc 1\n",
      "2018-04-13T15:51:39.568619: step 9613, loss 0.00075397, acc 1\n",
      "2018-04-13T15:51:39.887844: step 9614, loss 3.4634e-05, acc 1\n",
      "2018-04-13T15:51:40.202066: step 9615, loss 0.000173496, acc 1\n",
      "2018-04-13T15:51:40.538804: step 9616, loss 0.000536408, acc 1\n",
      "2018-04-13T15:51:40.867536: step 9617, loss 4.18575e-05, acc 1\n",
      "2018-04-13T15:51:41.187262: step 9618, loss 0.00104092, acc 1\n",
      "2018-04-13T15:51:41.511490: step 9619, loss 0.000135727, acc 1\n",
      "2018-04-13T15:51:41.828214: step 9620, loss 1.82777e-05, acc 1\n",
      "2018-04-13T15:51:42.142936: step 9621, loss 0.000185865, acc 1\n",
      "2018-04-13T15:51:42.457158: step 9622, loss 0.00070264, acc 1\n",
      "2018-04-13T15:51:42.799900: step 9623, loss 7.69232e-06, acc 1\n",
      "2018-04-13T15:51:43.114122: step 9624, loss 5.55764e-05, acc 1\n",
      "2018-04-13T15:51:43.433848: step 9625, loss 1.75499e-05, acc 1\n",
      "2018-04-13T15:51:43.746068: step 9626, loss 0.000306858, acc 1\n",
      "2018-04-13T15:51:44.060290: step 9627, loss 0.00040978, acc 1\n",
      "2018-04-13T15:51:44.397028: step 9628, loss 2.00818e-05, acc 1\n",
      "2018-04-13T15:51:44.721258: step 9629, loss 5.10312e-06, acc 1\n",
      "2018-04-13T15:51:45.038981: step 9630, loss 0.000117843, acc 1\n",
      "2018-04-13T15:51:45.350702: step 9631, loss 0.000133583, acc 1\n",
      "2018-04-13T15:51:45.703951: step 9632, loss 0.000419784, acc 1\n",
      "2018-04-13T15:51:46.030682: step 9633, loss 0.000610013, acc 1\n",
      "2018-04-13T15:51:46.348406: step 9634, loss 0.000394873, acc 1\n",
      "2018-04-13T15:51:46.672134: step 9635, loss 5.54903e-05, acc 1\n",
      "2018-04-13T15:51:46.988357: step 9636, loss 0.00019065, acc 1\n",
      "2018-04-13T15:51:47.368126: step 9637, loss 0.00145274, acc 1\n",
      "2018-04-13T15:51:47.712374: step 9638, loss 0.000110265, acc 1\n",
      "2018-04-13T15:51:48.077234: step 9639, loss 9.74653e-05, acc 1\n",
      "2018-04-13T15:51:48.441492: step 9640, loss 8.08113e-06, acc 1\n",
      "2018-04-13T15:51:48.803248: step 9641, loss 0.000305357, acc 1\n",
      "2018-04-13T15:51:49.144988: step 9642, loss 0.000116124, acc 1\n",
      "2018-04-13T15:51:49.486229: step 9643, loss 0.000100024, acc 1\n",
      "2018-04-13T15:51:49.808957: step 9644, loss 8.85751e-06, acc 1\n",
      "2018-04-13T15:51:50.139191: step 9645, loss 3.87429e-07, acc 1\n",
      "2018-04-13T15:51:50.471426: step 9646, loss 6.58405e-06, acc 1\n",
      "2018-04-13T15:51:50.799658: step 9647, loss 9.95037e-06, acc 1\n",
      "2018-04-13T15:51:51.129390: step 9648, loss 0.00166165, acc 1\n",
      "2018-04-13T15:51:51.434105: step 9649, loss 2.4011e-05, acc 1\n",
      "2018-04-13T15:51:51.789857: step 9650, loss 0.000159678, acc 1\n",
      "2018-04-13T15:51:52.127595: step 9651, loss 0.00014845, acc 1\n",
      "2018-04-13T15:51:52.457828: step 9652, loss 0.000291783, acc 1\n",
      "2018-04-13T15:51:52.776552: step 9653, loss 0.000161872, acc 1\n",
      "2018-04-13T15:51:53.099281: step 9654, loss 1.79039e-05, acc 1\n",
      "2018-04-13T15:51:53.432516: step 9655, loss 0.000163455, acc 1\n",
      "2018-04-13T15:51:53.747739: step 9656, loss 7.47386e-05, acc 1\n",
      "2018-04-13T15:51:54.072468: step 9657, loss 7.49732e-05, acc 1\n",
      "2018-04-13T15:51:54.401200: step 9658, loss 7.81752e-05, acc 1\n",
      "2018-04-13T15:51:54.769460: step 9659, loss 0.0231417, acc 0.984375\n",
      "2018-04-13T15:51:55.106698: step 9660, loss 0.00146506, acc 1\n",
      "2018-04-13T15:51:55.423422: step 9661, loss 2.76583e-05, acc 1\n",
      "2018-04-13T15:51:55.745659: step 9662, loss 0.00100398, acc 1\n",
      "2018-04-13T15:51:56.088391: step 9663, loss 3.06583e-06, acc 1\n",
      "2018-04-13T15:51:56.409618: step 9664, loss 0.000241243, acc 1\n",
      "2018-04-13T15:51:56.732346: step 9665, loss 0.000453174, acc 1\n",
      "2018-04-13T15:51:57.065082: step 9666, loss 1.42675e-06, acc 1\n",
      "2018-04-13T15:51:57.388309: step 9667, loss 3.44732e-05, acc 1\n",
      "2018-04-13T15:51:57.748564: step 9668, loss 2.3973e-05, acc 1\n",
      "2018-04-13T15:51:58.062285: step 9669, loss 0.000114769, acc 1\n",
      "2018-04-13T15:51:58.378008: step 9670, loss 0.000408841, acc 1\n",
      "2018-04-13T15:51:58.701737: step 9671, loss 0.00223538, acc 1\n",
      "2018-04-13T15:51:59.014958: step 9672, loss 0.00312462, acc 1\n",
      "2018-04-13T15:51:59.341689: step 9673, loss 0.000656104, acc 1\n",
      "2018-04-13T15:51:59.673924: step 9674, loss 0.063743, acc 0.984375\n",
      "2018-04-13T15:52:00.019167: step 9675, loss 0.0129547, acc 0.984375\n",
      "2018-04-13T15:52:00.341396: step 9676, loss 0.000410819, acc 1\n",
      "2018-04-13T15:52:00.694645: step 9677, loss 1.85255e-05, acc 1\n",
      "2018-04-13T15:52:01.019373: step 9678, loss 0.000224617, acc 1\n",
      "2018-04-13T15:52:01.351108: step 9679, loss 0.00010111, acc 1\n",
      "2018-04-13T15:52:01.677838: step 9680, loss 1.51694e-05, acc 1\n",
      "2018-04-13T15:52:02.030587: step 9681, loss 2.96716e-05, acc 1\n",
      "2018-04-13T15:52:02.376831: step 9682, loss 6.54343e-05, acc 1\n",
      "2018-04-13T15:52:02.719074: step 9683, loss 4.27944e-05, acc 1\n",
      "2018-04-13T15:52:03.042802: step 9684, loss 8.63858e-05, acc 1\n",
      "2018-04-13T15:52:03.355023: step 9685, loss 0.00037683, acc 1\n",
      "2018-04-13T15:52:03.738794: step 9686, loss 0.00135801, acc 1\n",
      "2018-04-13T15:52:04.080035: step 9687, loss 0.000152368, acc 1\n",
      "2018-04-13T15:52:04.389753: step 9688, loss 0.00362198, acc 1\n",
      "2018-04-13T15:52:04.709979: step 9689, loss 0.00122753, acc 1\n",
      "2018-04-13T15:52:05.026703: step 9690, loss 8.79601e-05, acc 1\n",
      "2018-04-13T15:52:05.349933: step 9691, loss 0.00159046, acc 1\n",
      "2018-04-13T15:52:05.672659: step 9692, loss 2.51573e-05, acc 1\n",
      "2018-04-13T15:52:06.002392: step 9693, loss 0.0049733, acc 1\n",
      "2018-04-13T15:52:06.326621: step 9694, loss 2.22619e-05, acc 1\n",
      "2018-04-13T15:52:06.674867: step 9695, loss 0.00363512, acc 1\n",
      "2018-04-13T15:52:07.005100: step 9696, loss 0.000102498, acc 1\n",
      "2018-04-13T15:52:07.324826: step 9697, loss 0.00188148, acc 1\n",
      "2018-04-13T15:52:07.659562: step 9698, loss 0.0220919, acc 0.984375\n",
      "2018-04-13T15:52:08.001804: step 9699, loss 2.97996e-05, acc 1\n",
      "2018-04-13T15:52:08.374567: step 9700, loss 0.000958079, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:52:09.599432: step 9700, loss 2.84653, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9700\n",
      "\n",
      "2018-04-13T15:52:11.224079: step 9701, loss 0.00018493, acc 1\n",
      "2018-04-13T15:52:11.568822: step 9702, loss 2.33644e-05, acc 1\n",
      "2018-04-13T15:52:11.893552: step 9703, loss 5.43296e-05, acc 1\n",
      "2018-04-13T15:52:12.226288: step 9704, loss 0.000836867, acc 1\n",
      "2018-04-13T15:52:12.552517: step 9705, loss 3.28876e-05, acc 1\n",
      "2018-04-13T15:52:12.893258: step 9706, loss 3.69315e-05, acc 1\n",
      "2018-04-13T15:52:13.219988: step 9707, loss 0.00519724, acc 1\n",
      "2018-04-13T15:52:13.593252: step 9708, loss 8.42477e-05, acc 1\n",
      "2018-04-13T15:52:13.961512: step 9709, loss 0.00136744, acc 1\n",
      "2018-04-13T15:52:14.289745: step 9710, loss 0.000119709, acc 1\n",
      "2018-04-13T15:52:14.620978: step 9711, loss 0.0145104, acc 0.984375\n",
      "2018-04-13T15:52:14.971225: step 9712, loss 0.00367389, acc 1\n",
      "2018-04-13T15:52:15.291951: step 9713, loss 5.76395e-05, acc 1\n",
      "2018-04-13T15:52:15.621685: step 9714, loss 2.03394e-05, acc 1\n",
      "2018-04-13T15:52:15.961925: step 9715, loss 8.27079e-06, acc 1\n",
      "2018-04-13T15:52:16.280650: step 9716, loss 0.000158079, acc 1\n",
      "2018-04-13T15:52:16.600875: step 9717, loss 2.45103e-05, acc 1\n",
      "2018-04-13T15:52:16.927106: step 9718, loss 4.35394e-05, acc 1\n",
      "2018-04-13T15:52:17.245331: step 9719, loss 0.000794133, acc 1\n",
      "2018-04-13T15:52:17.578566: step 9720, loss 0.000465027, acc 1\n",
      "2018-04-13T15:52:17.904796: step 9721, loss 9.01153e-06, acc 1\n",
      "2018-04-13T15:52:18.229526: step 9722, loss 0.000249559, acc 1\n",
      "2018-04-13T15:52:18.546749: step 9723, loss 3.82161e-05, acc 1\n",
      "2018-04-13T15:52:18.881986: step 9724, loss 0.00130425, acc 1\n",
      "2018-04-13T15:52:19.211218: step 9725, loss 0.00408489, acc 1\n",
      "2018-04-13T15:52:19.523940: step 9726, loss 0.000336836, acc 1\n",
      "2018-04-13T15:52:19.846668: step 9727, loss 0.0364962, acc 0.984375\n",
      "2018-04-13T15:52:20.176900: step 9728, loss 0.00014451, acc 1\n",
      "2018-04-13T15:52:20.503631: step 9729, loss 0.00019693, acc 1\n",
      "2018-04-13T15:52:20.818855: step 9730, loss 4.76517e-05, acc 1\n",
      "2018-04-13T15:52:21.162598: step 9731, loss 1.46425e-05, acc 1\n",
      "2018-04-13T15:52:21.503337: step 9732, loss 0.000499862, acc 1\n",
      "2018-04-13T15:52:21.873598: step 9733, loss 2.93862e-05, acc 1\n",
      "2018-04-13T15:52:22.202331: step 9734, loss 0.000124407, acc 1\n",
      "2018-04-13T15:52:22.546074: step 9735, loss 4.75311e-06, acc 1\n",
      "2018-04-13T15:52:22.883812: step 9736, loss 0.00112242, acc 1\n",
      "2018-04-13T15:52:23.226555: step 9737, loss 0.0413455, acc 0.984375\n",
      "2018-04-13T15:52:23.569797: step 9738, loss 2.24071e-06, acc 1\n",
      "2018-04-13T15:52:23.908035: step 9739, loss 4.46825e-05, acc 1\n",
      "2018-04-13T15:52:24.254780: step 9740, loss 1.90341e-05, acc 1\n",
      "2018-04-13T15:52:24.590017: step 9741, loss 0.00166295, acc 1\n",
      "2018-04-13T15:52:24.954775: step 9742, loss 0.000166222, acc 1\n",
      "2018-04-13T15:52:25.295015: step 9743, loss 0.00121523, acc 1\n",
      "2018-04-13T15:52:25.637257: step 9744, loss 4.08094e-06, acc 1\n",
      "2018-04-13T15:52:25.976997: step 9745, loss 2.4549e-06, acc 1\n",
      "2018-04-13T15:52:26.319738: step 9746, loss 0.00068543, acc 1\n",
      "2018-04-13T15:52:26.676490: step 9747, loss 2.37005e-05, acc 1\n",
      "2018-04-13T15:52:26.994215: step 9748, loss 8.18536e-06, acc 1\n",
      "2018-04-13T15:52:27.320445: step 9749, loss 0.024039, acc 0.984375\n",
      "2018-04-13T15:52:27.629163: step 9750, loss 4.28148e-05, acc 1\n",
      "2018-04-13T15:52:27.983413: step 9751, loss 5.2484e-06, acc 1\n",
      "2018-04-13T15:52:28.317649: step 9752, loss 0.000208714, acc 1\n",
      "2018-04-13T15:52:28.667396: step 9753, loss 0.000130118, acc 1\n",
      "2018-04-13T15:52:29.036657: step 9754, loss 1.46552e-05, acc 1\n",
      "2018-04-13T15:52:29.389405: step 9755, loss 0.00947585, acc 1\n",
      "2018-04-13T15:52:29.751661: step 9756, loss 6.99932e-05, acc 1\n",
      "2018-04-13T15:52:30.083896: step 9757, loss 0.000222336, acc 1\n",
      "2018-04-13T15:52:30.403122: step 9758, loss 8.41907e-07, acc 1\n",
      "2018-04-13T15:52:30.742861: step 9759, loss 3.52842e-05, acc 1\n",
      "2018-04-13T15:52:31.047576: step 9760, loss 1.41049e-05, acc 1\n",
      "2018-04-13T15:52:31.381312: step 9761, loss 0.00115762, acc 1\n",
      "2018-04-13T15:52:31.706543: step 9762, loss 0.000619743, acc 1\n",
      "2018-04-13T15:52:32.035775: step 9763, loss 0.00104186, acc 1\n",
      "2018-04-13T15:52:32.357501: step 9764, loss 5.5428e-05, acc 1\n",
      "2018-04-13T15:52:32.687234: step 9765, loss 0.000169488, acc 1\n",
      "2018-04-13T15:52:33.013464: step 9766, loss 0.000762928, acc 1\n",
      "2018-04-13T15:52:33.342197: step 9767, loss 0.00236282, acc 1\n",
      "2018-04-13T15:52:33.706455: step 9768, loss 0.0293619, acc 0.984375\n",
      "2018-04-13T15:52:34.049697: step 9769, loss 0.000392173, acc 1\n",
      "2018-04-13T15:52:34.377428: step 9770, loss 0.00123336, acc 1\n",
      "2018-04-13T15:52:34.712664: step 9771, loss 0.000446916, acc 1\n",
      "2018-04-13T15:52:35.044899: step 9772, loss 0.0283528, acc 0.984375\n",
      "2018-04-13T15:52:35.374132: step 9773, loss 5.391e-05, acc 1\n",
      "2018-04-13T15:52:35.699362: step 9774, loss 0.000148062, acc 1\n",
      "2018-04-13T15:52:36.024591: step 9775, loss 5.56837e-05, acc 1\n",
      "2018-04-13T15:52:36.348820: step 9776, loss 0.00298, acc 1\n",
      "2018-04-13T15:52:36.694064: step 9777, loss 0.00821309, acc 1\n",
      "2018-04-13T15:52:37.037807: step 9778, loss 0.000977748, acc 1\n",
      "2018-04-13T15:52:37.371042: step 9779, loss 0.00011514, acc 1\n",
      "2018-04-13T15:52:37.697773: step 9780, loss 0.000312509, acc 1\n",
      "2018-04-13T15:52:38.024504: step 9781, loss 0.000240097, acc 1\n",
      "2018-04-13T15:52:38.350734: step 9782, loss 0.000390204, acc 1\n",
      "2018-04-13T15:52:38.679466: step 9783, loss 0.0111273, acc 1\n",
      "2018-04-13T15:52:38.999192: step 9784, loss 0.000637219, acc 1\n",
      "2018-04-13T15:52:39.317917: step 9785, loss 0.000111855, acc 1\n",
      "2018-04-13T15:52:39.647149: step 9786, loss 0.000106256, acc 1\n",
      "2018-04-13T15:52:40.016429: step 9787, loss 9.11645e-06, acc 1\n",
      "2018-04-13T15:52:40.334635: step 9788, loss 6.66772e-05, acc 1\n",
      "2018-04-13T15:52:40.649357: step 9789, loss 3.64734e-05, acc 1\n",
      "2018-04-13T15:52:40.973085: step 9790, loss 6.74506e-05, acc 1\n",
      "2018-04-13T15:52:41.302318: step 9791, loss 0.000133619, acc 1\n",
      "2018-04-13T15:52:41.640557: step 9792, loss 0.000700495, acc 1\n",
      "2018-04-13T15:52:41.976794: step 9793, loss 4.11491e-05, acc 1\n",
      "2018-04-13T15:52:42.292017: step 9794, loss 0.00765068, acc 1\n",
      "2018-04-13T15:52:42.625752: step 9795, loss 6.85357e-05, acc 1\n",
      "2018-04-13T15:52:42.986007: step 9796, loss 0.000652147, acc 1\n",
      "2018-04-13T15:52:43.304231: step 9797, loss 0.0577484, acc 0.984375\n",
      "2018-04-13T15:52:43.623457: step 9798, loss 0.00020528, acc 1\n",
      "2018-04-13T15:52:43.961696: step 9799, loss 8.99304e-05, acc 1\n",
      "2018-04-13T15:52:44.288426: step 9800, loss 0.00132349, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:52:45.431734: step 9800, loss 2.92255, acc 0.734522\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9800\n",
      "\n",
      "2018-04-13T15:52:47.149946: step 9801, loss 0.000198226, acc 1\n",
      "2018-04-13T15:52:47.501194: step 9802, loss 4.26227e-05, acc 1\n",
      "2018-04-13T15:52:47.840435: step 9803, loss 0.00222529, acc 1\n",
      "2018-04-13T15:52:48.168666: step 9804, loss 0.000129126, acc 1\n",
      "2018-04-13T15:52:48.489393: step 9805, loss 1.32991e-06, acc 1\n",
      "2018-04-13T15:52:48.839640: step 9806, loss 0.0008435, acc 1\n",
      "2018-04-13T15:52:49.156864: step 9807, loss 2.3585e-05, acc 1\n",
      "2018-04-13T15:52:49.473588: step 9808, loss 0.000229832, acc 1\n",
      "2018-04-13T15:52:49.796315: step 9809, loss 0.000651046, acc 1\n",
      "2018-04-13T15:52:50.124047: step 9810, loss 8.58668e-07, acc 1\n",
      "2018-04-13T15:52:50.443272: step 9811, loss 3.4633e-05, acc 1\n",
      "2018-04-13T15:52:50.769003: step 9812, loss 0.000510753, acc 1\n",
      "2018-04-13T15:52:51.100236: step 9813, loss 0.0019042, acc 1\n",
      "2018-04-13T15:52:51.427967: step 9814, loss 0.05176, acc 0.984375\n",
      "2018-04-13T15:52:51.766707: step 9815, loss 0.00084956, acc 1\n",
      "2018-04-13T15:52:52.173995: step 9816, loss 0.000352497, acc 1\n",
      "2018-04-13T15:52:52.482211: step 9817, loss 1.14551e-06, acc 1\n",
      "2018-04-13T15:52:52.806941: step 9818, loss 1.78249e-05, acc 1\n",
      "2018-04-13T15:52:53.128169: step 9819, loss 1.20967e-05, acc 1\n",
      "2018-04-13T15:52:53.452897: step 9820, loss 0.00687303, acc 1\n",
      "2018-04-13T15:52:53.786133: step 9821, loss 8.45203e-06, acc 1\n",
      "2018-04-13T15:52:54.101355: step 9822, loss 8.6024e-05, acc 1\n",
      "2018-04-13T15:52:54.419079: step 9823, loss 0.000154055, acc 1\n",
      "2018-04-13T15:52:54.777333: step 9824, loss 6.27893e-05, acc 1\n",
      "2018-04-13T15:52:55.128081: step 9825, loss 0.000123161, acc 1\n",
      "2018-04-13T15:52:55.447306: step 9826, loss 1.27177e-05, acc 1\n",
      "2018-04-13T15:52:55.769033: step 9827, loss 3.28994e-05, acc 1\n",
      "2018-04-13T15:52:56.098772: step 9828, loss 0.00637896, acc 1\n",
      "2018-04-13T15:52:56.424496: step 9829, loss 0.0013935, acc 1\n",
      "2018-04-13T15:52:56.750225: step 9830, loss 0.000367997, acc 1\n",
      "2018-04-13T15:52:57.077457: step 9831, loss 0.000371587, acc 1\n",
      "2018-04-13T15:52:57.402185: step 9832, loss 0.00546523, acc 1\n",
      "2018-04-13T15:52:57.739424: step 9833, loss 6.26428e-05, acc 1\n",
      "2018-04-13T15:52:58.075661: step 9834, loss 0.0016695, acc 1\n",
      "2018-04-13T15:52:58.395888: step 9835, loss 0.00120523, acc 1\n",
      "2018-04-13T15:52:58.744134: step 9836, loss 0.000162422, acc 1\n",
      "2018-04-13T15:52:59.082372: step 9837, loss 2.28998e-05, acc 1\n",
      "2018-04-13T15:52:59.399096: step 9838, loss 0.00125015, acc 1\n",
      "2018-04-13T15:52:59.728335: step 9839, loss 6.74481e-05, acc 1\n",
      "2018-04-13T15:53:00.057561: step 9840, loss 0.000404963, acc 1\n",
      "2018-04-13T15:53:00.380789: step 9841, loss 0.000890325, acc 1\n",
      "2018-04-13T15:53:00.715026: step 9842, loss 0.0564756, acc 0.984375\n",
      "2018-04-13T15:53:01.082785: step 9843, loss 5.15797e-05, acc 1\n",
      "2018-04-13T15:53:01.430030: step 9844, loss 2.65424e-05, acc 1\n",
      "2018-04-13T15:53:01.751757: step 9845, loss 0.000333883, acc 1\n",
      "2018-04-13T15:53:02.078488: step 9846, loss 0.000389482, acc 1\n",
      "2018-04-13T15:53:02.397213: step 9847, loss 8.96588e-05, acc 1\n",
      "2018-04-13T15:53:02.749462: step 9848, loss 5.97954e-05, acc 1\n",
      "2018-04-13T15:53:03.090703: step 9849, loss 0.000443072, acc 1\n",
      "2018-04-13T15:53:03.417934: step 9850, loss 0.000833227, acc 1\n",
      "2018-04-13T15:53:03.742663: step 9851, loss 1.80999e-05, acc 1\n",
      "2018-04-13T15:53:04.077399: step 9852, loss 0.000216703, acc 1\n",
      "2018-04-13T15:53:04.387618: step 9853, loss 0.000114727, acc 1\n",
      "2018-04-13T15:53:04.702841: step 9854, loss 1.52922e-06, acc 1\n",
      "2018-04-13T15:53:05.017564: step 9855, loss 0.0370262, acc 0.984375\n",
      "2018-04-13T15:53:05.336288: step 9856, loss 3.95955e-05, acc 1\n",
      "2018-04-13T15:53:05.674528: step 9857, loss 1.49008e-05, acc 1\n",
      "2018-04-13T15:53:05.989750: step 9858, loss 0.0814725, acc 0.984375\n",
      "2018-04-13T15:53:06.311477: step 9859, loss 3.27216e-05, acc 1\n",
      "2018-04-13T15:53:06.633705: step 9860, loss 2.24315e-05, acc 1\n",
      "2018-04-13T15:53:06.986954: step 9861, loss 0.034291, acc 0.984375\n",
      "2018-04-13T15:53:07.318688: step 9862, loss 0.000149832, acc 1\n",
      "2018-04-13T15:53:07.643918: step 9863, loss 2.50035e-05, acc 1\n",
      "2018-04-13T15:53:07.990663: step 9864, loss 0.000192894, acc 1\n",
      "2018-04-13T15:53:08.316893: step 9865, loss 0.000309585, acc 1\n",
      "2018-04-13T15:53:08.634617: step 9866, loss 0.00015037, acc 1\n",
      "2018-04-13T15:53:08.964350: step 9867, loss 3.32732e-05, acc 1\n",
      "2018-04-13T15:53:09.275070: step 9868, loss 0.00118726, acc 1\n",
      "2018-04-13T15:53:09.594295: step 9869, loss 0.00101515, acc 1\n",
      "2018-04-13T15:53:09.956603: step 9870, loss 0.00245367, acc 1\n",
      "2018-04-13T15:53:10.293789: step 9871, loss 0.000131986, acc 1\n",
      "2018-04-13T15:53:10.638533: step 9872, loss 4.74927e-05, acc 1\n",
      "2018-04-13T15:53:10.989780: step 9873, loss 0.0123878, acc 0.984375\n",
      "2018-04-13T15:53:11.308506: step 9874, loss 0.000649907, acc 1\n",
      "2018-04-13T15:53:11.635238: step 9875, loss 0.0406749, acc 0.984375\n",
      "2018-04-13T15:53:11.967971: step 9876, loss 7.64657e-06, acc 1\n",
      "2018-04-13T15:53:12.303708: step 9877, loss 2.5667e-05, acc 1\n",
      "2018-04-13T15:53:12.736514: step 9878, loss 8.17132e-05, acc 1\n",
      "2018-04-13T15:53:13.135295: step 9879, loss 3.44947e-05, acc 1\n",
      "2018-04-13T15:53:13.467530: step 9880, loss 0.00101163, acc 1\n",
      "2018-04-13T15:53:13.834289: step 9881, loss 0.000432331, acc 1\n",
      "2018-04-13T15:53:14.192542: step 9882, loss 0.000101365, acc 1\n",
      "2018-04-13T15:53:14.553798: step 9883, loss 0.000286819, acc 1\n",
      "2018-04-13T15:53:14.915052: step 9884, loss 0.00190613, acc 1\n",
      "2018-04-13T15:53:15.348358: step 9885, loss 8.44925e-05, acc 1\n",
      "2018-04-13T15:53:15.671587: step 9886, loss 0.000320971, acc 1\n",
      "2018-04-13T15:53:16.032841: step 9887, loss 0.0539558, acc 0.984375\n",
      "2018-04-13T15:53:16.362574: step 9888, loss 0.00108332, acc 1\n",
      "2018-04-13T15:53:16.680799: step 9889, loss 3.34384e-05, acc 1\n",
      "2018-04-13T15:53:17.009030: step 9890, loss 0.00630645, acc 1\n",
      "2018-04-13T15:53:17.361780: step 9891, loss 0.000273905, acc 1\n",
      "2018-04-13T15:53:17.791084: step 9892, loss 0.000119649, acc 1\n",
      "2018-04-13T15:53:18.115812: step 9893, loss 2.82322e-05, acc 1\n",
      "2018-04-13T15:53:18.442043: step 9894, loss 0.00013788, acc 1\n",
      "2018-04-13T15:53:18.805299: step 9895, loss 0.000164976, acc 1\n",
      "2018-04-13T15:53:19.166054: step 9896, loss 0.000130613, acc 1\n",
      "2018-04-13T15:53:19.511298: step 9897, loss 6.80498e-05, acc 1\n",
      "2018-04-13T15:53:19.833025: step 9898, loss 0.000450177, acc 1\n",
      "2018-04-13T15:53:20.158755: step 9899, loss 8.28661e-05, acc 1\n",
      "2018-04-13T15:53:20.469974: step 9900, loss 0.0173535, acc 0.983333\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:53:21.605282: step 9900, loss 2.99867, acc 0.734522\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-9900\n",
      "\n",
      "2018-04-13T15:53:23.323995: step 9901, loss 3.26197e-05, acc 1\n",
      "2018-04-13T15:53:23.653228: step 9902, loss 0.000178559, acc 1\n",
      "2018-04-13T15:53:23.987964: step 9903, loss 0.000132645, acc 1\n",
      "2018-04-13T15:53:24.300685: step 9904, loss 0.000537281, acc 1\n",
      "2018-04-13T15:53:24.610905: step 9905, loss 0.00442633, acc 1\n",
      "2018-04-13T15:53:24.963653: step 9906, loss 0.000622609, acc 1\n",
      "2018-04-13T15:53:25.280877: step 9907, loss 0.000378394, acc 1\n",
      "2018-04-13T15:53:25.610610: step 9908, loss 0.0214707, acc 0.984375\n",
      "2018-04-13T15:53:25.931337: step 9909, loss 2.46847e-05, acc 1\n",
      "2018-04-13T15:53:26.243056: step 9910, loss 0.0003854, acc 1\n",
      "2018-04-13T15:53:26.555777: step 9911, loss 0.000139093, acc 1\n",
      "2018-04-13T15:53:26.887512: step 9912, loss 3.35957e-05, acc 1\n",
      "2018-04-13T15:53:27.216244: step 9913, loss 0.00087398, acc 1\n",
      "2018-04-13T15:53:27.527964: step 9914, loss 0.000536937, acc 1\n",
      "2018-04-13T15:53:27.872707: step 9915, loss 0.00196979, acc 1\n",
      "2018-04-13T15:53:28.220453: step 9916, loss 0.000153512, acc 1\n",
      "2018-04-13T15:53:28.531673: step 9917, loss 1.58899e-05, acc 1\n",
      "2018-04-13T15:53:28.847896: step 9918, loss 6.02142e-06, acc 1\n",
      "2018-04-13T15:53:29.170630: step 9919, loss 6.04239e-05, acc 1\n",
      "2018-04-13T15:53:29.501858: step 9920, loss 0.000344292, acc 1\n",
      "2018-04-13T15:53:29.829590: step 9921, loss 0.000864991, acc 1\n",
      "2018-04-13T15:53:30.158322: step 9922, loss 6.63614e-06, acc 1\n",
      "2018-04-13T15:53:30.477046: step 9923, loss 0.000190864, acc 1\n",
      "2018-04-13T15:53:30.815785: step 9924, loss 2.35803e-06, acc 1\n",
      "2018-04-13T15:53:31.149020: step 9925, loss 5.60626e-06, acc 1\n",
      "2018-04-13T15:53:31.457739: step 9926, loss 7.24696e-05, acc 1\n",
      "2018-04-13T15:53:31.786471: step 9927, loss 0.000774035, acc 1\n",
      "2018-04-13T15:53:32.108199: step 9928, loss 1.33414e-05, acc 1\n",
      "2018-04-13T15:53:32.431927: step 9929, loss 0.000586949, acc 1\n",
      "2018-04-13T15:53:32.764162: step 9930, loss 0.000212707, acc 1\n",
      "2018-04-13T15:53:33.096896: step 9931, loss 0.000301641, acc 1\n",
      "2018-04-13T15:53:33.416121: step 9932, loss 3.89547e-05, acc 1\n",
      "2018-04-13T15:53:33.738849: step 9933, loss 1.65334e-05, acc 1\n",
      "2018-04-13T15:53:34.092599: step 9934, loss 0.00526268, acc 1\n",
      "2018-04-13T15:53:34.411825: step 9935, loss 0.067952, acc 0.984375\n",
      "2018-04-13T15:53:34.731550: step 9936, loss 1.32316e-05, acc 1\n",
      "2018-04-13T15:53:35.053778: step 9937, loss 0.00800887, acc 1\n",
      "2018-04-13T15:53:35.385512: step 9938, loss 5.0509e-06, acc 1\n",
      "2018-04-13T15:53:35.713244: step 9939, loss 5.80976e-05, acc 1\n",
      "2018-04-13T15:53:36.034971: step 9940, loss 0.000142965, acc 1\n",
      "2018-04-13T15:53:36.352696: step 9941, loss 5.48361e-05, acc 1\n",
      "2018-04-13T15:53:36.672922: step 9942, loss 0.000176186, acc 1\n",
      "2018-04-13T15:53:37.025171: step 9943, loss 0.0128634, acc 0.984375\n",
      "2018-04-13T15:53:37.365911: step 9944, loss 0.000667379, acc 1\n",
      "2018-04-13T15:53:37.703649: step 9945, loss 0.00174644, acc 1\n",
      "2018-04-13T15:53:38.026877: step 9946, loss 0.000975999, acc 1\n",
      "2018-04-13T15:53:38.351607: step 9947, loss 8.96495e-05, acc 1\n",
      "2018-04-13T15:53:38.676336: step 9948, loss 1.87641e-05, acc 1\n",
      "2018-04-13T15:53:39.000065: step 9949, loss 0.0415539, acc 0.984375\n",
      "2018-04-13T15:53:39.323793: step 9950, loss 0.000374784, acc 1\n",
      "2018-04-13T15:53:39.644020: step 9951, loss 0.000380659, acc 1\n",
      "2018-04-13T15:53:39.991766: step 9952, loss 0.00126361, acc 1\n",
      "2018-04-13T15:53:40.328504: step 9953, loss 9.94739e-06, acc 1\n",
      "2018-04-13T15:53:40.634719: step 9954, loss 0.00182291, acc 1\n",
      "2018-04-13T15:53:40.968955: step 9955, loss 0.000182254, acc 1\n",
      "2018-04-13T15:53:41.299688: step 9956, loss 0.00822774, acc 1\n",
      "2018-04-13T15:53:41.628420: step 9957, loss 0.000744938, acc 1\n",
      "2018-04-13T15:53:41.959654: step 9958, loss 0.000343522, acc 1\n",
      "2018-04-13T15:53:42.294391: step 9959, loss 0.00697122, acc 1\n",
      "2018-04-13T15:53:42.629627: step 9960, loss 0.000904615, acc 1\n",
      "2018-04-13T15:53:43.027909: step 9961, loss 0.000352318, acc 1\n",
      "2018-04-13T15:53:43.372652: step 9962, loss 0.000184182, acc 1\n",
      "2018-04-13T15:53:43.738911: step 9963, loss 0.000133784, acc 1\n",
      "2018-04-13T15:53:44.082153: step 9964, loss 0.000800245, acc 1\n",
      "2018-04-13T15:53:44.400879: step 9965, loss 0.000197827, acc 1\n",
      "2018-04-13T15:53:44.754128: step 9966, loss 0.00364639, acc 1\n",
      "2018-04-13T15:53:45.100874: step 9967, loss 0.00367997, acc 1\n",
      "2018-04-13T15:53:45.423101: step 9968, loss 9.49317e-05, acc 1\n",
      "2018-04-13T15:53:45.755835: step 9969, loss 0.000145785, acc 1\n",
      "2018-04-13T15:53:46.144110: step 9970, loss 0.000593398, acc 1\n",
      "2018-04-13T15:53:46.458331: step 9971, loss 6.65696e-05, acc 1\n",
      "2018-04-13T15:53:46.782059: step 9972, loss 0.000101727, acc 1\n",
      "2018-04-13T15:53:47.110791: step 9973, loss 0.00107637, acc 1\n",
      "2018-04-13T15:53:47.460039: step 9974, loss 7.09069e-06, acc 1\n",
      "2018-04-13T15:53:47.816290: step 9975, loss 0.000476469, acc 1\n",
      "2018-04-13T15:53:48.170040: step 9976, loss 2.19838e-05, acc 1\n",
      "2018-04-13T15:53:48.480759: step 9977, loss 0.000333087, acc 1\n",
      "2018-04-13T15:53:48.772966: step 9978, loss 3.37985e-05, acc 1\n",
      "2018-04-13T15:53:49.090699: step 9979, loss 0.00537962, acc 1\n",
      "2018-04-13T15:53:49.380904: step 9980, loss 0.00113357, acc 1\n",
      "2018-04-13T15:53:49.677114: step 9981, loss 4.53595e-05, acc 1\n",
      "2018-04-13T15:53:49.974323: step 9982, loss 0.000228612, acc 1\n",
      "2018-04-13T15:53:50.270532: step 9983, loss 0.000248118, acc 1\n",
      "2018-04-13T15:53:50.567241: step 9984, loss 4.5037e-05, acc 1\n",
      "2018-04-13T15:53:50.861450: step 9985, loss 0.000332626, acc 1\n",
      "2018-04-13T15:53:51.144650: step 9986, loss 0.000212119, acc 1\n",
      "2018-04-13T15:53:51.419344: step 9987, loss 0.0450864, acc 0.984375\n",
      "2018-04-13T15:53:51.699040: step 9988, loss 0.000677951, acc 1\n",
      "2018-04-13T15:53:51.990747: step 9989, loss 5.55184e-05, acc 1\n",
      "2018-04-13T15:53:52.272947: step 9990, loss 1.13026e-05, acc 1\n",
      "2018-04-13T15:53:52.549195: step 9991, loss 1.21184e-05, acc 1\n",
      "2018-04-13T15:53:52.838900: step 9992, loss 1.89766e-05, acc 1\n",
      "2018-04-13T15:53:53.117597: step 9993, loss 0.000587386, acc 1\n",
      "2018-04-13T15:53:53.392790: step 9994, loss 0.0956134, acc 0.984375\n",
      "2018-04-13T15:53:53.679994: step 9995, loss 0.000482775, acc 1\n",
      "2018-04-13T15:53:53.961693: step 9996, loss 0.000102187, acc 1\n",
      "2018-04-13T15:53:54.246393: step 9997, loss 0.000300919, acc 1\n",
      "2018-04-13T15:53:54.525091: step 9998, loss 0.000132141, acc 1\n",
      "2018-04-13T15:53:54.807790: step 9999, loss 9.97053e-06, acc 1\n",
      "2018-04-13T15:53:55.103011: step 10000, loss 2.46509e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:53:56.031166: step 10000, loss 3.07159, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-10000\n",
      "\n",
      "2018-04-13T15:53:57.806626: step 10001, loss 0.00018588, acc 1\n",
      "2018-04-13T15:53:58.114845: step 10002, loss 0.000764307, acc 1\n",
      "2018-04-13T15:53:58.406050: step 10003, loss 0.00106165, acc 1\n",
      "2018-04-13T15:53:58.687748: step 10004, loss 0.000449723, acc 1\n",
      "2018-04-13T15:53:58.970947: step 10005, loss 0.00159, acc 1\n",
      "2018-04-13T15:53:59.245641: step 10006, loss 5.30938e-05, acc 1\n",
      "2018-04-13T15:53:59.520335: step 10007, loss 7.07948e-05, acc 1\n",
      "2018-04-13T15:53:59.823550: step 10008, loss 0.000572135, acc 1\n",
      "2018-04-13T15:54:00.106749: step 10009, loss 0.00010957, acc 1\n",
      "2018-04-13T15:54:00.379442: step 10010, loss 0.000521648, acc 1\n",
      "2018-04-13T15:54:00.663143: step 10011, loss 0.0151463, acc 0.984375\n",
      "2018-04-13T15:54:00.951346: step 10012, loss 0.000945404, acc 1\n",
      "2018-04-13T15:54:01.240050: step 10013, loss 0.000206133, acc 1\n",
      "2018-04-13T15:54:01.530755: step 10014, loss 0.0891814, acc 0.984375\n",
      "2018-04-13T15:54:01.816958: step 10015, loss 0.000718552, acc 1\n",
      "2018-04-13T15:54:02.097155: step 10016, loss 0.000788389, acc 1\n",
      "2018-04-13T15:54:02.383865: step 10017, loss 1.95054e-05, acc 1\n",
      "2018-04-13T15:54:02.672568: step 10018, loss 1.84893e-05, acc 1\n",
      "2018-04-13T15:54:02.951766: step 10019, loss 0.000742997, acc 1\n",
      "2018-04-13T15:54:03.241471: step 10020, loss 1.73223e-05, acc 1\n",
      "2018-04-13T15:54:03.519667: step 10021, loss 4.25949e-06, acc 1\n",
      "2018-04-13T15:54:03.796363: step 10022, loss 0.000509219, acc 1\n",
      "2018-04-13T15:54:04.101078: step 10023, loss 0.00230807, acc 1\n",
      "2018-04-13T15:54:04.382776: step 10024, loss 0.000112038, acc 1\n",
      "2018-04-13T15:54:04.661474: step 10025, loss 8.91204e-05, acc 1\n",
      "2018-04-13T15:54:04.953679: step 10026, loss 0.00255927, acc 1\n",
      "2018-04-13T15:54:05.261917: step 10027, loss 0.000309235, acc 1\n",
      "2018-04-13T15:54:05.540113: step 10028, loss 1.91415e-05, acc 1\n",
      "2018-04-13T15:54:05.832820: step 10029, loss 9.72835e-05, acc 1\n",
      "2018-04-13T15:54:06.112017: step 10030, loss 2.34803e-05, acc 1\n",
      "2018-04-13T15:54:06.381207: step 10031, loss 2.41707e-05, acc 1\n",
      "2018-04-13T15:54:06.668410: step 10032, loss 0.00273723, acc 1\n",
      "2018-04-13T15:54:06.954612: step 10033, loss 6.25e-06, acc 1\n",
      "2018-04-13T15:54:07.242315: step 10034, loss 0.000363006, acc 1\n",
      "2018-04-13T15:54:07.518009: step 10035, loss 0.00024759, acc 1\n",
      "2018-04-13T15:54:07.821729: step 10036, loss 0.000520388, acc 1\n",
      "2018-04-13T15:54:08.115486: step 10037, loss 0.000445107, acc 1\n",
      "2018-04-13T15:54:08.407191: step 10038, loss 0.0105571, acc 1\n",
      "2018-04-13T15:54:08.786962: step 10039, loss 0.000113906, acc 1\n",
      "2018-04-13T15:54:09.183239: step 10040, loss 0.000235514, acc 1\n",
      "2018-04-13T15:54:09.514974: step 10041, loss 0.000172393, acc 1\n",
      "2018-04-13T15:54:09.836701: step 10042, loss 8.16063e-05, acc 1\n",
      "2018-04-13T15:54:10.181444: step 10043, loss 6.92664e-05, acc 1\n",
      "2018-04-13T15:54:10.506174: step 10044, loss 6.51922e-07, acc 1\n",
      "2018-04-13T15:54:10.842414: step 10045, loss 1.28901e-05, acc 1\n",
      "2018-04-13T15:54:11.186154: step 10046, loss 1.19697e-05, acc 1\n",
      "2018-04-13T15:54:11.515886: step 10047, loss 2.02088e-06, acc 1\n",
      "2018-04-13T15:54:11.908664: step 10048, loss 0.0732208, acc 0.984375\n",
      "2018-04-13T15:54:12.249404: step 10049, loss 1.00582e-06, acc 1\n",
      "2018-04-13T15:54:12.557622: step 10050, loss 8.46624e-05, acc 1\n",
      "2018-04-13T15:54:12.903867: step 10051, loss 0.00139607, acc 1\n",
      "2018-04-13T15:54:13.272127: step 10052, loss 0.0106008, acc 1\n",
      "2018-04-13T15:54:13.593354: step 10053, loss 5.63468e-05, acc 1\n",
      "2018-04-13T15:54:13.927089: step 10054, loss 0.000562197, acc 1\n",
      "2018-04-13T15:54:14.235807: step 10055, loss 0.0106393, acc 1\n",
      "2018-04-13T15:54:14.550029: step 10056, loss 0.00638481, acc 1\n",
      "2018-04-13T15:54:14.885267: step 10057, loss 1.70217e-05, acc 1\n",
      "2018-04-13T15:54:15.216000: step 10058, loss 0.000102354, acc 1\n",
      "2018-04-13T15:54:15.536226: step 10059, loss 3.49228e-06, acc 1\n",
      "2018-04-13T15:54:15.856952: step 10060, loss 3.80523e-06, acc 1\n",
      "2018-04-13T15:54:16.209701: step 10061, loss 0.000473129, acc 1\n",
      "2018-04-13T15:54:16.540434: step 10062, loss 0.000908368, acc 1\n",
      "2018-04-13T15:54:16.867165: step 10063, loss 1.52224e-05, acc 1\n",
      "2018-04-13T15:54:17.183889: step 10064, loss 0.00953434, acc 1\n",
      "2018-04-13T15:54:17.512121: step 10065, loss 4.3772e-07, acc 1\n",
      "2018-04-13T15:54:17.835349: step 10066, loss 0.000145729, acc 1\n",
      "2018-04-13T15:54:18.163581: step 10067, loss 0.000440872, acc 1\n",
      "2018-04-13T15:54:18.518331: step 10068, loss 1.1536e-05, acc 1\n",
      "2018-04-13T15:54:18.857571: step 10069, loss 0.00287979, acc 1\n",
      "2018-04-13T15:54:19.245344: step 10070, loss 1.9134e-05, acc 1\n",
      "2018-04-13T15:54:19.584584: step 10071, loss 0.00202724, acc 1\n",
      "2018-04-13T15:54:19.925825: step 10072, loss 0.00255289, acc 1\n",
      "2018-04-13T15:54:20.232542: step 10073, loss 0.000140167, acc 1\n",
      "2018-04-13T15:54:20.563275: step 10074, loss 0.000235312, acc 1\n",
      "2018-04-13T15:54:20.911520: step 10075, loss 0.00330007, acc 1\n",
      "2018-04-13T15:54:21.241255: step 10076, loss 4.18088e-05, acc 1\n",
      "2018-04-13T15:54:21.584496: step 10077, loss 1.29823e-06, acc 1\n",
      "2018-04-13T15:54:21.943249: step 10078, loss 5.22229e-05, acc 1\n",
      "2018-04-13T15:54:22.423088: step 10079, loss 0.000115662, acc 1\n",
      "2018-04-13T15:54:22.787346: step 10080, loss 3.47279e-05, acc 1\n",
      "2018-04-13T15:54:23.124583: step 10081, loss 4.52987e-05, acc 1\n",
      "2018-04-13T15:54:23.456317: step 10082, loss 4.35281e-06, acc 1\n",
      "2018-04-13T15:54:23.802563: step 10083, loss 0.000656106, acc 1\n",
      "2018-04-13T15:54:24.139300: step 10084, loss 0.0330168, acc 0.984375\n",
      "2018-04-13T15:54:24.463029: step 10085, loss 4.32647e-06, acc 1\n",
      "2018-04-13T15:54:24.783756: step 10086, loss 4.2929e-05, acc 1\n",
      "2018-04-13T15:54:25.123495: step 10087, loss 1.68754e-06, acc 1\n",
      "2018-04-13T15:54:25.452727: step 10088, loss 0.00197183, acc 1\n",
      "2018-04-13T15:54:25.802474: step 10089, loss 6.40526e-06, acc 1\n",
      "2018-04-13T15:54:26.149720: step 10090, loss 0.0016034, acc 1\n",
      "2018-04-13T15:54:26.487959: step 10091, loss 0.00196259, acc 1\n",
      "2018-04-13T15:54:26.815691: step 10092, loss 0.000122227, acc 1\n",
      "2018-04-13T15:54:27.140419: step 10093, loss 1.94615e-05, acc 1\n",
      "2018-04-13T15:54:27.449637: step 10094, loss 4.88717e-06, acc 1\n",
      "2018-04-13T15:54:27.770364: step 10095, loss 0.000274899, acc 1\n",
      "2018-04-13T15:54:28.143630: step 10096, loss 0.000255561, acc 1\n",
      "2018-04-13T15:54:28.473861: step 10097, loss 0.00170767, acc 1\n",
      "2018-04-13T15:54:28.775574: step 10098, loss 8.34367e-06, acc 1\n",
      "2018-04-13T15:54:29.074285: step 10099, loss 2.16598e-05, acc 1\n",
      "2018-04-13T15:54:29.352982: step 10100, loss 2.1777e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:54:30.301652: step 10100, loss 2.99926, acc 0.747655\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-10100\n",
      "\n",
      "2018-04-13T15:54:31.795684: step 10101, loss 0.000217317, acc 1\n",
      "2018-04-13T15:54:32.092894: step 10102, loss 0.000191678, acc 1\n",
      "2018-04-13T15:54:32.412620: step 10103, loss 4.07265e-05, acc 1\n",
      "2018-04-13T15:54:32.714333: step 10104, loss 0.00809206, acc 1\n",
      "2018-04-13T15:54:33.013044: step 10105, loss 1.46942e-05, acc 1\n",
      "2018-04-13T15:54:33.303263: step 10106, loss 0.00201714, acc 1\n",
      "2018-04-13T15:54:33.594970: step 10107, loss 3.82526e-05, acc 1\n",
      "2018-04-13T15:54:33.922201: step 10108, loss 3.26021e-05, acc 1\n",
      "2018-04-13T15:54:34.263943: step 10109, loss 6.04339e-05, acc 1\n",
      "2018-04-13T15:54:34.575663: step 10110, loss 0.000109875, acc 1\n",
      "2018-04-13T15:54:34.881879: step 10111, loss 1.50635e-05, acc 1\n",
      "2018-04-13T15:54:35.171583: step 10112, loss 2.3143e-05, acc 1\n",
      "2018-04-13T15:54:35.451781: step 10113, loss 0.000236896, acc 1\n",
      "2018-04-13T15:54:35.748495: step 10114, loss 0.00473603, acc 1\n",
      "2018-04-13T15:54:36.048202: step 10115, loss 0.000640438, acc 1\n",
      "2018-04-13T15:54:36.329902: step 10116, loss 2.22588e-05, acc 1\n",
      "2018-04-13T15:54:36.620106: step 10117, loss 1.23531e-05, acc 1\n",
      "2018-04-13T15:54:36.911812: step 10118, loss 1.05468e-05, acc 1\n",
      "2018-04-13T15:54:37.244547: step 10119, loss 8.81212e-05, acc 1\n",
      "2018-04-13T15:54:37.521743: step 10120, loss 0.000519736, acc 1\n",
      "2018-04-13T15:54:37.801941: step 10121, loss 0.000467567, acc 1\n",
      "2018-04-13T15:54:38.080638: step 10122, loss 0.00242243, acc 1\n",
      "2018-04-13T15:54:38.350829: step 10123, loss 0.00074898, acc 1\n",
      "2018-04-13T15:54:38.635529: step 10124, loss 1.56879e-05, acc 1\n",
      "2018-04-13T15:54:38.924733: step 10125, loss 0.0178252, acc 0.984375\n",
      "2018-04-13T15:54:39.210936: step 10126, loss 3.92614e-06, acc 1\n",
      "2018-04-13T15:54:39.486630: step 10127, loss 0.00474396, acc 1\n",
      "2018-04-13T15:54:39.773332: step 10128, loss 0.00194373, acc 1\n",
      "2018-04-13T15:54:40.072544: step 10129, loss 1.25323e-05, acc 1\n",
      "2018-04-13T15:54:40.362248: step 10130, loss 0.00145201, acc 1\n",
      "2018-04-13T15:54:40.645949: step 10131, loss 0.000579544, acc 1\n",
      "2018-04-13T15:54:40.924146: step 10132, loss 0.00147669, acc 1\n",
      "2018-04-13T15:54:41.211348: step 10133, loss 0.000403494, acc 1\n",
      "2018-04-13T15:54:41.487542: step 10134, loss 0.0024583, acc 1\n",
      "2018-04-13T15:54:41.777748: step 10135, loss 3.2799e-05, acc 1\n",
      "2018-04-13T15:54:42.052942: step 10136, loss 0.000554449, acc 1\n",
      "2018-04-13T15:54:42.339144: step 10137, loss 0.00015774, acc 1\n",
      "2018-04-13T15:54:42.614840: step 10138, loss 0.00150111, acc 1\n",
      "2018-04-13T15:54:42.903043: step 10139, loss 0.00127709, acc 1\n",
      "2018-04-13T15:54:43.193247: step 10140, loss 0.00581607, acc 1\n",
      "2018-04-13T15:54:43.480951: step 10141, loss 0.000567665, acc 1\n",
      "2018-04-13T15:54:43.772157: step 10142, loss 6.30435e-05, acc 1\n",
      "2018-04-13T15:54:44.057859: step 10143, loss 0.000930192, acc 1\n",
      "2018-04-13T15:54:44.374089: step 10144, loss 0.000367141, acc 1\n",
      "2018-04-13T15:54:44.730041: step 10145, loss 6.51132e-06, acc 1\n",
      "2018-04-13T15:54:45.039759: step 10146, loss 7.58205e-05, acc 1\n",
      "2018-04-13T15:54:45.317955: step 10147, loss 5.24192e-05, acc 1\n",
      "2018-04-13T15:54:45.615166: step 10148, loss 2.21895e-05, acc 1\n",
      "2018-04-13T15:54:45.922388: step 10149, loss 7.40046e-05, acc 1\n",
      "2018-04-13T15:54:46.247112: step 10150, loss 0.0015258, acc 1\n",
      "2018-04-13T15:54:46.584850: step 10151, loss 1.22841e-05, acc 1\n",
      "2018-04-13T15:54:46.910079: step 10152, loss 0.0282377, acc 0.984375\n",
      "2018-04-13T15:54:47.217797: step 10153, loss 0.000943702, acc 1\n",
      "2018-04-13T15:54:47.526515: step 10154, loss 3.9106e-05, acc 1\n",
      "2018-04-13T15:54:47.861608: step 10155, loss 2.93445e-05, acc 1\n",
      "2018-04-13T15:54:48.196845: step 10156, loss 0.000172333, acc 1\n",
      "2018-04-13T15:54:48.472039: step 10157, loss 0.000347831, acc 1\n",
      "2018-04-13T15:54:48.779255: step 10158, loss 0.000228431, acc 1\n",
      "2018-04-13T15:54:49.069461: step 10159, loss 0.000195163, acc 1\n",
      "2018-04-13T15:54:49.373676: step 10160, loss 1.14177e-06, acc 1\n",
      "2018-04-13T15:54:49.652373: step 10161, loss 0.000590379, acc 1\n",
      "2018-04-13T15:54:49.936072: step 10162, loss 0.000384824, acc 1\n",
      "2018-04-13T15:54:50.214287: step 10163, loss 7.62863e-05, acc 1\n",
      "2018-04-13T15:54:50.510496: step 10164, loss 0.00033776, acc 1\n",
      "2018-04-13T15:54:50.803203: step 10165, loss 0.000297985, acc 1\n",
      "2018-04-13T15:54:51.088404: step 10166, loss 1.28162e-05, acc 1\n",
      "2018-04-13T15:54:51.369102: step 10167, loss 0.000103554, acc 1\n",
      "2018-04-13T15:54:51.649800: step 10168, loss 0.00313362, acc 1\n",
      "2018-04-13T15:54:51.927997: step 10169, loss 0.000787176, acc 1\n",
      "2018-04-13T15:54:52.283441: step 10170, loss 0.00162447, acc 1\n",
      "2018-04-13T15:54:52.572145: step 10171, loss 5.08977e-05, acc 1\n",
      "2018-04-13T15:54:52.860349: step 10172, loss 0.0509429, acc 0.984375\n",
      "2018-04-13T15:54:53.143048: step 10173, loss 4.95105e-05, acc 1\n",
      "2018-04-13T15:54:53.417743: step 10174, loss 0.000416838, acc 1\n",
      "2018-04-13T15:54:53.711950: step 10175, loss 1.99729e-05, acc 1\n",
      "2018-04-13T15:54:53.995150: step 10176, loss 0.000668614, acc 1\n",
      "2018-04-13T15:54:54.291359: step 10177, loss 0.000152112, acc 1\n",
      "2018-04-13T15:54:54.592071: step 10178, loss 3.85177e-06, acc 1\n",
      "2018-04-13T15:54:54.915800: step 10179, loss 0.000131685, acc 1\n",
      "2018-04-13T15:54:55.232022: step 10180, loss 2.35871e-05, acc 1\n",
      "2018-04-13T15:54:55.563757: step 10181, loss 0.0019768, acc 1\n",
      "2018-04-13T15:54:55.847514: step 10182, loss 0.000509841, acc 1\n",
      "2018-04-13T15:54:56.173244: step 10183, loss 0.0015302, acc 1\n",
      "2018-04-13T15:54:56.517486: step 10184, loss 1.95731e-05, acc 1\n",
      "2018-04-13T15:54:56.838714: step 10185, loss 0.00810856, acc 1\n",
      "2018-04-13T15:54:57.163943: step 10186, loss 6.54053e-06, acc 1\n",
      "2018-04-13T15:54:57.484670: step 10187, loss 3.71315e-05, acc 1\n",
      "2018-04-13T15:54:57.770372: step 10188, loss 2.2782e-05, acc 1\n",
      "2018-04-13T15:54:58.042064: step 10189, loss 7.34072e-05, acc 1\n",
      "2018-04-13T15:54:58.349280: step 10190, loss 0.00198448, acc 1\n",
      "2018-04-13T15:54:58.640486: step 10191, loss 0.000180041, acc 1\n",
      "2018-04-13T15:54:58.926188: step 10192, loss 0.000110675, acc 1\n",
      "2018-04-13T15:54:59.208888: step 10193, loss 1.04968e-05, acc 1\n",
      "2018-04-13T15:54:59.486584: step 10194, loss 0.021298, acc 0.984375\n",
      "2018-04-13T15:54:59.780791: step 10195, loss 0.000320988, acc 1\n",
      "2018-04-13T15:55:00.072998: step 10196, loss 0.000205576, acc 1\n",
      "2018-04-13T15:55:00.343187: step 10197, loss 0.000142608, acc 1\n",
      "2018-04-13T15:55:00.620384: step 10198, loss 0.00104049, acc 1\n",
      "2018-04-13T15:55:00.908587: step 10199, loss 3.82528e-05, acc 1\n",
      "2018-04-13T15:55:01.194789: step 10200, loss 0.010171, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:55:02.133448: step 10200, loss 3.03901, acc 0.74015\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-10200\n",
      "\n",
      "2018-04-13T15:55:03.653872: step 10201, loss 0.00452994, acc 1\n",
      "2018-04-13T15:55:03.933566: step 10202, loss 5.61513e-05, acc 1\n",
      "2018-04-13T15:55:04.243285: step 10203, loss 0.000453488, acc 1\n",
      "2018-04-13T15:55:04.530487: step 10204, loss 0.000159785, acc 1\n",
      "2018-04-13T15:55:04.834703: step 10205, loss 4.62438e-06, acc 1\n",
      "2018-04-13T15:55:05.123907: step 10206, loss 0.000645155, acc 1\n",
      "2018-04-13T15:55:05.398600: step 10207, loss 4.56157e-05, acc 1\n",
      "2018-04-13T15:55:05.683802: step 10208, loss 0.00300608, acc 1\n",
      "2018-04-13T15:55:05.985014: step 10209, loss 6.09974e-05, acc 1\n",
      "2018-04-13T15:55:06.262710: step 10210, loss 1.03454e-05, acc 1\n",
      "2018-04-13T15:55:06.547912: step 10211, loss 5.05844e-06, acc 1\n",
      "2018-04-13T15:55:06.840118: step 10212, loss 0.00103192, acc 1\n",
      "2018-04-13T15:55:07.125320: step 10213, loss 8.94203e-06, acc 1\n",
      "2018-04-13T15:55:07.428534: step 10214, loss 3.79567e-05, acc 1\n",
      "2018-04-13T15:55:07.715237: step 10215, loss 2.48577e-05, acc 1\n",
      "2018-04-13T15:55:08.002939: step 10216, loss 0.000310643, acc 1\n",
      "2018-04-13T15:55:08.321164: step 10217, loss 0.000103326, acc 1\n",
      "2018-04-13T15:55:08.649401: step 10218, loss 0.000141987, acc 1\n",
      "2018-04-13T15:55:08.951109: step 10219, loss 5.46878e-05, acc 1\n",
      "2018-04-13T15:55:09.227303: step 10220, loss 7.43367e-05, acc 1\n",
      "2018-04-13T15:55:09.519510: step 10221, loss 1.6689e-06, acc 1\n",
      "2018-04-13T15:55:09.811216: step 10222, loss 0.000437938, acc 1\n",
      "2018-04-13T15:55:10.097919: step 10223, loss 0.000109796, acc 1\n",
      "2018-04-13T15:55:10.415143: step 10224, loss 0.00775926, acc 1\n",
      "2018-04-13T15:55:10.724861: step 10225, loss 6.47606e-06, acc 1\n",
      "2018-04-13T15:55:11.007561: step 10226, loss 3.65829e-05, acc 1\n",
      "2018-04-13T15:55:11.344801: step 10227, loss 6.21248e-05, acc 1\n",
      "2018-04-13T15:55:11.672531: step 10228, loss 0.000103521, acc 1\n",
      "2018-04-13T15:55:11.964237: step 10229, loss 2.50842e-05, acc 1\n",
      "2018-04-13T15:55:12.239431: step 10230, loss 0.000154132, acc 1\n",
      "2018-04-13T15:55:12.533139: step 10231, loss 0.0215561, acc 0.984375\n",
      "2018-04-13T15:55:12.829848: step 10232, loss 7.57571e-06, acc 1\n",
      "2018-04-13T15:55:13.127562: step 10233, loss 0.000689833, acc 1\n",
      "2018-04-13T15:55:13.456289: step 10234, loss 4.57779e-05, acc 1\n",
      "2018-04-13T15:55:13.745494: step 10235, loss 0.0012508, acc 1\n",
      "2018-04-13T15:55:14.030195: step 10236, loss 0.000218752, acc 1\n",
      "2018-04-13T15:55:14.318900: step 10237, loss 0.000146918, acc 1\n",
      "2018-04-13T15:55:14.628618: step 10238, loss 0.0367002, acc 0.984375\n",
      "2018-04-13T15:55:14.925829: step 10239, loss 1.30579e-05, acc 1\n",
      "2018-04-13T15:55:15.222538: step 10240, loss 1.59799e-05, acc 1\n",
      "2018-04-13T15:55:15.502735: step 10241, loss 0.00214886, acc 1\n",
      "2018-04-13T15:55:15.803447: step 10242, loss 4.54483e-07, acc 1\n",
      "2018-04-13T15:55:16.086147: step 10243, loss 0.000486286, acc 1\n",
      "2018-04-13T15:55:16.404872: step 10244, loss 2.65174e-05, acc 1\n",
      "2018-04-13T15:55:16.689073: step 10245, loss 0.0154849, acc 0.984375\n",
      "2018-04-13T15:55:16.975775: step 10246, loss 0.00158207, acc 1\n",
      "2018-04-13T15:55:17.248967: step 10247, loss 3.35838e-05, acc 1\n",
      "2018-04-13T15:55:17.536672: step 10248, loss 0.00164168, acc 1\n",
      "2018-04-13T15:55:17.830879: step 10249, loss 2.39129e-05, acc 1\n",
      "2018-04-13T15:55:18.124587: step 10250, loss 0.000412938, acc 1\n",
      "2018-04-13T15:55:18.412789: step 10251, loss 0.0003236, acc 1\n",
      "2018-04-13T15:55:18.697991: step 10252, loss 0.000319128, acc 1\n",
      "2018-04-13T15:55:18.978189: step 10253, loss 0.000217956, acc 1\n",
      "2018-04-13T15:55:19.282904: step 10254, loss 0.00128131, acc 1\n",
      "2018-04-13T15:55:19.589124: step 10255, loss 0.00266989, acc 1\n",
      "2018-04-13T15:55:19.881328: step 10256, loss 0.000281451, acc 1\n",
      "2018-04-13T15:55:20.170532: step 10257, loss 0.000146954, acc 1\n",
      "2018-04-13T15:55:20.460737: step 10258, loss 0.000457263, acc 1\n",
      "2018-04-13T15:55:20.757446: step 10259, loss 0.0295718, acc 0.984375\n",
      "2018-04-13T15:55:21.044648: step 10260, loss 0.000275284, acc 1\n",
      "2018-04-13T15:55:21.324846: step 10261, loss 0.000499405, acc 1\n",
      "2018-04-13T15:55:21.612049: step 10262, loss 6.20781e-05, acc 1\n",
      "2018-04-13T15:55:21.905757: step 10263, loss 6.00269e-05, acc 1\n",
      "2018-04-13T15:55:22.201465: step 10264, loss 7.46703e-05, acc 1\n",
      "2018-04-13T15:55:22.506181: step 10265, loss 3.91858e-06, acc 1\n",
      "2018-04-13T15:55:22.804891: step 10266, loss 0.000217951, acc 1\n",
      "2018-04-13T15:55:23.084590: step 10267, loss 0.0020378, acc 1\n",
      "2018-04-13T15:55:23.371791: step 10268, loss 8.85436e-05, acc 1\n",
      "2018-04-13T15:55:23.654492: step 10269, loss 9.06116e-05, acc 1\n",
      "2018-04-13T15:55:23.951201: step 10270, loss 2.00789e-06, acc 1\n",
      "2018-04-13T15:55:24.228396: step 10271, loss 0.000793387, acc 1\n",
      "2018-04-13T15:55:24.508594: step 10272, loss 0.000211707, acc 1\n",
      "2018-04-13T15:55:24.803803: step 10273, loss 2.54754e-05, acc 1\n",
      "2018-04-13T15:55:25.083501: step 10274, loss 0.00084049, acc 1\n",
      "2018-04-13T15:55:25.385713: step 10275, loss 4.50845e-05, acc 1\n",
      "2018-04-13T15:55:25.681923: step 10276, loss 2.65752e-05, acc 1\n",
      "2018-04-13T15:55:25.995644: step 10277, loss 3.35671e-05, acc 1\n",
      "2018-04-13T15:55:26.282856: step 10278, loss 4.10813e-05, acc 1\n",
      "2018-04-13T15:55:26.572060: step 10279, loss 0.0002851, acc 1\n",
      "2018-04-13T15:55:26.877276: step 10280, loss 0.000165386, acc 1\n",
      "2018-04-13T15:55:27.198503: step 10281, loss 2.67962e-05, acc 1\n",
      "2018-04-13T15:55:27.484204: step 10282, loss 2.67649e-06, acc 1\n",
      "2018-04-13T15:55:27.781414: step 10283, loss 0.000330387, acc 1\n",
      "2018-04-13T15:55:28.055107: step 10284, loss 3.10288e-05, acc 1\n",
      "2018-04-13T15:55:28.350816: step 10285, loss 0.000849568, acc 1\n",
      "2018-04-13T15:55:28.641022: step 10286, loss 2.85349e-06, acc 1\n",
      "2018-04-13T15:55:28.922720: step 10287, loss 3.42543e-05, acc 1\n",
      "2018-04-13T15:55:29.199916: step 10288, loss 0.00150358, acc 1\n",
      "2018-04-13T15:55:29.481114: step 10289, loss 6.02199e-05, acc 1\n",
      "2018-04-13T15:55:29.775822: step 10290, loss 3.38375e-05, acc 1\n",
      "2018-04-13T15:55:30.063526: step 10291, loss 0.0496055, acc 0.984375\n",
      "2018-04-13T15:55:30.342724: step 10292, loss 3.45697e-06, acc 1\n",
      "2018-04-13T15:55:30.621920: step 10293, loss 3.93904e-05, acc 1\n",
      "2018-04-13T15:55:30.909631: step 10294, loss 9.32338e-05, acc 1\n",
      "2018-04-13T15:55:31.197827: step 10295, loss 8.83934e-06, acc 1\n",
      "2018-04-13T15:55:31.488532: step 10296, loss 4.60986e-05, acc 1\n",
      "2018-04-13T15:55:31.776736: step 10297, loss 1.30756e-06, acc 1\n",
      "2018-04-13T15:55:32.049928: step 10298, loss 0.000748566, acc 1\n",
      "2018-04-13T15:55:32.334129: step 10299, loss 2.76758e-05, acc 1\n",
      "2018-04-13T15:55:32.610324: step 10300, loss 8.22966e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:55:33.564498: step 10300, loss 3.03555, acc 0.743902\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-10300\n",
      "\n",
      "2018-04-13T15:55:35.044955: step 10301, loss 0.00428298, acc 1\n",
      "2018-04-13T15:55:35.316647: step 10302, loss 0.000113958, acc 1\n",
      "2018-04-13T15:55:35.603349: step 10303, loss 0.0026472, acc 1\n",
      "2018-04-13T15:55:35.892553: step 10304, loss 8.70565e-05, acc 1\n",
      "2018-04-13T15:55:36.177255: step 10305, loss 0.0445413, acc 0.984375\n",
      "2018-04-13T15:55:36.465958: step 10306, loss 1.32168e-05, acc 1\n",
      "2018-04-13T15:55:36.751159: step 10307, loss 2.41755e-05, acc 1\n",
      "2018-04-13T15:55:37.034360: step 10308, loss 0.000159133, acc 1\n",
      "2018-04-13T15:55:37.333070: step 10309, loss 0.00673602, acc 1\n",
      "2018-04-13T15:55:37.616272: step 10310, loss 3.48036e-05, acc 1\n",
      "2018-04-13T15:55:37.895468: step 10311, loss 0.0247406, acc 0.984375\n",
      "2018-04-13T15:55:38.188675: step 10312, loss 0.0145332, acc 0.984375\n",
      "2018-04-13T15:55:38.466871: step 10313, loss 0.0145625, acc 0.984375\n",
      "2018-04-13T15:55:38.764081: step 10314, loss 0.0475971, acc 0.984375\n",
      "2018-04-13T15:55:39.064294: step 10315, loss 3.26467e-05, acc 1\n",
      "2018-04-13T15:55:39.337986: step 10316, loss 0.000558987, acc 1\n",
      "2018-04-13T15:55:39.613181: step 10317, loss 9.49484e-05, acc 1\n",
      "2018-04-13T15:55:39.905887: step 10318, loss 2.27044e-06, acc 1\n",
      "2018-04-13T15:55:40.197094: step 10319, loss 0.0199237, acc 0.984375\n",
      "2018-04-13T15:55:40.479292: step 10320, loss 4.80561e-07, acc 1\n",
      "2018-04-13T15:55:40.767496: step 10321, loss 1.71768e-05, acc 1\n",
      "2018-04-13T15:55:41.038688: step 10322, loss 8.39556e-05, acc 1\n",
      "2018-04-13T15:55:41.305375: step 10323, loss 0.000435315, acc 1\n",
      "2018-04-13T15:55:41.591577: step 10324, loss 4.58331e-05, acc 1\n",
      "2018-04-13T15:55:41.868273: step 10325, loss 0.00202996, acc 1\n",
      "2018-04-13T15:55:42.155475: step 10326, loss 2.68042e-05, acc 1\n",
      "2018-04-13T15:55:42.458689: step 10327, loss 2.77879e-05, acc 1\n",
      "2018-04-13T15:55:42.738387: step 10328, loss 6.83558e-06, acc 1\n",
      "2018-04-13T15:55:43.022088: step 10329, loss 1.86704e-05, acc 1\n",
      "2018-04-13T15:55:43.323813: step 10330, loss 9.82691e-05, acc 1\n",
      "2018-04-13T15:55:43.599507: step 10331, loss 0.00110666, acc 1\n",
      "2018-04-13T15:55:43.881707: step 10332, loss 0.00123272, acc 1\n",
      "2018-04-13T15:55:44.172405: step 10333, loss 0.000196613, acc 1\n",
      "2018-04-13T15:55:44.456605: step 10334, loss 0.000450757, acc 1\n",
      "2018-04-13T15:55:44.741808: step 10335, loss 3.96941e-05, acc 1\n",
      "2018-04-13T15:55:45.029509: step 10336, loss 1.42739e-05, acc 1\n",
      "2018-04-13T15:55:45.304704: step 10337, loss 3.50162e-06, acc 1\n",
      "2018-04-13T15:55:45.585402: step 10338, loss 0.00103837, acc 1\n",
      "2018-04-13T15:55:45.863598: step 10339, loss 0.00167493, acc 1\n",
      "2018-04-13T15:55:46.152802: step 10340, loss 0.000963572, acc 1\n",
      "2018-04-13T15:55:46.445510: step 10341, loss 4.25186e-05, acc 1\n",
      "2018-04-13T15:55:46.732212: step 10342, loss 0.00913814, acc 1\n",
      "2018-04-13T15:55:47.011910: step 10343, loss 2.26489e-05, acc 1\n",
      "2018-04-13T15:55:47.291106: step 10344, loss 0.00341866, acc 1\n",
      "2018-04-13T15:55:47.565800: step 10345, loss 0.000193057, acc 1\n",
      "2018-04-13T15:55:47.855505: step 10346, loss 2.01038e-05, acc 1\n",
      "2018-04-13T15:55:48.140706: step 10347, loss 0.000210896, acc 1\n",
      "2018-04-13T15:55:48.427909: step 10348, loss 0.00830679, acc 1\n",
      "2018-04-13T15:55:48.728122: step 10349, loss 0.000444358, acc 1\n",
      "2018-04-13T15:55:49.006318: step 10350, loss 9.18487e-06, acc 1\n",
      "2018-04-13T15:55:49.312534: step 10351, loss 2.43772e-05, acc 1\n",
      "2018-04-13T15:55:49.604740: step 10352, loss 0.000143426, acc 1\n",
      "2018-04-13T15:55:49.886939: step 10353, loss 2.58957e-05, acc 1\n",
      "2018-04-13T15:55:50.171140: step 10354, loss 0.00518063, acc 1\n",
      "2018-04-13T15:55:50.451338: step 10355, loss 0.000299472, acc 1\n",
      "2018-04-13T15:55:50.730535: step 10356, loss 0.000284191, acc 1\n",
      "2018-04-13T15:55:51.015236: step 10357, loss 0.000247088, acc 1\n",
      "2018-04-13T15:55:51.306839: step 10358, loss 0.000169531, acc 1\n",
      "2018-04-13T15:55:51.595542: step 10359, loss 3.03043e-05, acc 1\n",
      "2018-04-13T15:55:51.875239: step 10360, loss 0.000240197, acc 1\n",
      "2018-04-13T15:55:52.172950: step 10361, loss 3.31499e-05, acc 1\n",
      "2018-04-13T15:55:52.463655: step 10362, loss 8.33505e-05, acc 1\n",
      "2018-04-13T15:55:52.744853: step 10363, loss 0.00588031, acc 1\n",
      "2018-04-13T15:55:53.030555: step 10364, loss 0.000305369, acc 1\n",
      "2018-04-13T15:55:53.310764: step 10365, loss 0.000369895, acc 1\n",
      "2018-04-13T15:55:53.583957: step 10366, loss 1.96132e-06, acc 1\n",
      "2018-04-13T15:55:53.870660: step 10367, loss 9.04268e-05, acc 1\n",
      "2018-04-13T15:55:54.151358: step 10368, loss 4.3916e-06, acc 1\n",
      "2018-04-13T15:55:54.426553: step 10369, loss 0.00161735, acc 1\n",
      "2018-04-13T15:55:54.709251: step 10370, loss 2.8255e-06, acc 1\n",
      "2018-04-13T15:55:54.989450: step 10371, loss 6.75705e-05, acc 1\n",
      "2018-04-13T15:55:55.286211: step 10372, loss 0.000513102, acc 1\n",
      "2018-04-13T15:55:55.569411: step 10373, loss 7.90222e-06, acc 1\n",
      "2018-04-13T15:55:55.848608: step 10374, loss 0.000319659, acc 1\n",
      "2018-04-13T15:55:56.145317: step 10375, loss 0.000186741, acc 1\n",
      "2018-04-13T15:55:56.420511: step 10376, loss 8.21021e-05, acc 1\n",
      "2018-04-13T15:55:56.703711: step 10377, loss 0.0071773, acc 1\n",
      "2018-04-13T15:55:56.988914: step 10378, loss 3.5427e-05, acc 1\n",
      "2018-04-13T15:55:57.283127: step 10379, loss 0.000189458, acc 1\n",
      "2018-04-13T15:55:57.558821: step 10380, loss 1.05317e-05, acc 1\n",
      "2018-04-13T15:55:57.835517: step 10381, loss 2.55549e-06, acc 1\n",
      "2018-04-13T15:55:58.108710: step 10382, loss 0.00012806, acc 1\n",
      "2018-04-13T15:55:58.432939: step 10383, loss 0.00358802, acc 1\n",
      "2018-04-13T15:55:58.718640: step 10384, loss 1.5143e-06, acc 1\n",
      "2018-04-13T15:55:58.999339: step 10385, loss 0.000704744, acc 1\n",
      "2018-04-13T15:55:59.286041: step 10386, loss 0.000139591, acc 1\n",
      "2018-04-13T15:55:59.562236: step 10387, loss 0.00735068, acc 1\n",
      "2018-04-13T15:55:59.842934: step 10388, loss 3.21477e-05, acc 1\n",
      "2018-04-13T15:56:00.142145: step 10389, loss 5.02412e-05, acc 1\n",
      "2018-04-13T15:56:00.418346: step 10390, loss 0.000155337, acc 1\n",
      "2018-04-13T15:56:00.697044: step 10391, loss 0.000684396, acc 1\n",
      "2018-04-13T15:56:00.986748: step 10392, loss 0.000337878, acc 1\n",
      "2018-04-13T15:56:01.307976: step 10393, loss 1.52477e-05, acc 1\n",
      "2018-04-13T15:56:01.587172: step 10394, loss 2.17644e-05, acc 1\n",
      "2018-04-13T15:56:01.878878: step 10395, loss 0.0434884, acc 0.984375\n",
      "2018-04-13T15:56:02.158077: step 10396, loss 0.000117311, acc 1\n",
      "2018-04-13T15:56:02.434270: step 10397, loss 0.000477821, acc 1\n",
      "2018-04-13T15:56:02.717970: step 10398, loss 0.000108156, acc 1\n",
      "2018-04-13T15:56:03.005174: step 10399, loss 0.00258996, acc 1\n",
      "2018-04-13T15:56:03.286872: step 10400, loss 4.3683e-05, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2018-04-13T15:56:04.231039: step 10400, loss 3.20133, acc 0.736398\n",
      "\n",
      "Saved model checkpoint to D:\\INFO\\cnn-text-classification-tf-master\\runs\\1523602483\\checkpoints\\model-10400\n",
      "\n",
      "2018-04-13T15:56:05.880998: step 10401, loss 0.00106134, acc 1\n",
      "2018-04-13T15:56:06.167221: step 10402, loss 0.0013502, acc 1\n",
      "2018-04-13T15:56:06.459427: step 10403, loss 6.45238e-05, acc 1\n",
      "2018-04-13T15:56:06.846200: step 10404, loss 0.00390826, acc 1\n",
      "2018-04-13T15:56:07.177934: step 10405, loss 0.000345073, acc 1\n",
      "2018-04-13T15:56:07.503664: step 10406, loss 5.38135e-05, acc 1\n",
      "2018-04-13T15:56:07.820387: step 10407, loss 9.52781e-05, acc 1\n",
      "2018-04-13T15:56:08.098083: step 10408, loss 5.22777e-05, acc 1\n",
      "2018-04-13T15:56:08.384786: step 10409, loss 6.23255e-05, acc 1\n",
      "2018-04-13T15:56:08.682496: step 10410, loss 4.05523e-05, acc 1\n",
      "2018-04-13T15:56:08.975703: step 10411, loss 0.000980445, acc 1\n",
      "2018-04-13T15:56:09.270411: step 10412, loss 2.67077e-05, acc 1\n",
      "2018-04-13T15:56:09.562118: step 10413, loss 3.63549e-05, acc 1\n",
      "2018-04-13T15:56:09.851822: step 10414, loss 0.000144178, acc 1\n",
      "2018-04-13T15:56:10.154035: step 10415, loss 0.00226559, acc 1\n",
      "2018-04-13T15:56:10.480265: step 10416, loss 0.000229848, acc 1\n",
      "2018-04-13T15:56:10.767468: step 10417, loss 6.82454e-05, acc 1\n",
      "2018-04-13T15:56:11.044163: step 10418, loss 2.85566e-05, acc 1\n",
      "2018-04-13T15:56:11.327364: step 10419, loss 1.00021e-05, acc 1\n",
      "2018-04-13T15:56:11.612077: step 10420, loss 5.00386e-05, acc 1\n",
      "2018-04-13T15:56:11.894283: step 10421, loss 0.0169147, acc 0.984375\n",
      "2018-04-13T15:56:12.192493: step 10422, loss 0.00475678, acc 1\n",
      "2018-04-13T15:56:12.481198: step 10423, loss 4.70351e-05, acc 1\n",
      "2018-04-13T15:56:12.772903: step 10424, loss 0.000104882, acc 1\n",
      "2018-04-13T15:56:13.049599: step 10425, loss 0.0103717, acc 1\n",
      "2018-04-13T15:56:13.438374: step 10426, loss 0.0015857, acc 1\n",
      "2018-04-13T15:56:13.756598: step 10427, loss 1.20046e-05, acc 1\n",
      "2018-04-13T15:56:14.028789: step 10428, loss 9.64482e-05, acc 1\n",
      "2018-04-13T15:56:14.311990: step 10429, loss 1.85018e-05, acc 1\n",
      "2018-04-13T15:56:14.597692: step 10430, loss 7.33243e-05, acc 1\n",
      "2018-04-13T15:56:14.896903: step 10431, loss 0.000962459, acc 1\n"
     ]
    }
   ],
   "source": [
    "%run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
